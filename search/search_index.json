{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Draft \u00b6 Draft \u00b6 Draft \u00b6 Draft Draft Draft Draft, Draft , Draft , Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft","title":"Home"},{"location":"#draft","text":"","title":"Draft"},{"location":"#draft_1","text":"","title":"Draft"},{"location":"#draft_2","text":"","title":"Draft"},{"location":"Catalogize/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Intake data-sets from scratch \u00b6 % load_ext lab_black import intake import dask import pandas as pd Open the data sources \u00b6 intake.open_csv reads CSV files into dataframes Parameters are: urlpath : str or iterable, location of data csv_kwargs : dict storage_options : dict path_as_pattern : bool or str, optional csv_kwargs are specific to the plugin. dask.dataframe.read_csv?Signature: dask.dataframe.read_csv( urlpath, blocksize='default', lineterminator=None, compression=None, sample=256000, enforce=False, assume_missing=False, storage_options=None, include_path_column=False, **kwargs, ) src = intake . open_csv ( urlpath = \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" , csv_kwargs = { \"sep\" : \",\" , \"blocksize\" : None , \"encoding\" : \"iso-8859-1\" , \"dtype\" : { \"departement\" : str , \"jour\" : pd . StringDtype , \"pop\" : pd . StringDtype , \"P\" : pd . StringDtype , \"cl_age90\" : pd . StringDtype , }, }, ) Feed a Catalog \u00b6 A Catalog instance is an object with one or more named entries.The entries might be read: - from a static file (e.g., YAML), - from an Intake server - from any other data service that has a driver. Those are ordinary DataSource classes, except that they have the container type \u201ccatalog\u201d, and do not return data products via the read() method. cat = intake . open_catalog ( name = \"mon catalogue\" ) cat mon catalogue: args: args: null name: mon catalogue description: '' driver: intake.catalog.base.Catalog metadata: {} intake.EntrypointsCatalog? intake.Schema holds details of data description for any type of data-source Subclasses: SQLCatalog from intake.catalog import Catalog from intake.catalog.local import LocalCatalogEntry mycat = Catalog . from_dict ( { \"source1\" : LocalCatalogEntry ( \"taux\" , description = \"Taux de positivit\u00e9 - quotidien - d\u00e9partement\" , driver = \"csv\" , args = { \"urlpath\" : \"https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675\" , \"csv_kwargs\" : { \"sep\" : \";\" , \"blocksize\" : None , \"encoding\" : \"iso-8859-1\" , \"dtype\" : { \"dep\" : str , }, }, }, ) } ) print ( mycat [ \"source1\" ] . yaml ()) sources: taux: args: csv_kwargs: blocksize: null dtype: dep: !!python/name:builtins.str '' encoding: iso-8859-1 sep: ; urlpath: https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675 description: \"Taux de positivit\\xE9 - quotidien - d\\xE9partement\" driver: intake.source.csv.CSVSource metadata: catalog_dir: '' mycat . source1 . read () . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour P T cl_age90 0 01 2020-05-13 0 16 9 1 01 2020-05-13 1 17 19 2 01 2020-05-13 0 33 29 3 01 2020-05-13 1 72 39 4 01 2020-05-13 0 54 49 acat = intake . open_catalog ( name = \" catalogue\" ) print ( src . yaml ()) sources: csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} from intake.catalog import Catalog from intake.catalog.local import LocalCatalogEntry mycat = Catalog . from_dict ( { \"cato\" : src }, description = \"Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19\" , ) mycat null: args: description: \"Donn\\xE9es relatives aux r\\xE9sultats des tests virologiques COVID-19\" description: \"Donn\\xE9es relatives aux r\\xE9sultats des tests virologiques COVID-19\" driver: intake.catalog.base.Catalog metadata: {} type ( mycat ) intake.catalog.base.Catalog mycat . cato csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} type ( src ) intake.source.csv.CSVSource mycat [ \"cato\" ] . description = \"blabla\" mycat . save ( \"aze.yaml\" ) % cat aze . yaml metadata: {} name: null sources: cato: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' parameters: {} urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e src . description src . get () csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} src . discover () {'datashape': None, 'dtype': {'extract_date': 'object', 'departement': 'object', 'region': 'int64', 'libelle_reg': 'object', 'libelle_dep': 'object', 'tx_incid': 'float64', 'R': 'float64', 'taux_occupation_sae': 'float64', 'tx_pos': 'float64', 'tx_incid_couleur': 'object', 'R_couleur': 'object', 'taux_occupation_sae_couleur': 'object', 'tx_pos_couleur': 'object', 'nb_orange': 'int64', 'nb_rouge': 'int64'}, 'shape': (None, 15), 'npartitions': 1, 'metadata': {}} src . catalog_object src . description = \"AZE\" from pathlib import Path Path ( \"./one.yml\" ) . write_text ( src . yaml ()) 498 print ( src . yaml ()) sources: csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} src . shape (None, 15) df = src . read () print ( src . yaml ()) src . urls = dict ( indicateurs = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/indicateurs-de-suivi-de-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ee9df5003284f565d561278/\" , titre = \"Indicateurs de suivi de l'\u00e9pid\u00e9mie de COVID-19\" , file_pattern = \"indicateurs-covid19-dep\" , delim = \",\" , ), tests_positivite = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed117db6c161bd5baf070be\" , titre = \"Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19 SI-DEP\" , file_pattern = \"sp-pos-quot-dep\" , delim = \";\" , ), tests_capacites = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/capacite-analytique-de-tests-virologiques-dans-le-cadre-de-lepidemie-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/0c230dc3-2d51-4f17-be97-aa9938564b39\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed11705afd28672e40fbc2f/\" , titre = \"Capacit\u00e9 analytique de tests virologiques dans le cadre de l'\u00e9pid\u00e9mie COVID-19 SI-DEP\" , file_pattern = \"sp-capa-quot-dep\" , delim = \";\" , ), incidence = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed1175ca00bbe1e4941a46a\" , titre = \"Taux d'incidence de l'\u00e9pid\u00e9mie de COVID-19 SI-DEP\" , file_pattern = \"sp-pe-tb-quot-dep\" , delim = \";\" , ), sursaud = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/donnees-des-urgences-hospitalieres-et-de-sos-medecins-relatives-a-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/eceb9fb4-3ebc-4da3-828d-f5939712600a\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5e74ecf52eb7514f2d3b8845\" , titre = \"Donn\u00e9es des urgences hospitali\u00e8res et de SOS m\u00e9decins relatives \u00e0 l'\u00e9pid\u00e9mie de COVID-19\" , file_pattern = \"sursaud-corona-quot-dep\" , delim = \";\" , ), ) import requests req = requests . get ( urls [ \"tests_positivite\" ][ \"url_api\" ]) resp = req . json () resources = [ r for r in resp [ \"resources\" ] if \"wordprocessingml\" not in r [ \"mime\" ]] import re resources [ 0 ][ \"title\" ] . rstrip ( r \"\\w*\" ) 'sp-pos-quot-dep-2020-09-25-19h15.csv' out = [ { \"args\" : { \"csv_kwargs\" : { \"blocksize\" : \"null\" , \"encoding\" : \"iso-8850-1\" , \"sep\" : \",\" } }, \"description\" : resource . get ( \"description\" , None ), \"metadata\" : { \"title\" : resp . get ( \"title\" , None ), \"uri\" : resp . get ( \"uri\" , None )}, } for resource in resources ] load ( out ) <ipython-input-93-f0a5f1c8081f>:12: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. load(out) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-93-f0a5f1c8081f> in <module> 10 ] 11 ---> 12 load ( out ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/__init__.py in load (stream, Loader) 110 Loader = FullLoader 111 --> 112 loader = Loader ( stream ) 113 try : 114 return loader . get_single_data ( ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/loader.py in __init__ (self, stream) 22 23 def __init__ ( self , stream ) : ---> 24 Reader . __init__ ( self , stream ) 25 Scanner . __init__ ( self ) 26 Parser . __init__ ( self ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in __init__ (self, stream) 83 self . eof = False 84 self . raw_buffer = None ---> 85 self . determine_encoding ( ) 86 87 def peek ( self , index = 0 ) : /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in determine_encoding (self) 122 def determine_encoding ( self ) : 123 while not self . eof and ( self . raw_buffer is None or len ( self . raw_buffer ) < 2 ) : --> 124 self . update_raw ( ) 125 if isinstance ( self . raw_buffer , bytes ) : 126 if self . raw_buffer . startswith ( codecs . BOM_UTF16_LE ) : /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in update_raw (self, size) 176 177 def update_raw ( self , size = 4096 ) : --> 178 data = self . stream . read ( size ) 179 if self . raw_buffer is None : 180 self . raw_buffer = data AttributeError : 'list' object has no attribute 'read' out [{'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - r\u00e9gion.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - france.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - departement.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - r\u00e9gion .', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - France.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - Quotidien.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Description des m\u00e9tadonn\u00e9es.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}] for k in resp : print ( \"*\" * 80 ) print ( k ) print ( \"-\" * 80 ) print ( resp . get ( k )) ******************************************************************************** acronym -------------------------------------------------------------------------------- SI-DEP ******************************************************************************** archived -------------------------------------------------------------------------------- None ******************************************************************************** badges -------------------------------------------------------------------------------- [] ******************************************************************************** created_at -------------------------------------------------------------------------------- 2020-05-29T16:10:35.407000 ******************************************************************************** deleted -------------------------------------------------------------------------------- None ******************************************************************************** description -------------------------------------------------------------------------------- ### Les actions de Sant\u00e9 publique France Sant\u00e9 publique France a pour mission d'am\u00e9liorer et de prot\u00e9ger la sant\u00e9 des populations. Durant la crise sanitaire li\u00e9e \u00e0 l'\u00e9pid\u00e9mie du COVID-19, Sant\u00e9 publique France se charge de surveiller et comprendre la dynamique de l'\u00e9pid\u00e9mie, d'anticiper les diff\u00e9rents sc\u00e9narii et de mettre en place des actions pour pr\u00e9venir et limiter la transmission de ce virus sur le territoire national. ### Le Syst\u00e8me d\u2019Informations de DEPistage (SI-DEP) Le nouveau syst\u00e8me d\u2019information de d\u00e9pistage (SI-DEP), en d\u00e9ploiement depuis le 13 mai 2020, est une plateforme s\u00e9curis\u00e9e o\u00f9 sont syst\u00e9matiquement enregistr\u00e9s les r\u00e9sultats des laboratoires des tests (RT-PCR) r\u00e9alis\u00e9s par l\u2019ensemble des laboratoires de ville et \u00e9tablissements hospitaliers concernant le SARS-COV2. La cr\u00e9ation de ce syst\u00e8me d'information est autoris\u00e9e pour une dur\u00e9e de 6 mois \u00e0 compter de la fin de l'\u00e9tat d'urgence sanitaire par application du [d\u00e9cret n\u00b0 2020-551 du 12 mai 2020](https://www.legifrance.gouv.fr/affichTexte.do?cidTexte=JORFTEXT000041869923) relatif aux syst\u00e8mes d\u2019information mentionn\u00e9s \u00e0 l\u2019article 11 de la loi n\u00b0 2020-546 du 11 mai 2020 prorogeant l\u2019\u00e9tat d\u2019urgence sanitaire et compl\u00e9tant ses dispositions. ### Description des donn\u00e9es Le pr\u00e9sent jeu de donn\u00e9es renseigne \u00e0 l'\u00e9chelle d\u00e9partementale et r\u00e9gionale : - le nombre de personnes test\u00e9es et le nombre de personnes d\u00e9clar\u00e9es positives par classe d'\u00e2ge (quotidien et hebdomadaire) ; - le nombre de personnes positives sur 7 jours glissants. Le pr\u00e9sent jeu de donn\u00e9es renseigne \u00e0 l'\u00e9chelle nationale : - le nombre de personnes test\u00e9es et le nombre de personnes d\u00e9clar\u00e9es positives par sexe et classe d'\u00e2ge (quotidien et hebdomadaire). Le taux de positivit\u00e9 correspond au nombre de tests positifs rapport\u00e9s au nombre de tests r\u00e9alis\u00e9s. Il est calcul\u00e9 de la mani\u00e8re suivante : 100*nombre de test positif/ nombre de tests r\u00e9alis\u00e9s **Pr\u00e9cisions** : Si plusieurs pr\u00e9l\u00e8vements sont rapport\u00e9s pour un m\u00eame patient: - S\u00e9lection de la premi\u00e8re date pour les pcr ayant le m\u00eame r\u00e9sultat (par exemple premi\u00e8re date si plusieurs pcr n\u00e9gatives) - Si pcr discordantes chez un m\u00eame patient (N et P), la premi\u00e8re pcr positive est conserv\u00e9e. Exclusion des r\u00e9sultats ininterpr\u00e9tables - A compter du 29/08, les indicateurs issus des donn\u00e9es de laboratoires (SI-DEP) pr\u00e9sentent des taux d\u2019incidence, de positivit\u00e9 et de d\u00e9pistage corrig\u00e9s en fonction des d\u00e9pistages r\u00e9alis\u00e9s dans les a\u00e9roports \u00e0 l\u2019arriv\u00e9e des vols internationaux. La correction s\u2019applique sur l\u2019ensemble des donn\u00e9es post\u00e9rieures \u00e0 la date du 12 ao\u00fbt. **Limites** : - Seuls les tests biologiques des personnes pour lesquelles le d\u00e9partement de r\u00e9sidence a pu \u00eatre localis\u00e9 sont repr\u00e9sent\u00e9s sur les cartes. Les personnes dont le d\u00e9partement n\u2019a pas pu \u00eatre remont\u00e9 dans les donn\u00e9es SIDEP ne sont comptabilis\u00e9es qu'au niveau France enti\u00e8re. De ce fait la somme des tests indiqu\u00e9s dans les d\u00e9partements ou r\u00e9gions est inf\u00e9rieure au nombre de tests indiqu\u00e9 en France. - Le d\u00e9lai de remont\u00e9e des tests peut exc\u00e9der 9 jours dans certains cas. Les indicateurs sont ajust\u00e9s quotidiennement selon la r\u00e9ception des r\u00e9sultats. Pour en savoir plus consultez la note m\u00e9thodologique disponible dans les ressources. ******************************************************************************** extras -------------------------------------------------------------------------------- {'recommendations': [{'id': '5e7de8cf4663c08d4f74ba01', 'score': 89, 'source': 'matomo'}], 'recommendations:sources': ['matomo']} ******************************************************************************** frequency -------------------------------------------------------------------------------- unknown ******************************************************************************** frequency_date -------------------------------------------------------------------------------- None ******************************************************************************** id -------------------------------------------------------------------------------- 5ed117db6c161bd5baf070be ******************************************************************************** last_modified -------------------------------------------------------------------------------- 2020-09-25T19:15:13.847000 ******************************************************************************** last_update -------------------------------------------------------------------------------- 2020-08-27T00:00:00 ******************************************************************************** license -------------------------------------------------------------------------------- fr-lo ******************************************************************************** metrics -------------------------------------------------------------------------------- {'discussions': 21, 'followers': 5, 'issues': 0, 'reuses': 22, 'views': 6112} ******************************************************************************** organization -------------------------------------------------------------------------------- {'acronym': 'SPF', 'class': 'Organization', 'id': '5e721a395d57f93d0bed451f', 'logo': 'https://static.data.gouv.fr/avatars/79/7e94cd7a8d43d39544d4018666e646-original.png', 'logo_thumbnail': 'https://static.data.gouv.fr/avatars/79/7e94cd7a8d43d39544d4018666e646-100.png', 'name': 'Sant\u00e9 publique France', 'page': 'https://www.data.gouv.fr/fr/organizations/sante-publique-france/', 'slug': 'sante-publique-france', 'uri': 'https://www.data.gouv.fr/api/1/organizations/sante-publique-france/'} ******************************************************************************** owner -------------------------------------------------------------------------------- None ******************************************************************************** page -------------------------------------------------------------------------------- https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/ ******************************************************************************** private -------------------------------------------------------------------------------- False ******************************************************************************** resources -------------------------------------------------------------------------------- [{'checksum': {'type': 'sha1', 'value': '21b8878f9b8df70e78a5a8ca6d9d28dd4b34a07e'}, 'created_at': '2020-09-01T15:01:03.280000', 'description': 'Note m\u00e9thodologique 27/08', 'extras': {}, 'filesize': 29885, 'filetype': 'file', 'format': 'docx', 'id': 'c98482d3-fba1-4397-99ae-1c958aa629f6', 'last_modified': '2020-09-01T15:04:27.976000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c98482d3-fba1-4397-99ae-1c958aa629f6', 'metrics': {'views': 167}, 'mime': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'preview_url': None, 'published': '2020-08-27T00:00:00', 'schema': None, 'title': 'analyse-de-la-base-sidep-note-methodologique.docx', 'type': 'documentation', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200901-150103/analyse-de-la-base-sidep-note-methodologique.docx'}, {'checksum': {'type': 'sha1', 'value': 'eb395230851890fe96cbc0618000ae70e302decd'}, 'created_at': '2020-05-29T18:02:26.703000', 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'extras': {}, 'filesize': 3361733, 'filetype': 'file', 'format': 'csv', 'id': '406c6a23-e283-4300-9484-54e78c8ae675', 'last_modified': '2020-09-25T19:15:06.758000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675', 'metrics': {'views': 8155}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:26', 'schema': None, 'title': 'sp-pos-quot-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': 'af41c6bc3aff81d2e3ab27e1fd4e85edd12efc77'}, 'created_at': '2020-05-29T18:03:11.045000', 'description': 'Taux de positivit\u00e9 - quotidien - r\u00e9gion.', 'extras': {}, 'filesize': 1026513, 'filetype': 'file', 'format': 'csv', 'id': '001aca18-df6a-45c8-89e6-f82d689e6c01', 'last_modified': '2020-09-25T19:15:13.194000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/001aca18-df6a-45c8-89e6-f82d689e6c01', 'metrics': {'views': 828}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191513%2Fsp-pos-quot-reg-2020-09-25-19h15.csv', 'published': '2020-05-29T18:03:11', 'schema': None, 'title': 'sp-pos-quot-reg-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191513/sp-pos-quot-reg-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '2879bad07eea8f4420beb68021944ab71af19b87'}, 'created_at': '2020-05-29T18:02:57.551000', 'description': 'Taux de positivit\u00e9 - quotidien - france.', 'extras': {}, 'filesize': 61466, 'filetype': 'file', 'format': 'csv', 'id': 'dd0de5d9-b5a5-4503-930a-7b08dc0adc7c', 'last_modified': '2020-09-25T19:15:13.762000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/dd0de5d9-b5a5-4503-930a-7b08dc0adc7c', 'metrics': {'views': 2639}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191513%2Fsp-pos-quot-fra-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:57', 'schema': None, 'title': 'sp-pos-quot-fra-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191513/sp-pos-quot-fra-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '511d145379f80e1fb1e2fe0bf90cff2d493b5fc5'}, 'created_at': '2020-05-29T18:01:11.291000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - departement.', 'extras': {}, 'filesize': 438028, 'filetype': 'file', 'format': 'csv', 'id': 'dd3ac13c-e87f-4b33-8897-07baff4e1783', 'last_modified': '2020-09-25T19:15:11.314000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/dd3ac13c-e87f-4b33-8897-07baff4e1783', 'metrics': {'views': 238}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191511%2Fsp-pos-heb-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:01:11', 'schema': None, 'title': 'sp-pos-heb-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191511/sp-pos-heb-dep-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '59b6f0c920f3aa5a700d1ee1b20fef26b211596a'}, 'created_at': '2020-05-29T18:02:10.342000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - r\u00e9gion .', 'extras': {}, 'filesize': 146314, 'filetype': 'file', 'format': 'csv', 'id': '1ff7af5f-88d6-44bd-b8b6-16308b046afc', 'last_modified': '2020-09-25T19:15:05.806000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/1ff7af5f-88d6-44bd-b8b6-16308b046afc', 'metrics': {'views': 25}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191505%2Fsp-pos-heb-reg-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:10', 'schema': None, 'title': 'sp-pos-heb-reg-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191505/sp-pos-heb-reg-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '27b6ce97a5004564ea5f876f8c8c00f83300a288'}, 'created_at': '2020-05-29T18:01:35.129000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - France.', 'extras': {}, 'filesize': 9087, 'filetype': 'file', 'format': 'csv', 'id': '2f0f720d-fbd2-41a7-95b4-3a70ff5a9253', 'last_modified': '2020-09-25T19:15:03.498000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/2f0f720d-fbd2-41a7-95b4-3a70ff5a9253', 'metrics': {'views': 293}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191503%2Fsp-pos-heb-fra-2020-09-25-19h15.csv', 'published': '2020-05-29T18:01:35', 'schema': None, 'title': 'sp-pos-heb-fra-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191503/sp-pos-heb-fra-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '41c46a8b6c450ddffea0845c85815dc42502192b'}, 'created_at': '2020-05-29T18:20:52.321000', 'description': None, 'extras': {}, 'filesize': 215055, 'filetype': 'file', 'format': 'csv', 'id': 'd1c1846c-f2d1-43cb-ad84-b46c40d1bec8', 'last_modified': '2020-07-03T19:15:20.039000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/d1c1846c-f2d1-43cb-ad84-b46c40d1bec8', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191519%2Fsp-ti-tp-7j-dep-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.321000', 'schema': None, 'title': 'sp-ti-tp-7j-dep-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191519/sp-ti-tp-7j-dep-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '215ad0960bbad3719ea13622cbca9b4f15d01332'}, 'created_at': '2020-05-29T18:20:52.324000', 'description': None, 'extras': {}, 'filesize': 52837, 'filetype': 'file', 'format': 'csv', 'id': 'df2f66d3-ef9b-48e0-abdf-f33a6a7ff2fa', 'last_modified': '2020-07-03T19:15:20.439000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/df2f66d3-ef9b-48e0-abdf-f33a6a7ff2fa', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191520%2Fsp-ti-tp-7j-reg-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.324000', 'schema': None, 'title': 'sp-ti-tp-7j-reg-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191520/sp-ti-tp-7j-reg-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '3272b07774ea14ed57c63bb7b9fd26065cf3125d'}, 'created_at': '2020-05-29T18:20:52.318000', 'description': None, 'extras': {}, 'filesize': 2880, 'filetype': 'file', 'format': 'csv', 'id': 'c1167c4e-8c89-40f2-adb3-1954f8fedfa7', 'last_modified': '2020-07-03T19:15:19.607000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c1167c4e-8c89-40f2-adb3-1954f8fedfa7', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191519%2Fsp-ti-tp-7j-fra-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.318000', 'schema': None, 'title': 'sp-ti-tp-7j-fra-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191519/sp-ti-tp-7j-fra-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': 'ce0d062e5faa1dcd83616f7bc9f74367b43fb6ff'}, 'created_at': '2020-05-29T17:19:23.764000', 'description': 'Taux de positivit\u00e9 - Quotidien.', 'extras': {}, 'filesize': 1337737, 'filetype': 'file', 'format': 'xlsx', 'id': 'c20aa429-d30b-41d1-8bea-37b106c5f33b', 'last_modified': '2020-07-03T19:15:27.711000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c20aa429-d30b-41d1-8bea-37b106c5f33b', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191527%2Fsp-pos-quot-2020-07-03-19h15.xlsx', 'published': '2020-05-29T17:19:23', 'schema': None, 'title': 'sp-pos-quot-2020-07-03-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191527/sp-pos-quot-2020-07-03-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': '62fb3c2bf176eed6254a72d4067d250bb5414490'}, 'created_at': '2020-05-29T17:17:47.913000', 'description': 'Taux de positivit\u00e9 - hebdomadaire.', 'extras': {}, 'filesize': 207005, 'filetype': 'file', 'format': 'xlsx', 'id': 'fc7f9844-05bd-41eb-9d9a-2a4b8010af1d', 'last_modified': '2020-07-01T19:15:23.424000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/fc7f9844-05bd-41eb-9d9a-2a4b8010af1d', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200701-191523%2Fsp-pos-heb-2020-07-01-19h15.xlsx', 'published': '2020-05-29T17:17:47', 'schema': None, 'title': 'sp-pos-heb-2020-07-01-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200701-191523/sp-pos-heb-2020-07-01-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': 'f526f981c17773cfc4207320275c2822ce425613'}, 'created_at': '2020-05-29T18:49:52.653000', 'description': None, 'extras': {}, 'filesize': 182582, 'filetype': 'file', 'format': 'xlsx', 'id': '708eb9ee-d8e8-4008-ac2d-0827acd95ba7', 'last_modified': '2020-07-03T19:15:20.863000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/708eb9ee-d8e8-4008-ac2d-0827acd95ba7', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191520%2Fsp-ti-tp-7j-2020-07-03-19h15.xlsx', 'published': '2020-05-29T18:49:52.653000', 'schema': None, 'title': 'sp-ti-tp-7j-2020-07-03-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191520/sp-ti-tp-7j-2020-07-03-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': '89c55f3a82bb8dcb5f1d1b1f4cb431b798a653ec'}, 'created_at': '2020-05-29T17:00:35.757000', 'description': 'Description des m\u00e9tadonn\u00e9es.', 'extras': {}, 'filesize': 10422, 'filetype': 'file', 'format': 'xlsx', 'id': '39aaad1c-9aac-4be8-96b2-6d001f892b34', 'last_modified': '2020-05-29T17:00:54.313000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/39aaad1c-9aac-4be8-96b2-6d001f892b34', 'metrics': {'views': 321}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Ftaux-de-positivite-aux-tests-virologiques-covid-19%2F20200529-170035%2Fmetadonnees-positivite.xlsx', 'published': '2020-05-29T17:00:35', 'schema': None, 'title': 'metadonnees-positivite.xlsx', 'type': 'documentation', 'url': 'https://static.data.gouv.fr/resources/taux-de-positivite-aux-tests-virologiques-covid-19/20200529-170035/metadonnees-positivite.xlsx'}] ******************************************************************************** slug -------------------------------------------------------------------------------- donnees-relatives-aux-resultats-des-tests-virologiques-covid-19 ******************************************************************************** spatial -------------------------------------------------------------------------------- None ******************************************************************************** tags -------------------------------------------------------------------------------- [] ******************************************************************************** temporal_coverage -------------------------------------------------------------------------------- None ******************************************************************************** title -------------------------------------------------------------------------------- Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19 ******************************************************************************** uri -------------------------------------------------------------------------------- https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/ resources = [ r for r in resp [ \"resources\" ] if \"wordprocessingml\" not in r [ \"mime\" ]] from yaml import load , dump resources [ 0 ] {'checksum': {'type': 'sha1', 'value': 'eb395230851890fe96cbc0618000ae70e302decd'}, 'created_at': '2020-05-29T18:02:26.703000', 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'extras': {}, 'filesize': 3361733, 'filetype': 'file', 'format': 'csv', 'id': '406c6a23-e283-4300-9484-54e78c8ae675', 'last_modified': '2020-09-25T19:15:06.758000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675', 'metrics': {'views': 8155}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:26', 'schema': None, 'title': 'sp-pos-quot-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv'} print ( dump ( resources [ 0 ])) checksum: type: sha1 value: eb395230851890fe96cbc0618000ae70e302decd created_at: '2020-05-29T18:02:26.703000' description: \"Taux de positivit\\xE9 - quotidien - d\\xE9partement .\" extras: {} filesize: 3361733 filetype: file format: csv id: 406c6a23-e283-4300-9484-54e78c8ae675 last_modified: '2020-09-25T19:15:06.758000' latest: https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675 metrics: views: 8155 mime: text/csv preview_url: /tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv published: '2020-05-29T18:02:26' schema: null title: sp-pos-quot-dep-2020-09-25-19h15.csv type: main url: https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv 'description' , 'latest' , 'title' for k in resources : print ( k [ \"title\" ]) sp-pos-quot-dep-2020-09-25-19h15.csv sp-pos-quot-reg-2020-09-25-19h15.csv sp-pos-quot-fra-2020-09-25-19h15.csv sp-pos-heb-dep-2020-09-25-19h15.csv sp-pos-heb-reg-2020-09-25-19h15.csv sp-pos-heb-fra-2020-09-25-19h15.csv sp-ti-tp-7j-dep-2020-07-03-19h15.csv sp-ti-tp-7j-reg-2020-07-03-19h15.csv sp-ti-tp-7j-fra-2020-07-03-19h15.csv sp-pos-quot-2020-07-03-19h15.xlsx sp-pos-heb-2020-07-01-19h15.xlsx sp-ti-tp-7j-2020-07-03-19h15.xlsx metadonnees-positivite.xlsx for k in resources [ - 1 ]: print ( \"*\" * 80 ) print ( k ) print ( \"-\" * 80 ) print ( resources [ - 1 ] . get ( k )) src [ \"indicateurs\" ] {'url_web': 'https://www.data.gouv.fr/fr/datasets/indicateurs-de-suivi-de-lepidemie-de-covid-19/', 'url_stable': 'https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e', 'url_api': 'https://www.data.gouv.fr/api/1/datasets/5ee9df5003284f565d561278/', 'titre': \"Indicateurs de suivi de l'\u00e9pid\u00e9mie de COVID-19\", 'file_pattern': 'indicateurs-covid19-dep', 'delim': ','}","title":"Catalogize"},{"location":"Catalogize/#intake-data-sets-from-scratch","text":"% load_ext lab_black import intake import dask import pandas as pd","title":"Intake data-sets from scratch"},{"location":"Catalogize/#open-the-data-sources","text":"intake.open_csv reads CSV files into dataframes Parameters are: urlpath : str or iterable, location of data csv_kwargs : dict storage_options : dict path_as_pattern : bool or str, optional csv_kwargs are specific to the plugin. dask.dataframe.read_csv?Signature: dask.dataframe.read_csv( urlpath, blocksize='default', lineterminator=None, compression=None, sample=256000, enforce=False, assume_missing=False, storage_options=None, include_path_column=False, **kwargs, ) src = intake . open_csv ( urlpath = \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" , csv_kwargs = { \"sep\" : \",\" , \"blocksize\" : None , \"encoding\" : \"iso-8859-1\" , \"dtype\" : { \"departement\" : str , \"jour\" : pd . StringDtype , \"pop\" : pd . StringDtype , \"P\" : pd . StringDtype , \"cl_age90\" : pd . StringDtype , }, }, )","title":"Open the data sources"},{"location":"Catalogize/#feed-a-catalog","text":"A Catalog instance is an object with one or more named entries.The entries might be read: - from a static file (e.g., YAML), - from an Intake server - from any other data service that has a driver. Those are ordinary DataSource classes, except that they have the container type \u201ccatalog\u201d, and do not return data products via the read() method. cat = intake . open_catalog ( name = \"mon catalogue\" ) cat mon catalogue: args: args: null name: mon catalogue description: '' driver: intake.catalog.base.Catalog metadata: {} intake.EntrypointsCatalog? intake.Schema holds details of data description for any type of data-source Subclasses: SQLCatalog from intake.catalog import Catalog from intake.catalog.local import LocalCatalogEntry mycat = Catalog . from_dict ( { \"source1\" : LocalCatalogEntry ( \"taux\" , description = \"Taux de positivit\u00e9 - quotidien - d\u00e9partement\" , driver = \"csv\" , args = { \"urlpath\" : \"https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675\" , \"csv_kwargs\" : { \"sep\" : \";\" , \"blocksize\" : None , \"encoding\" : \"iso-8859-1\" , \"dtype\" : { \"dep\" : str , }, }, }, ) } ) print ( mycat [ \"source1\" ] . yaml ()) sources: taux: args: csv_kwargs: blocksize: null dtype: dep: !!python/name:builtins.str '' encoding: iso-8859-1 sep: ; urlpath: https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675 description: \"Taux de positivit\\xE9 - quotidien - d\\xE9partement\" driver: intake.source.csv.CSVSource metadata: catalog_dir: '' mycat . source1 . read () . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour P T cl_age90 0 01 2020-05-13 0 16 9 1 01 2020-05-13 1 17 19 2 01 2020-05-13 0 33 29 3 01 2020-05-13 1 72 39 4 01 2020-05-13 0 54 49 acat = intake . open_catalog ( name = \" catalogue\" ) print ( src . yaml ()) sources: csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} from intake.catalog import Catalog from intake.catalog.local import LocalCatalogEntry mycat = Catalog . from_dict ( { \"cato\" : src }, description = \"Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19\" , ) mycat null: args: description: \"Donn\\xE9es relatives aux r\\xE9sultats des tests virologiques COVID-19\" description: \"Donn\\xE9es relatives aux r\\xE9sultats des tests virologiques COVID-19\" driver: intake.catalog.base.Catalog metadata: {} type ( mycat ) intake.catalog.base.Catalog mycat . cato csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} type ( src ) intake.source.csv.CSVSource mycat [ \"cato\" ] . description = \"blabla\" mycat . save ( \"aze.yaml\" ) % cat aze . yaml metadata: {} name: null sources: cato: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' parameters: {} urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e src . description src . get () csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} src . discover () {'datashape': None, 'dtype': {'extract_date': 'object', 'departement': 'object', 'region': 'int64', 'libelle_reg': 'object', 'libelle_dep': 'object', 'tx_incid': 'float64', 'R': 'float64', 'taux_occupation_sae': 'float64', 'tx_pos': 'float64', 'tx_incid_couleur': 'object', 'R_couleur': 'object', 'taux_occupation_sae_couleur': 'object', 'tx_pos_couleur': 'object', 'nb_orange': 'int64', 'nb_rouge': 'int64'}, 'shape': (None, 15), 'npartitions': 1, 'metadata': {}} src . catalog_object src . description = \"AZE\" from pathlib import Path Path ( \"./one.yml\" ) . write_text ( src . yaml ()) 498 print ( src . yaml ()) sources: csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} src . shape (None, 15) df = src . read () print ( src . yaml ()) src . urls = dict ( indicateurs = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/indicateurs-de-suivi-de-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ee9df5003284f565d561278/\" , titre = \"Indicateurs de suivi de l'\u00e9pid\u00e9mie de COVID-19\" , file_pattern = \"indicateurs-covid19-dep\" , delim = \",\" , ), tests_positivite = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed117db6c161bd5baf070be\" , titre = \"Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19 SI-DEP\" , file_pattern = \"sp-pos-quot-dep\" , delim = \";\" , ), tests_capacites = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/capacite-analytique-de-tests-virologiques-dans-le-cadre-de-lepidemie-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/0c230dc3-2d51-4f17-be97-aa9938564b39\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed11705afd28672e40fbc2f/\" , titre = \"Capacit\u00e9 analytique de tests virologiques dans le cadre de l'\u00e9pid\u00e9mie COVID-19 SI-DEP\" , file_pattern = \"sp-capa-quot-dep\" , delim = \";\" , ), incidence = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed1175ca00bbe1e4941a46a\" , titre = \"Taux d'incidence de l'\u00e9pid\u00e9mie de COVID-19 SI-DEP\" , file_pattern = \"sp-pe-tb-quot-dep\" , delim = \";\" , ), sursaud = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/donnees-des-urgences-hospitalieres-et-de-sos-medecins-relatives-a-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/eceb9fb4-3ebc-4da3-828d-f5939712600a\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5e74ecf52eb7514f2d3b8845\" , titre = \"Donn\u00e9es des urgences hospitali\u00e8res et de SOS m\u00e9decins relatives \u00e0 l'\u00e9pid\u00e9mie de COVID-19\" , file_pattern = \"sursaud-corona-quot-dep\" , delim = \";\" , ), ) import requests req = requests . get ( urls [ \"tests_positivite\" ][ \"url_api\" ]) resp = req . json () resources = [ r for r in resp [ \"resources\" ] if \"wordprocessingml\" not in r [ \"mime\" ]] import re resources [ 0 ][ \"title\" ] . rstrip ( r \"\\w*\" ) 'sp-pos-quot-dep-2020-09-25-19h15.csv' out = [ { \"args\" : { \"csv_kwargs\" : { \"blocksize\" : \"null\" , \"encoding\" : \"iso-8850-1\" , \"sep\" : \",\" } }, \"description\" : resource . get ( \"description\" , None ), \"metadata\" : { \"title\" : resp . get ( \"title\" , None ), \"uri\" : resp . get ( \"uri\" , None )}, } for resource in resources ] load ( out ) <ipython-input-93-f0a5f1c8081f>:12: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. load(out) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-93-f0a5f1c8081f> in <module> 10 ] 11 ---> 12 load ( out ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/__init__.py in load (stream, Loader) 110 Loader = FullLoader 111 --> 112 loader = Loader ( stream ) 113 try : 114 return loader . get_single_data ( ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/loader.py in __init__ (self, stream) 22 23 def __init__ ( self , stream ) : ---> 24 Reader . __init__ ( self , stream ) 25 Scanner . __init__ ( self ) 26 Parser . __init__ ( self ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in __init__ (self, stream) 83 self . eof = False 84 self . raw_buffer = None ---> 85 self . determine_encoding ( ) 86 87 def peek ( self , index = 0 ) : /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in determine_encoding (self) 122 def determine_encoding ( self ) : 123 while not self . eof and ( self . raw_buffer is None or len ( self . raw_buffer ) < 2 ) : --> 124 self . update_raw ( ) 125 if isinstance ( self . raw_buffer , bytes ) : 126 if self . raw_buffer . startswith ( codecs . BOM_UTF16_LE ) : /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in update_raw (self, size) 176 177 def update_raw ( self , size = 4096 ) : --> 178 data = self . stream . read ( size ) 179 if self . raw_buffer is None : 180 self . raw_buffer = data AttributeError : 'list' object has no attribute 'read' out [{'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - r\u00e9gion.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - france.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - departement.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - r\u00e9gion .', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - France.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - Quotidien.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Description des m\u00e9tadonn\u00e9es.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}] for k in resp : print ( \"*\" * 80 ) print ( k ) print ( \"-\" * 80 ) print ( resp . get ( k )) ******************************************************************************** acronym -------------------------------------------------------------------------------- SI-DEP ******************************************************************************** archived -------------------------------------------------------------------------------- None ******************************************************************************** badges -------------------------------------------------------------------------------- [] ******************************************************************************** created_at -------------------------------------------------------------------------------- 2020-05-29T16:10:35.407000 ******************************************************************************** deleted -------------------------------------------------------------------------------- None ******************************************************************************** description -------------------------------------------------------------------------------- ### Les actions de Sant\u00e9 publique France Sant\u00e9 publique France a pour mission d'am\u00e9liorer et de prot\u00e9ger la sant\u00e9 des populations. Durant la crise sanitaire li\u00e9e \u00e0 l'\u00e9pid\u00e9mie du COVID-19, Sant\u00e9 publique France se charge de surveiller et comprendre la dynamique de l'\u00e9pid\u00e9mie, d'anticiper les diff\u00e9rents sc\u00e9narii et de mettre en place des actions pour pr\u00e9venir et limiter la transmission de ce virus sur le territoire national. ### Le Syst\u00e8me d\u2019Informations de DEPistage (SI-DEP) Le nouveau syst\u00e8me d\u2019information de d\u00e9pistage (SI-DEP), en d\u00e9ploiement depuis le 13 mai 2020, est une plateforme s\u00e9curis\u00e9e o\u00f9 sont syst\u00e9matiquement enregistr\u00e9s les r\u00e9sultats des laboratoires des tests (RT-PCR) r\u00e9alis\u00e9s par l\u2019ensemble des laboratoires de ville et \u00e9tablissements hospitaliers concernant le SARS-COV2. La cr\u00e9ation de ce syst\u00e8me d'information est autoris\u00e9e pour une dur\u00e9e de 6 mois \u00e0 compter de la fin de l'\u00e9tat d'urgence sanitaire par application du [d\u00e9cret n\u00b0 2020-551 du 12 mai 2020](https://www.legifrance.gouv.fr/affichTexte.do?cidTexte=JORFTEXT000041869923) relatif aux syst\u00e8mes d\u2019information mentionn\u00e9s \u00e0 l\u2019article 11 de la loi n\u00b0 2020-546 du 11 mai 2020 prorogeant l\u2019\u00e9tat d\u2019urgence sanitaire et compl\u00e9tant ses dispositions. ### Description des donn\u00e9es Le pr\u00e9sent jeu de donn\u00e9es renseigne \u00e0 l'\u00e9chelle d\u00e9partementale et r\u00e9gionale : - le nombre de personnes test\u00e9es et le nombre de personnes d\u00e9clar\u00e9es positives par classe d'\u00e2ge (quotidien et hebdomadaire) ; - le nombre de personnes positives sur 7 jours glissants. Le pr\u00e9sent jeu de donn\u00e9es renseigne \u00e0 l'\u00e9chelle nationale : - le nombre de personnes test\u00e9es et le nombre de personnes d\u00e9clar\u00e9es positives par sexe et classe d'\u00e2ge (quotidien et hebdomadaire). Le taux de positivit\u00e9 correspond au nombre de tests positifs rapport\u00e9s au nombre de tests r\u00e9alis\u00e9s. Il est calcul\u00e9 de la mani\u00e8re suivante : 100*nombre de test positif/ nombre de tests r\u00e9alis\u00e9s **Pr\u00e9cisions** : Si plusieurs pr\u00e9l\u00e8vements sont rapport\u00e9s pour un m\u00eame patient: - S\u00e9lection de la premi\u00e8re date pour les pcr ayant le m\u00eame r\u00e9sultat (par exemple premi\u00e8re date si plusieurs pcr n\u00e9gatives) - Si pcr discordantes chez un m\u00eame patient (N et P), la premi\u00e8re pcr positive est conserv\u00e9e. Exclusion des r\u00e9sultats ininterpr\u00e9tables - A compter du 29/08, les indicateurs issus des donn\u00e9es de laboratoires (SI-DEP) pr\u00e9sentent des taux d\u2019incidence, de positivit\u00e9 et de d\u00e9pistage corrig\u00e9s en fonction des d\u00e9pistages r\u00e9alis\u00e9s dans les a\u00e9roports \u00e0 l\u2019arriv\u00e9e des vols internationaux. La correction s\u2019applique sur l\u2019ensemble des donn\u00e9es post\u00e9rieures \u00e0 la date du 12 ao\u00fbt. **Limites** : - Seuls les tests biologiques des personnes pour lesquelles le d\u00e9partement de r\u00e9sidence a pu \u00eatre localis\u00e9 sont repr\u00e9sent\u00e9s sur les cartes. Les personnes dont le d\u00e9partement n\u2019a pas pu \u00eatre remont\u00e9 dans les donn\u00e9es SIDEP ne sont comptabilis\u00e9es qu'au niveau France enti\u00e8re. De ce fait la somme des tests indiqu\u00e9s dans les d\u00e9partements ou r\u00e9gions est inf\u00e9rieure au nombre de tests indiqu\u00e9 en France. - Le d\u00e9lai de remont\u00e9e des tests peut exc\u00e9der 9 jours dans certains cas. Les indicateurs sont ajust\u00e9s quotidiennement selon la r\u00e9ception des r\u00e9sultats. Pour en savoir plus consultez la note m\u00e9thodologique disponible dans les ressources. ******************************************************************************** extras -------------------------------------------------------------------------------- {'recommendations': [{'id': '5e7de8cf4663c08d4f74ba01', 'score': 89, 'source': 'matomo'}], 'recommendations:sources': ['matomo']} ******************************************************************************** frequency -------------------------------------------------------------------------------- unknown ******************************************************************************** frequency_date -------------------------------------------------------------------------------- None ******************************************************************************** id -------------------------------------------------------------------------------- 5ed117db6c161bd5baf070be ******************************************************************************** last_modified -------------------------------------------------------------------------------- 2020-09-25T19:15:13.847000 ******************************************************************************** last_update -------------------------------------------------------------------------------- 2020-08-27T00:00:00 ******************************************************************************** license -------------------------------------------------------------------------------- fr-lo ******************************************************************************** metrics -------------------------------------------------------------------------------- {'discussions': 21, 'followers': 5, 'issues': 0, 'reuses': 22, 'views': 6112} ******************************************************************************** organization -------------------------------------------------------------------------------- {'acronym': 'SPF', 'class': 'Organization', 'id': '5e721a395d57f93d0bed451f', 'logo': 'https://static.data.gouv.fr/avatars/79/7e94cd7a8d43d39544d4018666e646-original.png', 'logo_thumbnail': 'https://static.data.gouv.fr/avatars/79/7e94cd7a8d43d39544d4018666e646-100.png', 'name': 'Sant\u00e9 publique France', 'page': 'https://www.data.gouv.fr/fr/organizations/sante-publique-france/', 'slug': 'sante-publique-france', 'uri': 'https://www.data.gouv.fr/api/1/organizations/sante-publique-france/'} ******************************************************************************** owner -------------------------------------------------------------------------------- None ******************************************************************************** page -------------------------------------------------------------------------------- https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/ ******************************************************************************** private -------------------------------------------------------------------------------- False ******************************************************************************** resources -------------------------------------------------------------------------------- [{'checksum': {'type': 'sha1', 'value': '21b8878f9b8df70e78a5a8ca6d9d28dd4b34a07e'}, 'created_at': '2020-09-01T15:01:03.280000', 'description': 'Note m\u00e9thodologique 27/08', 'extras': {}, 'filesize': 29885, 'filetype': 'file', 'format': 'docx', 'id': 'c98482d3-fba1-4397-99ae-1c958aa629f6', 'last_modified': '2020-09-01T15:04:27.976000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c98482d3-fba1-4397-99ae-1c958aa629f6', 'metrics': {'views': 167}, 'mime': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'preview_url': None, 'published': '2020-08-27T00:00:00', 'schema': None, 'title': 'analyse-de-la-base-sidep-note-methodologique.docx', 'type': 'documentation', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200901-150103/analyse-de-la-base-sidep-note-methodologique.docx'}, {'checksum': {'type': 'sha1', 'value': 'eb395230851890fe96cbc0618000ae70e302decd'}, 'created_at': '2020-05-29T18:02:26.703000', 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'extras': {}, 'filesize': 3361733, 'filetype': 'file', 'format': 'csv', 'id': '406c6a23-e283-4300-9484-54e78c8ae675', 'last_modified': '2020-09-25T19:15:06.758000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675', 'metrics': {'views': 8155}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:26', 'schema': None, 'title': 'sp-pos-quot-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': 'af41c6bc3aff81d2e3ab27e1fd4e85edd12efc77'}, 'created_at': '2020-05-29T18:03:11.045000', 'description': 'Taux de positivit\u00e9 - quotidien - r\u00e9gion.', 'extras': {}, 'filesize': 1026513, 'filetype': 'file', 'format': 'csv', 'id': '001aca18-df6a-45c8-89e6-f82d689e6c01', 'last_modified': '2020-09-25T19:15:13.194000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/001aca18-df6a-45c8-89e6-f82d689e6c01', 'metrics': {'views': 828}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191513%2Fsp-pos-quot-reg-2020-09-25-19h15.csv', 'published': '2020-05-29T18:03:11', 'schema': None, 'title': 'sp-pos-quot-reg-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191513/sp-pos-quot-reg-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '2879bad07eea8f4420beb68021944ab71af19b87'}, 'created_at': '2020-05-29T18:02:57.551000', 'description': 'Taux de positivit\u00e9 - quotidien - france.', 'extras': {}, 'filesize': 61466, 'filetype': 'file', 'format': 'csv', 'id': 'dd0de5d9-b5a5-4503-930a-7b08dc0adc7c', 'last_modified': '2020-09-25T19:15:13.762000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/dd0de5d9-b5a5-4503-930a-7b08dc0adc7c', 'metrics': {'views': 2639}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191513%2Fsp-pos-quot-fra-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:57', 'schema': None, 'title': 'sp-pos-quot-fra-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191513/sp-pos-quot-fra-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '511d145379f80e1fb1e2fe0bf90cff2d493b5fc5'}, 'created_at': '2020-05-29T18:01:11.291000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - departement.', 'extras': {}, 'filesize': 438028, 'filetype': 'file', 'format': 'csv', 'id': 'dd3ac13c-e87f-4b33-8897-07baff4e1783', 'last_modified': '2020-09-25T19:15:11.314000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/dd3ac13c-e87f-4b33-8897-07baff4e1783', 'metrics': {'views': 238}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191511%2Fsp-pos-heb-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:01:11', 'schema': None, 'title': 'sp-pos-heb-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191511/sp-pos-heb-dep-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '59b6f0c920f3aa5a700d1ee1b20fef26b211596a'}, 'created_at': '2020-05-29T18:02:10.342000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - r\u00e9gion .', 'extras': {}, 'filesize': 146314, 'filetype': 'file', 'format': 'csv', 'id': '1ff7af5f-88d6-44bd-b8b6-16308b046afc', 'last_modified': '2020-09-25T19:15:05.806000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/1ff7af5f-88d6-44bd-b8b6-16308b046afc', 'metrics': {'views': 25}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191505%2Fsp-pos-heb-reg-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:10', 'schema': None, 'title': 'sp-pos-heb-reg-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191505/sp-pos-heb-reg-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '27b6ce97a5004564ea5f876f8c8c00f83300a288'}, 'created_at': '2020-05-29T18:01:35.129000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - France.', 'extras': {}, 'filesize': 9087, 'filetype': 'file', 'format': 'csv', 'id': '2f0f720d-fbd2-41a7-95b4-3a70ff5a9253', 'last_modified': '2020-09-25T19:15:03.498000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/2f0f720d-fbd2-41a7-95b4-3a70ff5a9253', 'metrics': {'views': 293}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191503%2Fsp-pos-heb-fra-2020-09-25-19h15.csv', 'published': '2020-05-29T18:01:35', 'schema': None, 'title': 'sp-pos-heb-fra-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191503/sp-pos-heb-fra-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '41c46a8b6c450ddffea0845c85815dc42502192b'}, 'created_at': '2020-05-29T18:20:52.321000', 'description': None, 'extras': {}, 'filesize': 215055, 'filetype': 'file', 'format': 'csv', 'id': 'd1c1846c-f2d1-43cb-ad84-b46c40d1bec8', 'last_modified': '2020-07-03T19:15:20.039000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/d1c1846c-f2d1-43cb-ad84-b46c40d1bec8', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191519%2Fsp-ti-tp-7j-dep-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.321000', 'schema': None, 'title': 'sp-ti-tp-7j-dep-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191519/sp-ti-tp-7j-dep-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '215ad0960bbad3719ea13622cbca9b4f15d01332'}, 'created_at': '2020-05-29T18:20:52.324000', 'description': None, 'extras': {}, 'filesize': 52837, 'filetype': 'file', 'format': 'csv', 'id': 'df2f66d3-ef9b-48e0-abdf-f33a6a7ff2fa', 'last_modified': '2020-07-03T19:15:20.439000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/df2f66d3-ef9b-48e0-abdf-f33a6a7ff2fa', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191520%2Fsp-ti-tp-7j-reg-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.324000', 'schema': None, 'title': 'sp-ti-tp-7j-reg-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191520/sp-ti-tp-7j-reg-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '3272b07774ea14ed57c63bb7b9fd26065cf3125d'}, 'created_at': '2020-05-29T18:20:52.318000', 'description': None, 'extras': {}, 'filesize': 2880, 'filetype': 'file', 'format': 'csv', 'id': 'c1167c4e-8c89-40f2-adb3-1954f8fedfa7', 'last_modified': '2020-07-03T19:15:19.607000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c1167c4e-8c89-40f2-adb3-1954f8fedfa7', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191519%2Fsp-ti-tp-7j-fra-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.318000', 'schema': None, 'title': 'sp-ti-tp-7j-fra-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191519/sp-ti-tp-7j-fra-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': 'ce0d062e5faa1dcd83616f7bc9f74367b43fb6ff'}, 'created_at': '2020-05-29T17:19:23.764000', 'description': 'Taux de positivit\u00e9 - Quotidien.', 'extras': {}, 'filesize': 1337737, 'filetype': 'file', 'format': 'xlsx', 'id': 'c20aa429-d30b-41d1-8bea-37b106c5f33b', 'last_modified': '2020-07-03T19:15:27.711000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c20aa429-d30b-41d1-8bea-37b106c5f33b', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191527%2Fsp-pos-quot-2020-07-03-19h15.xlsx', 'published': '2020-05-29T17:19:23', 'schema': None, 'title': 'sp-pos-quot-2020-07-03-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191527/sp-pos-quot-2020-07-03-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': '62fb3c2bf176eed6254a72d4067d250bb5414490'}, 'created_at': '2020-05-29T17:17:47.913000', 'description': 'Taux de positivit\u00e9 - hebdomadaire.', 'extras': {}, 'filesize': 207005, 'filetype': 'file', 'format': 'xlsx', 'id': 'fc7f9844-05bd-41eb-9d9a-2a4b8010af1d', 'last_modified': '2020-07-01T19:15:23.424000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/fc7f9844-05bd-41eb-9d9a-2a4b8010af1d', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200701-191523%2Fsp-pos-heb-2020-07-01-19h15.xlsx', 'published': '2020-05-29T17:17:47', 'schema': None, 'title': 'sp-pos-heb-2020-07-01-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200701-191523/sp-pos-heb-2020-07-01-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': 'f526f981c17773cfc4207320275c2822ce425613'}, 'created_at': '2020-05-29T18:49:52.653000', 'description': None, 'extras': {}, 'filesize': 182582, 'filetype': 'file', 'format': 'xlsx', 'id': '708eb9ee-d8e8-4008-ac2d-0827acd95ba7', 'last_modified': '2020-07-03T19:15:20.863000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/708eb9ee-d8e8-4008-ac2d-0827acd95ba7', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191520%2Fsp-ti-tp-7j-2020-07-03-19h15.xlsx', 'published': '2020-05-29T18:49:52.653000', 'schema': None, 'title': 'sp-ti-tp-7j-2020-07-03-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191520/sp-ti-tp-7j-2020-07-03-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': '89c55f3a82bb8dcb5f1d1b1f4cb431b798a653ec'}, 'created_at': '2020-05-29T17:00:35.757000', 'description': 'Description des m\u00e9tadonn\u00e9es.', 'extras': {}, 'filesize': 10422, 'filetype': 'file', 'format': 'xlsx', 'id': '39aaad1c-9aac-4be8-96b2-6d001f892b34', 'last_modified': '2020-05-29T17:00:54.313000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/39aaad1c-9aac-4be8-96b2-6d001f892b34', 'metrics': {'views': 321}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Ftaux-de-positivite-aux-tests-virologiques-covid-19%2F20200529-170035%2Fmetadonnees-positivite.xlsx', 'published': '2020-05-29T17:00:35', 'schema': None, 'title': 'metadonnees-positivite.xlsx', 'type': 'documentation', 'url': 'https://static.data.gouv.fr/resources/taux-de-positivite-aux-tests-virologiques-covid-19/20200529-170035/metadonnees-positivite.xlsx'}] ******************************************************************************** slug -------------------------------------------------------------------------------- donnees-relatives-aux-resultats-des-tests-virologiques-covid-19 ******************************************************************************** spatial -------------------------------------------------------------------------------- None ******************************************************************************** tags -------------------------------------------------------------------------------- [] ******************************************************************************** temporal_coverage -------------------------------------------------------------------------------- None ******************************************************************************** title -------------------------------------------------------------------------------- Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19 ******************************************************************************** uri -------------------------------------------------------------------------------- https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/ resources = [ r for r in resp [ \"resources\" ] if \"wordprocessingml\" not in r [ \"mime\" ]] from yaml import load , dump resources [ 0 ] {'checksum': {'type': 'sha1', 'value': 'eb395230851890fe96cbc0618000ae70e302decd'}, 'created_at': '2020-05-29T18:02:26.703000', 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'extras': {}, 'filesize': 3361733, 'filetype': 'file', 'format': 'csv', 'id': '406c6a23-e283-4300-9484-54e78c8ae675', 'last_modified': '2020-09-25T19:15:06.758000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675', 'metrics': {'views': 8155}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:26', 'schema': None, 'title': 'sp-pos-quot-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv'} print ( dump ( resources [ 0 ])) checksum: type: sha1 value: eb395230851890fe96cbc0618000ae70e302decd created_at: '2020-05-29T18:02:26.703000' description: \"Taux de positivit\\xE9 - quotidien - d\\xE9partement .\" extras: {} filesize: 3361733 filetype: file format: csv id: 406c6a23-e283-4300-9484-54e78c8ae675 last_modified: '2020-09-25T19:15:06.758000' latest: https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675 metrics: views: 8155 mime: text/csv preview_url: /tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv published: '2020-05-29T18:02:26' schema: null title: sp-pos-quot-dep-2020-09-25-19h15.csv type: main url: https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv 'description' , 'latest' , 'title' for k in resources : print ( k [ \"title\" ]) sp-pos-quot-dep-2020-09-25-19h15.csv sp-pos-quot-reg-2020-09-25-19h15.csv sp-pos-quot-fra-2020-09-25-19h15.csv sp-pos-heb-dep-2020-09-25-19h15.csv sp-pos-heb-reg-2020-09-25-19h15.csv sp-pos-heb-fra-2020-09-25-19h15.csv sp-ti-tp-7j-dep-2020-07-03-19h15.csv sp-ti-tp-7j-reg-2020-07-03-19h15.csv sp-ti-tp-7j-fra-2020-07-03-19h15.csv sp-pos-quot-2020-07-03-19h15.xlsx sp-pos-heb-2020-07-01-19h15.xlsx sp-ti-tp-7j-2020-07-03-19h15.xlsx metadonnees-positivite.xlsx for k in resources [ - 1 ]: print ( \"*\" * 80 ) print ( k ) print ( \"-\" * 80 ) print ( resources [ - 1 ] . get ( k )) src [ \"indicateurs\" ] {'url_web': 'https://www.data.gouv.fr/fr/datasets/indicateurs-de-suivi-de-lepidemie-de-covid-19/', 'url_stable': 'https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e', 'url_api': 'https://www.data.gouv.fr/api/1/datasets/5ee9df5003284f565d561278/', 'titre': \"Indicateurs de suivi de l'\u00e9pid\u00e9mie de COVID-19\", 'file_pattern': 'indicateurs-covid19-dep', 'delim': ','}","title":"Feed a Catalog"},{"location":"Covid/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Covid19 \u00b6 % load_ext lab_black import intake import pandas as pd Metadata \u00b6 url_metadata = ( \"https://www.data.gouv.fr/fr/datasets/r/a8b5931a-3aa7-4aec-a81b-8b3de628cf63\" ) ! mkdir - p data / covid ; curl - s - o data / covid / metadata . xlsx - L $ url_metadata pd . read_excel ( \"data/covid/metadata.xlsx\" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colonne Type Description_FR Description_EN Exemple 0 dep String Departement State 01 1 reg String Region region 2 2 fra String France France FR 3 jour Date Jour Day 2020-05-13 4 week Date Semaine Week 2020-S21 5 pop integer Population de reference (du departement, de la... Reference population (department, region, nati... 656955 6 t integer Nombre de test r\u00e9alis\u00e9s Number of tests performed 2141 7 cl_age90 integer Classe d'age Age class 09 8 p integer Nombre de test positifs Number of positive tests 34 9 p_h integer Nombre de test positif chez les hommes Number of positive test in men 1688 10 t_h integer Nombre de test effectu\u00e9s chez les hommes Number of tests performed on men 93639 11 p_f integer Nombre de test positif chez les femmes Number of positive test in women 2415 12 t_f integer Nombre de test effectu\u00e9s chez les femmes Number of tests performed on women 122725 13 tx_std integer Taux d'incidence standardis\u00e9 (100000 * nombre ... Standardized incidence rate 1 Donn\u00e9es \u00b6 https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/ url = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" ! curl - LO $ url % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 473 100 473 0 0 987 0 --:--:-- --:--:-- --:--:-- 987 100 3761k 100 3761k 0 0 240k 0 0:00:15 0:00:15 --:--:-- 259k import pyarrow.csv as csv import pyarrow as pa csv . ParseOptions ( delimiter = \";\" ) <pyarrow._csv.ParseOptions at 0x7fd6c0060430> schema = pa . schema ( { \"dep\" : pa . string (), \"jour\" : pa . string (), \"pop\" : pa . float64 (), \"P\" : pa . int32 (), \"cl_age90\" : pa . int8 (), } ) table = csv . read_csv ( \"19a91d64-3cd3-42fc-9943-d635491a4d76\" , parse_options = csv . ParseOptions ( delimiter = \";\" ), convert_options = csv . ConvertOptions ( column_types = schema ), ) dfpa = table . to_pandas () . astype ({ \"jour\" : \"datetime64[ns]\" }) dfpa . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour pop P cl_age90 0 01 2020-05-13 83001.0 0 9 1 01 2020-05-13 84665.0 1 19 2 01 2020-05-13 65496.0 0 29 3 01 2020-05-13 85588.0 1 39 4 01 2020-05-13 89678.0 0 49 dfpa . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 152152 entries, 0 to 152151 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 dep 152152 non-null object 1 jour 152152 non-null datetime64[ns] 2 pop 152152 non-null float64 3 P 152152 non-null int32 4 cl_age90 152152 non-null int8 dtypes: datetime64[ns](1), float64(1), int32(1), int8(1), object(1) memory usage: 4.2+ MB df = pd.read_csv(\"19a91d64-3cd3-42fc-9943-d635491a4d76\", sep=\";\", parse_dates=[\"jour\"]) def plot_incidence ( dpt : int ): gp = dfpa . where ( dfpa . dep == dpt ) . groupby ( \"jour\" ) gp . P . sum () . plot () gp . P . sum () . rolling ( 7 ) . mean () . plot () plot_incidence ( \"43\" ) import numpy as np today = np . sort ( df . jour . unique ())[ - 1 ] today - np . timedelta64 ( 7 , 'D' ) numpy.datetime64('2020-09-15T00:00:00.000000000') import matplotlib.pyplot as plt df [ 'P_normed' ] = df . P / df [ 'pop' ] * 100_000 df_today = df [ df . jour >= today - np . timedelta64 ( 7 , 'D' )] gp_today_dep = df_today . groupby ( 'dep' ) ( gp_today_dep . sum () . P_normed / 2 / 7 ) . sort_values () . plot . bar ( figsize = ( 22 , 9 )) plt . axhline ( 50 , c = 'red' ) <matplotlib.lines.Line2D at 0x7f4cea8f1c70> plot_incidence ( '43' ) url_indic = ( \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" ) ! curl - LO $ url_indic % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 461 100 461 0 0 1546 0 --:--:-- --:--:-- --:--:-- 0-:--:-- --:--:-- 1546 100 1916k 100 1916k 0 0 236k 0 0:00:08 0:00:08 --:--:-- 259k ! head \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" \"extract_date\",\"departement\",\"region\",\"libelle_reg\",\"libelle_dep\",\"tx_incid\",\"R\",\"taux_occupation_sae\",\"tx_pos\",\"tx_incid_couleur\",\"R_couleur\",\"taux_occupation_sae_couleur\",\"tx_pos_couleur\",\"nb_orange\",\"nb_rouge\" \"2020-04-04\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,134,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-07\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,135.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-08\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,131.7,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-05\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,139.4,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-06\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,140.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-15\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,114.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-16\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,112.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-17\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,107.5,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-18\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,103.4,NA,\"\",\"\",\"rouge\",\"\",0,1 df_indic = pd . read_csv ( \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" , sep = \",\" , encoding = \"ISO-8859-1\" ) df_indic . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 18988 entries, 0 to 18987 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 extract_date 18988 non-null object 1 departement 18988 non-null object 2 region 18988 non-null int64 3 libelle_reg 18988 non-null object 4 libelle_dep 18988 non-null object 5 tx_incid 13029 non-null float64 6 R 2746 non-null float64 7 taux_occupation_sae 18988 non-null float64 8 tx_pos 13029 non-null float64 9 tx_incid_couleur 13029 non-null object 10 R_couleur 2746 non-null object 11 taux_occupation_sae_couleur 18988 non-null object 12 tx_pos_couleur 13029 non-null object 13 nb_orange 18988 non-null int64 14 nb_rouge 18988 non-null int64 dtypes: float64(4), int64(3), object(8) memory usage: 2.2+ MB df_indic [ df_indic . departement == \"43\" ] . tx_incid . plot . bar () <AxesSubplot:> df_indic [ df_indic . departement == \"43\" ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } extract_date departement region libelle_reg libelle_dep tx_incid R taux_occupation_sae tx_pos tx_incid_couleur R_couleur taux_occupation_sae_couleur tx_pos_couleur nb_orange nb_rouge 1316 2020-03-19 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 14.1 NaN NaN NaN vert NaN 0 0 1317 2020-03-20 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 15.6 NaN NaN NaN vert NaN 0 0 1318 2020-03-18 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 6.3 NaN NaN NaN vert NaN 0 0 1319 2020-04-01 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 120.2 NaN NaN NaN rouge NaN 0 1 1320 2020-04-02 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 125.2 NaN NaN NaN rouge NaN 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1499 2020-08-08 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.378788 vert NaN vert vert 0 0 1500 2020-08-09 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.377358 vert NaN vert vert 0 0 1501 2020-08-06 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 0.88 NaN 3.2 0.232558 vert NaN vert vert 0 0 1502 2020-08-11 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 1.17 3.0 1.003764 vert orange vert vert 1 0 1503 2020-08-10 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 NaN 3.4 1.021711 vert NaN vert vert 0 0 188 rows \u00d7 15 columns","title":"Covid"},{"location":"Covid/#covid19","text":"% load_ext lab_black import intake import pandas as pd","title":"Covid19"},{"location":"Covid/#metadata","text":"url_metadata = ( \"https://www.data.gouv.fr/fr/datasets/r/a8b5931a-3aa7-4aec-a81b-8b3de628cf63\" ) ! mkdir - p data / covid ; curl - s - o data / covid / metadata . xlsx - L $ url_metadata pd . read_excel ( \"data/covid/metadata.xlsx\" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colonne Type Description_FR Description_EN Exemple 0 dep String Departement State 01 1 reg String Region region 2 2 fra String France France FR 3 jour Date Jour Day 2020-05-13 4 week Date Semaine Week 2020-S21 5 pop integer Population de reference (du departement, de la... Reference population (department, region, nati... 656955 6 t integer Nombre de test r\u00e9alis\u00e9s Number of tests performed 2141 7 cl_age90 integer Classe d'age Age class 09 8 p integer Nombre de test positifs Number of positive tests 34 9 p_h integer Nombre de test positif chez les hommes Number of positive test in men 1688 10 t_h integer Nombre de test effectu\u00e9s chez les hommes Number of tests performed on men 93639 11 p_f integer Nombre de test positif chez les femmes Number of positive test in women 2415 12 t_f integer Nombre de test effectu\u00e9s chez les femmes Number of tests performed on women 122725 13 tx_std integer Taux d'incidence standardis\u00e9 (100000 * nombre ... Standardized incidence rate 1","title":"Metadata"},{"location":"Covid/#donnees","text":"https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/ url = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" ! curl - LO $ url % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 473 100 473 0 0 987 0 --:--:-- --:--:-- --:--:-- 987 100 3761k 100 3761k 0 0 240k 0 0:00:15 0:00:15 --:--:-- 259k import pyarrow.csv as csv import pyarrow as pa csv . ParseOptions ( delimiter = \";\" ) <pyarrow._csv.ParseOptions at 0x7fd6c0060430> schema = pa . schema ( { \"dep\" : pa . string (), \"jour\" : pa . string (), \"pop\" : pa . float64 (), \"P\" : pa . int32 (), \"cl_age90\" : pa . int8 (), } ) table = csv . read_csv ( \"19a91d64-3cd3-42fc-9943-d635491a4d76\" , parse_options = csv . ParseOptions ( delimiter = \";\" ), convert_options = csv . ConvertOptions ( column_types = schema ), ) dfpa = table . to_pandas () . astype ({ \"jour\" : \"datetime64[ns]\" }) dfpa . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour pop P cl_age90 0 01 2020-05-13 83001.0 0 9 1 01 2020-05-13 84665.0 1 19 2 01 2020-05-13 65496.0 0 29 3 01 2020-05-13 85588.0 1 39 4 01 2020-05-13 89678.0 0 49 dfpa . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 152152 entries, 0 to 152151 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 dep 152152 non-null object 1 jour 152152 non-null datetime64[ns] 2 pop 152152 non-null float64 3 P 152152 non-null int32 4 cl_age90 152152 non-null int8 dtypes: datetime64[ns](1), float64(1), int32(1), int8(1), object(1) memory usage: 4.2+ MB df = pd.read_csv(\"19a91d64-3cd3-42fc-9943-d635491a4d76\", sep=\";\", parse_dates=[\"jour\"]) def plot_incidence ( dpt : int ): gp = dfpa . where ( dfpa . dep == dpt ) . groupby ( \"jour\" ) gp . P . sum () . plot () gp . P . sum () . rolling ( 7 ) . mean () . plot () plot_incidence ( \"43\" ) import numpy as np today = np . sort ( df . jour . unique ())[ - 1 ] today - np . timedelta64 ( 7 , 'D' ) numpy.datetime64('2020-09-15T00:00:00.000000000') import matplotlib.pyplot as plt df [ 'P_normed' ] = df . P / df [ 'pop' ] * 100_000 df_today = df [ df . jour >= today - np . timedelta64 ( 7 , 'D' )] gp_today_dep = df_today . groupby ( 'dep' ) ( gp_today_dep . sum () . P_normed / 2 / 7 ) . sort_values () . plot . bar ( figsize = ( 22 , 9 )) plt . axhline ( 50 , c = 'red' ) <matplotlib.lines.Line2D at 0x7f4cea8f1c70> plot_incidence ( '43' ) url_indic = ( \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" ) ! curl - LO $ url_indic % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 461 100 461 0 0 1546 0 --:--:-- --:--:-- --:--:-- 0-:--:-- --:--:-- 1546 100 1916k 100 1916k 0 0 236k 0 0:00:08 0:00:08 --:--:-- 259k ! head \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" \"extract_date\",\"departement\",\"region\",\"libelle_reg\",\"libelle_dep\",\"tx_incid\",\"R\",\"taux_occupation_sae\",\"tx_pos\",\"tx_incid_couleur\",\"R_couleur\",\"taux_occupation_sae_couleur\",\"tx_pos_couleur\",\"nb_orange\",\"nb_rouge\" \"2020-04-04\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,134,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-07\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,135.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-08\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,131.7,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-05\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,139.4,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-06\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,140.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-15\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,114.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-16\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,112.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-17\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,107.5,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-18\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,103.4,NA,\"\",\"\",\"rouge\",\"\",0,1 df_indic = pd . read_csv ( \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" , sep = \",\" , encoding = \"ISO-8859-1\" ) df_indic . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 18988 entries, 0 to 18987 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 extract_date 18988 non-null object 1 departement 18988 non-null object 2 region 18988 non-null int64 3 libelle_reg 18988 non-null object 4 libelle_dep 18988 non-null object 5 tx_incid 13029 non-null float64 6 R 2746 non-null float64 7 taux_occupation_sae 18988 non-null float64 8 tx_pos 13029 non-null float64 9 tx_incid_couleur 13029 non-null object 10 R_couleur 2746 non-null object 11 taux_occupation_sae_couleur 18988 non-null object 12 tx_pos_couleur 13029 non-null object 13 nb_orange 18988 non-null int64 14 nb_rouge 18988 non-null int64 dtypes: float64(4), int64(3), object(8) memory usage: 2.2+ MB df_indic [ df_indic . departement == \"43\" ] . tx_incid . plot . bar () <AxesSubplot:> df_indic [ df_indic . departement == \"43\" ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } extract_date departement region libelle_reg libelle_dep tx_incid R taux_occupation_sae tx_pos tx_incid_couleur R_couleur taux_occupation_sae_couleur tx_pos_couleur nb_orange nb_rouge 1316 2020-03-19 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 14.1 NaN NaN NaN vert NaN 0 0 1317 2020-03-20 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 15.6 NaN NaN NaN vert NaN 0 0 1318 2020-03-18 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 6.3 NaN NaN NaN vert NaN 0 0 1319 2020-04-01 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 120.2 NaN NaN NaN rouge NaN 0 1 1320 2020-04-02 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 125.2 NaN NaN NaN rouge NaN 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1499 2020-08-08 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.378788 vert NaN vert vert 0 0 1500 2020-08-09 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.377358 vert NaN vert vert 0 0 1501 2020-08-06 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 0.88 NaN 3.2 0.232558 vert NaN vert vert 0 0 1502 2020-08-11 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 1.17 3.0 1.003764 vert orange vert vert 1 0 1503 2020-08-10 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 NaN 3.4 1.021711 vert NaN vert vert 0 0 188 rows \u00d7 15 columns","title":"Donn\u00e9es"},{"location":"WebDev/Intro/","text":"Web Developpment \u00b6 HTML and DOM specifications are issued from 2 main organisms, W3C and WHATWG 1 : WHATWG maintains the HTML and DOM Living Standards W3C bridges communities, develop use cases, fill issues, write tests, mediate issue resolution HTML semantic elements \u00b6 Elements, attributes, and attribute values in HTML are defined (by this specification) to have certain meanings (semantics). For example, the ol element represents an ordered list, and the lang attribute represents the language of the content. These definitions allow HTML processors, such as Web browsers or search engines, to present and use documents and applications in a wide variety of contexts that the author might not have considered. 2 Kind of content \u00b6 article aside nav section Heading content h1 h2 h3 h4 h5 h6 hgroup Web components \u00b6 JavaScript file defines a class called PopUpInfo , which extends HTMLElement . Inside the constructor, all the functionality the element will have when an instance of it is instantiated. Example Create a badge similar to the one at the top of the page: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class DocBadge extends HTMLElement { constructor () { // Always call super first in constructor super (); // Create a documentation badge var shadow = this . attachShadow ({ mode : 'open' }); var wrapper = document . createElement ( 'span' ); wrapper . setAttribute ( 'class' , 'myBadge' ); var href = this . hasAttribute ( 'href' ) ? this . getAttribute ( 'href' ) : 'img/default.png' ; var alt = this . hasAttribute ( 'alt' ) ? this . getAttribute ( 'alt' ) : 'Documentation' ; var label = this . hasAttribute ( 'label' ) ? this . getAttribute ( 'label' ) : 'docs' ; var message = this . hasAttribute ( 'message' ) ? this . getAttribute ( 'message' ) : 'stable' ; var color = this . hasAttribute ( 'color' ) ? this . getAttribute ( 'color' ) : 'brightgreen' ; var logo = this . hasAttribute ( 'logo' ) ? this . getAttribute ( 'logo' ) : 'Read-the-docs' ; var src = `https://img.shields.io/badge/ ${ label } - ${ message } - ${ color } ?style=flat&logo= ${ logo } ` ; var link = document . createElement ( 'a' ); link . setAttribute ( 'target' , '_blank' ); link . setAttribute ( 'href' , href ); var img = document . createElement ( 'img' ); img . setAttribute ( 'src' , src ); img . setAttribute ( 'alt' , alt ); shadow . appendChild ( wrapper ); wrapper . appendChild ( link ); link . appendChild ( img ); } } // register it customElements . define ( 'badge-doc' , DocBadge ); Usage: < badge-doc href = \"https://developer.mozilla.org/en-US/docs/Web/Web_Components\" message = \"MDN\" color = \"lightgrey\" ></ badge-doc > Resources \u00b6 Shield badges Simple icons W3C and WHATWG to work together to advance the open Web platform \u21a9 WHATWG spec \u21a9","title":"Intro"},{"location":"WebDev/Intro/#web-developpment","text":"HTML and DOM specifications are issued from 2 main organisms, W3C and WHATWG 1 : WHATWG maintains the HTML and DOM Living Standards W3C bridges communities, develop use cases, fill issues, write tests, mediate issue resolution","title":"Web Developpment"},{"location":"WebDev/Intro/#html-semantic-elements","text":"Elements, attributes, and attribute values in HTML are defined (by this specification) to have certain meanings (semantics). For example, the ol element represents an ordered list, and the lang attribute represents the language of the content. These definitions allow HTML processors, such as Web browsers or search engines, to present and use documents and applications in a wide variety of contexts that the author might not have considered. 2","title":"HTML semantic elements"},{"location":"WebDev/Intro/#kind-of-content","text":"article aside nav section Heading content h1 h2 h3 h4 h5 h6 hgroup","title":"Kind of content"},{"location":"WebDev/Intro/#web-components","text":"JavaScript file defines a class called PopUpInfo , which extends HTMLElement . Inside the constructor, all the functionality the element will have when an instance of it is instantiated. Example Create a badge similar to the one at the top of the page: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class DocBadge extends HTMLElement { constructor () { // Always call super first in constructor super (); // Create a documentation badge var shadow = this . attachShadow ({ mode : 'open' }); var wrapper = document . createElement ( 'span' ); wrapper . setAttribute ( 'class' , 'myBadge' ); var href = this . hasAttribute ( 'href' ) ? this . getAttribute ( 'href' ) : 'img/default.png' ; var alt = this . hasAttribute ( 'alt' ) ? this . getAttribute ( 'alt' ) : 'Documentation' ; var label = this . hasAttribute ( 'label' ) ? this . getAttribute ( 'label' ) : 'docs' ; var message = this . hasAttribute ( 'message' ) ? this . getAttribute ( 'message' ) : 'stable' ; var color = this . hasAttribute ( 'color' ) ? this . getAttribute ( 'color' ) : 'brightgreen' ; var logo = this . hasAttribute ( 'logo' ) ? this . getAttribute ( 'logo' ) : 'Read-the-docs' ; var src = `https://img.shields.io/badge/ ${ label } - ${ message } - ${ color } ?style=flat&logo= ${ logo } ` ; var link = document . createElement ( 'a' ); link . setAttribute ( 'target' , '_blank' ); link . setAttribute ( 'href' , href ); var img = document . createElement ( 'img' ); img . setAttribute ( 'src' , src ); img . setAttribute ( 'alt' , alt ); shadow . appendChild ( wrapper ); wrapper . appendChild ( link ); link . appendChild ( img ); } } // register it customElements . define ( 'badge-doc' , DocBadge ); Usage: < badge-doc href = \"https://developer.mozilla.org/en-US/docs/Web/Web_Components\" message = \"MDN\" color = \"lightgrey\" ></ badge-doc >","title":"Web components"},{"location":"WebDev/Intro/#resources","text":"Shield badges Simple icons W3C and WHATWG to work together to advance the open Web platform \u21a9 WHATWG spec \u21a9","title":"Resources"},{"location":"WebDev/REACT/","text":"REACT \u00b6 Synthetic events Theme \u00b6 material UI Forms \u00b6 See formik https://jaredpalmer.com/formik/docs/overview Hooks \u00b6 Introducing hooks Books \u00b6 Learning react by Kirupa Chinnathambi azeaze qsd Eloquent JavaScript by Marijn Haverbeke Read favorite Eloquent JavaScript by Marijn Haverbeke Read favorite Open \u00b6 Styled components make use of","title":"REACT"},{"location":"WebDev/REACT/#react","text":"Synthetic events","title":"REACT"},{"location":"WebDev/REACT/#theme","text":"material UI","title":"Theme"},{"location":"WebDev/REACT/#forms","text":"See formik https://jaredpalmer.com/formik/docs/overview","title":"Forms"},{"location":"WebDev/REACT/#hooks","text":"Introducing hooks","title":"Hooks"},{"location":"WebDev/REACT/#books","text":"","title":"Books"},{"location":"WebDev/REACT/#open","text":"Styled components make use of","title":"Open"},{"location":"WebDev/cors/","text":"Cross-Origin Resource Sharing - CORS \u00b6 is a mechanism that uses additional HTTP headers to tell browsers to give a web application running at one origin, access to selected resources from a different origin.","title":"CORS"},{"location":"WebDev/cors/#cross-origin-resource-sharing-cors","text":"is a mechanism that uses additional HTTP headers to tell browsers to give a web application running at one origin, access to selected resources from a different origin.","title":"Cross-Origin Resource Sharing - CORS"},{"location":"WebDev/css/","text":"CSS \u00b6 Element size \u00b6 Width [ <length> | <percentage> ] && [ border-box | content-box ]? | available | min-content | max-content | fit-content | auto Flex box \u00b6 Initialisation \u00b6 display: flex; or display: inline-flex; Properties that apply to the parent \u00b6 Ordering and Orientation Property Value Comment flex-direction row | row-reverse | column | column-reverse Ex. : div { flex-direction: row; } flex-wrap nowrap | wrap | wrap-reverse Ex. : div { flex-direction: column; flex-wrap: wrap; } flex-flow see individual properties Shorthand for flex-direction and flex-wrap Ex. : div { felx-flow: row-reverse wrap-reverse; } 1 2 3 4 1 2 3 4 Ordering justify-content align-items align-content Property Value Comment justify-content flex-start | flex-end | center | space-between | space-around align-items flex-start | flex-end | center | baseline | stretch align-content flex-start | flex-end | center | space-between | space-around | stretch Properties that apply to the child elements \u00b6 Ordering order : flex flow direction Property Value order <integer> Flexibility Property Value flex-grow <number> flex-shrink <number> flex-basis content | <width>","title":"CSS"},{"location":"WebDev/css/#css","text":"","title":"CSS"},{"location":"WebDev/css/#element-size","text":"Width [ <length> | <percentage> ] && [ border-box | content-box ]? | available | min-content | max-content | fit-content | auto","title":"Element size"},{"location":"WebDev/css/#flex-box","text":"","title":"Flex box"},{"location":"WebDev/css/#initialisation","text":"display: flex; or display: inline-flex;","title":"Initialisation"},{"location":"WebDev/css/#properties-that-apply-to-the-parent","text":"","title":"Properties that apply to the parent"},{"location":"WebDev/css/#properties-that-apply-to-the-child-elements","text":"Ordering order : flex flow direction Property Value order <integer> Flexibility Property Value flex-grow <number> flex-shrink <number> flex-basis content | <width>","title":"Properties that apply to the child elements"},{"location":"WebDev/jinja2/","text":"Jinja2 \u00b6 API \u00b6 Environment \u00b6 Environment is a central class whose instances grant access to configuration and globals: delimiters: block_start_string / block_end_string , defaults to {% / %} variable_start_string / variable_end_string , defaults to {{ / }} comment_start_string / comment_end_string , default to {# / #} prefix definition: line_statement_prefix line_comment_prefix ... cache control cache_size control the number of templates to be cached auto_reload enables template changes on source ... behavior: loader sets the loader finalize for variable expression post processing enable_async for async functions and generators usage in templates. variable definition: globals Because of its nature, Environment instances should only be modified if they are not shared and if no template was loaded so far. Several attributes and parameters are available, see the documentation Example from jinja2 import Environment , PackageLoader env = Environment ( loader = PackageLoader ( \"yourapp\" ), ) # Get a template template = env . get_template ( \"mytemplate.html\" ) # Render it template . render ( the = \"variables\" , go = \"here\" ) Template \u00b6 Normaly generated from an Environment , can Example template = Template ( 'Hello {{ name }}!' ) template . render ( name = 'John Doe' ) == u 'Hello John Doe!' True stream = template . stream ( name = 'John Doe' ) next ( stream ) == u 'Hello John Doe!' True next ( stream ) Traceback ( most recent call last ): ... StopIteration TemplateStream Context \u00b6 A context holds the variables of a template: values and public names it export. It defines various attributes: parent , a dict of read only, global variables the template looks up vars , template local variables environment whose belongs the context name of the template owning the context exported_vars call for calling a callable and passing parameters ... Loaders \u00b6 Subclass of BaseLoader , they are responsible for loading resources such as the file system. Builtin loaders: FileSystemLoader load templates from a directory in the file system. PackageLoader load templates from a directory in a Python package. DictLoader loads a template from a Python dict mapping template names to template source. FunctionLoader ... Autoescaping \u00b6 Utilities \u00b6 exceptions \u00b6 Templates \u00b6 Basic syntax \u00b6 Delimiters Defined in the Environment , theis default: {% ... %} for Statements {{ ... }} for Expressions to print to the template output {# ... #} for Comments not included in the template output # ... ## for Line Statements Variables Defined by the Context passed to the template. The are leveraging python attributes and item object access, defaulting to an undefined object. Filters Enables variables modification. Can accept arguments in parentheses. Builtin list Tests Implemented with the token is . Buildin list {% if loop .index is divisibleby ( 3 ) %} Whitespace control Language blocks are removed when the template is rendered but whitespaces remain in place. Striping can be configuring at the Environment level with trim_blocks and lstrip_blocks . They can also be manualy activated or deactivated with + and - symbols at block start and end level. {% for item in seq - %} {{ item }} {% - endfor %} Excaping","title":"jinja2"},{"location":"WebDev/jinja2/#jinja2","text":"","title":"Jinja2"},{"location":"WebDev/jinja2/#api","text":"","title":"API"},{"location":"WebDev/jinja2/#environment","text":"Environment is a central class whose instances grant access to configuration and globals: delimiters: block_start_string / block_end_string , defaults to {% / %} variable_start_string / variable_end_string , defaults to {{ / }} comment_start_string / comment_end_string , default to {# / #} prefix definition: line_statement_prefix line_comment_prefix ... cache control cache_size control the number of templates to be cached auto_reload enables template changes on source ... behavior: loader sets the loader finalize for variable expression post processing enable_async for async functions and generators usage in templates. variable definition: globals Because of its nature, Environment instances should only be modified if they are not shared and if no template was loaded so far. Several attributes and parameters are available, see the documentation Example from jinja2 import Environment , PackageLoader env = Environment ( loader = PackageLoader ( \"yourapp\" ), ) # Get a template template = env . get_template ( \"mytemplate.html\" ) # Render it template . render ( the = \"variables\" , go = \"here\" )","title":"Environment"},{"location":"WebDev/jinja2/#template","text":"Normaly generated from an Environment , can Example template = Template ( 'Hello {{ name }}!' ) template . render ( name = 'John Doe' ) == u 'Hello John Doe!' True stream = template . stream ( name = 'John Doe' ) next ( stream ) == u 'Hello John Doe!' True next ( stream ) Traceback ( most recent call last ): ... StopIteration TemplateStream","title":"Template"},{"location":"WebDev/jinja2/#context","text":"A context holds the variables of a template: values and public names it export. It defines various attributes: parent , a dict of read only, global variables the template looks up vars , template local variables environment whose belongs the context name of the template owning the context exported_vars call for calling a callable and passing parameters ...","title":"Context"},{"location":"WebDev/jinja2/#loaders","text":"Subclass of BaseLoader , they are responsible for loading resources such as the file system. Builtin loaders: FileSystemLoader load templates from a directory in the file system. PackageLoader load templates from a directory in a Python package. DictLoader loads a template from a Python dict mapping template names to template source. FunctionLoader ...","title":"Loaders"},{"location":"WebDev/jinja2/#autoescaping","text":"","title":"Autoescaping"},{"location":"WebDev/jinja2/#utilities","text":"","title":"Utilities"},{"location":"WebDev/jinja2/#exceptions","text":"","title":"exceptions"},{"location":"WebDev/jinja2/#templates","text":"","title":"Templates"},{"location":"WebDev/jinja2/#basic-syntax","text":"","title":"Basic syntax"},{"location":"WebDev/node/","text":"Node.js \u00b6 List packages and version from package-lock.json using jq cat package-lock.json | jq '[.dependencies | to_entries[] | {\"key\": .key, \"value\": .value.version}] | from_entries'","title":"node"},{"location":"WebDev/node/#nodejs","text":"List packages and version from package-lock.json using jq cat package-lock.json | jq '[.dependencies | to_entries[] | {\"key\": .key, \"value\": .value.version}] | from_entries'","title":"Node.js"},{"location":"cloud/cloudlandscape/","text":"","title":"Cloud landscape"},{"location":"cloud/cloudnative/","text":"Cloud native \u00b6 Definition \u00b6 CNCF Coud Native Definition v1.0 English Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach. These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil. The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone. Fran\u00e7ais Les technologies nativement cloud permettent aux entreprises de construire et d'exploiter des applications \u00e9lastiques dans des environnements modernes et dynamiques comme des clouds publics, priv\u00e9s ou bien hybrides. Les conteneurs, les services maill\u00e9s, les micro services, les infrastructures immuables et les API d\u00e9claratives illustrent cette approche. Ces techniques permettent la mise en \u0153uvre de syst\u00e8mes faiblement coupl\u00e9s, \u00e0 la fois r\u00e9sistants, pilotables et observables. Combin\u00e9s \u00e0 un robuste syst\u00e8me d'automatisation, ils permettent aux ing\u00e9nieurs de proc\u00e9der \u00e0 des modifications impactantes, fr\u00e9quemment et de fa\u00e7on pr\u00e9visible avec un minimum de travail. La Cloud Native Computing Foundation cherche \u00e0 favoriser l'adoption de ce paradigme en encourageant et en soutenant un \u00e9cosyst\u00e8me de projets \"opensource\" et ind\u00e9pendants. Nous d\u00e9mocratisons l'\u00e9tat de l'art des pratiques afin de rendre l'innovation accessible \u00e0 tous. Deutsch Cloud native Technologien erm\u00f6glichen es Unternehmen, skalierbare Anwendungen in modernen, dynamischen Umgebungen zu implementieren und zu betreiben. Dies k\u00f6nnen \u00f6ffentliche, private und Hybrid-Clouds sein. Best-Practises, wie Container, Service-Meshs, Microservices, immutable Infrastruktur und deklarative APIs, unterst\u00fctzen diesen Ansatz. Die zugrundeliegenden Techniken erm\u00f6glichen die Umsetzung von entkoppelten Systemen, die belastbar, handhabbar und beobachtbar sind. Kombiniert mit einer robusten Automatisierung k\u00f6nnen Softwareentwickler mit geringem Aufwand flexibel und schnell auf \u00c4nderungen reagieren. Die Cloud Native Computing Foundation f\u00f6rdert die Akzeptanz dieser Paradigmen durch die Ausgestaltung eines Open Source \u00d6kosystems aus herstellerneutralen Projekten. Wir demokratisieren modernste und innovative Softwareentwicklungs-Patterns, um diese Innovationen f\u00fcr alle zug\u00e4nglich zu machen. Microservices \u00b6 Status: Application where all configuration, and config run on a guest OS in a VM. For scaling, a new VM must be set up. Containers: Application run in containers with config, binarires and libraries. Abstraction over operating system. Elements of orchestration: Kubernetes Serverless vs containers: \u00b6 Abstraction of servers Event driven/event scale Micro-billing Cloud native uses DevOps Develop, Deliver, Operate, Security Pattern \u00b6 Fallacies of distributed computing are a set of assertions made by L Peter Deutsch and others at Sun Microsystems describing false assumptions that programmers new to distributed applications invariably make: The network is reliable; Latency is zero; Bandwidth is infinite; The network is secure; Topology doesn't change; There is one administrator; Transport cost is zero; The network is homogeneous. Retry Pattern \u00b6 On failure, an application retries to connect the server Circuit Breaker Pattern \u00b6 If a service is not available, the user can become quicker information on the failure. Kind of proxy. Made through a State machine: Open Closed: a timer will be increased. Over a threshold, no requests any more Half-Open: an amount of requests are satisfied; Over a threshold, goes in closed Pub & Sub \u00b6 A sender can reach several consumer without to know which part is interesting for the consumer Message Broker: from an input channel, fills output channels that can be consummed by consumers. Work at scale \u00b6 vertical scaling k horizontal scaling involves service instances, e.g. load balancer in K8s","title":"Cloud native"},{"location":"cloud/cloudnative/#cloud-native","text":"","title":"Cloud native"},{"location":"cloud/cloudnative/#definition","text":"CNCF Coud Native Definition v1.0 English Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach. These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil. The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone. Fran\u00e7ais Les technologies nativement cloud permettent aux entreprises de construire et d'exploiter des applications \u00e9lastiques dans des environnements modernes et dynamiques comme des clouds publics, priv\u00e9s ou bien hybrides. Les conteneurs, les services maill\u00e9s, les micro services, les infrastructures immuables et les API d\u00e9claratives illustrent cette approche. Ces techniques permettent la mise en \u0153uvre de syst\u00e8mes faiblement coupl\u00e9s, \u00e0 la fois r\u00e9sistants, pilotables et observables. Combin\u00e9s \u00e0 un robuste syst\u00e8me d'automatisation, ils permettent aux ing\u00e9nieurs de proc\u00e9der \u00e0 des modifications impactantes, fr\u00e9quemment et de fa\u00e7on pr\u00e9visible avec un minimum de travail. La Cloud Native Computing Foundation cherche \u00e0 favoriser l'adoption de ce paradigme en encourageant et en soutenant un \u00e9cosyst\u00e8me de projets \"opensource\" et ind\u00e9pendants. Nous d\u00e9mocratisons l'\u00e9tat de l'art des pratiques afin de rendre l'innovation accessible \u00e0 tous. Deutsch Cloud native Technologien erm\u00f6glichen es Unternehmen, skalierbare Anwendungen in modernen, dynamischen Umgebungen zu implementieren und zu betreiben. Dies k\u00f6nnen \u00f6ffentliche, private und Hybrid-Clouds sein. Best-Practises, wie Container, Service-Meshs, Microservices, immutable Infrastruktur und deklarative APIs, unterst\u00fctzen diesen Ansatz. Die zugrundeliegenden Techniken erm\u00f6glichen die Umsetzung von entkoppelten Systemen, die belastbar, handhabbar und beobachtbar sind. Kombiniert mit einer robusten Automatisierung k\u00f6nnen Softwareentwickler mit geringem Aufwand flexibel und schnell auf \u00c4nderungen reagieren. Die Cloud Native Computing Foundation f\u00f6rdert die Akzeptanz dieser Paradigmen durch die Ausgestaltung eines Open Source \u00d6kosystems aus herstellerneutralen Projekten. Wir demokratisieren modernste und innovative Softwareentwicklungs-Patterns, um diese Innovationen f\u00fcr alle zug\u00e4nglich zu machen.","title":"Definition"},{"location":"cloud/cloudnative/#microservices","text":"Status: Application where all configuration, and config run on a guest OS in a VM. For scaling, a new VM must be set up. Containers: Application run in containers with config, binarires and libraries. Abstraction over operating system. Elements of orchestration: Kubernetes","title":"Microservices"},{"location":"cloud/cloudnative/#serverless-vs-containers","text":"Abstraction of servers Event driven/event scale Micro-billing Cloud native uses DevOps Develop, Deliver, Operate, Security","title":"Serverless vs containers:"},{"location":"cloud/cloudnative/#pattern","text":"Fallacies of distributed computing are a set of assertions made by L Peter Deutsch and others at Sun Microsystems describing false assumptions that programmers new to distributed applications invariably make: The network is reliable; Latency is zero; Bandwidth is infinite; The network is secure; Topology doesn't change; There is one administrator; Transport cost is zero; The network is homogeneous.","title":"Pattern"},{"location":"cloud/cloudnative/#retry-pattern","text":"On failure, an application retries to connect the server","title":"Retry Pattern"},{"location":"cloud/cloudnative/#circuit-breaker-pattern","text":"If a service is not available, the user can become quicker information on the failure. Kind of proxy. Made through a State machine: Open Closed: a timer will be increased. Over a threshold, no requests any more Half-Open: an amount of requests are satisfied; Over a threshold, goes in closed","title":"Circuit Breaker Pattern"},{"location":"cloud/cloudnative/#pub-sub","text":"A sender can reach several consumer without to know which part is interesting for the consumer Message Broker: from an input channel, fills output channels that can be consummed by consumers.","title":"Pub &amp; Sub"},{"location":"cloud/cloudnative/#work-at-scale","text":"vertical scaling k horizontal scaling involves service instances, e.g. load balancer in K8s","title":"Work at scale"},{"location":"data/Covid/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Covid19 \u00b6 % load_ext lab_black import intake import pandas as pd Metadata \u00b6 url_metadata = ( \"https://www.data.gouv.fr/fr/datasets/r/a8b5931a-3aa7-4aec-a81b-8b3de628cf63\" ) ! mkdir - p data / covid ; curl - s - o data / covid / metadata . xlsx - L $ url_metadata pd . read_excel ( \"data/covid/metadata.xlsx\" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colonne Type Description_FR Description_EN Exemple 0 dep String Departement State 01 1 reg String Region region 2 2 fra String France France FR 3 jour Date Jour Day 2020-05-13 4 week Date Semaine Week 2020-S21 5 pop integer Population de reference (du departement, de la... Reference population (department, region, nati... 656955 6 t integer Nombre de test r\u00e9alis\u00e9s Number of tests performed 2141 7 cl_age90 integer Classe d'age Age class 09 8 p integer Nombre de test positifs Number of positive tests 34 9 p_h integer Nombre de test positif chez les hommes Number of positive test in men 1688 10 t_h integer Nombre de test effectu\u00e9s chez les hommes Number of tests performed on men 93639 11 p_f integer Nombre de test positif chez les femmes Number of positive test in women 2415 12 t_f integer Nombre de test effectu\u00e9s chez les femmes Number of tests performed on women 122725 13 tx_std integer Taux d'incidence standardis\u00e9 (100000 * nombre ... Standardized incidence rate 1 Donn\u00e9es \u00b6 https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/ url = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" ! curl - LO $ url % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 473 100 473 0 0 1017 0 --:--:-- --:--:-- --:--:-- 1017 100 3790k 100 3790k 0 0 208k 0 0:00:18 0:00:18 --:--:-- 220k import pyarrow.csv as csv import pyarrow as pa csv . ParseOptions ( delimiter = \";\" ) <pyarrow._csv.ParseOptions at 0x7fcfcbfab430> schema = pa . schema ( { \"dep\" : pa . string (), \"jour\" : pa . string (), \"pop\" : pa . float64 (), \"P\" : pa . int32 (), \"cl_age90\" : pa . int8 (), } ) table = csv . read_csv ( \"19a91d64-3cd3-42fc-9943-d635491a4d76\" , parse_options = csv . ParseOptions ( delimiter = \";\" ), convert_options = csv . ConvertOptions ( column_types = schema ), ) dfpa = table . to_pandas () . astype ({ \"jour\" : \"datetime64[ns]\" }) dfpa . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour pop P cl_age90 0 01 2020-05-13 83001.0 0 9 1 01 2020-05-13 84665.0 1 19 2 01 2020-05-13 65496.0 0 29 3 01 2020-05-13 85588.0 1 39 4 01 2020-05-13 89678.0 0 49 dfpa . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 153296 entries, 0 to 153295 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 dep 153296 non-null object 1 jour 153296 non-null datetime64[ns] 2 pop 153296 non-null float64 3 P 153296 non-null int32 4 cl_age90 153296 non-null int8 dtypes: datetime64[ns](1), float64(1), int32(1), int8(1), object(1) memory usage: 4.2+ MB df = pd.read_csv(\"19a91d64-3cd3-42fc-9943-d635491a4d76\", sep=\";\", parse_dates=[\"jour\"]) from matplotlib.axis import Axis dfpa [ \"pop\" ] 0 83001.00000 1 84665.00000 2 65496.00000 3 85588.00000 4 89678.00000 ... 153291 2878.06000 153292 1097.68600 153293 296.76760 153294 66.59655 153295 35746.00000 Name: pop, Length: 153296, dtype: float64 df2 = dfpa [ dfpa . cl_age90 == 0 ] df2 . groupby ( \"jour\" ) <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fcf683c6d00> def plot_incidence ( dpt : int , ax : Axis = None ): _df = dfpa . copy () _df [ \"P_pro_100k\" ] = dfpa . P / dfpa [ \"pop\" ] * 100_000 gp = _df . where ( _df . dep == dpt ) . groupby ( \"jour\" ) ( gp . P_pro_100k . sum () / 2 ) . plot ( ax = ax ) ( gp . P_pro_100k . sum () / 2 ) . rolling ( 7 ) . mean () . plot ( ax = ax ) plot_incidence ( \"43\" ) import matplotlib.pyplot as plt with plt . style . context ( \"ggplot\" ): fig , axs = plt . subplots ( 2 , 3 , figsize = ( 22 , 10 ), sharex = True ) depts = [ 43 , 63 , 42 , 15 , 69 , \"07\" ] for ax , dept in zip ( axs . ravel (), depts ): plot_incidence ( str ( dept ), ax ) ax . set_title ( dept ) plt . tight_layout () import numpy as np today = np . sort ( df . jour . unique ())[ - 1 ] today - np . timedelta64 ( 7 , 'D' ) numpy.datetime64('2020-09-15T00:00:00.000000000') import matplotlib.pyplot as plt df [ 'P_normed' ] = df . P / df [ 'pop' ] * 100_000 df_today = df [ df . jour >= today - np . timedelta64 ( 7 , 'D' )] gp_today_dep = df_today . groupby ( 'dep' ) ( gp_today_dep . sum () . P_normed / 2 / 7 ) . sort_values () . plot . bar ( figsize = ( 22 , 9 )) plt . axhline ( 50 , c = 'red' ) <matplotlib.lines.Line2D at 0x7f4cea8f1c70> plot_incidence ( '43' ) url_indic = ( \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" ) ! curl - LO $ url_indic % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 461 100 461 0 0 1546 0 --:--:-- --:--:-- --:--:-- 0-:--:-- --:--:-- 1546 100 1916k 100 1916k 0 0 236k 0 0:00:08 0:00:08 --:--:-- 259k ! head \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" \"extract_date\",\"departement\",\"region\",\"libelle_reg\",\"libelle_dep\",\"tx_incid\",\"R\",\"taux_occupation_sae\",\"tx_pos\",\"tx_incid_couleur\",\"R_couleur\",\"taux_occupation_sae_couleur\",\"tx_pos_couleur\",\"nb_orange\",\"nb_rouge\" \"2020-04-04\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,134,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-07\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,135.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-08\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,131.7,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-05\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,139.4,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-06\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,140.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-15\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,114.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-16\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,112.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-17\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,107.5,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-18\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,103.4,NA,\"\",\"\",\"rouge\",\"\",0,1 df_indic = pd . read_csv ( \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" , sep = \",\" , encoding = \"ISO-8859-1\" ) df_indic . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 18988 entries, 0 to 18987 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 extract_date 18988 non-null object 1 departement 18988 non-null object 2 region 18988 non-null int64 3 libelle_reg 18988 non-null object 4 libelle_dep 18988 non-null object 5 tx_incid 13029 non-null float64 6 R 2746 non-null float64 7 taux_occupation_sae 18988 non-null float64 8 tx_pos 13029 non-null float64 9 tx_incid_couleur 13029 non-null object 10 R_couleur 2746 non-null object 11 taux_occupation_sae_couleur 18988 non-null object 12 tx_pos_couleur 13029 non-null object 13 nb_orange 18988 non-null int64 14 nb_rouge 18988 non-null int64 dtypes: float64(4), int64(3), object(8) memory usage: 2.2+ MB df_indic [ df_indic . departement == \"43\" ] . tx_incid . plot . bar () <AxesSubplot:> df_indic [ df_indic . departement == \"43\" ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } extract_date departement region libelle_reg libelle_dep tx_incid R taux_occupation_sae tx_pos tx_incid_couleur R_couleur taux_occupation_sae_couleur tx_pos_couleur nb_orange nb_rouge 1316 2020-03-19 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 14.1 NaN NaN NaN vert NaN 0 0 1317 2020-03-20 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 15.6 NaN NaN NaN vert NaN 0 0 1318 2020-03-18 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 6.3 NaN NaN NaN vert NaN 0 0 1319 2020-04-01 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 120.2 NaN NaN NaN rouge NaN 0 1 1320 2020-04-02 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 125.2 NaN NaN NaN rouge NaN 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1499 2020-08-08 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.378788 vert NaN vert vert 0 0 1500 2020-08-09 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.377358 vert NaN vert vert 0 0 1501 2020-08-06 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 0.88 NaN 3.2 0.232558 vert NaN vert vert 0 0 1502 2020-08-11 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 1.17 3.0 1.003764 vert orange vert vert 1 0 1503 2020-08-10 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 NaN 3.4 1.021711 vert NaN vert vert 0 0 188 rows \u00d7 15 columns","title":"Covid"},{"location":"data/Covid/#covid19","text":"% load_ext lab_black import intake import pandas as pd","title":"Covid19"},{"location":"data/Covid/#metadata","text":"url_metadata = ( \"https://www.data.gouv.fr/fr/datasets/r/a8b5931a-3aa7-4aec-a81b-8b3de628cf63\" ) ! mkdir - p data / covid ; curl - s - o data / covid / metadata . xlsx - L $ url_metadata pd . read_excel ( \"data/covid/metadata.xlsx\" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colonne Type Description_FR Description_EN Exemple 0 dep String Departement State 01 1 reg String Region region 2 2 fra String France France FR 3 jour Date Jour Day 2020-05-13 4 week Date Semaine Week 2020-S21 5 pop integer Population de reference (du departement, de la... Reference population (department, region, nati... 656955 6 t integer Nombre de test r\u00e9alis\u00e9s Number of tests performed 2141 7 cl_age90 integer Classe d'age Age class 09 8 p integer Nombre de test positifs Number of positive tests 34 9 p_h integer Nombre de test positif chez les hommes Number of positive test in men 1688 10 t_h integer Nombre de test effectu\u00e9s chez les hommes Number of tests performed on men 93639 11 p_f integer Nombre de test positif chez les femmes Number of positive test in women 2415 12 t_f integer Nombre de test effectu\u00e9s chez les femmes Number of tests performed on women 122725 13 tx_std integer Taux d'incidence standardis\u00e9 (100000 * nombre ... Standardized incidence rate 1","title":"Metadata"},{"location":"data/Covid/#donnees","text":"https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/ url = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" ! curl - LO $ url % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 473 100 473 0 0 1017 0 --:--:-- --:--:-- --:--:-- 1017 100 3790k 100 3790k 0 0 208k 0 0:00:18 0:00:18 --:--:-- 220k import pyarrow.csv as csv import pyarrow as pa csv . ParseOptions ( delimiter = \";\" ) <pyarrow._csv.ParseOptions at 0x7fcfcbfab430> schema = pa . schema ( { \"dep\" : pa . string (), \"jour\" : pa . string (), \"pop\" : pa . float64 (), \"P\" : pa . int32 (), \"cl_age90\" : pa . int8 (), } ) table = csv . read_csv ( \"19a91d64-3cd3-42fc-9943-d635491a4d76\" , parse_options = csv . ParseOptions ( delimiter = \";\" ), convert_options = csv . ConvertOptions ( column_types = schema ), ) dfpa = table . to_pandas () . astype ({ \"jour\" : \"datetime64[ns]\" }) dfpa . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour pop P cl_age90 0 01 2020-05-13 83001.0 0 9 1 01 2020-05-13 84665.0 1 19 2 01 2020-05-13 65496.0 0 29 3 01 2020-05-13 85588.0 1 39 4 01 2020-05-13 89678.0 0 49 dfpa . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 153296 entries, 0 to 153295 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 dep 153296 non-null object 1 jour 153296 non-null datetime64[ns] 2 pop 153296 non-null float64 3 P 153296 non-null int32 4 cl_age90 153296 non-null int8 dtypes: datetime64[ns](1), float64(1), int32(1), int8(1), object(1) memory usage: 4.2+ MB df = pd.read_csv(\"19a91d64-3cd3-42fc-9943-d635491a4d76\", sep=\";\", parse_dates=[\"jour\"]) from matplotlib.axis import Axis dfpa [ \"pop\" ] 0 83001.00000 1 84665.00000 2 65496.00000 3 85588.00000 4 89678.00000 ... 153291 2878.06000 153292 1097.68600 153293 296.76760 153294 66.59655 153295 35746.00000 Name: pop, Length: 153296, dtype: float64 df2 = dfpa [ dfpa . cl_age90 == 0 ] df2 . groupby ( \"jour\" ) <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fcf683c6d00> def plot_incidence ( dpt : int , ax : Axis = None ): _df = dfpa . copy () _df [ \"P_pro_100k\" ] = dfpa . P / dfpa [ \"pop\" ] * 100_000 gp = _df . where ( _df . dep == dpt ) . groupby ( \"jour\" ) ( gp . P_pro_100k . sum () / 2 ) . plot ( ax = ax ) ( gp . P_pro_100k . sum () / 2 ) . rolling ( 7 ) . mean () . plot ( ax = ax ) plot_incidence ( \"43\" ) import matplotlib.pyplot as plt with plt . style . context ( \"ggplot\" ): fig , axs = plt . subplots ( 2 , 3 , figsize = ( 22 , 10 ), sharex = True ) depts = [ 43 , 63 , 42 , 15 , 69 , \"07\" ] for ax , dept in zip ( axs . ravel (), depts ): plot_incidence ( str ( dept ), ax ) ax . set_title ( dept ) plt . tight_layout () import numpy as np today = np . sort ( df . jour . unique ())[ - 1 ] today - np . timedelta64 ( 7 , 'D' ) numpy.datetime64('2020-09-15T00:00:00.000000000') import matplotlib.pyplot as plt df [ 'P_normed' ] = df . P / df [ 'pop' ] * 100_000 df_today = df [ df . jour >= today - np . timedelta64 ( 7 , 'D' )] gp_today_dep = df_today . groupby ( 'dep' ) ( gp_today_dep . sum () . P_normed / 2 / 7 ) . sort_values () . plot . bar ( figsize = ( 22 , 9 )) plt . axhline ( 50 , c = 'red' ) <matplotlib.lines.Line2D at 0x7f4cea8f1c70> plot_incidence ( '43' ) url_indic = ( \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" ) ! curl - LO $ url_indic % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 461 100 461 0 0 1546 0 --:--:-- --:--:-- --:--:-- 0-:--:-- --:--:-- 1546 100 1916k 100 1916k 0 0 236k 0 0:00:08 0:00:08 --:--:-- 259k ! head \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" \"extract_date\",\"departement\",\"region\",\"libelle_reg\",\"libelle_dep\",\"tx_incid\",\"R\",\"taux_occupation_sae\",\"tx_pos\",\"tx_incid_couleur\",\"R_couleur\",\"taux_occupation_sae_couleur\",\"tx_pos_couleur\",\"nb_orange\",\"nb_rouge\" \"2020-04-04\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,134,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-07\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,135.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-08\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,131.7,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-05\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,139.4,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-06\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,140.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-15\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,114.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-16\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,112.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-17\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,107.5,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-18\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,103.4,NA,\"\",\"\",\"rouge\",\"\",0,1 df_indic = pd . read_csv ( \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" , sep = \",\" , encoding = \"ISO-8859-1\" ) df_indic . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 18988 entries, 0 to 18987 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 extract_date 18988 non-null object 1 departement 18988 non-null object 2 region 18988 non-null int64 3 libelle_reg 18988 non-null object 4 libelle_dep 18988 non-null object 5 tx_incid 13029 non-null float64 6 R 2746 non-null float64 7 taux_occupation_sae 18988 non-null float64 8 tx_pos 13029 non-null float64 9 tx_incid_couleur 13029 non-null object 10 R_couleur 2746 non-null object 11 taux_occupation_sae_couleur 18988 non-null object 12 tx_pos_couleur 13029 non-null object 13 nb_orange 18988 non-null int64 14 nb_rouge 18988 non-null int64 dtypes: float64(4), int64(3), object(8) memory usage: 2.2+ MB df_indic [ df_indic . departement == \"43\" ] . tx_incid . plot . bar () <AxesSubplot:> df_indic [ df_indic . departement == \"43\" ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } extract_date departement region libelle_reg libelle_dep tx_incid R taux_occupation_sae tx_pos tx_incid_couleur R_couleur taux_occupation_sae_couleur tx_pos_couleur nb_orange nb_rouge 1316 2020-03-19 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 14.1 NaN NaN NaN vert NaN 0 0 1317 2020-03-20 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 15.6 NaN NaN NaN vert NaN 0 0 1318 2020-03-18 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 6.3 NaN NaN NaN vert NaN 0 0 1319 2020-04-01 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 120.2 NaN NaN NaN rouge NaN 0 1 1320 2020-04-02 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 125.2 NaN NaN NaN rouge NaN 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1499 2020-08-08 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.378788 vert NaN vert vert 0 0 1500 2020-08-09 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.377358 vert NaN vert vert 0 0 1501 2020-08-06 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 0.88 NaN 3.2 0.232558 vert NaN vert vert 0 0 1502 2020-08-11 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 1.17 3.0 1.003764 vert orange vert vert 1 0 1503 2020-08-10 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 NaN 3.4 1.021711 vert NaN vert vert 0 0 188 rows \u00d7 15 columns","title":"Donn\u00e9es"},{"location":"data/crisp-dm/","text":"CRISP-DM - Cross Industry Standard Process for Data Mining \u00b6","title":"CRISP-DM"},{"location":"data/crisp-dm/#crisp-dm-cross-industry-standard-process-for-data-mining","text":"","title":"CRISP-DM - Cross Industry Standard Process for Data Mining"},{"location":"data/spark/","text":"SparkSession Main entry point for DataFrame and SQL functionality. DataFrame A distributed collection of data grouped into named columns. Column A column expression in a DataFrame. Row A row of data in a DataFrame. GroupedData Aggregation methods, returned by DataFrame.groupBy(). DataFrameNaFunctions Methods for handling missing data (null values). DataFrameStatFunctions Methods for statistics functionality. functions List of built-in functions available for DataFrame. types List of data types available. Window For working with window functions.","title":"Spark"},{"location":"data/db/intro/","text":"Database \u00b6 Language statements \u00b6 DDL - Data Definition Language \u00b6 in impala DML - Data Manipulation Language \u00b6 in impala Data types \u00b6 Large objects, generaly up to 4Gb, and not supported universaly, e.g. not in Impala: BLOB : binary large objects CLOB character large object Entity Relationship Diagram (ERD) \u00b6 Type of data modeling representing objects or concepts within an information system or organization and their relation to one other. EdgeDB Framework \u00b6 Ibis \u00b6 Data catalog \u00b6 Intake \u00b6 Persisting data","title":"intro"},{"location":"data/db/intro/#database","text":"","title":"Database"},{"location":"data/db/intro/#language-statements","text":"","title":"Language statements"},{"location":"data/db/intro/#ddl-data-definition-language","text":"in impala","title":"DDL - Data Definition Language"},{"location":"data/db/intro/#dml-data-manipulation-language","text":"in impala","title":"DML - Data Manipulation Language"},{"location":"data/db/intro/#data-types","text":"Large objects, generaly up to 4Gb, and not supported universaly, e.g. not in Impala: BLOB : binary large objects CLOB character large object","title":"Data types"},{"location":"data/db/intro/#entity-relationship-diagram-erd","text":"Type of data modeling representing objects or concepts within an information system or organization and their relation to one other. EdgeDB","title":"Entity Relationship Diagram (ERD)"},{"location":"data/db/intro/#framework","text":"","title":"Framework"},{"location":"data/db/intro/#ibis","text":"","title":"Ibis"},{"location":"data/db/intro/#data-catalog","text":"","title":"Data catalog"},{"location":"data/db/intro/#intake","text":"Persisting data","title":"Intake"},{"location":"data/db/S3/_intro/","text":"Object Store (S3) \u00b6 MinIO \u00b6 https://docs.min.io/docs/minio-multi-user-quickstart-guide.html S3 API: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html","title":"Intro"},{"location":"data/db/S3/_intro/#object-store-s3","text":"","title":"Object Store (S3)"},{"location":"data/db/S3/_intro/#minio","text":"https://docs.min.io/docs/minio-multi-user-quickstart-guide.html S3 API: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html","title":"MinIO"},{"location":"data/db/SQL/_intro/","text":"SQL - Structured Query Language \u00b6 Command types \u00b6 Name Description Example DDL - Data Definition Language organization of data whithin the DB CREATE , ALTER , DROP , TRUNCATE DQL - Data Query Language to perform queries on the data SELECT DML - Data Manipulation Language used to retrieve and manipulate data in a relational DB SELECT...INTO , INSERT INTO... VALUES... DCL - Data Control Language user rights and permission GRANT , REVOKE TCL - Transaction Control Language deals with DB transactions COMMIT , ROLLBACK , SAVEPOINT SQL within Python \u00b6 For sql like data access, SQLAlchemy consists of two distinct components, known as the Core (abstraction toolkit) and an optional but convenient ORM (Object Relational Mapper). For analytics, Pandas provides facili tes and loads the data into the memory of the local host, Ibis leaves the data in its storage, and performs the computations there For SQL command in jupyter, see the SQL jupyter magic and a notebook example Sort order \u00b6 Collation \u00b6 String sorting is done on a character-by-character basis but custom alphanumeric values is possible . A DBMS uses a collating sequence, or collation, to determine the order in which characters are sorted. The collation defines the order of precedence for every character in your character set. Your character set depends on the language that you\u2019re using\u2014European languages (a Latin character set), Hebrew (the Hebrew alphabet), or Chinese (ideographs), for example. The collation also determines case sensitivity (is \u2018A\u2019 < \u2018a\u2019?), accent sensitivity (is \u2018A\u2019 < \u2018\u00c0\u2019 ?), width sensitivity (for multibyte or Unicode characters), and other factors such as linguistic practices. The SQL standard doesn\u2019t define particular collations and character sets, so each DBMS uses its own sorting strategy and default collation\u2026 Search your DBMS documentation for collation or sort order. Source: Fehily, Chris - SQL VIsual QuickStart Guide, 3 rd Edition . Missing values \u00b6 NULL values are handled differently on SQL engine, e.g.: Impala handles NULL as top values Hive and MySQL handles NULL as lower values. To override such a behavior, NULLS FIST or NULL LAST can be specified. This is not supported by all engines. Impala, Hive and PostgreSQL does when MySQL does not. Another possibility to achieve this is to double the sort operation: -- SQL will fist sort by 'col2 IS NULL' which is a boolean, then by 'col2' SELECT col , col2 FROM table1 ORDER BY col2 IS NULL ASC , col2 Engines limitations \u00b6 Selection must sometimes include the column on which the is done. Example -- This will not work in Hive SELECT col1 , col2 FROM table1 ORDER BY col3 -- Nor this SELECT col1 , col2 FROM table1 ORDER BY col3 * col4 -- This will be ok SELECT col1 , col2 , col3 , col4 FROM table1 ORDER BY col3 * col4 -- and this SELECT col1 , col2 , col3 * col4 AS muliplication FROM table1 ORDER BY multiplication Limit \u00b6 For pagination, sql specific implementations: -- For Impala and PostgreSQL LIMIT < limit > OFFSET < offset > -- For Hive Limit < offset > , < limit > -- MySQL supports both -- some use SKIP Danger Without ORDER BY , order is not deterministic: some row could be displayed multiple times or missing as selection is arbitrary. Impala require ORDER BY when using OFFSET Select \u00b6 Syntaxic order SELECT, FROM, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT Execution order (in general) FROM, WHERE, GROUP BY, HAVING, SELECT, ORDER BY, LIMIT Shortcut \u00b6 Order by position It is possible in some engine to specify the position or the column to apply the order on. This is not supported by every engine and will not raise an error. -- This will order by the 3rd column SELECT col1 , col2 , col3 FROM table1 ORDER BY 3","title":"Intro"},{"location":"data/db/SQL/_intro/#sql-structured-query-language","text":"","title":"SQL - Structured Query Language"},{"location":"data/db/SQL/_intro/#command-types","text":"Name Description Example DDL - Data Definition Language organization of data whithin the DB CREATE , ALTER , DROP , TRUNCATE DQL - Data Query Language to perform queries on the data SELECT DML - Data Manipulation Language used to retrieve and manipulate data in a relational DB SELECT...INTO , INSERT INTO... VALUES... DCL - Data Control Language user rights and permission GRANT , REVOKE TCL - Transaction Control Language deals with DB transactions COMMIT , ROLLBACK , SAVEPOINT","title":"Command types"},{"location":"data/db/SQL/_intro/#sql-within-python","text":"For sql like data access, SQLAlchemy consists of two distinct components, known as the Core (abstraction toolkit) and an optional but convenient ORM (Object Relational Mapper). For analytics, Pandas provides facili tes and loads the data into the memory of the local host, Ibis leaves the data in its storage, and performs the computations there For SQL command in jupyter, see the SQL jupyter magic and a notebook example","title":"SQL within Python"},{"location":"data/db/SQL/_intro/#sort-order","text":"","title":"Sort order"},{"location":"data/db/SQL/_intro/#collation","text":"String sorting is done on a character-by-character basis but custom alphanumeric values is possible . A DBMS uses a collating sequence, or collation, to determine the order in which characters are sorted. The collation defines the order of precedence for every character in your character set. Your character set depends on the language that you\u2019re using\u2014European languages (a Latin character set), Hebrew (the Hebrew alphabet), or Chinese (ideographs), for example. The collation also determines case sensitivity (is \u2018A\u2019 < \u2018a\u2019?), accent sensitivity (is \u2018A\u2019 < \u2018\u00c0\u2019 ?), width sensitivity (for multibyte or Unicode characters), and other factors such as linguistic practices. The SQL standard doesn\u2019t define particular collations and character sets, so each DBMS uses its own sorting strategy and default collation\u2026 Search your DBMS documentation for collation or sort order. Source: Fehily, Chris - SQL VIsual QuickStart Guide, 3 rd Edition .","title":"Collation"},{"location":"data/db/SQL/_intro/#missing-values","text":"NULL values are handled differently on SQL engine, e.g.: Impala handles NULL as top values Hive and MySQL handles NULL as lower values. To override such a behavior, NULLS FIST or NULL LAST can be specified. This is not supported by all engines. Impala, Hive and PostgreSQL does when MySQL does not. Another possibility to achieve this is to double the sort operation: -- SQL will fist sort by 'col2 IS NULL' which is a boolean, then by 'col2' SELECT col , col2 FROM table1 ORDER BY col2 IS NULL ASC , col2","title":"Missing values"},{"location":"data/db/SQL/_intro/#engines-limitations","text":"Selection must sometimes include the column on which the is done. Example -- This will not work in Hive SELECT col1 , col2 FROM table1 ORDER BY col3 -- Nor this SELECT col1 , col2 FROM table1 ORDER BY col3 * col4 -- This will be ok SELECT col1 , col2 , col3 , col4 FROM table1 ORDER BY col3 * col4 -- and this SELECT col1 , col2 , col3 * col4 AS muliplication FROM table1 ORDER BY multiplication","title":"Engines limitations"},{"location":"data/db/SQL/_intro/#limit","text":"For pagination, sql specific implementations: -- For Impala and PostgreSQL LIMIT < limit > OFFSET < offset > -- For Hive Limit < offset > , < limit > -- MySQL supports both -- some use SKIP Danger Without ORDER BY , order is not deterministic: some row could be displayed multiple times or missing as selection is arbitrary. Impala require ORDER BY when using OFFSET","title":"Limit"},{"location":"data/db/SQL/_intro/#select","text":"Syntaxic order SELECT, FROM, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT Execution order (in general) FROM, WHERE, GROUP BY, HAVING, SELECT, ORDER BY, LIMIT","title":"Select"},{"location":"data/db/SQL/_intro/#shortcut","text":"Order by position It is possible in some engine to specify the position or the column to apply the order on. This is not supported by every engine and will not raise an error. -- This will order by the 3rd column SELECT col1 , col2 , col3 FROM table1 ORDER BY 3","title":"Shortcut"},{"location":"data/db/SQL/impala/","text":"Impala \u00b6 Impala shell \u00b6 The impala-shell can be used for: ad hoc queries and exploration as a REPL process single statement with the -q flag or scripts with the -f flag Note The impala-shell uses readline .inputrc in your home direc","title":"Impala"},{"location":"data/db/SQL/impala/#impala","text":"","title":"Impala"},{"location":"data/db/SQL/impala/#impala-shell","text":"The impala-shell can be used for: ad hoc queries and exploration as a REPL process single statement with the -q flag or scripts with the -f flag Note The impala-shell uses readline .inputrc in your home direc","title":"Impala shell"},{"location":"data/db/SQL/postgres/","text":"PostgreSQL \u00b6 Connect From Your Local Machine to a PostgreSQL Database in Docker https://medium.com/better-programming/connect-from-local-machine-to-postgresql-docker-container-f785f00461a7 Linux downloads (Ubuntu) https://www.postgresql.org/download/linux/ubuntu/ http://zetcode.com/db/postgresqlc/ Docker \u00b6 Starting a docker container requires POSTGRES_PASSWORD to be set as environement variable. If POSTGRES_DB is not set, it is defaulted to POSTGRES_USER value. docker run -i -d -p 5432:5432 -e POSTGRES_PASSWORD=password postgres:latest PostgreSQL informational commands \u00b6 Basic commands to survive on PostgreSQL. Command Description \\l list databases \\c <DB> connect to a database \\d list tables, views, and sequences \\d <TABLE> describe named table, view, sequence or index \\dt list tables \\di list indexes \\dv list views \\q quit application Load data from cli/files \u00b6 -- Input from stdin echo \"\"\"1 | Paul | 32 | California| 20000 2 | Allen | 25 | Texas | 15000 3 | Teddy | 23 | Norway | 20000 4 | Mark | 25 | Rich-Mond | 65000 5 | David | 27 | Texas | 85000 6 | Kim | 22 | South-Hall| 45000 7 | James | 24 | Houston | 10000\"\"\" | \\ psql - U postgres - h localhost - p 5432 - d mydb \\ - c \"COPY mytable FROM STDIN DELIMITER '|'\" -- Or from a file CAT mydata . csv | psql - U postgres - c \"COPY mytable FROM STDIN\" Common Table Expression (CTE) \u00b6 A CTE is a temporary result set that can be referenced within another SQL statement, e.g. SELECT , INSERT , UPDATE , DELETE . generate_series \u00b6 Works with types int , bigint , numeric , timestamp w. and w.o. time zone. Examples SELECT * FROM generate_series ( 2 , 4 ); generate_series ----------------- 2 3 4 ( 3 rows ) SELECT * FROM generate_series ( 5 , 1 , - 2 ); generate_series ----------------- 5 3 1 ( 3 rows ) SELECT * FROM generate_series ( 4 , 3 ); generate_series ----------------- ( 0 rows ) SELECT generate_series ( 1 . 1 , 4 , 1 . 3 ); generate_series ----------------- 1 . 1 2 . 4 3 . 7 ( 3 rows ) -- this example relies on the date-plus-integer operator: SELECT current_date + s . a AS dates FROM generate_series ( 0 , 14 , 7 ) AS s ( a ); dates ------------ 2004 - 02 - 05 2004 - 02 - 12 2004 - 02 - 19 ( 3 rows ) SELECT * FROM generate_series ( '2008-03-01 00:00' :: timestamp , '2008-03-04 12:00' , '10 hours' ); generate_series --------------------- 2008 - 03 - 01 00 : 00 : 00 2008 - 03 - 01 10 : 00 : 00 2008 - 03 - 01 20 : 00 : 00 2008 - 03 - 02 06 : 00 : 00 2008 - 03 - 02 16 : 00 : 00 2008 - 03 - 03 02 : 00 : 00 2008 - 03 - 03 12 : 00 : 00 2008 - 03 - 03 22 : 00 : 00 2008 - 03 - 04 08 : 00 : 00 ( 9 rows )","title":"PostgreSQL"},{"location":"data/db/SQL/postgres/#postgresql","text":"Connect From Your Local Machine to a PostgreSQL Database in Docker https://medium.com/better-programming/connect-from-local-machine-to-postgresql-docker-container-f785f00461a7 Linux downloads (Ubuntu) https://www.postgresql.org/download/linux/ubuntu/ http://zetcode.com/db/postgresqlc/","title":"PostgreSQL"},{"location":"data/db/SQL/postgres/#docker","text":"Starting a docker container requires POSTGRES_PASSWORD to be set as environement variable. If POSTGRES_DB is not set, it is defaulted to POSTGRES_USER value. docker run -i -d -p 5432:5432 -e POSTGRES_PASSWORD=password postgres:latest","title":"Docker"},{"location":"data/db/SQL/postgres/#postgresql-informational-commands","text":"Basic commands to survive on PostgreSQL. Command Description \\l list databases \\c <DB> connect to a database \\d list tables, views, and sequences \\d <TABLE> describe named table, view, sequence or index \\dt list tables \\di list indexes \\dv list views \\q quit application","title":"PostgreSQL informational commands"},{"location":"data/db/SQL/postgres/#load-data-from-clifiles","text":"-- Input from stdin echo \"\"\"1 | Paul | 32 | California| 20000 2 | Allen | 25 | Texas | 15000 3 | Teddy | 23 | Norway | 20000 4 | Mark | 25 | Rich-Mond | 65000 5 | David | 27 | Texas | 85000 6 | Kim | 22 | South-Hall| 45000 7 | James | 24 | Houston | 10000\"\"\" | \\ psql - U postgres - h localhost - p 5432 - d mydb \\ - c \"COPY mytable FROM STDIN DELIMITER '|'\" -- Or from a file CAT mydata . csv | psql - U postgres - c \"COPY mytable FROM STDIN\"","title":"Load data from cli/files"},{"location":"data/db/SQL/postgres/#common-table-expression-cte","text":"A CTE is a temporary result set that can be referenced within another SQL statement, e.g. SELECT , INSERT , UPDATE , DELETE .","title":"Common Table Expression (CTE)"},{"location":"data/db/SQL/postgres/#generate_series","text":"Works with types int , bigint , numeric , timestamp w. and w.o. time zone. Examples SELECT * FROM generate_series ( 2 , 4 ); generate_series ----------------- 2 3 4 ( 3 rows ) SELECT * FROM generate_series ( 5 , 1 , - 2 ); generate_series ----------------- 5 3 1 ( 3 rows ) SELECT * FROM generate_series ( 4 , 3 ); generate_series ----------------- ( 0 rows ) SELECT generate_series ( 1 . 1 , 4 , 1 . 3 ); generate_series ----------------- 1 . 1 2 . 4 3 . 7 ( 3 rows ) -- this example relies on the date-plus-integer operator: SELECT current_date + s . a AS dates FROM generate_series ( 0 , 14 , 7 ) AS s ( a ); dates ------------ 2004 - 02 - 05 2004 - 02 - 12 2004 - 02 - 19 ( 3 rows ) SELECT * FROM generate_series ( '2008-03-01 00:00' :: timestamp , '2008-03-04 12:00' , '10 hours' ); generate_series --------------------- 2008 - 03 - 01 00 : 00 : 00 2008 - 03 - 01 10 : 00 : 00 2008 - 03 - 01 20 : 00 : 00 2008 - 03 - 02 06 : 00 : 00 2008 - 03 - 02 16 : 00 : 00 2008 - 03 - 03 02 : 00 : 00 2008 - 03 - 03 12 : 00 : 00 2008 - 03 - 03 22 : 00 : 00 2008 - 03 - 04 08 : 00 : 00 ( 9 rows )","title":"generate_series"},{"location":"data/db/mongoDB/Aggregation/","text":"Aggregation framework \u00b6 Aggregation structure and basic syntax rules: pipelines are always an array of one or more stages. stages are composed of one or more operators/expressions. expressions may take a single/an array of arguments. Code { $ match : { < query > } } Selection stage \u00b6 $match - filtering documents \u00b6 a $match may contain a $text query operator, but it must be the first in the pipeline $match should come early in the pipeline $where can not be used with $match $match uses the same syntax as find() $project - shaping document (projection) \u00b6 { $project: { } } specify fields to be retained _id must be explicitly removed let add new fields or reassign values can be used as many times as required in an aggregation pipeline $addFields : add transformation fields in the document \u00b6 $geoNear : filtering documents \u00b6 must be the first stage in the pipeline is a collection with only one geo index Example $geoNear: { near: <Point>, distanceField: \"<key>\", ... } Cursor-like stages \u00b6 $limit : limit \u00b6 $skip : limit \u00b6 $count : limit \u00b6 $sort : limit \u00b6 $sample : limit \u00b6 Group stage \u00b6 $group : limit \u00b6","title":"Aggregation framework"},{"location":"data/db/mongoDB/Aggregation/#aggregation-framework","text":"Aggregation structure and basic syntax rules: pipelines are always an array of one or more stages. stages are composed of one or more operators/expressions. expressions may take a single/an array of arguments. Code { $ match : { < query > } }","title":"Aggregation framework"},{"location":"data/db/mongoDB/Aggregation/#selection-stage","text":"","title":"Selection stage"},{"location":"data/db/mongoDB/Aggregation/#match-filtering-documents","text":"a $match may contain a $text query operator, but it must be the first in the pipeline $match should come early in the pipeline $where can not be used with $match $match uses the same syntax as find()","title":"$match - filtering documents"},{"location":"data/db/mongoDB/Aggregation/#project-shaping-document-projection","text":"{ $project: { } } specify fields to be retained _id must be explicitly removed let add new fields or reassign values can be used as many times as required in an aggregation pipeline","title":"$project - shaping document (projection)"},{"location":"data/db/mongoDB/Aggregation/#addfields-add-transformation-fields-in-the-document","text":"","title":"$addFields: add transformation fields in the document"},{"location":"data/db/mongoDB/Aggregation/#geonear-filtering-documents","text":"must be the first stage in the pipeline is a collection with only one geo index Example $geoNear: { near: <Point>, distanceField: \"<key>\", ... }","title":"$geoNear: filtering    documents"},{"location":"data/db/mongoDB/Aggregation/#cursor-like-stages","text":"","title":"Cursor-like stages"},{"location":"data/db/mongoDB/Aggregation/#limit-limit","text":"","title":"$limit: limit"},{"location":"data/db/mongoDB/Aggregation/#skip-limit","text":"","title":"$skip: limit"},{"location":"data/db/mongoDB/Aggregation/#count-limit","text":"","title":"$count: limit"},{"location":"data/db/mongoDB/Aggregation/#sort-limit","text":"","title":"$sort: limit"},{"location":"data/db/mongoDB/Aggregation/#sample-limit","text":"","title":"$sample: limit"},{"location":"data/db/mongoDB/Aggregation/#group-stage","text":"","title":"Group stage"},{"location":"data/db/mongoDB/Aggregation/#group-limit","text":"","title":"$group: limit"},{"location":"data/db/mongoDB/_intro/","text":"MongoDB \u00b6 Notation: field path: $fieldName system variable: $$UPPERCASE user variable: $$foo mongod is the main daemon process for mongoDB. Interaction is not performed directly but through a driver. Basic flags for the cli: --port / --dbpath / --logpath / --fork . Server shutdown is performed with db.shutdownServer after selecting the admin db ( use admin ). Configuration file: Jupyter kernel imongo \u00b6 imongo ipython wrapper kernel Jupyter messenging doc http://zguide.zeromq.org/page:all","title":"Intro"},{"location":"data/db/mongoDB/_intro/#mongodb","text":"Notation: field path: $fieldName system variable: $$UPPERCASE user variable: $$foo mongod is the main daemon process for mongoDB. Interaction is not performed directly but through a driver. Basic flags for the cli: --port / --dbpath / --logpath / --fork . Server shutdown is performed with db.shutdownServer after selecting the admin db ( use admin ). Configuration file:","title":"MongoDB"},{"location":"data/db/mongoDB/_intro/#jupyter-kernel-imongo","text":"imongo ipython wrapper kernel Jupyter messenging doc http://zguide.zeromq.org/page:all","title":"Jupyter kernel imongo"},{"location":"data/db/mongoDB/docker/","text":"MongoDB docker image \u00b6 Environment variables / startup scripts \u00b6 Danger Any pre-existing DB will be left untouched, so env. var. have no effect MONGO_INITDB_ROOT_USERNAME MONGO_INITDB_ROOT_PASSWORD , when used with ..._USERNAME , creates user in the admin auth DB with root role MONGO_INITDB_DATABASE specify the name of a DB used in initialization scripts Info Files can be passed for sensitive informatin by appending _FILE a env. var., e.g.: MONGO_INITB_ROOT_PASSWORD_FILE='/var/mongodb_root_secret' Initialization \u00b6 optional and used for more complex setup all files located at /dock-entrypoint-initdb.d/ with extension .js and .sh will be executed. execution in alphabetical order .js files will be executed by mongo using MONGO_INIT_DATABASE otherwise 'test' Connection \u00b6 Either with dockerized shell or with the OS mongo shell. $ docker exec -it <CONTAINER_NAME> mongo $ mongo --port 27017 -u <USERNAME> -p <PASSWORD> --authenticatioinDatabase admin","title":"Docker Image"},{"location":"data/db/mongoDB/docker/#mongodb-docker-image","text":"","title":"MongoDB docker image"},{"location":"data/db/mongoDB/docker/#environment-variables-startup-scripts","text":"Danger Any pre-existing DB will be left untouched, so env. var. have no effect MONGO_INITDB_ROOT_USERNAME MONGO_INITDB_ROOT_PASSWORD , when used with ..._USERNAME , creates user in the admin auth DB with root role MONGO_INITDB_DATABASE specify the name of a DB used in initialization scripts Info Files can be passed for sensitive informatin by appending _FILE a env. var., e.g.: MONGO_INITB_ROOT_PASSWORD_FILE='/var/mongodb_root_secret'","title":"Environment variables / startup scripts"},{"location":"data/db/mongoDB/docker/#initialization","text":"optional and used for more complex setup all files located at /dock-entrypoint-initdb.d/ with extension .js and .sh will be executed. execution in alphabetical order .js files will be executed by mongo using MONGO_INIT_DATABASE otherwise 'test'","title":"Initialization"},{"location":"data/db/mongoDB/docker/#connection","text":"Either with dockerized shell or with the OS mongo shell. $ docker exec -it <CONTAINER_NAME> mongo $ mongo --port 27017 -u <USERNAME> -p <PASSWORD> --authenticatioinDatabase admin","title":"Connection"},{"location":"data/pipelines/luigi/","text":"Luigi \u00b6 2 fundamentals buidling blocks, both abstract classes: Tasks defines three methods: run() , output() and requires() . Target , resource generated by a Task defines one method that must be overridden: exists , returns a boolean. corresponds to a file on a disk, a file on HDFS or some kind of a checkpoint, like an entry in a database, already defined LocalTarget and HdfsTarget , and from luigi.contribi : s3.S3Target , ssh.RemoteTarget , ftp.RemoteTarget , mysqldb.MySqlTarget , ... filesystem like targets implement the open() method returning s stream object whose mode can be specified, e.g. mode='w' Gzip support by providing format=format.Gzip Parameter Source: https://luigi.readthedocs.io","title":"Luigi"},{"location":"data/pipelines/luigi/#luigi","text":"2 fundamentals buidling blocks, both abstract classes: Tasks defines three methods: run() , output() and requires() . Target , resource generated by a Task defines one method that must be overridden: exists , returns a boolean. corresponds to a file on a disk, a file on HDFS or some kind of a checkpoint, like an entry in a database, already defined LocalTarget and HdfsTarget , and from luigi.contribi : s3.S3Target , ssh.RemoteTarget , ftp.RemoteTarget , mysqldb.MySqlTarget , ... filesystem like targets implement the open() method returning s stream object whose mode can be specified, e.g. mode='w' Gzip support by providing format=format.Gzip Parameter Source: https://luigi.readthedocs.io","title":"Luigi"},{"location":"data/pipelines/prefect/","text":"Prefect \u00b6","title":"prefect"},{"location":"data/pipelines/prefect/#prefect","text":"","title":"Prefect"},{"location":"data/viz/matplotlib/","text":"Matplotlib \u00b6 verything in matplotlib is organized in a hierarchy: at the top of the hierarchy is the matplotlib \"state-machine environment\" which is provided by the matplotlib.pyplot module. At this level, simple functions are used to add plot elements (lines, images, text, etc.) to the current axes in the current figure. https://dev.to/skotaro/artist-in-matplotlib---something-i-wanted-to-know-before-spending-tremendous-hours-on-googling-how-tos--31oo Anatomy of a figure \u00b6 https://matplotlib.org/tutorials/intermediate/artists.html Axis \u00b6 Accessor method Description get_scale The scale of the axis, e.g., 'log' or 'linear' get_view_interval The interval instance of the axis view limits get_data_interval The interval instance of the axis data limits get_gridlines A list of grid lines for the Axis get_label The axis label - a Text instance get_ticklabels A list of Text instances - keyword minor-True get_ticklines A list of Line2D instances - keyword minor-True get_ticklocs A list of Tick locations - keyword minor-True get_major_locator The matplotlib.ticker.Locator instance for major ticks get_major_formatter The matplotlib.ticker.Formatter instance for major ticks get_minor_locator The matplotlib.ticker.Locator instance for minor ticks get_minor_formatter The matplotlib.ticker.Formatter instance for minor ticks get_major_ticks A list of Tick instances for major ticks get_minor_ticks A list of Tick instances for minor ticks grid Turn the grid on or off for the major or minor ticks Spines \u00b6","title":"Matplolib"},{"location":"data/viz/matplotlib/#matplotlib","text":"verything in matplotlib is organized in a hierarchy: at the top of the hierarchy is the matplotlib \"state-machine environment\" which is provided by the matplotlib.pyplot module. At this level, simple functions are used to add plot elements (lines, images, text, etc.) to the current axes in the current figure. https://dev.to/skotaro/artist-in-matplotlib---something-i-wanted-to-know-before-spending-tremendous-hours-on-googling-how-tos--31oo","title":"Matplotlib"},{"location":"data/viz/matplotlib/#anatomy-of-a-figure","text":"https://matplotlib.org/tutorials/intermediate/artists.html","title":"Anatomy of a figure"},{"location":"data/viz/matplotlib/#axis","text":"Accessor method Description get_scale The scale of the axis, e.g., 'log' or 'linear' get_view_interval The interval instance of the axis view limits get_data_interval The interval instance of the axis data limits get_gridlines A list of grid lines for the Axis get_label The axis label - a Text instance get_ticklabels A list of Text instances - keyword minor-True get_ticklines A list of Line2D instances - keyword minor-True get_ticklocs A list of Tick locations - keyword minor-True get_major_locator The matplotlib.ticker.Locator instance for major ticks get_major_formatter The matplotlib.ticker.Formatter instance for major ticks get_minor_locator The matplotlib.ticker.Locator instance for minor ticks get_minor_formatter The matplotlib.ticker.Formatter instance for minor ticks get_major_ticks A list of Tick instances for major ticks get_minor_ticks A list of Tick instances for minor ticks grid Turn the grid on or off for the major or minor ticks","title":"Axis"},{"location":"data/viz/matplotlib/#spines","text":"","title":"Spines"},{"location":"doc/md/","text":"usage and plugins \u00b6 mkdocs mkdocs-material Github guide Comments \u00b6 [comment]: <> (This is a comment, it will not be included) [//]: <> (This is also a comment.) [//]: # (This may be the most platform independent comment) Source: Stack Overflow 4823469 Extensions \u00b6 PyMdown extensions \u00b6 Collection of extensions for Python Markdown. Arithmatex is an extension that preserves LaTeX math equations during the Markdown conversion process so that they can be used with MathJax. p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} , p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} . Admonition \u00b6 Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content Note !!! note For fixed block Note ??? note For collapsible block Supported types: note, seealso abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq warning, caution, attention failure, fail, missing danger, error Bug Example quote, cite Content tab \u00b6 Unordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Keys \u00b6 ++ctrl+alt+del++ ++ctrl+C++","title":"Help"},{"location":"doc/md/#usage-and-plugins","text":"mkdocs mkdocs-material Github guide","title":"usage and plugins"},{"location":"doc/md/#comments","text":"[comment]: <> (This is a comment, it will not be included) [//]: <> (This is also a comment.) [//]: # (This may be the most platform independent comment) Source: Stack Overflow 4823469","title":"Comments"},{"location":"doc/md/#extensions","text":"","title":"Extensions"},{"location":"doc/md/#pymdown-extensions","text":"Collection of extensions for Python Markdown. Arithmatex is an extension that preserves LaTeX math equations during the Markdown conversion process so that they can be used with MathJax. p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} , p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} .","title":"PyMdown extensions  "},{"location":"doc/md/#admonition","text":"Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content Note !!! note For fixed block Note ??? note For collapsible block Supported types: note, seealso abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq warning, caution, attention failure, fail, missing danger, error Bug Example quote, cite","title":"Admonition"},{"location":"doc/md/#content-tab","text":"Unordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Content tab"},{"location":"doc/md/#keys","text":"++ctrl+alt+del++ ++ctrl+C++","title":"Keys"},{"location":"editor/vim/edition/","text":"Editing \u00b6 Operation ...entire line ...to eol entire word ...to eow ... to begin of next word Change cc C ( or c$ ) ciw / caw cw (or ce ) Delete dd D ( or d$ ) diw / daw de dw Registers \u00b6 There are 10 types of :h registers : The unnamed register \"\" 10 numbered registers \"0 to \"9 filled with text from the last 10 yank and delete commands. The small delete register \"- from commands that delete less than a line. 26 named registers \"a to \"z or \"A to \"Z Three read-only registers: \": , most recent command, \". , \"% , name of the current file) Alternate buffer register \"# The expression register \"= : The selection and drop registers (: \"* , contains the PRIMARY selection which is available on Linux when users select some data. \"+ , contains the CLIPBOARD select, available on active requests of copy. To use the PRIMARY selection too, set clipboard^=unnamed,unnamedplus \"~ registers the dropped text from the last drag'n'drop operation. The black hole register \"_ Last search pattern register \"/ Insertion of register in command mode in triggerd by C-r . Selection \u00b6 :h text-objects or operate in visual mode and consists ot two characters: i and a and correspond to an inner resp. outer selection. Comment \u00b6 Comment line (via plugin vim-commentary): gcc in normal mode, gc in visual mode Surroung element while editing Completion \u00b6 complete \u00b6 Completion is set up by the complete options, a list of location used for completion lookup. The default is \".,w,b,u,t,i\", which means to scan: 1. the current buffer 2. buffers in other windows 3. other loaded buffers 4. unloaded buffers 5. tags 6. included files See h: 535 completeopt \u00b6 The completion menu appearance is controlled by completeopt ( ofu ) ins-completion \u00b6 Completion in insert mode h: ins-completion is activated with C-x and triggers a sub-mode h: i_CTRL-X . Desc Key 1. Whole lines CTRL-L 2. keywords in the current file CTRL-N 3. keywords in 'dictionary' CTRL-K 4. keywords in 'thesaurus', thesaurus-style CTRL-T 5. keywords in the current and included files CTRL-I 6. tags CTRL-] 7. file names CTRL-F 8. definitions or macros CTRL-D 9. Vim command-line CTRL-V 10. User defined completion CTRL-U 11. omni completion CTRL-O 12. Spelling suggestions s 13. keywords in 'complete' CTRL-N / CTRL-P omnifunc \u00b6 Omni completion supports filetype-specific completion. Ex: omnifunc=htmlcomplete#CompleteTags function! InputTarget() let c = getchar() echo c endfunction function! Codify() let selection = getpos('.') echo string(selection) . \"Yo\" \" Get selection \" Length == 1 (normal mode) \" -> expand selection to zone delimited by space \" Length >= 1 (visual mode) \" -> get selection and introduce ` around selection endfunction Syntax \u00b6 Keywords \u00b6 The generic form for defining syntaxing is: syntax keyword {group} {keyword} ... The correspoding hightlighting is set with hightlight Example syntax keyword xType int long char highlight link xType Type Matches \u00b6 Syntax can match ordinary identifiers: syntax match xIdentifier /\\<\\l\\+\\>/ Keywords have a high precedence over matches. Regions \u00b6 Region can be defined with a start and end parameter, optional skip : syntax region xString start = /\"/ end = /\"/ syntax region xString start = /\"/ skip = /\\\\\"/ end = /\"/ Clusters \u00b6 A cluster is a collection of syntax groups. Example \" Instead of manualy defining elements contained in match syntax match xFor /^for.*/ contains = xNumber , xIdent syntax match xIf /^if.*/ contains = xNumber , xIdent syntax match xWhile /^while.*/ contains = xNumber , xIdent \" One can define a cluster syntax cluster xState contains = xNumber , xIdent \" And later reuse it syntax match xFor /^for.*/ contains = @xState syntax match xIf /^if.*/ contains = @xState syntax match xWhile /^while.*/ contains = @xState \" Add and remove to a cluster syntax cluster xState add = xString syntax cluster xState remove = xString Folding \u00b6 Types of Folding : Type Description manual folds are created manually and remain in RAM indent lines with equal indent form a fold expr vim scripts give identation of a line marker based on specific characters syntax syntax highlightung items specify folds diff fold test that is not changed The command zc will close a fold (if the cursor is in an open fold), and zo will open a fold (if the cursor is in a closed fold). It's easier to just use za which will toggle the current fold (close it if it was open, or open it if it was closed). The commands zc (close), zo (open), and za (toggle) operate on one level of folding, at the cursor. The commands zC, zO and zA are similar, but operate on all folding levels (for example, the cursor line may be in an open fold, which is inside another open fold; typing zC would close all folds at the cursor). The command zr reduces folding by opening one more level of folds throughout the whole buffer (the cursor position is not relevant). Use zR to open all folds. The command zm gives more folding by closing one more level of folds throughout the whole buffer. Use zM to close all folds. Source: https://vim.fandom.com/wiki/Folding Folding principel: folds at defined per level: :set foldlevel=<LEVEL> and adjacent lines are fold grouped by level value to fold level at start :set foldlevelstart=<LEVEL> Macros \u00b6 Editing a macro \u00b6 From vim.fandom.com : Type :let @a='i Press Ctrl-R Ctrl-R a to insert the current contents of register a (type Ctrl-R twice to insert the register exactly). Edit the text as required. Append an apostrophe ' to finish the command, and press Enter. Enter :reg a to view the new value in the register. Type @a to execute the contents of register a . Note the caveat above about macros which end in <CR> or <NL> . Linting \u00b6 ale","title":"Edition"},{"location":"editor/vim/edition/#editing","text":"Operation ...entire line ...to eol entire word ...to eow ... to begin of next word Change cc C ( or c$ ) ciw / caw cw (or ce ) Delete dd D ( or d$ ) diw / daw de dw","title":"Editing"},{"location":"editor/vim/edition/#registers","text":"There are 10 types of :h registers : The unnamed register \"\" 10 numbered registers \"0 to \"9 filled with text from the last 10 yank and delete commands. The small delete register \"- from commands that delete less than a line. 26 named registers \"a to \"z or \"A to \"Z Three read-only registers: \": , most recent command, \". , \"% , name of the current file) Alternate buffer register \"# The expression register \"= : The selection and drop registers (: \"* , contains the PRIMARY selection which is available on Linux when users select some data. \"+ , contains the CLIPBOARD select, available on active requests of copy. To use the PRIMARY selection too, set clipboard^=unnamed,unnamedplus \"~ registers the dropped text from the last drag'n'drop operation. The black hole register \"_ Last search pattern register \"/ Insertion of register in command mode in triggerd by C-r .","title":"Registers"},{"location":"editor/vim/edition/#selection","text":":h text-objects or operate in visual mode and consists ot two characters: i and a and correspond to an inner resp. outer selection.","title":"Selection"},{"location":"editor/vim/edition/#comment","text":"Comment line (via plugin vim-commentary): gcc in normal mode, gc in visual mode Surroung element while editing","title":"Comment"},{"location":"editor/vim/edition/#completion","text":"","title":"Completion"},{"location":"editor/vim/edition/#complete","text":"Completion is set up by the complete options, a list of location used for completion lookup. The default is \".,w,b,u,t,i\", which means to scan: 1. the current buffer 2. buffers in other windows 3. other loaded buffers 4. unloaded buffers 5. tags 6. included files See h: 535","title":"complete"},{"location":"editor/vim/edition/#completeopt","text":"The completion menu appearance is controlled by completeopt ( ofu )","title":"completeopt"},{"location":"editor/vim/edition/#ins-completion","text":"Completion in insert mode h: ins-completion is activated with C-x and triggers a sub-mode h: i_CTRL-X . Desc Key 1. Whole lines CTRL-L 2. keywords in the current file CTRL-N 3. keywords in 'dictionary' CTRL-K 4. keywords in 'thesaurus', thesaurus-style CTRL-T 5. keywords in the current and included files CTRL-I 6. tags CTRL-] 7. file names CTRL-F 8. definitions or macros CTRL-D 9. Vim command-line CTRL-V 10. User defined completion CTRL-U 11. omni completion CTRL-O 12. Spelling suggestions s 13. keywords in 'complete' CTRL-N / CTRL-P","title":"ins-completion"},{"location":"editor/vim/edition/#omnifunc","text":"Omni completion supports filetype-specific completion. Ex: omnifunc=htmlcomplete#CompleteTags function! InputTarget() let c = getchar() echo c endfunction function! Codify() let selection = getpos('.') echo string(selection) . \"Yo\" \" Get selection \" Length == 1 (normal mode) \" -> expand selection to zone delimited by space \" Length >= 1 (visual mode) \" -> get selection and introduce ` around selection endfunction","title":"omnifunc"},{"location":"editor/vim/edition/#syntax","text":"","title":"Syntax"},{"location":"editor/vim/edition/#keywords","text":"The generic form for defining syntaxing is: syntax keyword {group} {keyword} ... The correspoding hightlighting is set with hightlight Example syntax keyword xType int long char highlight link xType Type","title":"Keywords"},{"location":"editor/vim/edition/#matches","text":"Syntax can match ordinary identifiers: syntax match xIdentifier /\\<\\l\\+\\>/ Keywords have a high precedence over matches.","title":"Matches"},{"location":"editor/vim/edition/#regions","text":"Region can be defined with a start and end parameter, optional skip : syntax region xString start = /\"/ end = /\"/ syntax region xString start = /\"/ skip = /\\\\\"/ end = /\"/","title":"Regions"},{"location":"editor/vim/edition/#clusters","text":"A cluster is a collection of syntax groups. Example \" Instead of manualy defining elements contained in match syntax match xFor /^for.*/ contains = xNumber , xIdent syntax match xIf /^if.*/ contains = xNumber , xIdent syntax match xWhile /^while.*/ contains = xNumber , xIdent \" One can define a cluster syntax cluster xState contains = xNumber , xIdent \" And later reuse it syntax match xFor /^for.*/ contains = @xState syntax match xIf /^if.*/ contains = @xState syntax match xWhile /^while.*/ contains = @xState \" Add and remove to a cluster syntax cluster xState add = xString syntax cluster xState remove = xString","title":"Clusters"},{"location":"editor/vim/edition/#folding","text":"Types of Folding : Type Description manual folds are created manually and remain in RAM indent lines with equal indent form a fold expr vim scripts give identation of a line marker based on specific characters syntax syntax highlightung items specify folds diff fold test that is not changed The command zc will close a fold (if the cursor is in an open fold), and zo will open a fold (if the cursor is in a closed fold). It's easier to just use za which will toggle the current fold (close it if it was open, or open it if it was closed). The commands zc (close), zo (open), and za (toggle) operate on one level of folding, at the cursor. The commands zC, zO and zA are similar, but operate on all folding levels (for example, the cursor line may be in an open fold, which is inside another open fold; typing zC would close all folds at the cursor). The command zr reduces folding by opening one more level of folds throughout the whole buffer (the cursor position is not relevant). Use zR to open all folds. The command zm gives more folding by closing one more level of folds throughout the whole buffer. Use zM to close all folds. Source: https://vim.fandom.com/wiki/Folding Folding principel: folds at defined per level: :set foldlevel=<LEVEL> and adjacent lines are fold grouped by level value to fold level at start :set foldlevelstart=<LEVEL>","title":"Folding"},{"location":"editor/vim/edition/#macros","text":"","title":"Macros"},{"location":"editor/vim/edition/#editing-a-macro","text":"From vim.fandom.com : Type :let @a='i Press Ctrl-R Ctrl-R a to insert the current contents of register a (type Ctrl-R twice to insert the register exactly). Edit the text as required. Append an apostrophe ' to finish the command, and press Enter. Enter :reg a to view the new value in the register. Type @a to execute the contents of register a . Note the caveat above about macros which end in <CR> or <NL> .","title":"Editing a macro"},{"location":"editor/vim/edition/#linting","text":"ale","title":"Linting"},{"location":"editor/vim/intro/","text":"Vim \u00b6 Cheatsheet Start \u00b6 Vim can be started with several options, loading or not configuration file, plugins or viminfo. This can be especially useful in case of problem at start. vim -N -u NONE -U NONE -i NONE vim -N -u NONE -U NONE vim -N -u ~/.vimrc --noplugin -i NONE Initialisation \u00b6 :h init or At startup, Vim checks environment variables and files and sets values in this order: Set the 'shell' and 'term' option Process the arguments Execute Ex commands, from environment variables and/or files Load the plugin scripts. Set 'shellpipe' and 'shellredir' Set various less used initialization until windows open (see doc) Execute startup commands Configuration \u00b6 Vim has a number of internal variables and switches: options description of all options map key mapping and abbreviations autocmd automatically executing commands on an event fold hide (fold) ranges of lines When starting, vim will look in the runtimepath and underlying directories for runtime files. Basicaly on unix like systems: $HOME/.vim, $VIM/vimfiles, $VIMRUNTIME, $VIM/vimfiles/after, $HOME/.vim/after This is a list of some directories which will be searched for runtime files: File Description filetype.vim filetypes by file name new-filetype scripts.vim filetypes by file contents new-filetype-scripts autoload/ automatically loaded scripts autoload-functions colors/ color scheme files compiler/ compiler files ftplugin/ filetype plugins write-filetype-plugin import/ files that are found by :import indent/ indent scripts indent-expression pack/ packages :packadd plugin/ plugin scripts write-plugin syntax/ syntax files mysyntaxfile ~/.vim/syntax contains Packages (Plugins) \u00b6 :h packages' Links \u00b6 Learn vim script the hard way VIM cheatsheet VIM script aheatsheet","title":"Intro"},{"location":"editor/vim/intro/#vim","text":"Cheatsheet","title":"Vim"},{"location":"editor/vim/intro/#start","text":"Vim can be started with several options, loading or not configuration file, plugins or viminfo. This can be especially useful in case of problem at start. vim -N -u NONE -U NONE -i NONE vim -N -u NONE -U NONE vim -N -u ~/.vimrc --noplugin -i NONE","title":"Start"},{"location":"editor/vim/intro/#initialisation","text":":h init or At startup, Vim checks environment variables and files and sets values in this order: Set the 'shell' and 'term' option Process the arguments Execute Ex commands, from environment variables and/or files Load the plugin scripts. Set 'shellpipe' and 'shellredir' Set various less used initialization until windows open (see doc) Execute startup commands","title":"Initialisation"},{"location":"editor/vim/intro/#configuration","text":"Vim has a number of internal variables and switches: options description of all options map key mapping and abbreviations autocmd automatically executing commands on an event fold hide (fold) ranges of lines When starting, vim will look in the runtimepath and underlying directories for runtime files. Basicaly on unix like systems: $HOME/.vim, $VIM/vimfiles, $VIMRUNTIME, $VIM/vimfiles/after, $HOME/.vim/after This is a list of some directories which will be searched for runtime files: File Description filetype.vim filetypes by file name new-filetype scripts.vim filetypes by file contents new-filetype-scripts autoload/ automatically loaded scripts autoload-functions colors/ color scheme files compiler/ compiler files ftplugin/ filetype plugins write-filetype-plugin import/ files that are found by :import indent/ indent scripts indent-expression pack/ packages :packadd plugin/ plugin scripts write-plugin syntax/ syntax files mysyntaxfile ~/.vim/syntax contains","title":"Configuration"},{"location":"editor/vim/intro/#packages-plugins","text":":h packages'","title":"Packages (Plugins)"},{"location":"editor/vim/intro/#links","text":"Learn vim script the hard way VIM cheatsheet VIM script aheatsheet","title":"Links"},{"location":"editor/vim/languages/","text":"LSP \u00b6 Language Server Protocol Source: Microsoft on Github A language server runs as a separate process and development tools communicate with the server using the language protocol over JSON-RPC Example of server-client communication: Implementation \u00b6 Coc.vim \u00b6 has full support for Language Server Protocol completion LanguageClient-neovim \u00b6 Language specific \u00b6 go \u00b6 LSP server html \u00b6 :set omnifunc=htmlcomplete#CompleteTags Javascript \u00b6 vim-javascript , comment stuff out vim-polyglot , collection of language packs for Vim. Links: A guide to setting up Vim for JavaScript development JavaScript Documentation Standards Mardown md \u00b6 vim-markdown , Markdown Vim Mode. Python \u00b6 LSP server https://docs.python-guide.org/dev/env/ https://www.vimfromscratch.com/articles/vim-for-python/ https://github.com/neoclide/coc-python jedi-language-server Vim \u00b6 LSP server let g:markdown_fenced_languages = ['vim', 'help'] This is a JS project, installation done with yarn global add vim-language-server YAML \u00b6 LSP server","title":"Language support"},{"location":"editor/vim/languages/#lsp","text":"Language Server Protocol Source: Microsoft on Github A language server runs as a separate process and development tools communicate with the server using the language protocol over JSON-RPC Example of server-client communication:","title":"LSP"},{"location":"editor/vim/languages/#implementation","text":"","title":"Implementation"},{"location":"editor/vim/languages/#cocvim","text":"has full support for Language Server Protocol completion","title":"Coc.vim"},{"location":"editor/vim/languages/#languageclient-neovim","text":"","title":"LanguageClient-neovim"},{"location":"editor/vim/languages/#language-specific","text":"","title":"Language specific"},{"location":"editor/vim/languages/#go","text":"LSP server","title":"go"},{"location":"editor/vim/languages/#html","text":":set omnifunc=htmlcomplete#CompleteTags","title":"html"},{"location":"editor/vim/languages/#javascript","text":"vim-javascript , comment stuff out vim-polyglot , collection of language packs for Vim. Links: A guide to setting up Vim for JavaScript development JavaScript Documentation Standards","title":"Javascript"},{"location":"editor/vim/languages/#mardown-md","text":"vim-markdown , Markdown Vim Mode.","title":"Mardown md"},{"location":"editor/vim/languages/#python","text":"LSP server https://docs.python-guide.org/dev/env/ https://www.vimfromscratch.com/articles/vim-for-python/ https://github.com/neoclide/coc-python jedi-language-server","title":"Python"},{"location":"editor/vim/languages/#vim","text":"LSP server let g:markdown_fenced_languages = ['vim', 'help'] This is a JS project, installation done with yarn global add vim-language-server","title":"Vim"},{"location":"editor/vim/languages/#yaml","text":"LSP server","title":"YAML"},{"location":"editor/vim/motion/","text":"The last motion commands can be repeated with ;","title":"Motion"},{"location":"editor/vim/panes/","text":"Interface \u00b6 Close a terminal pane with C-w C-c To change two verticaly split windows to horizonaly split C-w t C-w K Horizontally to verticaly: C-w t C-w H C-w t makes the first (topleft) window current C-w H moves the current window to full-height at far left C-w K moves the current window to full-width at the very top","title":"Panes"},{"location":"editor/vim/panes/#interface","text":"Close a terminal pane with C-w C-c To change two verticaly split windows to horizonaly split C-w t C-w K Horizontally to verticaly: C-w t C-w H C-w t makes the first (topleft) window current C-w H moves the current window to full-height at far left C-w K moves the current window to full-width at the very top","title":"Interface"},{"location":"editor/vim/plugins/","text":"Plugins \u00b6 Vim interface \u00b6 Airline \u00b6 provides a status/tabline for vim. Airline integrates with a lot of utilities and therefor has a lot of configuration variables, see doc. Github project README +-----------------------------------------------------------------------------+ |~ | |~ | |~ VIM - Vi IMproved | |~ | |~ version 8.2 | |~ by Bram Moolenaar et al. | |~ Vim is open source and freely distributable | |~ | |~ type :h :q<Enter> to exit | |~ type :help<Enter> or <F1> for on-line help | |~ type :help version8<Enter> for version info | |~ | |~ | +-----------------------------------------------------------------------------+ | A | B | C X | Y | Z | [...] | +-----------------------------------------------------------------------------+ The statusline is the colored line at the bottom, which contains the sections (possibly in different colors): section meaning (example) A displays the mode + additional flags like crypt/spell/paste (INSERT) B Environment status (VCS information - branch, hunk summary (master), [battery][61] level) C filename + read-only flag (~/.vim/vimrc RO) X filetype (vim) Y file encoding[fileformat] (utf-8[unix]) Z current position in the file [...] additional sections (warning/errors/statistics) from external plugins (e.g. YCM, syntastic, ...) The information in Section Z looks like this: 10% \u2630 10/100 ln : 20 This means: 10% - 10 percent down the top of the file \u2630 10 - current line 10 /100 ln - of 100 lines : 20 - current column 20 Commands Command Descrption :AirlineTheme {theme-name} Displays or changes the current theme. random will switch to a random theme. :AirlineToggleWhitespace Toggles whitespace detection. :AirlineToggle between the standard 'statusline' and airline. :AirlineRefresh[!] Refreshes all highlight groups and redraws the statusline. With the '!' attribute, skips refreshing the highlighting groups. :AirlineExtensions Shows the status of all available airline extensions. Extern means, the extensions does not come bundled with Airline. Airline section variable names default content let g:airline_section_a (mode, crypt, paste, spell, iminsert) let g:airline_section_b (hunks, branch) let g:airline_section_c (bufferline or filename, readonly) let g:airline_section_gutter (csv) let g:airline_section_x (tagbar, filetype, virtualenv) let g:airline_section_y (fileencoding, fileformat) let g:airline_section_z (percentage, line number, column number) let g:airline_section_error (ycm_error_count, syntastic-err, eclim, languageclient_error_count) let g:airline_section_warning (ycm_warning_count, syntastic-warn, languageclient_warning_count, whitespace) Section b needs the fugitive plugin-in. Configuration \" the separator used on the left and right side let g :airline_left_sep = '' let g :airline_right_sep = '' \" enable fzf integration let g :airline#extensions#fzf#enabled = 1 \" tabline activated in airline let g :airline#extensions# tabline #enabled = 1 let g :airline#extensions# tabline #left_sep = ' ' let g :airline#extensions# tabline #left_alt_sep = '|' let g :airline#extensions# tabline #formatter = 'unique_tail_improved' \" let g:airline_theme = 'sonokai' let g :airline_powerline_fonts = 1 echodoc.vim displays function signatures from completions in the command line. Tags \u00b6 https://github.com/liuchengxu/vista.vi://github.com/liuchengxu/vista.vim Session \u00b6 obsession continuously updates session files. :mksession command to write a file. File editing \u00b6 vim-commentary comment stuff out vim-surround provides mapping for parentheses, brackets, quotes, XML tags, and more. vim-multiple-cursors is a Sublime Text style multiple selections for Vim Browse files: nnn \u00b6 Other projects: Ranger.vim , Ranger integration in vim search; fzf \u00b6 Commands \u00b6 Command Description :Files [PATH] Files (runs $FZF_DEFAULT_COMMAND if defined) :GFiles [OPTS] Git files ( git ls-files ) :GFiles? Git files ( git status ) :Buffers Open buffers :Colors Color schemes :Ag [PATTERN] ag search result ( ALT-A to select all, ALT-D to deselect all) :Rg [PATTERN] rg search result ( ALT-A to select all, ALT-D to deselect all) :Lines [QUERY] Lines in loaded buffers :BLines [QUERY] Lines in the current buffer :Tags [QUERY] Tags in the project ( ctags -R ) :BTags [QUERY] Tags in the current buffer :Marks Marks :Windows Windows :Locate PATTERN locate command output :History v:oldfiles and open buffers :History: Command history :History/ Search history :Snippets Snippets ( UltiSnips ) :Commits Git commits (requires [fugitive.vim][f]) :BCommits Git commits for the current buffer :Commands Commands :Maps Normal mode mappings :Helptags Help tags 1 :Filetypes File types Other projects: ctrlp.vim is a fuzzy file, buffer, mru, tag finder. ack.vim is a plugin for the Perl module / CLI script 'ack'. DB \u00b6 Modern database interface for Vim Linting: ALE \u00b6 ALE supports a wide range of tools","title":"Plugins"},{"location":"editor/vim/plugins/#plugins","text":"","title":"Plugins"},{"location":"editor/vim/plugins/#vim-interface","text":"","title":"Vim interface"},{"location":"editor/vim/plugins/#airline","text":"provides a status/tabline for vim. Airline integrates with a lot of utilities and therefor has a lot of configuration variables, see doc. Github project README +-----------------------------------------------------------------------------+ |~ | |~ | |~ VIM - Vi IMproved | |~ | |~ version 8.2 | |~ by Bram Moolenaar et al. | |~ Vim is open source and freely distributable | |~ | |~ type :h :q<Enter> to exit | |~ type :help<Enter> or <F1> for on-line help | |~ type :help version8<Enter> for version info | |~ | |~ | +-----------------------------------------------------------------------------+ | A | B | C X | Y | Z | [...] | +-----------------------------------------------------------------------------+ The statusline is the colored line at the bottom, which contains the sections (possibly in different colors): section meaning (example) A displays the mode + additional flags like crypt/spell/paste (INSERT) B Environment status (VCS information - branch, hunk summary (master), [battery][61] level) C filename + read-only flag (~/.vim/vimrc RO) X filetype (vim) Y file encoding[fileformat] (utf-8[unix]) Z current position in the file [...] additional sections (warning/errors/statistics) from external plugins (e.g. YCM, syntastic, ...) The information in Section Z looks like this: 10% \u2630 10/100 ln : 20 This means: 10% - 10 percent down the top of the file \u2630 10 - current line 10 /100 ln - of 100 lines : 20 - current column 20","title":"Airline"},{"location":"editor/vim/plugins/#tags","text":"https://github.com/liuchengxu/vista.vi://github.com/liuchengxu/vista.vim","title":"Tags"},{"location":"editor/vim/plugins/#session","text":"obsession continuously updates session files. :mksession command to write a file.","title":"Session"},{"location":"editor/vim/plugins/#file-editing","text":"vim-commentary comment stuff out vim-surround provides mapping for parentheses, brackets, quotes, XML tags, and more. vim-multiple-cursors is a Sublime Text style multiple selections for Vim","title":"File editing"},{"location":"editor/vim/plugins/#browse-files-nnn","text":"Other projects: Ranger.vim , Ranger integration in vim","title":"Browse files: nnn"},{"location":"editor/vim/plugins/#search-fzf","text":"","title":"search; fzf"},{"location":"editor/vim/plugins/#commands","text":"Command Description :Files [PATH] Files (runs $FZF_DEFAULT_COMMAND if defined) :GFiles [OPTS] Git files ( git ls-files ) :GFiles? Git files ( git status ) :Buffers Open buffers :Colors Color schemes :Ag [PATTERN] ag search result ( ALT-A to select all, ALT-D to deselect all) :Rg [PATTERN] rg search result ( ALT-A to select all, ALT-D to deselect all) :Lines [QUERY] Lines in loaded buffers :BLines [QUERY] Lines in the current buffer :Tags [QUERY] Tags in the project ( ctags -R ) :BTags [QUERY] Tags in the current buffer :Marks Marks :Windows Windows :Locate PATTERN locate command output :History v:oldfiles and open buffers :History: Command history :History/ Search history :Snippets Snippets ( UltiSnips ) :Commits Git commits (requires [fugitive.vim][f]) :BCommits Git commits for the current buffer :Commands Commands :Maps Normal mode mappings :Helptags Help tags 1 :Filetypes File types Other projects: ctrlp.vim is a fuzzy file, buffer, mru, tag finder. ack.vim is a plugin for the Perl module / CLI script 'ack'.","title":"Commands"},{"location":"editor/vim/plugins/#db","text":"Modern database interface for Vim","title":"DB"},{"location":"editor/vim/plugins/#linting-ale","text":"ALE supports a wide range of tools","title":"Linting: ALE"},{"location":"editor/vim/script/","text":"Vim script \u00b6 Options \u00b6 Set options : set or se Cmd Comment :se[t][!] show all options that differ from the default value, ! forces printing to new line :se[t][!] all show all but terminal options, if ! : every option is on a separate line. :se[t] {option}? show value of option :se[t] {option} Toggle option: set, switch it on. Number option: show value. String option: show value. Variables \u00b6 Scope: Scope Identifier Comment buffer-variable b: Local to the current buffer. window-variable w: Local to the current window tabpage-variable t: Local to the current tab page. global-variable g: Global. local-variable l: Local to a function. script-variable s: Local to a Vim script. function-argument a: Function argument (only inside a function). vim-variable v: Global, predefined by Vim. Commands \u00b6 Vim doc: :h user-commands : com [mand][ ! ] [{attr}...] {cmd} {rep} -nargs : specify that the command can take arguments. -nargs=0 No arguments are allowed (the default) -nargs=1 Exactly one argument is required, it includes spaces -nargs=* Any number of arguments are allowed (0, 1, or many), separated by white space -nargs=? 0 or 1 arguments are allowed -nargs=+ Arguments must be supplied, but any number are allowed -complete enables argument completion. -complete=arglist file names in argument list -complete=augroup autocmd groups -complete=buffer buffer names -complete=behave :behave suboptions -complete=color color schemes -complete=command Ex command (and arguments) -complete=compiler compilers -complete=cscope |:cscope| suboptions -complete=dir directory names -complete=environment environment variable names -complete=event autocommand events -complete=expression Vim expression -complete=file file and directory names -complete=file_in_path file and directory names in |'path'| -complete=filetype filetype names |'filetype'| -complete=function function name -complete=help help subjects -complete=highlight highlight groups -complete=history :history suboptions -complete=locale locale names (as output of locale -a) -complete=mapclear buffer argument -complete=mapping mapping name -complete=menu menus -complete=messages |:messages| suboptions -complete=option options -complete=packadd optional package |pack-add| names -complete=shellcmd Shell command -complete=sign |:sign| suboptions -complete=syntax syntax file names |'syntax'| -complete=syntime |:syntime| suboptions -complete=tag tags -complete=tag_listfiles tags, file names are shown when CTRL-D is hit -complete=user user names -complete=var user variables -complete=custom,{func} custom completion, defined via {func} -complete=customlist,{func} custom completion, defined via {func} -bang The command can take a ! modifier (like :q or :w) -bar The command can be followed by a \"|\" and another command. A \"|\" inside the command argument is not allowed then. Also checks for a \" to start a comment. -register The first argument to the command can be an optional register name (like :del, :put, :yank). -buffer The command will only be available in the current buffer. -range Range allowed, default is current line -range=% Range allowed, default is whole file (1,$) -range=N A count (default N) which is specified in the line number position (like |:split|); allows for zero line number. -count=N A count (default N) which is specified either in the line number position, or as an initial argument (like |:Next|). -count acts like -count=0 Note that -range=N and -count=N are mutually exclusive - only one should be specified.","title":"Script"},{"location":"editor/vim/script/#vim-script","text":"","title":"Vim script"},{"location":"editor/vim/script/#options","text":"Set options : set or se Cmd Comment :se[t][!] show all options that differ from the default value, ! forces printing to new line :se[t][!] all show all but terminal options, if ! : every option is on a separate line. :se[t] {option}? show value of option :se[t] {option} Toggle option: set, switch it on. Number option: show value. String option: show value.","title":"Options"},{"location":"editor/vim/script/#variables","text":"Scope: Scope Identifier Comment buffer-variable b: Local to the current buffer. window-variable w: Local to the current window tabpage-variable t: Local to the current tab page. global-variable g: Global. local-variable l: Local to a function. script-variable s: Local to a Vim script. function-argument a: Function argument (only inside a function). vim-variable v: Global, predefined by Vim.","title":"Variables"},{"location":"editor/vim/script/#commands","text":"Vim doc: :h user-commands : com [mand][ ! ] [{attr}...] {cmd} {rep} -nargs : specify that the command can take arguments. -nargs=0 No arguments are allowed (the default) -nargs=1 Exactly one argument is required, it includes spaces -nargs=* Any number of arguments are allowed (0, 1, or many), separated by white space -nargs=? 0 or 1 arguments are allowed -nargs=+ Arguments must be supplied, but any number are allowed -complete enables argument completion. -complete=arglist file names in argument list -complete=augroup autocmd groups -complete=buffer buffer names -complete=behave :behave suboptions -complete=color color schemes -complete=command Ex command (and arguments) -complete=compiler compilers -complete=cscope |:cscope| suboptions -complete=dir directory names -complete=environment environment variable names -complete=event autocommand events -complete=expression Vim expression -complete=file file and directory names -complete=file_in_path file and directory names in |'path'| -complete=filetype filetype names |'filetype'| -complete=function function name -complete=help help subjects -complete=highlight highlight groups -complete=history :history suboptions -complete=locale locale names (as output of locale -a) -complete=mapclear buffer argument -complete=mapping mapping name -complete=menu menus -complete=messages |:messages| suboptions -complete=option options -complete=packadd optional package |pack-add| names -complete=shellcmd Shell command -complete=sign |:sign| suboptions -complete=syntax syntax file names |'syntax'| -complete=syntime |:syntime| suboptions -complete=tag tags -complete=tag_listfiles tags, file names are shown when CTRL-D is hit -complete=user user names -complete=var user variables -complete=custom,{func} custom completion, defined via {func} -complete=customlist,{func} custom completion, defined via {func} -bang The command can take a ! modifier (like :q or :w) -bar The command can be followed by a \"|\" and another command. A \"|\" inside the command argument is not allowed then. Also checks for a \" to start a comment. -register The first argument to the command can be an optional register name (like :del, :put, :yank). -buffer The command will only be available in the current buffer. -range Range allowed, default is current line -range=% Range allowed, default is whole file (1,$) -range=N A count (default N) which is specified in the line number position (like |:split|); allows for zero line number. -count=N A count (default N) which is specified either in the line number position, or as an initial argument (like |:Next|). -count acts like -count=0 Note that -range=N and -count=N are mutually exclusive - only one should be specified.","title":"Commands"},{"location":"editor/vim/search/","text":"Search \u00b6","title":"Search"},{"location":"editor/vim/search/#search","text":"","title":"Search"},{"location":"editor/vim/statusline/","text":"Status line \u00b6 Visibility \u00b6 Visibility is controled by set laststatus /badge-doc>","title":"Status line"},{"location":"editor/vim/statusline/#status-line","text":"","title":"Status line"},{"location":"editor/vim/statusline/#visibility","text":"Visibility is controled by set laststatus /badge-doc>","title":"Visibility"},{"location":"extern/md-guide/","text":"Markdown Guide \u00b6 The Markdown Guide is a comprehensive Markdown reference designed for both novices and experts. It was born out of frustration with existing Markdown references that are incomplete, inadequate, or both. Contributing \u00b6 Contributions are welcome. Feel free to open a pull request with changes. Running it Locally \u00b6 It can be helpful to preview changes on your computer before opening a pull request. The Markdown Guide uses the Jekyll static site generator . After forking or cloning the repository, perform the following steps to generate the site and preview it: Make sure you have ruby installed on your computer. See https://www.ruby-lang.org/en/downloads/ bundle install bundle exec jekyll serve Point your browser at http://127.0.0.1:4000/ Adding tools \u00b6 See this page for information about adding applications to the Markdown tools directory . Deployment \u00b6 Pull requests merged to the master branch are automatically deployed to the production website. License \u00b6 The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license , and the underlying source code used to format and display that content is licensed under the MIT license .","title":"Markdown Guide"},{"location":"extern/md-guide/#markdown-guide","text":"The Markdown Guide is a comprehensive Markdown reference designed for both novices and experts. It was born out of frustration with existing Markdown references that are incomplete, inadequate, or both.","title":"Markdown Guide"},{"location":"extern/md-guide/#contributing","text":"Contributions are welcome. Feel free to open a pull request with changes.","title":"Contributing"},{"location":"extern/md-guide/#running-it-locally","text":"It can be helpful to preview changes on your computer before opening a pull request. The Markdown Guide uses the Jekyll static site generator . After forking or cloning the repository, perform the following steps to generate the site and preview it: Make sure you have ruby installed on your computer. See https://www.ruby-lang.org/en/downloads/ bundle install bundle exec jekyll serve Point your browser at http://127.0.0.1:4000/","title":"Running it Locally"},{"location":"extern/md-guide/#adding-tools","text":"See this page for information about adding applications to the Markdown tools directory .","title":"Adding tools"},{"location":"extern/md-guide/#deployment","text":"Pull requests merged to the master branch are automatically deployed to the production website.","title":"Deployment"},{"location":"extern/md-guide/#license","text":"The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license , and the underlying source code used to format and display that content is licensed under the MIT license .","title":"License"},{"location":"extern/md-guide/about/","text":"Purpose \u00b6 The Markdown Guide is a comprehensive Markdown reference designed for both novices and experts. It was born out of frustration with existing Markdown references that are incomplete, inadequate, or both. Contributing \u00b6 This is an open-source project, and your contributions are welcome. The repository is hosted on GitHub . See the README for instructions and guidelines. Reporting Issues \u00b6 Find a typo or inaccurate statement? Please create an issue in the GitHub project. Contacting \u00b6 Use the contact form to send a message to the maintainer of The Markdown Guide . Acknowledgements \u00b6 The Markdown Guide is made possible by the support of several individuals and organizations. Thanks to all who have contributed to this project. License \u00b6 The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license , and the underlying source code used to format and display that content is licensed under the MIT license . Affiliate Links \u00b6 Some links to products on this website use Amazon affiliate links. If you purchase an item through one of these links, I receive a small percentage of the purchase price (around 4-5%). Here's the fine print: The Markdown Guide is a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to Amazon.com.","title":"About"},{"location":"extern/md-guide/about/#purpose","text":"The Markdown Guide is a comprehensive Markdown reference designed for both novices and experts. It was born out of frustration with existing Markdown references that are incomplete, inadequate, or both.","title":"Purpose"},{"location":"extern/md-guide/about/#contributing","text":"This is an open-source project, and your contributions are welcome. The repository is hosted on GitHub . See the README for instructions and guidelines.","title":"Contributing"},{"location":"extern/md-guide/about/#reporting-issues","text":"Find a typo or inaccurate statement? Please create an issue in the GitHub project.","title":"Reporting Issues"},{"location":"extern/md-guide/about/#contacting","text":"Use the contact form to send a message to the maintainer of The Markdown Guide .","title":"Contacting"},{"location":"extern/md-guide/about/#acknowledgements","text":"The Markdown Guide is made possible by the support of several individuals and organizations. Thanks to all who have contributed to this project.","title":"Acknowledgements"},{"location":"extern/md-guide/about/#license","text":"The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license , and the underlying source code used to format and display that content is licensed under the MIT license .","title":"License"},{"location":"extern/md-guide/about/#affiliate-links","text":"Some links to products on this website use Amazon affiliate links. If you purchase an item through one of these links, I receive a small percentage of the purchase price (around 4-5%). Here's the fine print: The Markdown Guide is a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to Amazon.com.","title":"Affiliate Links"},{"location":"extern/md-guide/basic-syntax/","text":"{% include syntax.html type=\"basic\" syntax-id=\"overview\" %} {% include syntax.html type=\"basic\" syntax-id=\"headings\" %} {% include syntax.html type=\"basic\" syntax-id=\"paragraphs\" %} {% include syntax.html type=\"basic\" syntax-id=\"line-breaks\" %} {% include syntax.html type=\"basic\" syntax-id=\"emphasis\" %} {% include syntax.html type=\"basic\" syntax-id=\"blockquotes\" %} {% include syntax.html type=\"basic\" syntax-id=\"lists\" %} {% include syntax.html type=\"basic\" syntax-id=\"code\" %} {% include syntax.html type=\"basic\" syntax-id=\"horizontal-rules\" %} {% include syntax.html type=\"basic\" syntax-id=\"links\" %} {% include syntax.html type=\"basic\" syntax-id=\"images\" %} {% include syntax.html type=\"basic\" syntax-id=\"escaping-characters\" %} {% include syntax.html type=\"basic\" syntax-id=\"html\" %}","title":"MD: basic"},{"location":"extern/md-guide/book/","text":"The Markdown Guide By Matt Cone Learn Markdown in 60 pages. The Markdown Guide book includes everything you need to get started and master Markdown syntax. \u2714\ufe0f Professional quality PDF, MOBI, and EPUB files (DRM-free) \u2714\ufe0f Unlimited free lifetime updates \u2714\ufe0f 100% satisfaction guaranteed Buy now for $9.99 Read free sample The Markdown Guide is also available on Leanpub and Amazon . Read by professionals working at: Take your Markdown skills to the next level. Master the power of Markdown and take full control of the syntax. \ud83d\udcda Learn how Markdown works and dive in using an online editor. \ud83d\udcdd Practice using basic and extended Markdown syntax elements. \ud83d\udcaa Start using Markdown everywhere for all of your writing. What's inside. Detailed descriptions. Clear and concise examples. Beautifully formatted pages. What readers are saying. The Markdown Guide is hands-down the best Markdown reference. Michael Hartl, Founder of Learn Enough and author of the Ruby on Rails Tutorial The Markdown Guide is awesome. I keep it open in a browser tab for reference while working on my guides. Rob Reeder, Documentation Specialist, Software Engineering Institute, CMU Well done! This is an incredibly valuable and well-done resource. It does a great job of educating without becoming too overwhelming or too narrowly focused on one application of Markdown. nxprefect, via Reddit This book provides the right amount of information to learn Markdown and I highly recommend it! Mohamad Kalaaji, via Goodreads If you\u2019re working with Markdown, then do yourself a favour and check out The Markdown Guide ... It\u2019s excellent. Matthew Setter, via Twitter I've found this very simple guide to Markdown syntax very useful in a pinch. Morgan Thompson, via Twitter 100% satisfaction guaranteed. If you're not completely satisfied with The Markdown Guide , I'll refund your money, no questions asked. Buy now for $9.99 About the Author Matt Cone is a technical writer at Fastly . He has experience creating documentation for organizations like Linode and the U.S. Department of Health and Human Services. Matt's first book, Master Your Mac , was published by No Starch Press. To get in touch with Matt, visit https://www.mattcone.com .","title":"The Markdown Guide Book"},{"location":"extern/md-guide/cheat-sheet/","text":"Overview \u00b6 This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can't cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax . Basic Syntax \u00b6 These are the elements outlined in John Gruber's original design document. All Markdown applications support these elements. Element Markdown Syntax Heading # H1 ## H2 ### H3 Bold **bold text** Italic *italicized text* Blockquote > blockquote Ordered List 1. First item 2. Second item 3. Third item Unordered List - First item - Second item - Third item Code `code` Horizontal Rule --- Link [title](https://www.example.com) Image ![alt text](image.jpg) Extended Syntax \u00b6 These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements. Element Markdown Syntax Table | Syntax | Description | | ----------- | ----------- | | Header | Title | | Paragraph | Text | Fenced Code Block ``` { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` Footnote Here's a sentence with a footnote. [^1] [^1]: This is the footnote. Heading ID ### My Great Heading {#custom-id} Definition List term : definition Strikethrough ~~The world is flat.~~ Task List - [x] Write the press release - [ ] Update the website - [ ] Contact the media Downloads \u00b6 You can download this cheat sheet as a Markdown file for use in your Markdown application.","title":"Markdown Cheat Sheet"},{"location":"extern/md-guide/cheat-sheet/#overview","text":"This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can't cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax .","title":"Overview"},{"location":"extern/md-guide/cheat-sheet/#basic-syntax","text":"These are the elements outlined in John Gruber's original design document. All Markdown applications support these elements. Element Markdown Syntax Heading # H1 ## H2 ### H3 Bold **bold text** Italic *italicized text* Blockquote > blockquote Ordered List 1. First item 2. Second item 3. Third item Unordered List - First item - Second item - Third item Code `code` Horizontal Rule --- Link [title](https://www.example.com) Image ![alt text](image.jpg)","title":"Basic Syntax"},{"location":"extern/md-guide/cheat-sheet/#extended-syntax","text":"These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements. Element Markdown Syntax Table | Syntax | Description | | ----------- | ----------- | | Header | Title | | Paragraph | Text | Fenced Code Block ``` { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` Footnote Here's a sentence with a footnote. [^1] [^1]: This is the footnote. Heading ID ### My Great Heading {#custom-id} Definition List term : definition Strikethrough ~~The world is flat.~~ Task List - [x] Write the press release - [ ] Update the website - [ ] Contact the media","title":"Extended Syntax"},{"location":"extern/md-guide/cheat-sheet/#downloads","text":"You can download this cheat sheet as a Markdown file for use in your Markdown application.","title":"Downloads"},{"location":"extern/md-guide/contact/","text":"Email address We'll never share your email with anyone else. Message Submit","title":"Contact"},{"location":"extern/md-guide/extended-syntax/","text":"{% include syntax.html type=\"extended\" syntax-id=\"overview\" %} {% include syntax.html type=\"extended\" syntax-id=\"availability\" %} {% include syntax.html type=\"extended\" syntax-id=\"tables\" %} {% include syntax.html type=\"extended\" syntax-id=\"fenced-code-blocks\" %} {% include syntax.html type=\"extended\" syntax-id=\"footnotes\" %} {% include syntax.html type=\"extended\" syntax-id=\"heading-ids\" %} {% include syntax.html type=\"extended\" syntax-id=\"definition-lists\" %} {% include syntax.html type=\"extended\" syntax-id=\"strikethrough\" %} {% include syntax.html type=\"extended\" syntax-id=\"task-lists\" %} {% include syntax.html type=\"extended\" syntax-id=\"emoji\" %} {% include syntax.html type=\"extended\" syntax-id=\"automatic-url-linking\" %}","title":"MD: extended"},{"location":"extern/md-guide/getting-started/","text":"{% include_relative _getting-started/what-is-markdown.md %} {% include_relative _getting-started/why-use-markdown.md %} {% include_relative _getting-started/kicking-the-tires.md %} {% include_relative _getting-started/how-does-it-work.md %} {% include_relative _getting-started/whats-markdown-good-for.md %} {% include_relative _getting-started/flavors-of-markdown.md %} {% include_relative _getting-started/additional-resources.md %}","title":"Getting Started"},{"location":"extern/md-guide/tools/","text":"\ud83d\udc4b Howdy! This is the start of a comprehensive Markdown tool directory. Compiling all this will take some time! Learn how to contribute. {% for tool in site.tools %} {{ tool.title }} {{ tool.description }} Learn more {% endfor %}","title":"Tools"},{"location":"extern/md-guide/_basic-syntax/blockquotes/","text":"To create a blockquote, add a > in front of a paragraph. > Dorothy followed her through many of the beautiful rooms in her castle. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. Blockquotes with Multiple Paragraphs \u00b6 Blockquotes can contain multiple paragraphs. Add a > on the blank lines between the paragraphs. > Dorothy followed her through many of the beautiful rooms in her castle. > > The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Nested Blockquotes \u00b6 Blockquotes can be nested. Add a >> in front of the paragraph you want to nest. > Dorothy followed her through many of the beautiful rooms in her castle. > >> The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Blockquotes with Other Elements \u00b6 Blockquotes can contain other Markdown formatted elements. Not all elements can be used \u2014 you'll need to experiment to see which ones work. > #### The quarterly results look great! > > - Revenue was off the chart. > - Profits were higher than ever. > > *Everything* is going according to **plan**. The rendered output looks like this: The quarterly results look great! Revenue was off the chart. Profits were higher than ever. Everything is going according to plan .","title":"Blockquotes"},{"location":"extern/md-guide/_basic-syntax/blockquotes/#blockquotes-with-multiple-paragraphs","text":"Blockquotes can contain multiple paragraphs. Add a > on the blank lines between the paragraphs. > Dorothy followed her through many of the beautiful rooms in her castle. > > The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood.","title":"Blockquotes with Multiple Paragraphs"},{"location":"extern/md-guide/_basic-syntax/blockquotes/#nested-blockquotes","text":"Blockquotes can be nested. Add a >> in front of the paragraph you want to nest. > Dorothy followed her through many of the beautiful rooms in her castle. > >> The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood.","title":"Nested Blockquotes"},{"location":"extern/md-guide/_basic-syntax/blockquotes/#blockquotes-with-other-elements","text":"Blockquotes can contain other Markdown formatted elements. Not all elements can be used \u2014 you'll need to experiment to see which ones work. > #### The quarterly results look great! > > - Revenue was off the chart. > - Profits were higher than ever. > > *Everything* is going according to **plan**. The rendered output looks like this:","title":"Blockquotes with Other Elements"},{"location":"extern/md-guide/_basic-syntax/bold/","text":"To bold text, add two asterisks or underscores before and after a word or phrase. To bold the middle of a word for emphasis, add two asterisks without spaces around the letters. Markdown HTML Rendered Output I just love **bold text**. I just love <strong>bold text</strong>. I just love bold text . I just love __bold text__. I just love <strong>bold text</strong>. I just love bold text . Love**is**bold Love<strong>is</strong>bold Love is bold Bold Best Practices Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to bold the middle of a word for emphasis. \u2705 Do this \u274c Don't do this Love**is**bold Love__is__bold","title":"Bold"},{"location":"extern/md-guide/_basic-syntax/code/","text":"To denote a word or phrase as code, enclose it in backticks ( ` ). Markdown HTML Rendered Output At the command prompt, type `nano`. At the command prompt, type <code>nano</code>. At the command prompt, type nano . Escaping Backticks \u00b6 If the word or phrase you want to denote as code includes one or more backticks, you can escape it by enclosing the word or phrase in double backticks ( `` ). Markdown HTML Rendered Output ``Use `code` in your Markdown file.`` <code>Use `code` in your Markdown file.</code> Use `code` in your Markdown file. Code Blocks \u00b6 To create code blocks, indent every line of the block by at least four spaces or one tab. <html> <head> </head> </html> The rendered output looks like this: <html> <head> </head> </html> Note: To create code blocks without indenting lines, use fenced code blocks .","title":"Code"},{"location":"extern/md-guide/_basic-syntax/code/#escaping-backticks","text":"If the word or phrase you want to denote as code includes one or more backticks, you can escape it by enclosing the word or phrase in double backticks ( `` ). Markdown HTML Rendered Output ``Use `code` in your Markdown file.`` <code>Use `code` in your Markdown file.</code> Use `code` in your Markdown file.","title":"Escaping Backticks"},{"location":"extern/md-guide/_basic-syntax/code/#code-blocks","text":"To create code blocks, indent every line of the block by at least four spaces or one tab. <html> <head> </head> </html> The rendered output looks like this: <html> <head> </head> </html> Note: To create code blocks without indenting lines, use fenced code blocks .","title":"Code Blocks"},{"location":"extern/md-guide/_basic-syntax/emphasis/","text":"You can add emphasis by making text bold or italic. {% include syntax.html type=\"basic-sub\" syntax-id=\"bold\" %} {% include syntax.html type=\"basic-sub\" syntax-id=\"italic\" %} Bold and Italic \u00b6 To emphasize text with bold and italics at the same time, add three asterisks or underscores before and after a word or phrase. To bold and italicize the middle of a word for emphasis, add three asterisks without spaces around the letters. Markdown HTML Rendered Output This text is ***really important***. This text is <strong><em>really important</em></strong>. This text is really important . This text is ___really important___. This text is <strong><em>really important</em></strong>. This text is really important . This text is __*really important*__. This text is <strong><em>really important</em></strong>. This text is really important . This text is **_really important_**. This text is <strong><em>really important</em></strong>. This text is really important . This is really***very***important text. This is really<strong><em>very</em></strong>important text. This is really very important text. Bold and Italic Best Practices Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to bold and italicize the middle of a word for emphasis. \u2705 Do this \u274c Don't do this This is really***very***important text. This is really___very___important text.","title":"Emphasis"},{"location":"extern/md-guide/_basic-syntax/emphasis/#bold-and-italic","text":"To emphasize text with bold and italics at the same time, add three asterisks or underscores before and after a word or phrase. To bold and italicize the middle of a word for emphasis, add three asterisks without spaces around the letters. Markdown HTML Rendered Output This text is ***really important***. This text is <strong><em>really important</em></strong>. This text is really important . This text is ___really important___. This text is <strong><em>really important</em></strong>. This text is really important . This text is __*really important*__. This text is <strong><em>really important</em></strong>. This text is really important . This text is **_really important_**. This text is <strong><em>really important</em></strong>. This text is really important . This is really***very***important text. This is really<strong><em>very</em></strong>important text. This is really very important text.","title":"Bold and Italic"},{"location":"extern/md-guide/_basic-syntax/escaping-characters/","text":"To display a literal character that would otherwise be used to format text in a Markdown document, add a backslash ( \\ ) in front of the character. \\* Without the backslash, this would be a bullet in an unordered list. The rendered output looks like this: * Without the backslash, this would be a bullet in an unordered list. Characters You Can Escape \u00b6 You can use a backslash to escape the following characters. Character Name \\ backslash ` backtick (see also escaping backticks in code ) * asterisk _ underscore { } curly braces [ ] brackets ( ) parentheses # pound sign + plus sign - minus sign (hyphen) . dot ! exclamation mark | pipe (see also escaping pipe in tables )","title":"Escaping Characters"},{"location":"extern/md-guide/_basic-syntax/escaping-characters/#characters-you-can-escape","text":"You can use a backslash to escape the following characters. Character Name \\ backslash ` backtick (see also escaping backticks in code ) * asterisk _ underscore { } curly braces [ ] brackets ( ) parentheses # pound sign + plus sign - minus sign (hyphen) . dot ! exclamation mark | pipe (see also escaping pipe in tables )","title":"Characters You Can Escape"},{"location":"extern/md-guide/_basic-syntax/headings/","text":"To create a heading, add number signs ( # ) in front of a word or phrase. The number of number signs you use should correspond to the heading level. For example, to create a heading level three ( <h3> ), use three number signs (e.g., ### My Header ). Markdown HTML Rendered Output # Heading level 1 <h1>Heading level 1</h1> Heading level 1 ## Heading level 2 <h2>Heading level 2</h2> Heading level 2 ### Heading level 3 <h3>Heading level 3</h3> Heading level 3 #### Heading level 4 <h4>Heading level 4</h4> Heading level 4 ##### Heading level 5 <h5>Heading level 5</h5> Heading level 5 ###### Heading level 6 <h6>Heading level 6</h6> Heading level 6 Alternate Syntax \u00b6 Alternatively, on the line below the text, add any number of == characters for heading level 1 or -- characters for heading level 2. Markdown HTML Rendered Output Heading level 1 =============== <h1>Heading level 1</h1> Heading level 1 Heading level 2 --------------- <h2>Heading level 2</h2> Heading level 2 Heading Best Practices \u00b6 Markdown applications don't agree on how to handle a missing space between the number signs ( # ) and the heading name. For compatibility, always put a space between the number signs and the heading name. \u2705 Do this \u274c Don't do this # Here's a Heading #Here's a Heading","title":"Headings"},{"location":"extern/md-guide/_basic-syntax/headings/#alternate-syntax","text":"Alternatively, on the line below the text, add any number of == characters for heading level 1 or -- characters for heading level 2. Markdown HTML Rendered Output Heading level 1 =============== <h1>Heading level 1</h1>","title":"Alternate Syntax"},{"location":"extern/md-guide/_basic-syntax/headings/#heading-best-practices","text":"Markdown applications don't agree on how to handle a missing space between the number signs ( # ) and the heading name. For compatibility, always put a space between the number signs and the heading name. \u2705 Do this \u274c Don't do this # Here's a Heading #Here's a Heading","title":"Heading Best Practices"},{"location":"extern/md-guide/_basic-syntax/horizontal-rules/","text":"To create a horizontal rule, use three or more asterisks ( *** ), dashes ( --- ), or underscores ( ___ ) on a line by themselves. *** --- _________________ The rendered output of all three looks identical: Horizontal Rule Best Practices \u00b6 For compatibility, put blank lines before and after horizontal rules. \u2705 Do this \u274c Don't do this Try to put a blank line before... --- ...and after a horizontal rule. Without blank lines, this would be a heading. --- Don't do this!","title":"Horizontal Rules"},{"location":"extern/md-guide/_basic-syntax/horizontal-rules/#horizontal-rule-best-practices","text":"For compatibility, put blank lines before and after horizontal rules. \u2705 Do this \u274c Don't do this Try to put a blank line before... --- ...and after a horizontal rule. Without blank lines, this would be a heading. --- Don't do this!","title":"Horizontal Rule Best Practices"},{"location":"extern/md-guide/_basic-syntax/html/","text":"Many Markdown applications allow you to use HTML tags in Markdown-formatted text. This is helpful if you prefer certain HTML tags to Markdown syntax. For example, some people find it easier to use HTML tags for images. Using HTML is also helpful when you need to change the attributes of an element, like specifying the color of text or changing the width of an image. To use HTML, place the tags in the text of your Markdown-formatted file. This **word** is bold. This <em>word</em> is italic. The rendered output looks like this: This word is bold. This word is italic. HTML Best Practices \u00b6 For security reasons, not all Markdown applications support HTML in Markdown documents. When in doubt, check your Markdown application's documentation. Some applications support only a subset of HTML tags. Use blank lines to separate block-level HTML elements\u2009like <div> , <table> , <pre> , and <p> from the surrounding content. Try not to indent the tags with tabs or spaces \u2014 that can interfere with the formatting. You can't use Markdown syntax inside block-level HTML tags. For example, <p>italic and **bold**</p> won't work.","title":"HTML"},{"location":"extern/md-guide/_basic-syntax/html/#html-best-practices","text":"For security reasons, not all Markdown applications support HTML in Markdown documents. When in doubt, check your Markdown application's documentation. Some applications support only a subset of HTML tags. Use blank lines to separate block-level HTML elements\u2009like <div> , <table> , <pre> , and <p> from the surrounding content. Try not to indent the tags with tabs or spaces \u2014 that can interfere with the formatting. You can't use Markdown syntax inside block-level HTML tags. For example, <p>italic and **bold**</p> won't work.","title":"HTML Best Practices"},{"location":"extern/md-guide/_basic-syntax/images/","text":"To add an image, add an exclamation mark ( ! ), followed by alt text in brackets, and the path or URL to the image asset in parentheses. You can optionally add a title after the URL in the parentheses. ![Philadelphia's Magic Gardens. This place was so cool!](/assets/images/philly-magic-gardens.jpg \"Philadelphia's Magic Gardens\") The rendered output looks like this: Linking Images \u00b6 To add a link to an image, enclose the Markdown for the image in brackets, and then add the link in parentheses. [![An old rock in the desert](/assets/images/shiprock.jpg \"Shiprock, New Mexico by Beau Rogers\")](https://www.flickr.com/photos/beaurogers/31833779864/in/photolist-Qv3rFw-34mt9F-a9Cmfy-5Ha3Zi-9msKdv-o3hgjr-hWpUte-4WMsJ1-KUQ8N-deshUb-vssBD-6CQci6-8AFCiD-zsJWT-nNfsgB-dPDwZJ-bn9JGn-5HtSXY-6CUhAL-a4UTXB-ugPum-KUPSo-fBLNm-6CUmpy-4WMsc9-8a7D3T-83KJev-6CQ2bK-nNusHJ-a78rQH-nw3NvT-7aq2qf-8wwBso-3nNceh-ugSKP-4mh4kh-bbeeqH-a7biME-q3PtTf-brFpgb-cg38zw-bXMZc-nJPELD-f58Lmo-bXMYG-bz8AAi-bxNtNT-bXMYi-bXMY6-bXMYv) The rendered output looks like this:","title":"Images"},{"location":"extern/md-guide/_basic-syntax/images/#linking-images","text":"To add a link to an image, enclose the Markdown for the image in brackets, and then add the link in parentheses. [![An old rock in the desert](/assets/images/shiprock.jpg \"Shiprock, New Mexico by Beau Rogers\")](https://www.flickr.com/photos/beaurogers/31833779864/in/photolist-Qv3rFw-34mt9F-a9Cmfy-5Ha3Zi-9msKdv-o3hgjr-hWpUte-4WMsJ1-KUQ8N-deshUb-vssBD-6CQci6-8AFCiD-zsJWT-nNfsgB-dPDwZJ-bn9JGn-5HtSXY-6CUhAL-a4UTXB-ugPum-KUPSo-fBLNm-6CUmpy-4WMsc9-8a7D3T-83KJev-6CQ2bK-nNusHJ-a78rQH-nw3NvT-7aq2qf-8wwBso-3nNceh-ugSKP-4mh4kh-bbeeqH-a7biME-q3PtTf-brFpgb-cg38zw-bXMZc-nJPELD-f58Lmo-bXMYG-bz8AAi-bxNtNT-bXMYi-bXMY6-bXMYv) The rendered output looks like this:","title":"Linking Images"},{"location":"extern/md-guide/_basic-syntax/italic/","text":"To italicize text, add one asterisk or underscore before and after a word or phrase. To italicize the middle of a word for emphasis, add one asterisk without spaces around the letters. Markdown HTML Rendered Output Italicized text is the *cat's meow*. Italicized text is the <em>cat's meow</em>. Italicized text is the cat\u2019s meow . Italicized text is the _cat's meow_. Italicized text is the <em>cat's meow</em>. Italicized text is the cat\u2019s meow . A*cat*meow A<em>cat</em>meow A cat meow Italic Best Practices Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to italicize the middle of a word for emphasis. \u2705 Do this \u274c Don't do this A*cat*meow A_cat_meow","title":"Italic"},{"location":"extern/md-guide/_basic-syntax/line-breaks/","text":"To create a line break ( <br> ), end a line with two or more spaces, and then type return. Markdown HTML Rendered Output This is the first line. And this is the second line. <p>This is the first line.<br> And this is the second line.</p> This is the first line. And this is the second line. Line Break Best Practices \u00b6 You can use two or more spaces (commonly referred to as \"trailing whitespace\") for line breaks in nearly every Markdown application, but it's controversial. It's hard to see trailing whitespace in an editor, and many people accidentally or intentionally put two spaces after every sentence. For this reason, you may want to use something other than trailing whitespace for line breaks. Fortunately, there is another option supported by nearly every Markdown application: the <br> HTML tag. For compatibility, use trailing white space or the <br> HTML tag at the end of the line. There are two other options I don't recommend using. CommonMark and a few other lightweight markup languages let you type a backslash ( \\ ) at the end of the line, but not all Markdown applications support this, so it isn't a great option from a compatibility perspective. And at least a couple lightweight markup languages don't require anything at the end of the line \u2014 just type return and they'll create a line break. \u2705 Do this \u274c Don't do this First line with two spaces after. And the next line. First line with the HTML tag after.<br> And the next line. First line with a backslash after.\\ And the next line. First line with nothing after. And the next line.","title":"Line Breaks"},{"location":"extern/md-guide/_basic-syntax/line-breaks/#line-break-best-practices","text":"You can use two or more spaces (commonly referred to as \"trailing whitespace\") for line breaks in nearly every Markdown application, but it's controversial. It's hard to see trailing whitespace in an editor, and many people accidentally or intentionally put two spaces after every sentence. For this reason, you may want to use something other than trailing whitespace for line breaks. Fortunately, there is another option supported by nearly every Markdown application: the <br> HTML tag. For compatibility, use trailing white space or the <br> HTML tag at the end of the line. There are two other options I don't recommend using. CommonMark and a few other lightweight markup languages let you type a backslash ( \\ ) at the end of the line, but not all Markdown applications support this, so it isn't a great option from a compatibility perspective. And at least a couple lightweight markup languages don't require anything at the end of the line \u2014 just type return and they'll create a line break. \u2705 Do this \u274c Don't do this First line with two spaces after. And the next line. First line with the HTML tag after.<br> And the next line. First line with a backslash after.\\ And the next line. First line with nothing after. And the next line.","title":"Line Break Best Practices"},{"location":"extern/md-guide/_basic-syntax/links/","text":"To create a link, enclose the link text in brackets (e.g., [Duck Duck Go] ) and then follow it immediately with the URL in parentheses (e.g., (https://duckduckgo.com) ). My favorite search engine is [Duck Duck Go](https://duckduckgo.com). The rendered output looks like this: My favorite search engine is Duck Duck Go . Adding Titles \u00b6 You can optionally add a title for a link. This will appear as a tooltip when the user hovers over the link. To add a title, enclose it in parentheses after the URL. My favorite search engine is [Duck Duck Go](https://duckduckgo.com \"The best search engine for privacy\"). The rendered output looks like this: My favorite search engine is Duck Duck Go . URLs and Email Addresses \u00b6 To quickly turn a URL or email address into a link, enclose it in angle brackets. <https://www.markdownguide.org> <fake@example.com> The rendered output looks like this: https://www.markdownguide.org fake@example.com Formatting Links \u00b6 To emphasize links, add asterisks before and after the brackets and parentheses. To denote links as code , add backticks in the brackets. I love supporting the **[EFF](https://eff.org)**. This is the *[Markdown Guide](https://www.markdownguide.org)*. See the section on [`code`](#code). The rendered output looks like this: I love supporting the EFF . This is the Markdown Guide . See the section on code . Reference-style Links \u00b6 Reference-style links are a special kind of link that make URLs easier to display and read in Markdown. Reference-style links are constructed in two parts: the part you keep inline with your text and the part you store somewhere else in the file to keep the text easy to read. Formatting the First Part of the Link The first part of a reference-style link is formatted with two sets of brackets. The first set of brackets surrounds the text that should appear linked. The second set of brackets displays a label used to point to the link you're storing elsewhere in your document. Although not required, you can include a space between the first and second set of brackets. The label in the second set of brackets is not case sensitive and can include letters, numbers, spaces, or punctuation. This means the following example formats are roughly equivalent for the first part of the link: [hobbit-hole][1] [hobbit-hole] [1] Formatting the Second Part of the Link The second part of a reference-style link is formatted with the following attributes: The label, in brackets, followed immediately by a colon and at least one space (e.g., [label]: ). The URL for the link, which you can optionally enclose in angle brackets. The optional title for the link, which you can enclose in double quotes, single quotes, or parentheses. This means the following example formats are all roughly equivalent for the second part of the link: [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle \"Hobbit lifestyles\" [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle 'Hobbit lifestyles' [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle (Hobbit lifestyles) [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> \"Hobbit lifestyles\" [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> 'Hobbit lifestyles' [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> (Hobbit lifestyles) You can place this second part of the link anywhere in your Markdown document. Some people place them immediately after the paragraph in which they appear while other people place them at the end of the document (like endnotes or footnotes). An Example Putting the Parts Together Say you add a URL as a standard URL link to a paragraph and it looks like this in Markdown: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a [hobbit-hole](https://en.wikipedia.org/wiki/Hobbit#Lifestyle \"Hobbit lifestyles\"), and that means comfort. Though it may point to interesting additional information, the URL as displayed really doesn't add much to the existing raw text other than making it harder to read. To fix that, you could format the URL like this instead: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a [hobbit-hole][1], and that means comfort. [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> \"Hobbit lifestyles\" In both instances above, the rendered output would be identical: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole , and that means comfort. and the HTML for the link would be: <a href=\"https://en.wikipedia.org/wiki/Hobbit#Lifestyle\" title=\"Hobbit lifestyles\">hobbit-hole</a> Link Best Practices \u00b6 Markdown applications don't agree on how to handle spaces in the middle of a URL. For compatibility, try to URL encode any spaces with %20 . \u2705 Do this \u274c Don't do this [link](https://www.example.com/my%20great%20page) [link](https://www.example.com/my great page)","title":"Links"},{"location":"extern/md-guide/_basic-syntax/links/#adding-titles","text":"You can optionally add a title for a link. This will appear as a tooltip when the user hovers over the link. To add a title, enclose it in parentheses after the URL. My favorite search engine is [Duck Duck Go](https://duckduckgo.com \"The best search engine for privacy\"). The rendered output looks like this: My favorite search engine is Duck Duck Go .","title":"Adding Titles"},{"location":"extern/md-guide/_basic-syntax/links/#urls-and-email-addresses","text":"To quickly turn a URL or email address into a link, enclose it in angle brackets. <https://www.markdownguide.org> <fake@example.com> The rendered output looks like this: https://www.markdownguide.org fake@example.com","title":"URLs and Email Addresses"},{"location":"extern/md-guide/_basic-syntax/links/#formatting-links","text":"To emphasize links, add asterisks before and after the brackets and parentheses. To denote links as code , add backticks in the brackets. I love supporting the **[EFF](https://eff.org)**. This is the *[Markdown Guide](https://www.markdownguide.org)*. See the section on [`code`](#code). The rendered output looks like this: I love supporting the EFF . This is the Markdown Guide . See the section on code .","title":"Formatting Links"},{"location":"extern/md-guide/_basic-syntax/links/#reference-style-links","text":"Reference-style links are a special kind of link that make URLs easier to display and read in Markdown. Reference-style links are constructed in two parts: the part you keep inline with your text and the part you store somewhere else in the file to keep the text easy to read.","title":"Reference-style Links"},{"location":"extern/md-guide/_basic-syntax/links/#link-best-practices","text":"Markdown applications don't agree on how to handle spaces in the middle of a URL. For compatibility, try to URL encode any spaces with %20 . \u2705 Do this \u274c Don't do this [link](https://www.example.com/my%20great%20page) [link](https://www.example.com/my great page)","title":"Link Best Practices"},{"location":"extern/md-guide/_basic-syntax/lists/","text":"You can organize items into ordered and unordered lists. {% include syntax.html type=\"basic-sub\" syntax-id=\"ordered-lists\" %} {% include syntax.html type=\"basic-sub\" syntax-id=\"unordered-lists\" %} Adding Elements in Lists \u00b6 To add another element in a list while preserving the continuity of the list, indent the element four spaces or one tab, as shown in the following examples. Paragraphs * This is the first list item. * Here's the second list item. I need to add another paragraph below the second list item. * And here's the third list item. The rendered output looks like this: This is the first list item. Here's the second list item. I need to add another paragraph below the second list item. And here's the third list item. Blockquotes * This is the first list item. * Here's the second list item. > A blockquote would look great below the second list item. * And here's the third list item. The rendered output looks like this: This is the first list item. Here's the second list item. A blockquote would look great below the second list item. And here's the third list item. Code Blocks Code blocks are normally indented four spaces or one tab. When they're in a list, indent them eight spaces or two tabs. 1. Open the file. 2. Find the following code block on line 21: <html> <head> <title>Test</title> </head> 3. Update the title to match the name of your website. The rendered output looks like this: Open the file. Find the following code block on line 21: <html> <head> <title>Test</title> </head> Update the title to match the name of your website. Images 1. Open the file containing the Linux mascot. 2. Marvel at its beauty. ![Tux, the Linux mascot](/assets/images/tux.png) 3. Close the file. The rendered output looks like this: Open the file containing the Linux mascot. Marvel at its beauty. Close the file. Lists You can nest an unordered list in an ordered list, or vice versa. 1. First item 2. Second item 3. Third item - Indented item - Indented item 4. Fourth item The rendered output looks like this: First item Second item Third item Indented item Indented item Fourth item","title":"Lists"},{"location":"extern/md-guide/_basic-syntax/lists/#adding-elements-in-lists","text":"To add another element in a list while preserving the continuity of the list, indent the element four spaces or one tab, as shown in the following examples.","title":"Adding Elements in Lists"},{"location":"extern/md-guide/_basic-syntax/ordered-lists/","text":"To create an ordered list, add line items with numbers followed by periods. The numbers don't have to be in numerical order, but the list should start with the number one. Markdown HTML Rendered Output 1. First item 2. Second item 3. Third item 4. Fourth item <ol> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ol> First item Second item Third item Fourth item 1. First item 1. Second item 1. Third item 1. Fourth item <ol> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ol> First item Second item Third item Fourth item 1. First item 8. Second item 3. Third item 5. Fourth item <ol> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ol> First item Second item Third item Fourth item 1. First item 2. Second item 3. Third item 1. Indented item 2. Indented item 4. Fourth item <ol> <li>First item</li> <li>Second item</li> <li>Third item <ol> <li>Indented item</li> <li>Indented item</li> </ol> </li> <li>Fourth item</li> </ol> First item Second item Third item Indented item Indented item Fourth item Ordered List Best Practices CommonMark and a few other lightweight markup languages let you use a parenthesis ( ) ) as a delimiter (e.g., 1) First item ), but not all Markdown applications support this, so it isn\u2019t a great option from a compatibility perspective. For compatibility, use periods only. \u2705 Do this \u274c Don't do this 1. First item 2. Second item 1) First item 2) Second item","title":"Ordered Lists"},{"location":"extern/md-guide/_basic-syntax/overview/","text":"Nearly all Markdown applications support the basic syntax outlined in John Gruber's original design document. There are minor variations and discrepancies between Markdown processors \u2014 those are noted inline wherever possible.","title":"Overview"},{"location":"extern/md-guide/_basic-syntax/paragraphs/","text":"To create paragraphs, use a blank line to separate one or more lines of text. Markdown HTML Rendered Output I really like using Markdown. I think I'll use it to format all of my documents from now on. <p>I really like using Markdown.</p> <p>I think I'll use it to format all of my documents from now on.</p> I really like using Markdown. I think I'll use it to format all of my documents from now on. Paragraph Best Practices \u00b6 Unless the paragraph is in a list , don't indent paragraphs with spaces or tabs. \u2705 Do this \u274c Don't do this Don't put tabs or spaces in front of your paragraphs. Keep lines left-aligned like this. This can result in unexpected formatting problems. Don't add tabs or spaces in front of paragraphs.","title":"Paragraphs"},{"location":"extern/md-guide/_basic-syntax/paragraphs/#paragraph-best-practices","text":"Unless the paragraph is in a list , don't indent paragraphs with spaces or tabs. \u2705 Do this \u274c Don't do this Don't put tabs or spaces in front of your paragraphs. Keep lines left-aligned like this. This can result in unexpected formatting problems. Don't add tabs or spaces in front of paragraphs.","title":"Paragraph Best Practices"},{"location":"extern/md-guide/_basic-syntax/unordered-lists/","text":"To create an unordered list, add dashes ( - ), asterisks ( * ), or plus signs ( + ) in front of line items. Indent one or more items to create a nested list. Markdown HTML Rendered Output - First item - Second item - Third item - Fourth item <ul> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ul> First item Second item Third item Fourth item * First item * Second item * Third item * Fourth item <ul> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ul> First item Second item Third item Fourth item + First item + Second item + Third item + Fourth item <ul> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ul> First item Second item Third item Fourth item - First item - Second item - Third item - Indented item - Indented item - Fourth item <ul> <li>First item</li> <li>Second item</li> <li>Third item <ul> <li>Indented item</li> <li>Indented item</li> </ul> </li> <li>Fourth item</li> </ul> First item Second item Third item Indented item Indented item Fourth item Unordered List Best Practices Markdown applications don\u2019t agree on how to handle different delimiters in the same list. For compatibility, don't mix and match delimiters in the same list \u2014 pick one and stick with it. \u2705 Do this \u274c Don't do this - First item - Second item - Third item - Fourth item + First item * Second item - Third item + Fourth item","title":"Unordered Lists"},{"location":"extern/md-guide/_extended-syntax/automatic-url-linking/","text":"Many Markdown processors automatically turn URLs into links. That means if you type http://www.example.com, your Markdown processor will automatically turn it into a link even though you haven\u2019t used brackets . http://www.example.com The rendered output looks like this: http://www.example.com Disabling Automatic URL Linking \u00b6 If you don't want a URL to be automatically linked, you can remove the link by denoting the URL as code with backticks. `http://www.example.com` The rendered output looks like this: http://www.example.com","title":"Automatic URL Linking"},{"location":"extern/md-guide/_extended-syntax/automatic-url-linking/#disabling-automatic-url-linking","text":"If you don't want a URL to be automatically linked, you can remove the link by denoting the URL as code with backticks. `http://www.example.com` The rendered output looks like this: http://www.example.com","title":"Disabling Automatic URL Linking"},{"location":"extern/md-guide/_extended-syntax/availability/","text":"Not all Markdown applications support extended syntax elements. You'll need to check whether or not the lightweight markup language your application is using supports the extended syntax elements you want to use. If it doesn't, it may still be possible to enable extensions in your Markdown processor. Lightweight Markup Languages \u00b6 There are several lightweight markup languages that are supersets of Markdown. They include Gruber's basic syntax and build upon it by adding additional elements like tables, code blocks, syntax highlighting, URL auto-linking, and footnotes. Many of the most popular Markdown applications use one of the following lightweight markup languages: CommonMark GitHub Flavored Markdown (GFM) Markdown Extra MultiMarkdown R Markdown Markdown Processors \u00b6 There are dozens of Markdown processors available. Many of them allow you to add extensions that enable extended syntax elements. Check your processor's documentation for more information.","title":"Availability"},{"location":"extern/md-guide/_extended-syntax/availability/#lightweight-markup-languages","text":"There are several lightweight markup languages that are supersets of Markdown. They include Gruber's basic syntax and build upon it by adding additional elements like tables, code blocks, syntax highlighting, URL auto-linking, and footnotes. Many of the most popular Markdown applications use one of the following lightweight markup languages: CommonMark GitHub Flavored Markdown (GFM) Markdown Extra MultiMarkdown R Markdown","title":"Lightweight Markup Languages"},{"location":"extern/md-guide/_extended-syntax/availability/#markdown-processors","text":"There are dozens of Markdown processors available. Many of them allow you to add extensions that enable extended syntax elements. Check your processor's documentation for more information.","title":"Markdown Processors"},{"location":"extern/md-guide/_extended-syntax/definition-lists/","text":"Some Markdown processors allow you to create definition lists of terms and their corresponding definitions. To create a definition list, type the term on the first line. On the next line, type a colon followed by a space and the definition. First Term : This is the definition of the first term. Second Term : This is one definition of the second term. : This is another definition of the second term. The HTML looks like this: < dl > < dt > First Term </ dt > < dd > This is the definition of the first term. </ dd > < dt > Second Term </ dt > < dd > This is one definition of the second term. </ dd > < dd > This is another definition of the second term. </ dd > </ dl > The rendered output looks like this: First Term This is the definition of the first term. Second Term This is one definition of the second term. This is another definition of the second term.","title":"Definition Lists"},{"location":"extern/md-guide/_extended-syntax/emoji/","text":"There are two ways to add emoji to Markdown files: copy and paste the emoji into your Markdown-formatted text, or type emoji shortcodes . Copying and Pasting Emoji \u00b6 In most cases, you can simply copy an emoji from a source like Emojipedia and paste it into your document. Many Markdown applications will automatically display the emoji in the Markdown-formatted text. The HTML and PDF files you export from your Markdown application should display the emoji. Tip: If you're using a static site generator, make sure you encode HTML pages as UTF-8 . Using Emoji Shortcodes \u00b6 Some Markdown applications allow you to insert emoji by typing emoji shortcodes. These begin and end with a colon and include the name of an emoji. Gone camping! :tent: Be back soon. That is so funny! :joy: The rendered output looks like this: Gone camping! \u26fa Be back soon. That is so funny! \ud83d\ude02 Note: You can use this list of emoji shortcodes , but keep in mind that emoji shortcodes vary from application to application. Refer to your Markdown application's documentation for more information.","title":"Emoji"},{"location":"extern/md-guide/_extended-syntax/emoji/#copying-and-pasting-emoji","text":"In most cases, you can simply copy an emoji from a source like Emojipedia and paste it into your document. Many Markdown applications will automatically display the emoji in the Markdown-formatted text. The HTML and PDF files you export from your Markdown application should display the emoji. Tip: If you're using a static site generator, make sure you encode HTML pages as UTF-8 .","title":"Copying and Pasting Emoji"},{"location":"extern/md-guide/_extended-syntax/emoji/#using-emoji-shortcodes","text":"Some Markdown applications allow you to insert emoji by typing emoji shortcodes. These begin and end with a colon and include the name of an emoji. Gone camping! :tent: Be back soon. That is so funny! :joy: The rendered output looks like this: Gone camping! \u26fa Be back soon. That is so funny! \ud83d\ude02 Note: You can use this list of emoji shortcodes , but keep in mind that emoji shortcodes vary from application to application. Refer to your Markdown application's documentation for more information.","title":"Using Emoji Shortcodes"},{"location":"extern/md-guide/_extended-syntax/fenced-code-blocks/","text":"The basic Markdown syntax allows you to create code blocks by indenting lines by four spaces or one tab. If you find that inconvenient, try using fenced code blocks. Depending on your Markdown processor or editor, you'll use three backticks ( ``</code>) or three tildes ( ~ `) on the lines before and after the code block. The best part? You don't have to indent any lines! ``` { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` The rendered output looks like this: { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } Tip: Need to display backticks inside a code block? See this section to learn how to escape them. Syntax Highlighting \u00b6 Many Markdown processors support syntax highlighting for fenced code blocks. This feature allows you to add color highlighting for whatever language your code was written in. To add syntax highlighting, specify a language next to the backticks before the fenced code block. ```json { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` The rendered output looks like this: { \"firstName\" : \"John\" , \"lastName\" : \"Smith\" , \"age\" : 25 }","title":"Fenced Code Blocks"},{"location":"extern/md-guide/_extended-syntax/fenced-code-blocks/#syntax-highlighting","text":"Many Markdown processors support syntax highlighting for fenced code blocks. This feature allows you to add color highlighting for whatever language your code was written in. To add syntax highlighting, specify a language next to the backticks before the fenced code block. ```json { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` The rendered output looks like this: { \"firstName\" : \"John\" , \"lastName\" : \"Smith\" , \"age\" : 25 }","title":"Syntax Highlighting"},{"location":"extern/md-guide/_extended-syntax/footnotes/","text":"Footnotes allow you to add notes and references without cluttering the body of the document. When you create a footnote, a superscript number with a link appears where you added the footnote reference. Readers can click the link to jump to the content of the footnote at the bottom of the page. To create a footnote reference, add a caret and an identifier inside brackets ( [^1] ). Identifiers can be numbers or words, but they can't contain spaces or tabs. Identifiers only correlate the footnote reference with the footnote itself \u2014 in the output, footnotes are numbered sequentially. Add the footnote using another caret and number inside brackets with a colon and text ( [^1]: My footnote. ). You don't have to put footnotes at the end of the document. You can put them anywhere except inside other elements like lists, block quotes, and tables. Here's a simple footnote,[^1] and here's a longer one.[^bignote] [^1]: This is the first footnote. [^bignote]: Here's one with multiple paragraphs and code. Indent paragraphs to include them in the footnote. `{ my code }` Add as many paragraphs as you like. The rendered output looks like this: Here's a simple footnote, 1 and here's a longer one. 2 This is the first footnote. \u21a9 Here's one with multiple paragraphs and code. Indent paragraphs to include them in the footnote. { my code } Add as many paragraphs as you like. \u21a9","title":"Footnotes"},{"location":"extern/md-guide/_extended-syntax/heading-ids/","text":"Many Markdown processors support custom IDs for headings \u2014 some Markdown processors automatically add them. Adding custom IDs allows you to link directly to headings and modify them with CSS. To add a custom heading ID, enclose the custom ID in curly braces on the same line as the heading. ### My Great Heading {#custom-id} The HTML looks like this: < h3 id = \"custom-id\" > My Great Heading </ h3 > Linking to Heading IDs \u00b6 You can link to headings with custom IDs in the file by creating a standard link with a number sign ( # ) followed by the custom heading ID. Markdown HTML Rendered Output [Heading IDs](#heading-ids) <a href=\"#heading-ids\">Heading IDs</a> Heading IDs Other websites can link to the heading by adding the custom heading ID to the full URL of the webpage (e.g, [Heading IDs](https://www.markdownguide.org/extended-syntax#heading-ids) ).","title":"Heading IDs"},{"location":"extern/md-guide/_extended-syntax/heading-ids/#linking-to-heading-ids","text":"You can link to headings with custom IDs in the file by creating a standard link with a number sign ( # ) followed by the custom heading ID. Markdown HTML Rendered Output [Heading IDs](#heading-ids) <a href=\"#heading-ids\">Heading IDs</a> Heading IDs Other websites can link to the heading by adding the custom heading ID to the full URL of the webpage (e.g, [Heading IDs](https://www.markdownguide.org/extended-syntax#heading-ids) ).","title":"Linking to Heading IDs"},{"location":"extern/md-guide/_extended-syntax/overview/","text":"The basic syntax outlined in John Gruber's original design document added many of the elements needed on a day-to-day basis, but it wasn't enough for some people. That's where extended syntax comes in. Several individuals and organizations took it upon themselves to extend the basic syntax by adding additional elements like tables, code blocks, syntax highlighting, URL auto-linking, and footnotes. These elements can be enabled by using a lightweight markup language that builds upon the basic Markdown syntax, or by adding an extension to a compatible Markdown processor.","title":"Overview"},{"location":"extern/md-guide/_extended-syntax/strikethrough/","text":"You can strikethrough words by putting a horizontal line through the center of them. The result looks like this . This feature allows you to indicate that certain words are a mistake not meant for inclusion in the document. To strikethrough words, use two tilde symbols ( ~~ ) before and after the words. ~~The world is flat.~~ We now know that the world is round. The rendered output looks like this: The world is flat. We now know that the world is round.","title":"Strikethrough"},{"location":"extern/md-guide/_extended-syntax/tables/","text":"To add a table, use three or more hyphens ( --- ) to create each column's header, and use pipes ( | ) to separate each column. You can optionally add pipes on either end of the table. | Syntax | Description | | ----------- | ----------- | | Header | Title | | Paragraph | Text | The rendered output looks like this: Syntax Description Header Title Paragraph Text Cell widths can vary, as shown below. The rendered output will look the same. | Syntax | Description | | --- | ----------- | | Header | Title | | Paragraph | Text | Tip: Creating tables with hyphens and pipes can be tedious. To speed up the process, try using the Markdown Tables Generator . Build a table using the graphical interface, and then copy the generated Markdown-formatted text into your file. Alignment \u00b6 You can align text in the columns to the left, right, or center by adding a colon ( : ) to the left, right, or on both side of the hyphens within the header row. | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | The rendered output looks like this: Syntax Description Test Text Header Title Here\u2019s this Paragraph Text And more Formatting Text in Tables \u00b6 You can format the text within tables. For example, you can add links , code (words or phrases in backticks ( ` ) only, not code blocks ), and emphasis . You can't add headings, blockquotes, lists, horizontal rules, images, or HTML tags. Escaping Pipe Characters in Tables \u00b6 You can display a pipe ( | ) character in a table by using its HTML character code ( &#124; ).","title":"Tables"},{"location":"extern/md-guide/_extended-syntax/tables/#alignment","text":"You can align text in the columns to the left, right, or center by adding a colon ( : ) to the left, right, or on both side of the hyphens within the header row. | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | The rendered output looks like this: Syntax Description Test Text Header Title Here\u2019s this Paragraph Text And more","title":"Alignment"},{"location":"extern/md-guide/_extended-syntax/tables/#formatting-text-in-tables","text":"You can format the text within tables. For example, you can add links , code (words or phrases in backticks ( ` ) only, not code blocks ), and emphasis . You can't add headings, blockquotes, lists, horizontal rules, images, or HTML tags.","title":"Formatting Text in Tables"},{"location":"extern/md-guide/_extended-syntax/tables/#escaping-pipe-characters-in-tables","text":"You can display a pipe ( | ) character in a table by using its HTML character code ( &#124; ).","title":"Escaping Pipe Characters in Tables"},{"location":"extern/md-guide/_extended-syntax/task-lists/","text":"Task lists allow you to create a list of items with checkboxes. In Markdown applications that support task lists, checkboxes will be displayed next to the content. To create a task list, add dashes ( - ) and brackets with a space ( [ ] ) in front of task list items. To select a checkbox, add an x in between the brackets ( [x] ). - [x] Write the press release - [ ] Update the website - [ ] Contact the media The rendered output looks like this:","title":"Task Lists"},{"location":"extern/md-guide/_getting-started/additional-resources/","text":"Additional Resources \u00b6 There are lots of resources you can use to learn Markdown. Here are some other introductory resources: John Gruber's Markdown documentation . The original guide written by the creator of Markdown. Markdown Tutorial . An open source website that allows you to try Markdown in your web browser. Awesome Markdown . A list of Markdown tools and learning resources. Typesetting Markdown . A multi-part series that describes an ecosystem for typesetting Markdown documents using pandoc and ConTeXt .","title":"Additional resources"},{"location":"extern/md-guide/_getting-started/additional-resources/#additional-resources","text":"There are lots of resources you can use to learn Markdown. Here are some other introductory resources: John Gruber's Markdown documentation . The original guide written by the creator of Markdown. Markdown Tutorial . An open source website that allows you to try Markdown in your web browser. Awesome Markdown . A list of Markdown tools and learning resources. Typesetting Markdown . A multi-part series that describes an ecosystem for typesetting Markdown documents using pandoc and ConTeXt .","title":"Additional Resources"},{"location":"extern/md-guide/_getting-started/flavors-of-markdown/","text":"Flavors of Markdown \u00b6 One of the most confusing aspects of using Markdown is that practically every Markdown application implements a slightly different version of Markdown. These variants of Markdown are commonly referred to as flavors . It's your job to master whatever flavor of Markdown your application has implemented. To wrap your head around the concept of Markdown flavors, it might help to think of them as language dialects. People in Ciudad Ju\u00e1rez speak Spanish just like the people in Barcelona, but there are substantial differences between the dialects used in both cities. The same is true for people using different Markdown applications. Using Dillinger to write with Markdown is a vastly different experience than using Ulysses . Practically speaking, this means you never know exactly what a company means when they say they support \"Markdown.\" Are they talking about only the basic syntax elements , or all of the basic and extended syntax elements combined, or some arbitrary combination of syntax elements? You won't know until you read the documentation or start using the application. If you're just starting out, the best advice I can give you is to pick a Markdown application with good Markdown support. That'll go a long way towards maintaining the portability of your Markdown files. You might want to store and use your Markdown files in other applications, and to do that you need to start with an application that provides good support. You can use the tool directory to find an application that fits the bill.","title":"Flavors of markdown"},{"location":"extern/md-guide/_getting-started/flavors-of-markdown/#flavors-of-markdown","text":"One of the most confusing aspects of using Markdown is that practically every Markdown application implements a slightly different version of Markdown. These variants of Markdown are commonly referred to as flavors . It's your job to master whatever flavor of Markdown your application has implemented. To wrap your head around the concept of Markdown flavors, it might help to think of them as language dialects. People in Ciudad Ju\u00e1rez speak Spanish just like the people in Barcelona, but there are substantial differences between the dialects used in both cities. The same is true for people using different Markdown applications. Using Dillinger to write with Markdown is a vastly different experience than using Ulysses . Practically speaking, this means you never know exactly what a company means when they say they support \"Markdown.\" Are they talking about only the basic syntax elements , or all of the basic and extended syntax elements combined, or some arbitrary combination of syntax elements? You won't know until you read the documentation or start using the application. If you're just starting out, the best advice I can give you is to pick a Markdown application with good Markdown support. That'll go a long way towards maintaining the portability of your Markdown files. You might want to store and use your Markdown files in other applications, and to do that you need to start with an application that provides good support. You can use the tool directory to find an application that fits the bill.","title":"Flavors of Markdown"},{"location":"extern/md-guide/_getting-started/how-does-it-work/","text":"How Does it Work? \u00b6 Dillinger makes writing in Markdown easy because it hides the stuff happening behind the scenes, but it's worth exploring how the process works in general. When you write in Markdown, the text is stored in a plaintext file that has an .md or .markdown extension. But then what? How is your Markdown-formatted file converted into HTML or a print-ready document? The short answer is that you need a Markdown application capable of processing the Markdown file. There are lots of applications available \u2014 everything from simple scripts to desktop applications that look like Microsoft Word. Despite their visual differences, all of the applications do the same thing. Like Dillinger, they all convert Markdown-formatted text to HTML so it can be displayed in web browsers. Markdown applications use something called a Markdown processor (also commonly referred to as a \"parser\" or an \"implementation\") to take the Markdown-formatted text and output it to HTML format. At that point, your document can be viewed in a web browser or combined with a style sheet and printed. You can see a visual representation of this process below. Note: The Markdown application and processor are two separate components. For the sake of brevity, I've combined them into one element (\"Markdown App\") in the figure below. To summarize, this is a four-part process: Create a Markdown file using a text editor or a dedicated Markdown application. The file should have an .md or .markdown extension. Open the Markdown file in a Markdown application. Use the Markdown application to convert the Markdown file to an HTML document. View the HTML file in a web browser or use the Markdown application to convert it to another file format, like PDF. From your perspective, the process will vary somewhat depending on the application you use. For example, Dillinger essentially combines steps 1-3 into a single, seamless interface \u2014 all you have to do is type in the left pane and the rendered output magically appears in the right pane. But if you use other tools, like a text editor with a static website generator, you'll find that the process is much more visible.","title":"How does it work"},{"location":"extern/md-guide/_getting-started/how-does-it-work/#how-does-it-work","text":"Dillinger makes writing in Markdown easy because it hides the stuff happening behind the scenes, but it's worth exploring how the process works in general. When you write in Markdown, the text is stored in a plaintext file that has an .md or .markdown extension. But then what? How is your Markdown-formatted file converted into HTML or a print-ready document? The short answer is that you need a Markdown application capable of processing the Markdown file. There are lots of applications available \u2014 everything from simple scripts to desktop applications that look like Microsoft Word. Despite their visual differences, all of the applications do the same thing. Like Dillinger, they all convert Markdown-formatted text to HTML so it can be displayed in web browsers. Markdown applications use something called a Markdown processor (also commonly referred to as a \"parser\" or an \"implementation\") to take the Markdown-formatted text and output it to HTML format. At that point, your document can be viewed in a web browser or combined with a style sheet and printed. You can see a visual representation of this process below. Note: The Markdown application and processor are two separate components. For the sake of brevity, I've combined them into one element (\"Markdown App\") in the figure below. To summarize, this is a four-part process: Create a Markdown file using a text editor or a dedicated Markdown application. The file should have an .md or .markdown extension. Open the Markdown file in a Markdown application. Use the Markdown application to convert the Markdown file to an HTML document. View the HTML file in a web browser or use the Markdown application to convert it to another file format, like PDF. From your perspective, the process will vary somewhat depending on the application you use. For example, Dillinger essentially combines steps 1-3 into a single, seamless interface \u2014 all you have to do is type in the left pane and the rendered output magically appears in the right pane. But if you use other tools, like a text editor with a static website generator, you'll find that the process is much more visible.","title":"How Does it Work?"},{"location":"extern/md-guide/_getting-started/kicking-the-tires/","text":"Kicking the Tires \u00b6 The best way to get started with Markdown is to use it. That's easier than ever before thanks to a variety of free tools. You don't even need to download anything. There are several online Markdown editors that you can use to try writing in Markdown. Dillinger is one of the best online Markdown editors. Just open the site and start typing in the left pane. A preview of the rendered document appears in the right pane. You'll probably want to keep the Dillinger website open as you read through this guide. That way you can try the syntax as you learn about it. After you've become familiar with Markdown, you may want to use a Markdown application that can be installed on your desktop computer or mobile device.","title":"Kicking the tires"},{"location":"extern/md-guide/_getting-started/kicking-the-tires/#kicking-the-tires","text":"The best way to get started with Markdown is to use it. That's easier than ever before thanks to a variety of free tools. You don't even need to download anything. There are several online Markdown editors that you can use to try writing in Markdown. Dillinger is one of the best online Markdown editors. Just open the site and start typing in the left pane. A preview of the rendered document appears in the right pane. You'll probably want to keep the Dillinger website open as you read through this guide. That way you can try the syntax as you learn about it. After you've become familiar with Markdown, you may want to use a Markdown application that can be installed on your desktop computer or mobile device.","title":"Kicking the Tires"},{"location":"extern/md-guide/_getting-started/what-is-markdown/","text":"What is Markdown? \u00b6 Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents. Created by John Gruber in 2004, Markdown is now one of the world's most popular markup languages. Using Markdown is different than using a WYSIWYG editor. In an application like Microsoft Word, you click buttons to format words and phrases, and the changes are visible immediately. Markdown isn't like that. When you create a Markdown-formatted file, you add Markdown syntax to the text to indicate which words and phrases should look different. For instance, to denote a heading, you add a number sign before it (e.g., # Heading One ). Or to make a phrase bold, you add two asterisks before and after it (e.g., **this text is bold** ). It may take a while to get used to seeing Markdown syntax in your text, especially if you're accustomed to WYSIWYG applications. The screenshot below shows a Markdown file displayed in the Atom text editor . You can add Markdown formatting elements to a plaintext file using a text editor application. Or you can use one of the many Markdown applications for macOS, Windows, Linux, iOS, and Android operating systems. There are also several web-based applications specifically designed for writing in Markdown. Depending on the application you use, you may not be able to preview the formatted document in real time. But that's okay. According to Gruber , Markdown syntax is designed to be readable and unobtrusive, so the text in Markdown files can be read even if it isn't rendered. The overriding design goal for Markdown\u2019s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it\u2019s been marked up with tags or formatting instructions.","title":"What is markdown"},{"location":"extern/md-guide/_getting-started/what-is-markdown/#what-is-markdown","text":"Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents. Created by John Gruber in 2004, Markdown is now one of the world's most popular markup languages. Using Markdown is different than using a WYSIWYG editor. In an application like Microsoft Word, you click buttons to format words and phrases, and the changes are visible immediately. Markdown isn't like that. When you create a Markdown-formatted file, you add Markdown syntax to the text to indicate which words and phrases should look different. For instance, to denote a heading, you add a number sign before it (e.g., # Heading One ). Or to make a phrase bold, you add two asterisks before and after it (e.g., **this text is bold** ). It may take a while to get used to seeing Markdown syntax in your text, especially if you're accustomed to WYSIWYG applications. The screenshot below shows a Markdown file displayed in the Atom text editor . You can add Markdown formatting elements to a plaintext file using a text editor application. Or you can use one of the many Markdown applications for macOS, Windows, Linux, iOS, and Android operating systems. There are also several web-based applications specifically designed for writing in Markdown. Depending on the application you use, you may not be able to preview the formatted document in real time. But that's okay. According to Gruber , Markdown syntax is designed to be readable and unobtrusive, so the text in Markdown files can be read even if it isn't rendered. The overriding design goal for Markdown\u2019s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it\u2019s been marked up with tags or formatting instructions.","title":"What is Markdown?"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/","text":"What's Markdown Good For? \u00b6 Markdown is a fast and easy way to take notes, create content for a website, and produce print-ready documents. It doesn't take long to learn the Markdown syntax, and once you know how to use it, you can write using Markdown just about everywhere. Most people use Markdown to create content for the web, but Markdown is good for formatting everything from email messages to grocery lists. Here are some examples of what you can do with Markdown. Websites \u00b6 Markdown was designed for the web, so it should come as no surprise that there are plenty of applications specifically designed for creating website content. If you're looking for the simplest possible way to create a website with Markdown files, check out blot.im and smallvictori.es . After you sign up for one of these services, they create a Dropbox folder on your computer. Just drag and drop your Markdown files into the folder and \u2014 poof! \u2014 they're on your website. It couldn't be easier. If you're familiar with HTML, CSS, and version control, check out Jekyll , a popular static site generator that takes Markdown files and builds an HTML website. One advantage to this approach is that GitHub Pages provides free hosting for Jekyll-generated websites. If Jekyll isn't your cup of tea, just pick one of the many other static site generators available . Note: I used Jekyll to create the Markdown Guide . You can view the source code on GitHub . If you'd like to use a content management system (CMS) to power your website, take a look at Ghost . It's a free and open-source blogging platform with a nice Markdown editor. If you're a WordPress user, you'll be happy to know there's Markdown support for websites hosted on WordPress.com. Self-hosted WordPress sites can use the Jetpack plugin . Documents \u00b6 Markdown doesn't have all the bells and whistles of word processors like Microsoft Word, but it's good enough for creating basic documents like assignments and letters. You can use a Markdown document authoring application to create and export Markdown-formatted documents to PDF or HTML file format. The PDF part is key, because once you have a PDF document, you can do anything with it \u2014 print it, email it, or upload it to a website. Here are some Markdown document authoring applications I recommend: Mac: MacDown , iA Writer , or Marked iOS / Android: iA Writer Windows: ghostwriter or Markdown Monster Linux: ReText or ghostwriter Web: Dillinger or StackEdit Tip: iA Writer provides templates for previewing, printing, and exporting Markdown-formatted documents. For example, the \"Academic \u2013 MLA Style\" template indents paragraphs and adds double sentence spacing. Notes \u00b6 In nearly every way, Markdown is the ideal syntax for taking notes. Sadly, Evernote and OneNote , two of the most popular note applications, don't currently support Markdown. The good news is that several other note applications do support Markdown: Simplenote is a free, barebones note-taking application available for every platform. Notable is a note-taking application that runs on a variety of platforms. Bear is an Evernote-like application available for Mac and iOS devices. It doesn't exclusively use Markdown by default, but you can enable Markdown compatibility mode. Boostnote bills itself as an \"open source note-taking app designed for programmers.\" If you can't part with Evernote, check out Marxico , a subscription-based Markdown editor for Evernote, or use Markdown Here with the Evernote website. Books \u00b6 Looking to self-publish a novel? Try Leanpub , a service that takes your Markdown-formatted files and turns them into an electronic book. Leanpub outputs your book in PDF, EPUB, and MOBI file format. If you'd like to create paperback copies of your book, you can upload the PDF file to another service such as Kindle Direct Publishing . To learn more about writing and self-publishing a book using Markdown, read this blog post . Presentations \u00b6 Believe it or not, you can generate presentations from Markdown-formatted files. Creating presentations in Markdown takes a little getting used to, but once you get the hang of it, it's a lot faster and easier than using an application like PowerPoint or Keynote. Remark ( GitHub project ) is a popular browser-based Markdown slideshow tool, as is Cleaver ( GitHub project ). If you use a Mac and would prefer to use an application, check out Deckset or Marked . Email \u00b6 If you send a lot of email and you're tired of the formatting controls available on most email provider websites, you'll be happy to learn there's an easy way to write email messages using Markdown. Markdown Here is a free and open-source browser extension that converts Markdown-formatted text into HTML that's ready to send. Documentation \u00b6 Markdown is a natural fit for technical documentation. Companies like GitHub are increasingly switching to Markdown for their documentation \u2014 check out their blog post about how they migrated their Markdown-formatted documentation to Jekyll . If you write documentation for a product or service, take a look at these handy tools: Read the Docs can generate a documentation website from your open source Markdown files. Just connect your GitHub repository to their service and push \u2014 Read the Docs does the rest. They also have a service for commercial entities . MkDocs is a fast and simple static site generator that's geared towards building project documentation. Documentation source files are written in Markdown and configured with a single YAML configuration file. MkDocs has several built in themes , including a port of the Read the Docs documentation theme for use with MkDocs. One of the newest themes is MkDocs Material . Docusaurus is a static site generator designed exclusively for creating documentation websites. It supports translations, search, and versioning. VuePress is a static site generator powered by Vue and optimized for writing technical documentation. Jekyll was mentioned earlier in the section on websites, but it's also a good option for generating a documentation website from Markdown files. If you go this route, be sure to check out the Jekyll documentation theme .","title":"Whats markdown good for"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#whats-markdown-good-for","text":"Markdown is a fast and easy way to take notes, create content for a website, and produce print-ready documents. It doesn't take long to learn the Markdown syntax, and once you know how to use it, you can write using Markdown just about everywhere. Most people use Markdown to create content for the web, but Markdown is good for formatting everything from email messages to grocery lists. Here are some examples of what you can do with Markdown.","title":"What's Markdown Good For?"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#websites","text":"Markdown was designed for the web, so it should come as no surprise that there are plenty of applications specifically designed for creating website content. If you're looking for the simplest possible way to create a website with Markdown files, check out blot.im and smallvictori.es . After you sign up for one of these services, they create a Dropbox folder on your computer. Just drag and drop your Markdown files into the folder and \u2014 poof! \u2014 they're on your website. It couldn't be easier. If you're familiar with HTML, CSS, and version control, check out Jekyll , a popular static site generator that takes Markdown files and builds an HTML website. One advantage to this approach is that GitHub Pages provides free hosting for Jekyll-generated websites. If Jekyll isn't your cup of tea, just pick one of the many other static site generators available . Note: I used Jekyll to create the Markdown Guide . You can view the source code on GitHub . If you'd like to use a content management system (CMS) to power your website, take a look at Ghost . It's a free and open-source blogging platform with a nice Markdown editor. If you're a WordPress user, you'll be happy to know there's Markdown support for websites hosted on WordPress.com. Self-hosted WordPress sites can use the Jetpack plugin .","title":"Websites"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#documents","text":"Markdown doesn't have all the bells and whistles of word processors like Microsoft Word, but it's good enough for creating basic documents like assignments and letters. You can use a Markdown document authoring application to create and export Markdown-formatted documents to PDF or HTML file format. The PDF part is key, because once you have a PDF document, you can do anything with it \u2014 print it, email it, or upload it to a website. Here are some Markdown document authoring applications I recommend: Mac: MacDown , iA Writer , or Marked iOS / Android: iA Writer Windows: ghostwriter or Markdown Monster Linux: ReText or ghostwriter Web: Dillinger or StackEdit Tip: iA Writer provides templates for previewing, printing, and exporting Markdown-formatted documents. For example, the \"Academic \u2013 MLA Style\" template indents paragraphs and adds double sentence spacing.","title":"Documents"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#notes","text":"In nearly every way, Markdown is the ideal syntax for taking notes. Sadly, Evernote and OneNote , two of the most popular note applications, don't currently support Markdown. The good news is that several other note applications do support Markdown: Simplenote is a free, barebones note-taking application available for every platform. Notable is a note-taking application that runs on a variety of platforms. Bear is an Evernote-like application available for Mac and iOS devices. It doesn't exclusively use Markdown by default, but you can enable Markdown compatibility mode. Boostnote bills itself as an \"open source note-taking app designed for programmers.\" If you can't part with Evernote, check out Marxico , a subscription-based Markdown editor for Evernote, or use Markdown Here with the Evernote website.","title":"Notes"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#books","text":"Looking to self-publish a novel? Try Leanpub , a service that takes your Markdown-formatted files and turns them into an electronic book. Leanpub outputs your book in PDF, EPUB, and MOBI file format. If you'd like to create paperback copies of your book, you can upload the PDF file to another service such as Kindle Direct Publishing . To learn more about writing and self-publishing a book using Markdown, read this blog post .","title":"Books"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#presentations","text":"Believe it or not, you can generate presentations from Markdown-formatted files. Creating presentations in Markdown takes a little getting used to, but once you get the hang of it, it's a lot faster and easier than using an application like PowerPoint or Keynote. Remark ( GitHub project ) is a popular browser-based Markdown slideshow tool, as is Cleaver ( GitHub project ). If you use a Mac and would prefer to use an application, check out Deckset or Marked .","title":"Presentations"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#email","text":"If you send a lot of email and you're tired of the formatting controls available on most email provider websites, you'll be happy to learn there's an easy way to write email messages using Markdown. Markdown Here is a free and open-source browser extension that converts Markdown-formatted text into HTML that's ready to send.","title":"Email"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#documentation","text":"Markdown is a natural fit for technical documentation. Companies like GitHub are increasingly switching to Markdown for their documentation \u2014 check out their blog post about how they migrated their Markdown-formatted documentation to Jekyll . If you write documentation for a product or service, take a look at these handy tools: Read the Docs can generate a documentation website from your open source Markdown files. Just connect your GitHub repository to their service and push \u2014 Read the Docs does the rest. They also have a service for commercial entities . MkDocs is a fast and simple static site generator that's geared towards building project documentation. Documentation source files are written in Markdown and configured with a single YAML configuration file. MkDocs has several built in themes , including a port of the Read the Docs documentation theme for use with MkDocs. One of the newest themes is MkDocs Material . Docusaurus is a static site generator designed exclusively for creating documentation websites. It supports translations, search, and versioning. VuePress is a static site generator powered by Vue and optimized for writing technical documentation. Jekyll was mentioned earlier in the section on websites, but it's also a good option for generating a documentation website from Markdown files. If you go this route, be sure to check out the Jekyll documentation theme .","title":"Documentation"},{"location":"extern/md-guide/_getting-started/why-use-markdown/","text":"Why Use Markdown? \u00b6 You might be wondering why people use Markdown instead of a WYSIWYG editor. Why write with Markdown when you can press buttons in an interface to format your text? As it turns out, there are a couple different reasons why people use Markdown instead of WYSIWYG editors. Markdown can be used for everything. People use it to create websites , documents , notes , books , presentations , email messages , and technical documentation . Markdown is portable. Files containing Markdown-formatted text can be opened using virtually any application. If you decide you don't like the Markdown application you're currently using, you can import your Markdown files into another Markdown application. That's in stark contrast to word processing applications like Microsoft Word that lock your content into a proprietary file format. Markdown is platform independent. You can create Markdown-formatted text on any device running any operating system. Markdown is future proof. Even if the application you're using stops working at some point in the future, you'll still be able to read your Markdown-formatted text using a text editing application. This is an important consideration when it comes to books, university theses, and other milestone documents that need to be preserved indefinitely. Markdown is everywhere. Websites like Reddit and GitHub support Markdown, and lots of desktop and web-based applications support it.","title":"Why use markdown"},{"location":"extern/md-guide/_getting-started/why-use-markdown/#why-use-markdown","text":"You might be wondering why people use Markdown instead of a WYSIWYG editor. Why write with Markdown when you can press buttons in an interface to format your text? As it turns out, there are a couple different reasons why people use Markdown instead of WYSIWYG editors. Markdown can be used for everything. People use it to create websites , documents , notes , books , presentations , email messages , and technical documentation . Markdown is portable. Files containing Markdown-formatted text can be opened using virtually any application. If you decide you don't like the Markdown application you're currently using, you can import your Markdown files into another Markdown application. That's in stark contrast to word processing applications like Microsoft Word that lock your content into a proprietary file format. Markdown is platform independent. You can create Markdown-formatted text on any device running any operating system. Markdown is future proof. Even if the application you're using stops working at some point in the future, you'll still be able to read your Markdown-formatted text using a text editing application. This is an important consideration when it comes to books, university theses, and other milestone documents that need to be preserved indefinitely. Markdown is everywhere. Websites like Reddit and GitHub support Markdown, and lots of desktop and web-based applications support it.","title":"Why Use Markdown?"},{"location":"extern/md-guide/_tools/bear/","text":"Bear is a macOS and iOS application designed for one thing: note taking. It's like Evernote , but without the bloat. There aren't a lot of whizbang features in Bear. Instead, Bear consistently delivers on all of its promises. Tags, search, and syncing all work flawlessly. The application is intuitive, and that's exactly what you want when you're taking notes. Bear doesn't automatically enable support Markdown by default, but you can enable it in the preferences . The application has a hybrid live editor and text editor \u2014 you can see both the Markdown syntax and the way the formatting changes the text. It takes a while to get used to, but it's useful if you're just getting started with Markdown. Enabling Markdown Support \u00b6 To enable Markdown support in Bear, open the Preferences window. On the General tab, turn on the setting for Markdown compatibility mode . Tip: If you're using Bear on more than one device, you'll need to enable the Markdown compatibility mode setting on all of your devices. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Bear provides support for several obscure elements. Element Markdown Rendered Output Highlight ::word or phrase:: word or phrase Underline ~word or phrase~ word or phrase","title":"Bear"},{"location":"extern/md-guide/_tools/bear/#enabling-markdown-support","text":"To enable Markdown support in Bear, open the Preferences window. On the General tab, turn on the setting for Markdown compatibility mode . Tip: If you're using Bear on more than one device, you'll need to enable the Markdown compatibility mode setting on all of your devices. {% include tool-syntax-table.html %}","title":"Enabling Markdown Support"},{"location":"extern/md-guide/_tools/bear/#support-for-additional-syntax-elements","text":"As an added bonus, Bear provides support for several obscure elements. Element Markdown Rendered Output Highlight ::word or phrase:: word or phrase Underline ~word or phrase~ word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/boostnote/","text":"Boostnote bills itself as a note taking application for developers, but anyone in need of a Markdown application for notes would be happy with this application. Markdown support is excellent. The application's interface is polished and intuitive, and open source clients are freely available for macOS, Windows, and Linux operating systems. Boostnote allows you create folders, tag notes, and export Markdown files to HTML and PDF file format. {% include tool-syntax-table.html %}","title":"Boostnote"},{"location":"extern/md-guide/_tools/byword/","text":"Byword is no-frills Markdown editor for macOS and iOS. You type Markdown-formatted text, use a menu option to invoke the preview, and export to one of several available file formats including HTML, PDF, Microsoft Word, and LaTeX. You can publish to several blogging services, and the iCloud sync feature lets you author and access the files from all of your Apple devices. Byword isn't fancy by any means \u2014 some people might even be put off by the application's insubstantial look and feel \u2014 but it gets the job done. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Byword provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Byword"},{"location":"extern/md-guide/_tools/byword/#support-for-additional-syntax-elements","text":"As an added bonus, Byword provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/codimd/","text":"CodiMD is an open-source real-time collaborative Markdown editor. You can easily deploy CodiMD with Docker following this tutorial . CodiMD supports CommonMark and other markup syntax, such as: MathJax for formulas Mermaid and Graphviz for UML diagrams Vega-lite for data visualizations CodiMD is the open-source version of HackMD . {% include tool-syntax-table.html %}","title":"CodiMD"},{"location":"extern/md-guide/_tools/collected-notes/","text":"Collected Notes is a note-taking platform that can publish your Markdown notes on the internet. Your notes can be kept private or published on a public webpage. You can author notes using the Collected Notes website or the macOS and iOS applications. This is a new application that debuted in the middle of 2020. Some of the kinks are still being worked out, but there's a lot of potential here! See the feature roadmap for a list of stuff that's slated to be implemented. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Collected Notes provides support for several obscure elements. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase","title":"Collected Notes"},{"location":"extern/md-guide/_tools/collected-notes/#support-for-additional-syntax-elements","text":"As an added bonus, Collected Notes provides support for several obscure elements. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/dillinger/","text":"Dillinger is an online Markdown editor. Like StackEdit , it loads right in your web browser, so there's no need to download and install an application on your computer. Dillinger has two panes: the editor on the left, and the live preview on the right. The split panes make it easy to see what Markdown-formatted text looks like. Dillinger provides excellent Markdown support. Unfortunately, the export options are not customizable and the file saving features are a bit flaky. And since Dillinger loads in your web browser, it's entirely dependent on a consistent internet connection. If your internet connection goes down or your web browser crashes, you could lose your work. For those reasons, Dillinger is best used for experimentation and quick note taking. The application uses the markdown-it Markdown processor. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Dillinger provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Insert ++This text has been inserted++ This text has been inserted Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Dillinger"},{"location":"extern/md-guide/_tools/dillinger/#support-for-additional-syntax-elements","text":"As an added bonus, Dillinger provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Insert ++This text has been inserted++ This text has been inserted Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/docusaurus/","text":"Docusaurus is an open-source static site generator that converts Markdown files to a documentation website. Created by Facebook, Docusaurus is written in the Node.js programming language. Thousands of organizations use Docusaurus to power their documentation websites. An example of a website generated by Docusaurus is shown below. Docusaurus uses the remarkable Markdown processor. {% include tool-syntax-table.html %}","title":"Docusaurus"},{"location":"extern/md-guide/_tools/ghost/","text":"Ghost is a relatively new content management system (CMS) for blogging that competes with older, established CMS products like WordPress and Drupal. Ghost is an open source project renowned for its speed, simplicity, and ease of use. Markdown support is standard and available out-of-the-box. There are a couple minor compatibility issues noted below but, generally speaking, Ghost has solid Markdown support. The live editor is fairly intuitive and seems like a good choice for bloggers. Copying and pasting Markdown-formatted text into the editor works the way you'd expect it to. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Ghost provides support for several obscure elements. Element Markdown Rendered Output Subscript H~2~O H 2 O Superscript X^super^ X super","title":"Ghost"},{"location":"extern/md-guide/_tools/ghost/#support-for-additional-syntax-elements","text":"As an added bonus, Ghost provides support for several obscure elements. Element Markdown Rendered Output Subscript H~2~O H 2 O Superscript X^super^ X super","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/gitbook/","text":"GitBook is a hosted solution for documentation websites and knowledge bases. In a nutshell, you sign in to GitBook's website and use their web-based editor to write your documentation. Or, if you'd rather maintain control over your content, you can keep it in a GitHub repository that is integrated with GitBook . Either way, you can create different webpages and organize them in a logical order. When everything looks the way you want it, you can publish it on a custom domain. Like so many projects, GitBook started as an open source toolchain with a commercial offering, but eventually dropped the open source project in favor of a new proprietary and closed-source offering that's hosted exclusively on their website. The open source toolchain is still available , but as that option is now unsupported, this article only documents the new hosted option. The advantage of GitBook over a tool like Docusaurus is that GitBook takes care of building and hosting the site, and the WYSIWYG controls are intuitive enough to be used by Markdown novices. On the GitBook website, the live editor hides the Markdown formatting syntax after you type it. The editor is a bit flaky, but weird little bugs aside, the website generally works for both Markdown experts and people who don't have any experience with Markdown. You can also simply copy and paste Markdown-formatted text into the GitBook interface. {% include tool-syntax-table.html %}","title":"GitBook"},{"location":"extern/md-guide/_tools/github-pages/","text":"GitHub Pages is a service that turns Markdown files into a website and hosts them for free on the internet. If you know how to use GitHub and you need to create a simple webpage, you can't do better than GitHub Pages. Just create a new repository on GitHub, commit the Markdown files, and enable the GitHub Pages feature. GitHub Pages uses the Jekyll static site generator to create your website, and the Markdown support is excellent. You can pick one of GitHub's pre-made themes for your website, use a Jekyll theme , or use your own custom CSS. Shown below is a sample webpage using one of GitHub's pre-made themes. Confusingly, GitHub Pages renders Markdown differently than GitHub does. GitHub uses its own Markdown processor; GitHub Pages uses jekyll-commonmark . This means your README.md file will look different on GitHub's website than on your GitHub Pages website. For example, emoji are rendered on GitHub's website, but not on websites generated using GitHub Pages. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, GitHub Pages provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C.","title":"GitHub Pages"},{"location":"extern/md-guide/_tools/github-pages/#support-for-additional-syntax-elements","text":"As an added bonus, GitHub Pages provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C.","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/gitjournal/","text":"GitJournal is a mobile-first Markdown editor integrated with Git. It supporting syncing your notes using any git repository accessible vis SSH, including GitHub, GitLab, Gitea, or your own server. The entire code base is also completely open source. GitJournal focuses on giving users control of their data and allowing them to access it with multiple devices using an open and well known protocol: git. There are various free and commercial git hosting providers, and setting up your own git server has a lower bar of entry than any other syncing solution. GitJournal additionally lets you easily link your notes together with a Wiki style link - [[FileName]] . This lets you easily interlink different ideas and even build your own knowledge base. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, GitJournal provides support for several obscure elements. Element Markdown Rendered Output WikiLinks [[PageName]] Links to the file PageName.md","title":"GitJournal"},{"location":"extern/md-guide/_tools/gitjournal/#support-for-additional-syntax-elements","text":"As an added bonus, GitJournal provides support for several obscure elements. Element Markdown Rendered Output WikiLinks [[PageName]] Links to the file PageName.md","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/hackmd/","text":"HackMD is a real-time, multi-platform collaborative Markdown editor. You can use HackMD to write notes with other people on your computer, tablet, or phone. HackMD provides a variety of document templates and allows users to push documents to GitHub. You can import and export documents from Dropbox, Google Drive, and GitHub gists. HackMD supports CommonMark and other markup syntax, such as: MathJax for formulas Mermaid and Graphviz for UML diagrams Vega-lite for data visualizations HackMD is the commercial version of CodiMD . {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, HackMD provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"HackMD"},{"location":"extern/md-guide/_tools/hackmd/#support-for-additional-syntax-elements","text":"As an added bonus, HackMD provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/hugo/","text":"Hugo is a popular static site generator written in the Go programming language. Hugo is jam-packed with features, but one of its main selling points is speed \u2014 Hugo takes mere seconds to generate a site with thousands of pages. Smashing Magazine recently switched to Hugo from WordPress. Hugo has excellent Markdown support out of the box. By default, Hugo uses the Goldmark Markdown processor which is fully CommonMark-compliant. See the configuration instructions to learn more about the extensions you can configure. You can change Hugo's Goldmark settings in the config.toml file, as shown below. baseURL = \"http://mysite.org/\" languageCode = \"en-us\" title = \"My Site\" theme = \"ananke\" [markup] taskLists = false {% include tool-syntax-table.html %}","title":"Hugo"},{"location":"extern/md-guide/_tools/ia-writer/","text":"iA Writer is one of the most established and widely-acclaimed Markdown editors. Considered to be a \"gold standard\" Markdown editor, iA Writer is available for devices running macOS, Windows, iOS, and Android operating systems. The application allows you to export Markdown files to HTML, PDF, and Microsoft Word file format using custom templates . One of the hallmarks of the application is focus mode . When enabled, that feature keeps the sentence you're currently working on horizontally centered, as shown in the screenshot below. It feels a little like using a typewriter. There are a couple of quirks you should be aware of. iA Writer doesn't save new files with the Markdown extension ( .md ) by default. If you plan to exclusively create Markdown files using iA Writer, you should change the default extension to .md in Preferences > Files . The Preview button is the little triangle button in the top-right corner of the window. You can click that to preview the output, and then click it again to return to the source. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, iA Writer provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"iA Writer"},{"location":"extern/md-guide/_tools/ia-writer/#support-for-additional-syntax-elements","text":"As an added bonus, iA Writer provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/imdone/","text":"Imdone is a simple and powerful kanban board for people who work with Markdown and code. Markdown blocks in your notes, docs, and code are represented as cards on your kanban boards. You can add and edit cards using the built-in card editor or your favorite text editor, making it convenient to update your tasks while you're working on a Markdown document or code. {% include tool-syntax-table.html %}","title":"Imdone"},{"location":"extern/md-guide/_tools/inkdrop/","text":"Inkdrop is a Markdown note-taking app with a great feature set. You create an account on the Inkdrop website (free trial available, then monthly subscription required), download the desktop and mobile applications, and start writing. Organizing notes is easy with notebooks, statuses, and tags. One of the best parts of Inkdrop is that it's extensible. A variety of plugins allow you to add flowcharts, sequence diagrams, and (my personal favorite) admonitions . And, on a note somewhat unrelated to the application itself, you might be interested in learning that Inkdrop's developer is a prolific blogger who takes security seriously . {% include tool-syntax-table.html %}","title":"Inkdrop"},{"location":"extern/md-guide/_tools/jekyll/","text":"Jekyll is a static site generator that takes Markdown files and converts them to a website. Jekyll is a free and open-source application written in the Ruby programming language. Thousands of websites, including the Markdown Guide , rely on Jekyll to convert Markdown source files to HTML output. GitHub Pages uses Jekyll as the backend for its free website creation service. By default, Jekyll uses the kramdown Markdown processor with stock settings, but you can enable other kramdown options or even switch Jekyll to another Markdown processor. See the Jekyll Markdown configuration options documentation for more information. You can change Jekyll's kramdown settings in the _config.yml file. The settings for the Markdown Guide are shown below. kramdown : syntax_highlighter : rouge input : GFM auto_ids : true toc_levels : 1..3 {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Jekyll provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C.","title":"Jekyll"},{"location":"extern/md-guide/_tools/jekyll/#support-for-additional-syntax-elements","text":"As an added bonus, Jekyll provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C.","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/joplin/","text":"Joplin is a free and open-source note taking application that works on every platform. Joplin's user interface isn't as polished as some of its competitors \u2014 it feels more geeky, if that makes any sense \u2014 but the application is a favorite among privacy advocates and is recommended by privacytools.io . Joplin stores notes on your local file system, provides end-to-end encryption, and allows you to synchronize files across devices by storing them on a service like Dropbox or Nextcloud. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Joplin provides support for several obscure elements. Tip: Most of these elements are disabled by default. You can enable them in Preferences > Plugins . Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Insert ++This text has been inserted++ This text has been inserted Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Joplin"},{"location":"extern/md-guide/_tools/joplin/#support-for-additional-syntax-elements","text":"As an added bonus, Joplin provides support for several obscure elements. Tip: Most of these elements are disabled by default. You can enable them in Preferences > Plugins . Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Insert ++This text has been inserted++ This text has been inserted Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/macdown/","text":"MacDown is one of the best Markdown editors available for macOS. The application is free and open source, and it strikes a good balance between power and simplicity. MacDown provides excellent Markdown support. MacDown sports two panes \u2014 you type on the left and preview the formatted text on the right. Basic export options for HTML and PDF file format are provided. You can enable and disable support for many syntax elements, a nice feature for people who simply don't want or need all of the bells and whistles. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, MacDown provides support for several obscure elements. These are disabled by default, but you can enable them in Preferences > Markdown . Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Superscript X^2 X 2 Underline _word or phrase_ word or phrase","title":"MacDown"},{"location":"extern/md-guide/_tools/macdown/#support-for-additional-syntax-elements","text":"As an added bonus, MacDown provides support for several obscure elements. These are disabled by default, but you can enable them in Preferences > Markdown . Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Superscript X^2 X 2 Underline _word or phrase_ word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/madoko/","text":"Madoko is a fast Markdown processor for writing professional articles, books, manuals, webpages and presentations, with a focus on simplicity and plain text readability. You can use Madoko to write complex documents in Markdown and get beautiful PDF and HTML output. Madoko is a Javascript Markdown processor written in Koka. It started out as a demo program for the new, strongly typed, Koka language and the name comes from \"Markdown in Koka.\" Madoko can both be run locally as a command-line program or on Madoko.net to take advantage of storage and collaboration features. Madoko integrates seamlessly with Dropbox, Github, and OneDrive. It automatically synchronizes all changes in the cloud. This way, your document is always available from any device. The online editor can also edit files on the local disk, or run LaTeX locally, using the Madoko local program. Madoko implements extensions like Github Flavored Markdown, pandoc , Markdown Extra , and multi-markdown , and it adds other useful features for writing academic and industrial documents. In Madoko, tabs are considered to be equivalent to 4 spaces. It's best to configure your editor to view tabs as 4 spaces wide or documents may look off. {% include tool-syntax-table.html %}","title":"Madoko"},{"location":"extern/md-guide/_tools/mark-text/","text":"Mark Text is a popular free and open-source document editor designed exclusively for writing in Markdown. Like Typora , Mark Text has a polished interface and a live editor that hides the Markdown formatting after you type it. The PDF and HTML export options are handy, as is the feature that allows you to copy text out of the editor as Markdown, HTML, or plaintext. There are some minor annoyances. In several instances (noted below in the table), the appearance of the text in the application didn't match the rendered output of the exported HTML and PDF. And as with Notion , it can be difficult to edit Markdown-formatted text after the live editor has converted it. {% include tool-syntax-table.html %}","title":"Mark Text"},{"location":"extern/md-guide/_tools/markdeep/","text":"Markdeep is a free and simple tool that turns any Markdown file into a self-contained HTML file that can be viewed in a web browser. There's nothing to install and there's no service to register for \u2014 you simply add one line of code to the bottom of your Markdown file. This is a great option if you need to quickly view a Markdown file in a web browser or share a Markdown file with someone who needs to view the rendered output. Using Markdeep is a three-part process: Add the following tag for Markdeep on a single line at the bottom of a Markdown file. <!-- Markdeep: --><style class=\"fallback\">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src=\"markdeep.min.js\" charset=\"utf-8\"></script><script src=\"https://casual-effects.com/markdeep/latest/markdeep.min.js\" charset=\"utf-8\"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility=\"visible\")</script> Rename the Markdown file to add the .md.html extension (i.e., myfile.md.html ). Open the file in a web browser to see the rendered output. This tool has a lot of features beyond what's described here. For instance, you can choose from a variety of templates to customize the look of your page. Markdeep also supports diagrams, LaTeX typesetting for equations, and much more. Check out the excellent documentation for the full details. {% include tool-syntax-table.html %}","title":"Markdeep"},{"location":"extern/md-guide/_tools/markdown-here/","text":"Markdown Here is a free and open-source browser extension that converts Markdown text in website forms to properly-formatted rich text. This a good way to start using Markdown everywhere you type, whether you're drafting email messages in Gmail or writing blog posts in WordPress. The marketing material positions Markdown Here as a solution for email, but the extension can be used with virtually any website that supports rich text, including Evernote. See the list of compatible websites and services for more information. To use Markdown Here after installing it, start typing Markdown-formatted text in a form, like a new email message in Gmail. When you're finished writing the message, right click in the form and select Markdown Toggle , as shown in the screenshot below. Markdown Here will convert your Markdown-formatted text to properly-formatted rich text. One source of frustration is the inconsistency in rendered output. Since Markdown Here relies on the features provided by whatever rich text editor you happen to be working in, the rendered output varies from website to website. This probably goes without saying, but you should be careful to examine the output before sending your email message or saving your file. {% include tool-syntax-table.html %}","title":"Markdown Here"},{"location":"extern/md-guide/_tools/mattermost/","text":"Mattermost is an open source enterprise messaging and team collaboration application. It's like Slack , but with excellent Markdown support. In fact, Mattermost provides exactly the type of Markdown support you want to see in a messaging application. You can type messages in Markdown or copy and paste Markdown-formatted text into the message field \u2014 it works exactly the way you'd expect it to. The application uses a fork of the marked Markdown processor . {% include tool-syntax-table.html %}","title":"Mattermost"},{"location":"extern/md-guide/_tools/mkdocs/","text":"MkDocs is a static site generator designed for building documentation websites. Written in the Python programming language, MkDocs is an open-source project with a lot of community support. A variety of themes are available. In terms of Markdown support, MkDocs does an excellent job supporting the basic syntax elements, but it lacks support for some extended syntax elements. The application uses the Python-Markdown Markdown processor. You can enable additional extensions . {% include tool-syntax-table.html %} Using Admonitions \u00b6 Here's a handy feature: You can enable an extension to use admonitions in MkDocs. This is a quick and easy way to start using notes, warnings, and tips on your MkDocs site. See this GitHub issue for more information and examples.","title":"MkDocs"},{"location":"extern/md-guide/_tools/mkdocs/#using-admonitions","text":"Here's a handy feature: You can enable an extension to use admonitions in MkDocs. This is a quick and easy way to start using notes, warnings, and tips on your MkDocs site. See this GitHub issue for more information and examples.","title":"Using Admonitions"},{"location":"extern/md-guide/_tools/notable/","text":"Notable is a bare-bones note taking application with excellent Markdown support. Free for desktop use, Notable is designed for people who like to see Markdown-formatted text while they're typing. There's no live editor here. It's just you and raw text. You can click the Edit button to switch between the editor and preview screen \u2014 a handy feature when you're reading through your notes. One of Notable's best features, if you can call it that, is the lack of features. There's no need to create an account, and there's no synchronization feature. Some might see that as a limitation, but it does eliminate the possibility of your files being compromised on a third-party server. But without a doubt, Notable's best feature is that it doesn't manipulate your Markdown files in any way \u2014 they're stored on your computer in the same format you see in Notable. If you decide later that you don't like Notable, you can take your Markdown files and do anything with them. The application uses the markdown-it Markdown processor. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Notable provides support for several obscure elements. Element Markdown Rendered Output Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Notable"},{"location":"extern/md-guide/_tools/notable/#support-for-additional-syntax-elements","text":"As an added bonus, Notable provides support for several obscure elements. Element Markdown Rendered Output Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/notion/","text":"Notion is an innovative application that bills itself as an all-in-one knowledge management solution for individuals and teams. You could think of it as a note-taking app or a wiki, but those descriptions don't really do it justice. You really have to try it to get a sense of what it's capable of. Some organizations use Notion for project management and task tracking, among other things. The application can even function as a database of sorts. Notion has desktop and mobile apps available, as well as a web-based interface. You create an account for yourself and your organization \u2014 the accounts are used to sync everything with Notion's servers. Notion's Markdown support is hit or miss. Copying and pasting Markdown-formatted text into Notion generally works the way you'd expect, but using Notion's live editor to write using Markdown doesn't always work. You can, for instance, use asterisks to make text bold, but trying to use brackets to create a link or pipes to create a table doesn't work \u2014 which is strange considering that those syntax elements do work when you copy and paste them in. It's also difficult to edit Markdown-formatted text that you've copied and pasted in Notion. {% include tool-syntax-table.html %}","title":"Notion"},{"location":"extern/md-guide/_tools/outline/","text":"Outline is a fast knowledge base and wiki designed for teams. Outline's live editor supports a wide variety of Markdown shortcuts. Documents created in the app are stored in Markdown format and can be exported as Markdown too, so you're never locked in. Beyond Markdown, Outline supports a range of features such as structured organization of documents, search, read/write permissions, user groups, backlinking, public sharing, and more. Outline is offered as a hosted service, and is also available for self hosting as a docker container. The source code is publicly available on GitHub. {% include tool-syntax-table.html %}","title":"Outline"},{"location":"extern/md-guide/_tools/reddit/","text":"With Markdown, Reddit text formatting is a breeze. All Reddit users have the option of writing comments and posts in Markdown. The popular news website has developed its own Markdown processor called \"snoomark\" which is based on GitHub-Flavored Markdown. Some have started referring to this as \"Reddit-flavored Markdown.\" For a deep dive into Reddit's Markdown support, see this wiki article . Enabling Markdown Support \u00b6 By default, Reddit disables Markdown support for new posts and comments. You can switch from the rich text editor to Markdown by clicking the Switch to markdown link, as shown below. To permanently save this setting, you can enable the Default to Markdown setting in User Settings > Feed Settings . Enabling that setting will automatically enable Markdown for new posts or comments. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Reddit provides support for several obscure elements. Element Markdown Rendered Output Spoilers This text will be hidden: >!spoilers! < Superscript The greatest thing you'll ever learn is just to ^reddit and be ^(reddited here) in return. The greatest thing you'll ever learn is just to reddit and be reddited here in return.","title":"Reddit"},{"location":"extern/md-guide/_tools/reddit/#enabling-markdown-support","text":"By default, Reddit disables Markdown support for new posts and comments. You can switch from the rich text editor to Markdown by clicking the Switch to markdown link, as shown below. To permanently save this setting, you can enable the Default to Markdown setting in User Settings > Feed Settings . Enabling that setting will automatically enable Markdown for new posts or comments. {% include tool-syntax-table.html %}","title":"Enabling Markdown Support"},{"location":"extern/md-guide/_tools/reddit/#support-for-additional-syntax-elements","text":"As an added bonus, Reddit provides support for several obscure elements. Element Markdown Rendered Output Spoilers This text will be hidden: >!spoilers! < Superscript The greatest thing you'll ever learn is just to ^reddit and be ^(reddited here) in return. The greatest thing you'll ever learn is just to reddit and be reddited here in return.","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/simpleen/","text":"Simpleen is a Markdown translation web app and API service. You create an account on the Simpleen website (free during beta), set up a translator (source/target language, format Markdown) and copy/paste your Markdown files into the In-App Translator. Use a custom glossary to further improve your translation results. Currently the Github Flavored Markdown Spec (GFM) is supported. More features as well as other flavors are planned (depending on user input). {% include tool-syntax-table.html %}","title":"Simpleen"},{"location":"extern/md-guide/_tools/simplenote/","text":"Simplenote is a basic note-taking application developed by Automattic, the same company that created WordPress. The application is free and available on every platform, including Linux. It's also open source . You can use Simplenote in your web browser. After you download the application, you'll be prompted to create an account. That account is used to back up your notes to Automattic's servers and synchronize your notes across all of your other devices. Note that Automattic doesn't encrypt your content on their servers. You can't disable the synchronizing feature. Export options are limited, but the Publish to Web feature allows you to share your notes on the internet with a public URL. Enabling Markdown Support \u00b6 To enable Markdown support in Simplenote, create a note, click the Info icon, and then select Markdown Formatted . The currently selected note and any new notes you create in the future will have this setting enabled automatically. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Simplenote provides support for several obscure elements. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Superscript The greatest thing you'll ever learn is just to ^reddit and be ^(reddited here) in return. The greatest thing you'll ever learn is just to reddit and be reddited here in return. Underline _word or phrase_ word or phrase Previewing Markdown Documents \u00b6 Simplenote doesn't use a live editor. You'll continue to see the Markdown-formatted text after you've typed it. To preview Markdown documents in Simplenote, click the Preview Markdown icon \u2014 it looks like an eye.","title":"Simplenote"},{"location":"extern/md-guide/_tools/simplenote/#enabling-markdown-support","text":"To enable Markdown support in Simplenote, create a note, click the Info icon, and then select Markdown Formatted . The currently selected note and any new notes you create in the future will have this setting enabled automatically. {% include tool-syntax-table.html %}","title":"Enabling Markdown Support"},{"location":"extern/md-guide/_tools/simplenote/#support-for-additional-syntax-elements","text":"As an added bonus, Simplenote provides support for several obscure elements. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Superscript The greatest thing you'll ever learn is just to ^reddit and be ^(reddited here) in return. The greatest thing you'll ever learn is just to reddit and be reddited here in return. Underline _word or phrase_ word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/simplenote/#previewing-markdown-documents","text":"Simplenote doesn't use a live editor. You'll continue to see the Markdown-formatted text after you've typed it. To preview Markdown documents in Simplenote, click the Preview Markdown icon \u2014 it looks like an eye.","title":"Previewing Markdown Documents"},{"location":"extern/md-guide/_tools/slack/","text":"Slack is a popular team messaging and collaboration application that supports a subset of the Markdown syntax. Different parts of the interface provide different levels of Markdown support. Messages \u00b6 Slack's message interface is the one people use most. Support for some basic syntax is provided, although support for many elements is notably absent. In November 2019, Slack introduced a new WYSIWYG interface, as shown below. This feature is enabled for all users by default. The most obvious change is the addition of formatting buttons in the interface controls, but there's also a live editor that hides the Markdown formatting after you type it. You don't have to use the interface controls to format your text \u2014 you can still use the Markdown syntax elements described in the next section. You can disable the WYSIWYG interface in Preferences > Advanced . Select the Format messages with markup setting, as shown below. Enabling this setting will hide the WYSIWYG formatting buttons and disable the live editor so you can see the Markdown formatting as you type it. Tip: If you have multiple workplaces open in Slack, you'll need to enable this setting for each workplace. Slack Markdown Support in Messages The Slack message interface provides support for the following the Markdown elements. Element Support Notes Headings No Paragraphs No Line Breaks No The Markdown syntax is not supported, but you can press the Shift and Return keys to go to the next line. Bold No The Markdown syntax is not supported, but you can add bold styling with single asterisks, which is the standard Markdown syntax for italic. Very confusing! Italic Partial Only underscores are supported. Blockquotes Yes Ordered Lists No Unordered Lists No Code Partial Code blocks are not supported. Horizontal Rules No Links No Images No The Markdown syntax is not supported, but you can drag and drop images to share them. Tables No Fenced Code Blocks Yes Syntax Highlighting No Footnotes No Heading IDs No Definition Lists No Strikethrough Partial Use only one tilde symbol before and after the phrase. Task Lists No Emoji (copy and paste) Yes Emoji (shortcodes) Yes Automatic URL Linking Yes Disabling Automatic URL Linking No HTML No Tip: This information relates to the message interface in Slack's user interface. The Slack API for messages supports additional syntax elements that aren't supported in Slack's user interface. See Slack's API documentation for more information. Posts \u00b6 The Slack post interface is editor that allows you to create a document for sharing in Slack. This is a live editor, which means you will see the actual formatting immediately after you type Markdown formatted text. For example, if you type _test_ , the underscores will disappear and you'll see the word \"test\" in italics. To create a post, click the shortcuts icon and select Create a Post as shown below. Slack Markdown Support in Posts The Slack post interface provides support for the following Markdown elements. Element Support Notes Headings Partial Only heading levels one and two are supported. Only number signs are supported. Paragraphs Yes Line Breaks No Bold No The Markdown syntax is not supported, but you can add bold styling with single asterisks, which is the standard Markdown syntax for italic. Very confusing! Italic Partial Only underscores are supported. Blockquotes Yes Ordered Lists Yes Unordered Lists Yes Code Yes Horizontal Rules No Links No Images No Tables No Fenced Code Blocks Yes Syntax Highlighting No Footnotes No Heading IDs No Definition Lists No Strikethrough Partial Use only one tilde symbol before and after the phrase. Task Lists No Emoji (copy and paste) Yes Emoji (shortcodes) Yes Automatic URL Linking Yes Disabling Automatic URL Linking Yes HTML No See Also \u00b6 Formatting Slack messages in the interface Formatting Slack posts in the interface API documentation for formatting Slack messages slack_markdown ruby gem","title":"Slack"},{"location":"extern/md-guide/_tools/slack/#messages","text":"Slack's message interface is the one people use most. Support for some basic syntax is provided, although support for many elements is notably absent. In November 2019, Slack introduced a new WYSIWYG interface, as shown below. This feature is enabled for all users by default. The most obvious change is the addition of formatting buttons in the interface controls, but there's also a live editor that hides the Markdown formatting after you type it. You don't have to use the interface controls to format your text \u2014 you can still use the Markdown syntax elements described in the next section. You can disable the WYSIWYG interface in Preferences > Advanced . Select the Format messages with markup setting, as shown below. Enabling this setting will hide the WYSIWYG formatting buttons and disable the live editor so you can see the Markdown formatting as you type it. Tip: If you have multiple workplaces open in Slack, you'll need to enable this setting for each workplace.","title":"Messages"},{"location":"extern/md-guide/_tools/slack/#posts","text":"The Slack post interface is editor that allows you to create a document for sharing in Slack. This is a live editor, which means you will see the actual formatting immediately after you type Markdown formatted text. For example, if you type _test_ , the underscores will disappear and you'll see the word \"test\" in italics. To create a post, click the shortcuts icon and select Create a Post as shown below.","title":"Posts"},{"location":"extern/md-guide/_tools/slack/#see-also","text":"Formatting Slack messages in the interface Formatting Slack posts in the interface API documentation for formatting Slack messages slack_markdown ruby gem","title":"See Also"},{"location":"extern/md-guide/_tools/squarespace/","text":"id: headings available: y id: paragraphs available: y id: line-breaks available: y id: bold available: y id: italic available: y id: blockquotes available: y id: ordered-lists available: y id: unordered-lists available: y id: code available: y id: horizontal-rules available: y id: links available: p notes: \"Using angle brackets for URLs and email addresses is not supported.\" id: images available: y id: tables available: y id: fenced-code-blocks available: y id: syntax-highlighting available: n id: footnotes available: n id: heading-ids available: n id: definition-lists available: n id: strikethrough available: y id: task-lists available: n id: emoji-cp available: y id: emoji-sc available: n id: auto-url-linking available: y id: disabling-auto-url available: y id: html available: y see-also: name: Markdown cheat sheet link: https://support.squarespace.com/hc/en-us/articles/206543587-Markdown-cheat-sheet name: Markdown blocks link: https://support.squarespace.com/hc/en-us/articles/205813788-Markdown-Blocks Squarespace is a popular subscription service for building websites. The service features a drag-and-drop interface that lets you build websites right in your web browser. One of the components available for webpages is a Markdown block \u2014 a content area that supports Markdown. You'll see the option when you click the Add Block icon, as shown below. Squarespace supports most basic Markdown syntax elements, but support for a number of extended syntax elements is lacking. One disadvantage is that the editor for the Markdown block is a tiny box and the text is displayed in a minuscule (and non-adjustable) font size. You're probably better off copying and pasting the text in from another application. {% include tool-syntax-table.html %}","title":"Squarespace"},{"location":"extern/md-guide/_tools/stackedit/","text":"StackEdit is a powerful online Markdown editor. Like Dillinger , it loads right in your web browser, so there's no need to download and install an application on your computer. StackEdit has a wide variety of features and configurable options for power users, making it in many ways a better all-around option than comparable desktop applications. StackEdit's Markdown support is excellent. Features include the ability to sync and save files to third-party services, output to various file formats using custom templates, and configure metadata properties for files. (Note that you must subscribe to StackEdit to output to some of the file formats, like PDF.) LaTeX and UML diagrams are also supported. You can apparently use StackEdit without an internet connection. StackEdit is limited by a lack of documentation. Users are left to discover and toy around with many of the application's features on their own. That's a shame, because the undocumented features are essentially unusable by all but the most advanced users. For example, you can create your own templates for exported files, but there's no information about what templating language is used, and no guidance on how to create your own templates. There is a community support forum , but users shouldn't have to read through questions and answers to figure out how to do something simple. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, StackEdit provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"StackEdit"},{"location":"extern/md-guide/_tools/stackedit/#support-for-additional-syntax-elements","text":"As an added bonus, StackEdit provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/standard-notes/","text":"Standard Notes is an elegant, open-source note taking application with an excellent feature set. Markdown support is not provided by default, but by paying for the optional subscription , you can enable one of several Markdown extensions available to subscribers. I used the Advanced Markdown extension , which is what's documented below. Admittedly, the category for Markdown note taking applications is a crowded one. Standard Notes stands out by offering a great user experience, outstanding privacy and synchronization features, and a strong commitment to open source software. The application and the overall experience feels professional-grade. Standard Notes works on every platform. {% include tool-syntax-table.html %}","title":"Standard Notes"},{"location":"extern/md-guide/_tools/todoist/","text":"Todoist is a to-do list application that helps you record and track tasks to completion. Todoist provides surprisingly good Markdown support for an application of this type. You can use Markdown syntax to format the task names and comments you create in the Todoist website and mobile applications (unfortunately, you can't use Markdown in the names for projects, labels, or filters). {% include tool-syntax-table.html %}","title":"Todoist"},{"location":"extern/md-guide/_tools/trello/","text":"Trello is a popular kanban-style project management application that can be used for everything from project management to making grocery shopping lists. You create a board, add columns (called \"lists\"), and then add cards to lists. The interactive drag-and-drop interface allows you to easily reorder cards and move them between lists as you work on tasks. Trello has excellent support for basic Markdown syntax. You can use Markdown in the card descriptions, checklists, and comments. You can also use Markdown for your Trello bio. Not all formatting is properly displayed when viewed in the iOS and Andriod applications. {% include tool-syntax-table.html %} See Also \u00b6 How To Format Your Text in Trello","title":"Trello"},{"location":"extern/md-guide/_tools/trello/#see-also","text":"How To Format Your Text in Trello","title":"See Also"},{"location":"extern/md-guide/_tools/typora/","text":"Typora is a simple and configurable document editor that provides excellent Markdown support. This application is ideal for students and professionals who need to write essays and reports. It might be difficult using Typora for multi-file projects or for website publishing. Typora stands out by offering a variety of settings without sacrificing the simplicity of a barebones interface. Newcomers to Markdown may appreciate the keyboard shortcuts for formatting options as well as the intuitive live editor that hides the Markdown formatting syntax after you type it. See the Typora Markdown reference for the official documentation. The Typora documentation indicates that the application generally uses GitHub Flavored Markdown (GFM) . {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Typora provides support for several obscure elements, including diagrams and inline math. Most of these elements are disabled by default. To enable them, open the Preferences window and modify the settings under Markdown > Syntax Support . See the Typora Markdown reference for additional information. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2 Themes \u00b6 Typora provides a variety of themes for when you export your documents. If you know CSS, you can customize these themes. Open the Preferences window and see the settings under Appearance > Themes . Strict Mode \u00b6 Typora provides strict mode settings for users who want to enforce syntax limitations on headings, ordered lists, and unordered lists. For example, you could configure unordered lists to only use hyphens and not asterisks. Configure these settings in the Preferences window under Markdown > Syntax Preference . See the Typora documentation for additional information. Source Code Mode \u00b6 You can disable Typora's live editor by selecting View > Source Code Mode . This will reveal all of the Markdown formatting that's hidden by the live editor. Export Options \u00b6 Typora provides a wide variety of export options under File > Export for when you're ready to publish your Markdown document. Some of the export options, like Microsoft Word and LaTeX format, require Pandoc .","title":"Typora"},{"location":"extern/md-guide/_tools/typora/#support-for-additional-syntax-elements","text":"As an added bonus, Typora provides support for several obscure elements, including diagrams and inline math. Most of these elements are disabled by default. To enable them, open the Preferences window and modify the settings under Markdown > Syntax Support . See the Typora Markdown reference for additional information. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/typora/#themes","text":"Typora provides a variety of themes for when you export your documents. If you know CSS, you can customize these themes. Open the Preferences window and see the settings under Appearance > Themes .","title":"Themes"},{"location":"extern/md-guide/_tools/typora/#strict-mode","text":"Typora provides strict mode settings for users who want to enforce syntax limitations on headings, ordered lists, and unordered lists. For example, you could configure unordered lists to only use hyphens and not asterisks. Configure these settings in the Preferences window under Markdown > Syntax Preference . See the Typora documentation for additional information.","title":"Strict Mode"},{"location":"extern/md-guide/_tools/typora/#source-code-mode","text":"You can disable Typora's live editor by selecting View > Source Code Mode . This will reveal all of the Markdown formatting that's hidden by the live editor.","title":"Source Code Mode"},{"location":"extern/md-guide/_tools/typora/#export-options","text":"Typora provides a wide variety of export options under File > Export for when you're ready to publish your Markdown document. Some of the export options, like Microsoft Word and LaTeX format, require Pandoc .","title":"Export Options"},{"location":"extern/md-guide/_tools/ulysses/","text":"Ulysses is a popular writing application for macOS and iOS devices. Lauded by journalists and reviewers, Ulysses provides lots of useful features and nice touches for people who write professionally. The theming and export options are second to none. Unfortunately, using Ulysses to write in Markdown is an exercise in frustration. The application supports a subset of the Markdown syntax, but support for many syntax elements is notably absent. Even worse, support for some elements is provided using non-standard notation. Ulysses might not be your first choice if you're wanting to write exclusively in Markdown. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Ulysses provides support for several obscure elements. Element Markdown Rendered Output Highlight ::word or phrase:: word or phrase","title":"Ulysses"},{"location":"extern/md-guide/_tools/ulysses/#support-for-additional-syntax-elements","text":"As an added bonus, Ulysses provides support for several obscure elements. Element Markdown Rendered Output Highlight ::word or phrase:: word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/zettlr/","text":"Zettlr is free and open source Markdown application designed for academic writing. It provides a lot of powerful tools to help you write academic texts right out of the box. The application's stated goal is simple: \"Enabling researchers of arts and humanities, e.g. those people without any knowledge of coding, to finally free themselves from software that costs hundreds of dollars and pave the way into an Open Source era. This would be only fitting, given the fact that especially in political science and sociology, cries for Open Access journals are on the rise. So here\u2019s what Zettlr is all about: It wants to be serious competition for word processors.\" Zettlr Markdown Support \u00b6 Zettlr provides support for the following Markdown elements. See the Zettlr Documentation for the official documentation. Zettlr itself implements a mixture of different dialects. The editor itself highlights only GitHub Flavored Markdown plus some extra elements which extends Markdown syntax with Zettelkasten elements. You can also add LaTeX-commands. {% include tool-syntax-table.html %}","title":"Zettlr"},{"location":"extern/md-guide/_tools/zettlr/#zettlr-markdown-support","text":"Zettlr provides support for the following Markdown elements. See the Zettlr Documentation for the official documentation. Zettlr itself implements a mixture of different dialects. The editor itself highlights only GitHub Flavored Markdown plus some extra elements which extends Markdown syntax with Zettelkasten elements. You can also add LaTeX-commands. {% include tool-syntax-table.html %}","title":"Zettlr Markdown Support"},{"location":"extern/md-guide/_tools/znote/","text":"Znote is a free application designed to help you write organized Markdown documents. You can quickly edit your texts, notes, and files using the simplistic left-side widget organizer for smoothly navigating different files. The dark mode and code highlighter features are designed for developers. Available for macOS, Windows and Linux. {% include tool-syntax-table.html %}","title":"Znote"},{"location":"extern/md-guide/api/v1/","text":"Introduction \u00b6 The Markdown Guide API provides a subset of documentation from the Markdown Guide in JSON format. We hope that software developers and organizations use this API to programmatically consume our documentation and display it in applications and on websites. Why? \u00b6 Why create an API for Markdown documentation? Because there's so much duplicated Markdown documentation on the web! It seems like everybody has their own version of Markdown documentation for their application or website. That's a shame since most of it is exactly the same. Then came the epiphany. \ud83d\udca1 We realized we could create a JSON API using documentation from the Markdown Guide . That way, software developers could start using the API to include our documentation in their applications, and organizations like universities and libraries could use the API to include our documentation on their websites. We'd love to see the Markdown Guide become the central documentation repository for the thousands of Markdown instructions sprinkled around the internet. Will it work? Who knows! One thing's for sure though: We can't wait to see what you do with it. \ud83e\udd18 Limitations \u00b6 The Markdown Guide API is designed to provide only essential Markdown documentation. As a result, the API doesn't include all of the documentation available on the Markdown Guide website. For example, the Adding Elements in Lists section is not available through the basic syntax endpoint. Basic Syntax Endpoint \u00b6 The basic syntax endpoint contains documentation about the Markdown elements outlined in John Gruber's design document and described on the Basic Syntax page . API Endpoint /api/v1/basic-syntax.json Request \u00b6 curl https://www.markdownguide.org/api/v1/basic-syntax.json Response \u00b6 Cheat Sheet Endpoint \u00b6 The cheat sheet endpoint provides an overview of the most popular basic and extended Markdown syntax elements, as described on the Cheat Sheet page . API Endpoint /api/v1/cheat-sheet.json Request \u00b6 curl https://www.markdownguide.org/api/v1/cheat-sheet.json Response \u00b6 Changelog Here's a list of all the changes we've made to the Markdown Guide API. 2018-10-18 - Updated cheat sheet endpoint to include information about definition lists 2018-07-12 - Updated links description to include information about adding titles 2017-11-10 - Added cheat sheet endpoint 2017-11-04 - Added section about escaping backticks in code 2017-10-24 - Released API v1 - Published docs","title":"API"},{"location":"extern/md-guide/api/v1/#introduction","text":"The Markdown Guide API provides a subset of documentation from the Markdown Guide in JSON format. We hope that software developers and organizations use this API to programmatically consume our documentation and display it in applications and on websites.","title":"Introduction"},{"location":"extern/md-guide/api/v1/#why","text":"Why create an API for Markdown documentation? Because there's so much duplicated Markdown documentation on the web! It seems like everybody has their own version of Markdown documentation for their application or website. That's a shame since most of it is exactly the same. Then came the epiphany. \ud83d\udca1 We realized we could create a JSON API using documentation from the Markdown Guide . That way, software developers could start using the API to include our documentation in their applications, and organizations like universities and libraries could use the API to include our documentation on their websites. We'd love to see the Markdown Guide become the central documentation repository for the thousands of Markdown instructions sprinkled around the internet. Will it work? Who knows! One thing's for sure though: We can't wait to see what you do with it. \ud83e\udd18","title":"Why?"},{"location":"extern/md-guide/api/v1/#limitations","text":"The Markdown Guide API is designed to provide only essential Markdown documentation. As a result, the API doesn't include all of the documentation available on the Markdown Guide website. For example, the Adding Elements in Lists section is not available through the basic syntax endpoint.","title":"Limitations"},{"location":"extern/md-guide/api/v1/#basic-syntax-endpoint","text":"The basic syntax endpoint contains documentation about the Markdown elements outlined in John Gruber's design document and described on the Basic Syntax page .","title":"Basic Syntax Endpoint"},{"location":"extern/md-guide/api/v1/#request","text":"curl https://www.markdownguide.org/api/v1/basic-syntax.json","title":"Request"},{"location":"extern/md-guide/api/v1/#response","text":"","title":"Response"},{"location":"extern/md-guide/api/v1/#cheat-sheet-endpoint","text":"The cheat sheet endpoint provides an overview of the most popular basic and extended Markdown syntax elements, as described on the Cheat Sheet page .","title":"Cheat Sheet Endpoint"},{"location":"extern/md-guide/api/v1/#request_1","text":"curl https://www.markdownguide.org/api/v1/cheat-sheet.json","title":"Request"},{"location":"extern/md-guide/api/v1/#response_1","text":"","title":"Response"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/","text":"Markdown Cheat Sheet \u00b6 Thanks for visiting The Markdown Guide ! This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can\u2019t cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax . Basic Syntax \u00b6 These are the elements outlined in John Gruber\u2019s original design document. All Markdown applications support these elements. Heading \u00b6 H1 \u00b6 H2 \u00b6 H3 \u00b6 Bold \u00b6 bold text Italic \u00b6 italicized text Blockquote \u00b6 blockquote Ordered List \u00b6 First item Second item Third item Unordered List \u00b6 First item Second item Third item Code \u00b6 code Horizontal Rule \u00b6 Link \u00b6 title Image \u00b6 Extended Syntax \u00b6 These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements. Table \u00b6 Syntax Description Header Title Paragraph Text Fenced Code Block \u00b6 { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } Footnote \u00b6 Here's a sentence with a footnote. 1 Heading ID \u00b6 My Great Heading \u00b6 Definition List \u00b6 term definition Strikethrough \u00b6 The world is flat. Task List \u00b6 [x] Write the press release [ ] Update the website [ ] Contact the media This is the footnote. \u21a9","title":"Markdown Cheat Sheet"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#markdown-cheat-sheet","text":"Thanks for visiting The Markdown Guide ! This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can\u2019t cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax .","title":"Markdown Cheat Sheet"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#basic-syntax","text":"These are the elements outlined in John Gruber\u2019s original design document. All Markdown applications support these elements.","title":"Basic Syntax"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#heading","text":"","title":"Heading"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#h1","text":"","title":"H1"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#h2","text":"","title":"H2"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#h3","text":"","title":"H3"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#bold","text":"bold text","title":"Bold"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#italic","text":"italicized text","title":"Italic"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#blockquote","text":"blockquote","title":"Blockquote"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#ordered-list","text":"First item Second item Third item","title":"Ordered List"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#unordered-list","text":"First item Second item Third item","title":"Unordered List"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#code","text":"code","title":"Code"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#horizontal-rule","text":"","title":"Horizontal Rule"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#link","text":"title","title":"Link"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#image","text":"","title":"Image"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#extended-syntax","text":"These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements.","title":"Extended Syntax"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#table","text":"Syntax Description Header Title Paragraph Text","title":"Table"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#fenced-code-block","text":"{ \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 }","title":"Fenced Code Block"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#footnote","text":"Here's a sentence with a footnote. 1","title":"Footnote"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#heading-id","text":"","title":"Heading ID"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#custom-id","text":"","title":"My Great Heading"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#definition-list","text":"term definition","title":"Definition List"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#strikethrough","text":"The world is flat.","title":"Strikethrough"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#task-list","text":"[x] Write the press release [ ] Update the website [ ] Contact the media This is the footnote. \u21a9","title":"Task List"},{"location":"go/concurency/","text":"Go concurency \u00b6 Do not communicate by sharing memory; instead, share memory by communicating. 1 Context \u00b6 Context pkg defines the Context type, which carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes. Notes: \u00b6 https://golang.org/doc/effective_go.html#concurrency \u21a9","title":"Concurency"},{"location":"go/concurency/#go-concurency","text":"Do not communicate by sharing memory; instead, share memory by communicating. 1","title":"Go concurency"},{"location":"go/concurency/#context","text":"Context pkg defines the Context type, which carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes.","title":"Context"},{"location":"go/concurency/#notes","text":"https://golang.org/doc/effective_go.html#concurrency \u21a9","title":"Notes:"},{"location":"go/distributed/","text":"Distributed \u00b6 RAFT algorithm \u00b6 Blog post Used in Kubernets etcd distributed key-value store.","title":"Distributed"},{"location":"go/distributed/#distributed","text":"","title":"Distributed"},{"location":"go/distributed/#raft-algorithm","text":"Blog post Used in Kubernets etcd distributed key-value store.","title":"RAFT algorithm"},{"location":"go/intro/","text":"Go lang \u00b6 In Go, when you call a function or a method the arguments are copied. High performance go by Dave Cheney (Paris 2019)","title":"Go lang"},{"location":"go/intro/#go-lang","text":"In Go, when you call a function or a method the arguments are copied. High performance go by Dave Cheney (Paris 2019)","title":"Go lang"},{"location":"infrastructure/ldap/","text":"Lightweight Directory Access Protocol (LDAP) \u00b6 Implementations \u00b6 Python \u00b6 Python ldap provides an interface to LDAP v3. Base objects are: ldap provides access to OpenLDAP's C API.","title":"Lightweight Directory Access Protocol (LDAP)"},{"location":"infrastructure/ldap/#lightweight-directory-access-protocol-ldap","text":"","title":"Lightweight Directory Access Protocol (LDAP)"},{"location":"infrastructure/ldap/#implementations","text":"","title":"Implementations"},{"location":"infrastructure/ldap/#python","text":"Python ldap provides an interface to LDAP v3. Base objects are: ldap provides access to OpenLDAP's C API.","title":"Python"},{"location":"infrastructure/vm/","text":"VM \u00b6 Wikipedia VirtualBox \u00b6 VirtualBox is a general-purpose full virtualizer for x86 hardware, targeted at server, desktop and embedded use. Installation \u00b6 Binaries, extension and source code can be installed from the wiki . A handy feature is the ability to run common commands for managing VM from the cli after installing the extension pack Basic command for running VM \u00b6 The extension pack cli entry point VBoxManage can be aliased as: alias vbm = VBoxManage List VM's: vbm list vms # List running vms vbm list runningvms Change the name of a VM: vbm modifyvm \"VirtualMachine provided for test purpose\" --name \"MyVM\" Start a VM in headless mode: vbm startvm \"MyVM\" --type headless Once started, a VM in headless mode can be controlled (pause/resume/poweroff): vbm controlvm \"MyVM\" pause --type headless vbm controlvm \"MyVM\" resume --type headless vbm controlvm \"MyVM\" poweroff --type headless View VM properties with vboxmanage guestproperty # Enumerate all properties of the VM named MyVM vbm guestproperty enumerate MyVM # Get the IP address of the VM named Cloudera vbm guestproperty get Cloudera /VirtualBox/GuestInfo/Net/0/V4/IP Vagrant \u00b6 Installation on Debian based systems \u00b6 deb package can be found at download curl -LO https://releases.hashicorp.com/vagrant/2.2.17/vagrant_2.2.17_x86_64.deb sudo apt install ./vagrant_2.2.17_x86_64.deb # or dpkg -i vagranfile \u00b6 Vagrant climbs up the directory tree looking for the first Vagrantfile it can find, starting first in the current directory (or using $VAGRANT_CWD value). See load oder and merging . Customizing Vagrant VMware Fusion Virtual Machines with VMX Parameters How to create a Vagrant Box running Red Hat Enterprise Linux Troubleshooting on hosts with secure mode enabled \u00b6 UEFI 1 Secure Boot 2 (SB) is a verification mechanism for ensuring that code launched by a computer's UEFI firmware is trusted. Unsigned drivers are therefor not allowed to load. 2 kernels modules are compiled at installation time and must be loaded. If the host provides the proper kernel headers and gcc, these two modules will be built silently. The progress is logged into /tmp/vmware-root/vmware-PID.log 3 . On error type like: Cannot open /dev/vmmon : No such file or directory. Please make sure that the kernel module vmmon is loaded The modules must be signed and the keys added to a database recognised by the first stage of the bootloader, the Machine Owner Key # Modules must be signed by a CA ( Certificate Authority ) , here self-signed openssl req -new -x509 -newkey rsa:2048 -keyout <MOK.priv> -outform DER -out <MOK.der> -nodes -days 36500 -subj \"/CN=VMware/\" sudo /usr/src/linux-headers-``uname -r``/scripts/sign-file sha256 <MOK.priv> <MOK.der> $(modinfo -n vmmon) sudo /usr/src/linux-headers-``uname -r``/scripts/sign-file sha256 <MOK.priv> <MOK.der> $(modinfo -n vmnet) sudo mokutil --test-key <MOK.der> # cert should not be currently enrolled sudo mokutil --import <MOK.der> # mokutil should request pwd sudo mokutil --test-key <MOK.der> # cert should be enrolled now sudo mokutil --list-new # your cert should be displayed reboot Links \u00b6 Unified Extensible Firmware Interface - https://wiki.debian.org/UEFI \u21a9 Debian secure boot documentation page \u21a9 VMware knowledge base \u21a9","title":"VM"},{"location":"infrastructure/vm/#vm","text":"Wikipedia","title":"VM"},{"location":"infrastructure/vm/#virtualbox","text":"VirtualBox is a general-purpose full virtualizer for x86 hardware, targeted at server, desktop and embedded use.","title":"VirtualBox"},{"location":"infrastructure/vm/#installation","text":"Binaries, extension and source code can be installed from the wiki . A handy feature is the ability to run common commands for managing VM from the cli after installing the extension pack","title":"Installation"},{"location":"infrastructure/vm/#basic-command-for-running-vm","text":"The extension pack cli entry point VBoxManage can be aliased as: alias vbm = VBoxManage List VM's: vbm list vms # List running vms vbm list runningvms Change the name of a VM: vbm modifyvm \"VirtualMachine provided for test purpose\" --name \"MyVM\" Start a VM in headless mode: vbm startvm \"MyVM\" --type headless Once started, a VM in headless mode can be controlled (pause/resume/poweroff): vbm controlvm \"MyVM\" pause --type headless vbm controlvm \"MyVM\" resume --type headless vbm controlvm \"MyVM\" poweroff --type headless View VM properties with vboxmanage guestproperty # Enumerate all properties of the VM named MyVM vbm guestproperty enumerate MyVM # Get the IP address of the VM named Cloudera vbm guestproperty get Cloudera /VirtualBox/GuestInfo/Net/0/V4/IP","title":"Basic command for running VM"},{"location":"infrastructure/vm/#vagrant","text":"","title":"Vagrant"},{"location":"infrastructure/vm/#installation-on-debian-based-systems","text":"deb package can be found at download curl -LO https://releases.hashicorp.com/vagrant/2.2.17/vagrant_2.2.17_x86_64.deb sudo apt install ./vagrant_2.2.17_x86_64.deb # or dpkg -i","title":"Installation on Debian based systems"},{"location":"infrastructure/vm/#vagranfile","text":"Vagrant climbs up the directory tree looking for the first Vagrantfile it can find, starting first in the current directory (or using $VAGRANT_CWD value). See load oder and merging . Customizing Vagrant VMware Fusion Virtual Machines with VMX Parameters How to create a Vagrant Box running Red Hat Enterprise Linux","title":"vagranfile"},{"location":"infrastructure/vm/#troubleshooting-on-hosts-with-secure-mode-enabled","text":"UEFI 1 Secure Boot 2 (SB) is a verification mechanism for ensuring that code launched by a computer's UEFI firmware is trusted. Unsigned drivers are therefor not allowed to load. 2 kernels modules are compiled at installation time and must be loaded. If the host provides the proper kernel headers and gcc, these two modules will be built silently. The progress is logged into /tmp/vmware-root/vmware-PID.log 3 . On error type like: Cannot open /dev/vmmon : No such file or directory. Please make sure that the kernel module vmmon is loaded The modules must be signed and the keys added to a database recognised by the first stage of the bootloader, the Machine Owner Key # Modules must be signed by a CA ( Certificate Authority ) , here self-signed openssl req -new -x509 -newkey rsa:2048 -keyout <MOK.priv> -outform DER -out <MOK.der> -nodes -days 36500 -subj \"/CN=VMware/\" sudo /usr/src/linux-headers-``uname -r``/scripts/sign-file sha256 <MOK.priv> <MOK.der> $(modinfo -n vmmon) sudo /usr/src/linux-headers-``uname -r``/scripts/sign-file sha256 <MOK.priv> <MOK.der> $(modinfo -n vmnet) sudo mokutil --test-key <MOK.der> # cert should not be currently enrolled sudo mokutil --import <MOK.der> # mokutil should request pwd sudo mokutil --test-key <MOK.der> # cert should be enrolled now sudo mokutil --list-new # your cert should be displayed reboot","title":"Troubleshooting on hosts with secure mode enabled"},{"location":"infrastructure/vm/#links","text":"Unified Extensible Firmware Interface - https://wiki.debian.org/UEFI \u21a9 Debian secure boot documentation page \u21a9 VMware knowledge base \u21a9","title":"Links"},{"location":"infrastructure/containerization/cli/","text":"Docker CLI \u00b6 Docker Application \u00b6 Command Description docker app bundle Create a CNAB invocation image and bundle.json for the application docker app completion Generates completion scripts for the specified shell (bash or zsh) docker app init Initialize Docker Application definition docker app inspect Shows metadata, parameters and a summary of the Compose file for a given application docker app install Install an application docker app list List the installations and their last known installation result docker app merge Merge a directory format Docker Application definition into a single file docker app pull Pull an application package from a registry docker app push Push an application package to a registry docker app render Render the Compose file for an Application Package docker app split Split a single-file Docker Application definition into the directory format docker app status Get the installation status of an application docker app uninstall Uninstall an application docker app upgrade Upgrade an installed application docker app validate Checks the rendered application is syntactically correct docker app version Print version information Docker builder \u00b6 Command Description docker builder build Build an image from a Dockerfile docker builder prune Remove build cache Docker buildx \u00b6 Command Description docker buildx bake Build from a file docker buildx build Start a build docker buildx create Create a new builder instance docker buildx du Disk usage docker buildx imagetools Commands to work on images in registry docker buildx inspect Inspect current builder instance docker buildx ls List builder instances docker buildx prune Remove build cache docker buildx rm Remove a builder instance docker buildx stop Stop builder instance docker buildx use Set the current builder instance docker buildx version Show buildx version information Docker compose \u00b6 Command Description docker compose build Build or rebuild services docker compose convert Converts the compose file to platform\u2019s canonical format docker compose create Creates containers for a service. docker compose down Stop and remove containers, networks docker compose events Receive real time events from containers. docker compose exec Execute a command in a running container. docker compose kill Force stop service containers. docker compose logs View output from containers docker compose ls List running compose projects docker compose pause pause services docker compose ps List containers docker compose pull Pull service images docker compose push Push service images docker compose rm Removes stopped service containers docker compose run Run a one-off command on a service. docker compose start Start services docker compose stop Stop services docker compose top Display the running processes docker compose unpause unpause services docker compose up Create and start containers","title":"Docker CLI"},{"location":"infrastructure/containerization/cli/#docker-cli","text":"","title":"Docker CLI"},{"location":"infrastructure/containerization/cli/#docker-application","text":"Command Description docker app bundle Create a CNAB invocation image and bundle.json for the application docker app completion Generates completion scripts for the specified shell (bash or zsh) docker app init Initialize Docker Application definition docker app inspect Shows metadata, parameters and a summary of the Compose file for a given application docker app install Install an application docker app list List the installations and their last known installation result docker app merge Merge a directory format Docker Application definition into a single file docker app pull Pull an application package from a registry docker app push Push an application package to a registry docker app render Render the Compose file for an Application Package docker app split Split a single-file Docker Application definition into the directory format docker app status Get the installation status of an application docker app uninstall Uninstall an application docker app upgrade Upgrade an installed application docker app validate Checks the rendered application is syntactically correct docker app version Print version information","title":"Docker Application"},{"location":"infrastructure/containerization/cli/#docker-builder","text":"Command Description docker builder build Build an image from a Dockerfile docker builder prune Remove build cache","title":"Docker builder"},{"location":"infrastructure/containerization/cli/#docker-buildx","text":"Command Description docker buildx bake Build from a file docker buildx build Start a build docker buildx create Create a new builder instance docker buildx du Disk usage docker buildx imagetools Commands to work on images in registry docker buildx inspect Inspect current builder instance docker buildx ls List builder instances docker buildx prune Remove build cache docker buildx rm Remove a builder instance docker buildx stop Stop builder instance docker buildx use Set the current builder instance docker buildx version Show buildx version information","title":"Docker buildx"},{"location":"infrastructure/containerization/cli/#docker-compose","text":"Command Description docker compose build Build or rebuild services docker compose convert Converts the compose file to platform\u2019s canonical format docker compose create Creates containers for a service. docker compose down Stop and remove containers, networks docker compose events Receive real time events from containers. docker compose exec Execute a command in a running container. docker compose kill Force stop service containers. docker compose logs View output from containers docker compose ls List running compose projects docker compose pause pause services docker compose ps List containers docker compose pull Pull service images docker compose push Push service images docker compose rm Removes stopped service containers docker compose run Run a one-off command on a service. docker compose start Start services docker compose stop Stop services docker compose top Display the running processes docker compose unpause unpause services docker compose up Create and start containers","title":"Docker compose"},{"location":"infrastructure/containerization/containerd/","text":"Docker \u00b6 Containerd \u00b6 A \u201ccontainer runtime\u201d layer located between platforms (Docker, Kubernetes) and lower level runtimes (runc, Kata, Firecracker, gVisor) a resource manager for container processes, image artifacts, filesystem snapshots, metadata and dependencies Originally built up alongside Docker, the project was nor forked nor inherited but grew in scope from a container supervisor to full runtime. Completely new interfaces for managing containers and images were created. Source: https://static.sched.com/hosted_files/kccnceu20/99/2020%20-%20Kubecon%20EU%20Introduction-containerd.pdf https://youtube.com/watch?v=aVReM1D82iY https://static.sched.com/hosted_files/kccnceu20/c1/containerd-deep-dive.pdf https://youtube.com/c/cloudnativef","title":"Containerd"},{"location":"infrastructure/containerization/containerd/#docker","text":"","title":"Docker"},{"location":"infrastructure/containerization/containerd/#containerd","text":"A \u201ccontainer runtime\u201d layer located between platforms (Docker, Kubernetes) and lower level runtimes (runc, Kata, Firecracker, gVisor) a resource manager for container processes, image artifacts, filesystem snapshots, metadata and dependencies Originally built up alongside Docker, the project was nor forked nor inherited but grew in scope from a container supervisor to full runtime. Completely new interfaces for managing containers and images were created. Source: https://static.sched.com/hosted_files/kccnceu20/99/2020%20-%20Kubecon%20EU%20Introduction-containerd.pdf https://youtube.com/watch?v=aVReM1D82iY https://static.sched.com/hosted_files/kccnceu20/c1/containerd-deep-dive.pdf https://youtube.com/c/cloudnativef","title":"Containerd"},{"location":"infrastructure/containerization/intro/","text":"Docker \u00b6 Containers and virtual machines have similar resource isolation and allocation benefits, but function differently because containers virtualize the operating system instead of hardware. Containers are more portable and efficient. Source: http://docker.com Tools \u00b6 container-diff is a tool for analyzing and comparing container images along several different criteria, e.g. Docker Image History, image file system andsize, Apt, RPM, pip and npm packages. Dive is a tool for exploring each layer in a docker image. DockerSlim minify docker image and Generate Security Profiles.","title":"Docker"},{"location":"infrastructure/containerization/intro/#docker","text":"Containers and virtual machines have similar resource isolation and allocation benefits, but function differently because containers virtualize the operating system instead of hardware. Containers are more portable and efficient. Source: http://docker.com","title":"Docker"},{"location":"infrastructure/containerization/intro/#tools","text":"container-diff is a tool for analyzing and comparing container images along several different criteria, e.g. Docker Image History, image file system andsize, Apt, RPM, pip and npm packages. Dive is a tool for exploring each layer in a docker image. DockerSlim minify docker image and Generate Security Profiles.","title":"Tools"},{"location":"infrastructure/devops/ansible/","text":"Ansible \u00b6 Global configuration is in /etc/ansible By default, Ansible will try to use native OpenSSH for remote communication when possible. This enables ControlPersist 1 , Kerberos, and options in ~/.ssh/config such as Jump Host setup. Variables \u00b6 Variable names should be letters, numbers, and underscores. Variables should always start with a letter. YAML also supports dictionaries which map keys to values . Variables can be defined in: inventories playbooks and later be used in playbooks using the Jinja2 templating system. Ansible Facts : system variables \u00b6 As well as with the ansible_facts variable, facts are variables discovered from systems. $ ansible localhost -m setup 127.0.0.1 | SUCCESS => { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ ... \"changed\": false } $ ansible localhost -m setup -a \"filter=*arch*\" 127.0.0.1 | SUCCESS => { \"ansible_facts\": { \"ansible_architecture\": \"x86_64\", \"ansible_userspace_architecture\": \"x86_64\" }, \"changed\": false } Playbooks \u00b6 The goal of a playbook is to map a group of hosts to some well defined roles, represented by things ansible calls tasks. Basic elements Task \u00b6 A task is in its simple form triggers the executing of a module, with specific arguments. Tasks can be condionally executed , looped . Logical grouping of tasks can be organised in blocks . Variables can be used in arguments to modules. Modules should be idempotent and changes trigger handlers . Handlers \u00b6 Modules can relay when they have made a change on the remote system: notify . loops \u00b6 loop is prefered over with_* (not deprecated) Best practices Run a playbook and load password stored in vault ansible-playbook --ask-vault-pass --extra-vars '@/etc/ansible/vault.yml' oh-my-zsh.yml Specifying an inventory file ansible-playbook -i inventories/hosts --ask-vault-pass --extra-vars '@/etc/ansible/vault.yml' oh-my-zsh.yml Inventory \u00b6 Variables can be assigned to hosts [atlanta] host1 http_port=80 maxRequestsPerChild=808 host2 http_port=303 maxRequestsPerChild=909 Roles \u00b6 Roles are ways of automatically loading certain vars_files, tasks, and handlers based on a known file structure. Grouping content by roles also allows easy sharing of roles with other users. A role is distributed as directory structure and contains at least one of the following directory, containing itself a main.yml that will be added to the playbook. tasks - contains the main list of tasks to be executed by the role. handlers - contains handlers, which may be used by this role or even anywhere - outside this role. defaults - default variables for the role (see Using Variables for more - information). vars - other variables for the role (see Using Variables for more information). files - contains files which can be deployed via this role. templates - contains templates which can be deployed via this role. meta - defines some meta data for this role. See below for more details. Role dependencies \u00b6 https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html#role-dependencies List roles \u00b6 The command ansible-galaxy list -p roles outputs list of roles in the roles directory and warnings about missing directories Import and include role in playbooks \u00b6 The module import_role and include_role . On import, keywords, loops and conditionals will only be applied to the imported tasks, not to this statement itself. Install multiples roles \u00b6 ansible-galaxy install -r requirements.yml requirements.yml specification can be found in the official documentation . Debug \u00b6 Print variables Print all variables in debug mode (flag -vvvv ) - name : \"Ansible | List all known variables and facts\" debug : var : hostvars[inventory_hostname] Ansible-galaxy \u00b6 Get the number of distribution ( platforms key in metadata) $ curl https://galaxy.ansible.com/api/v1/platforms/ | jq '.results | group_by(.name)[] | {key: .[0].name, length: length}' Notes \u00b6 Note on this in post \u21a9","title":"Ansible"},{"location":"infrastructure/devops/ansible/#ansible","text":"Global configuration is in /etc/ansible By default, Ansible will try to use native OpenSSH for remote communication when possible. This enables ControlPersist 1 , Kerberos, and options in ~/.ssh/config such as Jump Host setup.","title":"Ansible"},{"location":"infrastructure/devops/ansible/#variables","text":"Variable names should be letters, numbers, and underscores. Variables should always start with a letter. YAML also supports dictionaries which map keys to values . Variables can be defined in: inventories playbooks and later be used in playbooks using the Jinja2 templating system.","title":"Variables"},{"location":"infrastructure/devops/ansible/#ansible-facts-system-variables","text":"As well as with the ansible_facts variable, facts are variables discovered from systems. $ ansible localhost -m setup 127.0.0.1 | SUCCESS => { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ ... \"changed\": false } $ ansible localhost -m setup -a \"filter=*arch*\" 127.0.0.1 | SUCCESS => { \"ansible_facts\": { \"ansible_architecture\": \"x86_64\", \"ansible_userspace_architecture\": \"x86_64\" }, \"changed\": false }","title":"Ansible Facts: system variables"},{"location":"infrastructure/devops/ansible/#playbooks","text":"The goal of a playbook is to map a group of hosts to some well defined roles, represented by things ansible calls tasks. Basic elements","title":"Playbooks"},{"location":"infrastructure/devops/ansible/#task","text":"A task is in its simple form triggers the executing of a module, with specific arguments. Tasks can be condionally executed , looped . Logical grouping of tasks can be organised in blocks . Variables can be used in arguments to modules. Modules should be idempotent and changes trigger handlers .","title":"Task"},{"location":"infrastructure/devops/ansible/#handlers","text":"Modules can relay when they have made a change on the remote system: notify .","title":"Handlers"},{"location":"infrastructure/devops/ansible/#loops","text":"loop is prefered over with_* (not deprecated) Best practices Run a playbook and load password stored in vault ansible-playbook --ask-vault-pass --extra-vars '@/etc/ansible/vault.yml' oh-my-zsh.yml Specifying an inventory file ansible-playbook -i inventories/hosts --ask-vault-pass --extra-vars '@/etc/ansible/vault.yml' oh-my-zsh.yml","title":"loops"},{"location":"infrastructure/devops/ansible/#inventory","text":"Variables can be assigned to hosts [atlanta] host1 http_port=80 maxRequestsPerChild=808 host2 http_port=303 maxRequestsPerChild=909","title":"Inventory"},{"location":"infrastructure/devops/ansible/#roles","text":"Roles are ways of automatically loading certain vars_files, tasks, and handlers based on a known file structure. Grouping content by roles also allows easy sharing of roles with other users. A role is distributed as directory structure and contains at least one of the following directory, containing itself a main.yml that will be added to the playbook. tasks - contains the main list of tasks to be executed by the role. handlers - contains handlers, which may be used by this role or even anywhere - outside this role. defaults - default variables for the role (see Using Variables for more - information). vars - other variables for the role (see Using Variables for more information). files - contains files which can be deployed via this role. templates - contains templates which can be deployed via this role. meta - defines some meta data for this role. See below for more details.","title":"Roles"},{"location":"infrastructure/devops/ansible/#role-dependencies","text":"https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html#role-dependencies","title":"Role dependencies"},{"location":"infrastructure/devops/ansible/#list-roles","text":"The command ansible-galaxy list -p roles outputs list of roles in the roles directory and warnings about missing directories","title":"List roles"},{"location":"infrastructure/devops/ansible/#import-and-include-role-in-playbooks","text":"The module import_role and include_role . On import, keywords, loops and conditionals will only be applied to the imported tasks, not to this statement itself.","title":"Import and include role in playbooks"},{"location":"infrastructure/devops/ansible/#install-multiples-roles","text":"ansible-galaxy install -r requirements.yml requirements.yml specification can be found in the official documentation .","title":"Install multiples roles"},{"location":"infrastructure/devops/ansible/#debug","text":"Print variables Print all variables in debug mode (flag -vvvv ) - name : \"Ansible | List all known variables and facts\" debug : var : hostvars[inventory_hostname]","title":"Debug"},{"location":"infrastructure/devops/ansible/#ansible-galaxy","text":"Get the number of distribution ( platforms key in metadata) $ curl https://galaxy.ansible.com/api/v1/platforms/ | jq '.results | group_by(.name)[] | {key: .[0].name, length: length}'","title":"Ansible-galaxy"},{"location":"infrastructure/devops/ansible/#notes","text":"Note on this in post \u21a9","title":"Notes"},{"location":"infrastructure/devops/molecule/","text":"Molecule \u00b6 Molecule is designed to aid in the development and testing of Ansible roles. It provides support for: testing with multiple instances, operating systems and distributions; virtualization providers; test frameworks and testing scenarios. Installation \u00b6 With pipx : pipx install ansible pipx inject --include-apps ansible 'molecule[docker]' Role initialisation \u00b6 New role are initialized with the molecule init role command. Configuration can contain environment variables and is beeing loaded from: project config local config (~/.config/molecule/config.yml) default config (molecule.yml) Options can be set on the command line Usage: molecule init role [OPTIONS] ROLE_NAME Initialize a new role for use with Molecule. Options: --dependency-name [galaxy] Name of dependency to initialize. (galaxy) -d, --driver-name [delegated|docker] Name of driver to initialize. (delegated) --lint-name [yamllint] Name of lint to initialize. (yamllint) --provisioner-name [ansible] Name of provisioner to initialize. (ansible) --verifier-name [ansible|testinfra] Name of verifier to initialize. (ansible) --help Show this message and exit. Note: default configuration is defined in molecule.config Role metadata \u00b6 Using molecule init role <ROLE_NAME> creates a meta/main.yaml file storing role informations. Role name role_name In the past, Galaxy would apply a regex expression to the GitHub repository name and automatically remove \u2018ansible-\u2018 and \u2018ansible-role-\u2018. For example, if your repository name was \u2018ansible-role-apache\u2019, the role name would translate to \u2018apache\u2019. Galaxy no longer does this automatically. Instead, use the role_name setting to tell Galaxy what the role name should be. Scenarios \u00b6 Scenarios are first-class citizens and can be though as multiple test suites. By default, scenarios are stored organized in directories in the molecule project directory. A default scenario named default is mandatory. Each scenario is configured in molecule.yml with top level key: dependency : dependency manager [galaxy, gilt, shell] driver : driver for spinning-up the environment to test on [delegated, docker, podman] lint : external lint commands. platforms : instances to be tested, and the groups to which the instances belong. provisioner : handles provisioning and converging the role (ansible). scenario : to override the defaults actions state : internal bookkeeping mechanism verifier : test suite The provisioner handles provisioning and converging the role. The only supported provisioner is ansible itself. Action \u00b6 Action are provisionied with ansible and following subcommands are available: check Use the provisioner to perform a Dry-Run (destroy,... cleanup Use the provisioner to cleanup any changes made to... converge Use the provisioner to configure instances (dependency,... create Use the provisioner to start the instances. destroy Use the provisioner to destroy the instances. idempotence Use the provisioner to configure the instances and parse... prepare Use the provisioner to prepare the instances into a... side-effect Use the provisioner to perform side-effects to the instances. syntax Use the provisioner to syntax check the role. The corresponding playbooks are stored in the files whose default names are: \"cleanup\": \"cleanup.yml\", \"create\": \"create.yml\", \"converge\": \"converge.yml\", \"destroy\": \"destroy.yml\", \"prepare\": \"prepare.yml\", \"side_effect\": \"side_effect.yml\", \"verify\": \"verify.yml\", Default scenarios sequences can be displayed with: molecule matrix <SUBCOMMAND> Defaults are: dependency lint cleanup destroy syntax create prepare converge check idempotence side_effect verify cleanup destroy create_sequence \u2713 \u2713 \u2713 check_sequence \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 converge_sequence \u2713 \u2713 \u2713 \u2713 destroy_sequence \u2713 \u2713 \u2713 test_sequence \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 Environment variables \u00b6 Configuration options may contain environment variables . There are following environment variables available in molecule.yml : Variable Description MOLECULE_DEBUG If debug is turned on or off MOLECULE_FILE Path to molecule config file MOLECULE_ENV_FILE Path to molecule environment file MOLECULE_STATE_FILE ? MOLECULE_INVENTORY_FILE Path to generated inventory file MOLECULE_EPHEMERAL_DIRECTORY Path to generated directory, usually ~/.cache/molecule/<scenario-name> MOLECULE_SCENARIO_DIRECTORY Path to scenario directory MOLECULE_PROJECT_DIRECTORY Path to your project directory MOLECULE_INSTANCE_CONFIG ? MOLECULE_DEPENDENCY_NAME Dependency type name, usually 'galaxy' MOLECULE_DRIVER_NAME Name of the molecule scenario driver MOLECULE_PROVISIONER_NAME Name of the provisioner tool (usually 'ansible') MOLECULE_REPORT Name of HTML file where to dump execution report. MOLECULE_SCENARIO_NAME Name of the scenario MOLECULE_VERBOSITY Determine Ansible verbosity level. MOLECULE_VERIFIER_NAME Name of the verifier tool (usually 'ansible') MOLECULE_VERIFIER_TEST_DIRECTORY ? Links \u00b6 Jeff Geerling's blog Fabian von Feilitzsch - Practical Ansible Testing with Molecule FAQ \u00b6 ERROR! no action detected in task","title":"Molecule"},{"location":"infrastructure/devops/molecule/#molecule","text":"Molecule is designed to aid in the development and testing of Ansible roles. It provides support for: testing with multiple instances, operating systems and distributions; virtualization providers; test frameworks and testing scenarios.","title":"Molecule"},{"location":"infrastructure/devops/molecule/#installation","text":"With pipx : pipx install ansible pipx inject --include-apps ansible 'molecule[docker]'","title":"Installation"},{"location":"infrastructure/devops/molecule/#role-initialisation","text":"New role are initialized with the molecule init role command. Configuration can contain environment variables and is beeing loaded from: project config local config (~/.config/molecule/config.yml) default config (molecule.yml) Options can be set on the command line Usage: molecule init role [OPTIONS] ROLE_NAME Initialize a new role for use with Molecule. Options: --dependency-name [galaxy] Name of dependency to initialize. (galaxy) -d, --driver-name [delegated|docker] Name of driver to initialize. (delegated) --lint-name [yamllint] Name of lint to initialize. (yamllint) --provisioner-name [ansible] Name of provisioner to initialize. (ansible) --verifier-name [ansible|testinfra] Name of verifier to initialize. (ansible) --help Show this message and exit. Note: default configuration is defined in molecule.config","title":"Role initialisation"},{"location":"infrastructure/devops/molecule/#role-metadata","text":"Using molecule init role <ROLE_NAME> creates a meta/main.yaml file storing role informations. Role name role_name In the past, Galaxy would apply a regex expression to the GitHub repository name and automatically remove \u2018ansible-\u2018 and \u2018ansible-role-\u2018. For example, if your repository name was \u2018ansible-role-apache\u2019, the role name would translate to \u2018apache\u2019. Galaxy no longer does this automatically. Instead, use the role_name setting to tell Galaxy what the role name should be.","title":"Role metadata"},{"location":"infrastructure/devops/molecule/#scenarios","text":"Scenarios are first-class citizens and can be though as multiple test suites. By default, scenarios are stored organized in directories in the molecule project directory. A default scenario named default is mandatory. Each scenario is configured in molecule.yml with top level key: dependency : dependency manager [galaxy, gilt, shell] driver : driver for spinning-up the environment to test on [delegated, docker, podman] lint : external lint commands. platforms : instances to be tested, and the groups to which the instances belong. provisioner : handles provisioning and converging the role (ansible). scenario : to override the defaults actions state : internal bookkeeping mechanism verifier : test suite The provisioner handles provisioning and converging the role. The only supported provisioner is ansible itself.","title":"Scenarios"},{"location":"infrastructure/devops/molecule/#action","text":"Action are provisionied with ansible and following subcommands are available: check Use the provisioner to perform a Dry-Run (destroy,... cleanup Use the provisioner to cleanup any changes made to... converge Use the provisioner to configure instances (dependency,... create Use the provisioner to start the instances. destroy Use the provisioner to destroy the instances. idempotence Use the provisioner to configure the instances and parse... prepare Use the provisioner to prepare the instances into a... side-effect Use the provisioner to perform side-effects to the instances. syntax Use the provisioner to syntax check the role. The corresponding playbooks are stored in the files whose default names are: \"cleanup\": \"cleanup.yml\", \"create\": \"create.yml\", \"converge\": \"converge.yml\", \"destroy\": \"destroy.yml\", \"prepare\": \"prepare.yml\", \"side_effect\": \"side_effect.yml\", \"verify\": \"verify.yml\", Default scenarios sequences can be displayed with: molecule matrix <SUBCOMMAND> Defaults are: dependency lint cleanup destroy syntax create prepare converge check idempotence side_effect verify cleanup destroy create_sequence \u2713 \u2713 \u2713 check_sequence \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 converge_sequence \u2713 \u2713 \u2713 \u2713 destroy_sequence \u2713 \u2713 \u2713 test_sequence \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713","title":"Action"},{"location":"infrastructure/devops/molecule/#environment-variables","text":"Configuration options may contain environment variables . There are following environment variables available in molecule.yml : Variable Description MOLECULE_DEBUG If debug is turned on or off MOLECULE_FILE Path to molecule config file MOLECULE_ENV_FILE Path to molecule environment file MOLECULE_STATE_FILE ? MOLECULE_INVENTORY_FILE Path to generated inventory file MOLECULE_EPHEMERAL_DIRECTORY Path to generated directory, usually ~/.cache/molecule/<scenario-name> MOLECULE_SCENARIO_DIRECTORY Path to scenario directory MOLECULE_PROJECT_DIRECTORY Path to your project directory MOLECULE_INSTANCE_CONFIG ? MOLECULE_DEPENDENCY_NAME Dependency type name, usually 'galaxy' MOLECULE_DRIVER_NAME Name of the molecule scenario driver MOLECULE_PROVISIONER_NAME Name of the provisioner tool (usually 'ansible') MOLECULE_REPORT Name of HTML file where to dump execution report. MOLECULE_SCENARIO_NAME Name of the scenario MOLECULE_VERBOSITY Determine Ansible verbosity level. MOLECULE_VERIFIER_NAME Name of the verifier tool (usually 'ansible') MOLECULE_VERIFIER_TEST_DIRECTORY ?","title":"Environment variables"},{"location":"infrastructure/devops/molecule/#links","text":"Jeff Geerling's blog Fabian von Feilitzsch - Practical Ansible Testing with Molecule","title":"Links"},{"location":"infrastructure/devops/molecule/#faq","text":"ERROR! no action detected in task","title":"FAQ"},{"location":"infrastructure/orchestration/cli/","text":"CLI \u00b6 helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources. kustomize lets you customize raw, template-free YAML files for multiple purposes, leaving the original YAML untouched and usable as is. kustomize build system has been included in kubectl. helm convert let you convert existing charts into Kustomize compatible package. kubectl \u00b6 Context \u00b6 Clusters and users can be managed within contexts . kubectl enable setting the different parameters: # Completion results: > kubectl config <TAB> current-context get-contexts set-context view delete-cluster rename-context set-credentials delete-context set unset get-clusters set-cluster use-context > kubectl config --<TAB> --add-dir-header --logtostderr --alsologtostderr --match-server-version --as --namespace --as-group --password --cache-dir --profile --certificate-authority --profile-output --client-certificate --request-timeout --client-key --server --cluster --skip-headers --context --skip-log-headers --insecure-skip-tls-verify --stderrthreshold --kubeconfig --token --log-backtrace-at --user --log-dir --username --log-file --v --log-file-max-size --vmodule --log-flush-frequency Config example ```yaml apiVersion: v1 clusters: - cluster: certificate-authority: fake-ca-file server: https://1.2.3.4 name: development - cluster: insecure-skip-tls-verify: true server: https://5.6.7.8 name: scratch contexts: - context: cluster: development namespace: frontend user: developer name: dev-frontend - context: cluster: development namespace: storage user: developer name: dev-storage - context: cluster: scratch namespace: default user: experimenter name: exp-scratch current-context: \"\" kind: Config preferences: {} users: - name: developer user: client-certificate: fake-cert-file client-key: fake-key-file - name: experimenter user: password: some-password username: exp ''' kubectl config is stored by default in $HOME/.kube/config . The default location are several locations can be set in $KUBECONFIG . helm \u00b6 kustomize \u00b6","title":"kubectl"},{"location":"infrastructure/orchestration/cli/#cli","text":"helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources. kustomize lets you customize raw, template-free YAML files for multiple purposes, leaving the original YAML untouched and usable as is. kustomize build system has been included in kubectl. helm convert let you convert existing charts into Kustomize compatible package.","title":"CLI"},{"location":"infrastructure/orchestration/cli/#kubectl","text":"","title":"kubectl"},{"location":"infrastructure/orchestration/cli/#context","text":"Clusters and users can be managed within contexts . kubectl enable setting the different parameters: # Completion results: > kubectl config <TAB> current-context get-contexts set-context view delete-cluster rename-context set-credentials delete-context set unset get-clusters set-cluster use-context > kubectl config --<TAB> --add-dir-header --logtostderr --alsologtostderr --match-server-version --as --namespace --as-group --password --cache-dir --profile --certificate-authority --profile-output --client-certificate --request-timeout --client-key --server --cluster --skip-headers --context --skip-log-headers --insecure-skip-tls-verify --stderrthreshold --kubeconfig --token --log-backtrace-at --user --log-dir --username --log-file --v --log-file-max-size --vmodule --log-flush-frequency Config example ```yaml apiVersion: v1 clusters: - cluster: certificate-authority: fake-ca-file server: https://1.2.3.4 name: development - cluster: insecure-skip-tls-verify: true server: https://5.6.7.8 name: scratch contexts: - context: cluster: development namespace: frontend user: developer name: dev-frontend - context: cluster: development namespace: storage user: developer name: dev-storage - context: cluster: scratch namespace: default user: experimenter name: exp-scratch current-context: \"\" kind: Config preferences: {} users: - name: developer user: client-certificate: fake-cert-file client-key: fake-key-file - name: experimenter user: password: some-password username: exp ''' kubectl config is stored by default in $HOME/.kube/config . The default location are several locations can be set in $KUBECONFIG .","title":"Context"},{"location":"infrastructure/orchestration/cli/#helm","text":"","title":"helm"},{"location":"infrastructure/orchestration/cli/#kustomize","text":"","title":"kustomize"},{"location":"infrastructure/orchestration/intro/","text":"Kubernetes \u00b6 K8S components \u00b6 Brendan Burns Elements of orchestration \u00b6 Orchestrator role: get a status defined declarativly by the prgrammer. Control Plane Components \u00b6 kube-apiserver exposes K8S API. etcd is distributed key-value store used to store all cluster data. kube-scheduler watches and decide on why node to run newly created pods. kube-controller-manager Node controller : notices and responds when nodes go down. Replication controller : maintains the correct number of pods for every replication controller object Endpoints controller : populates the Endpoints object (that is, joins Services & Pods). Service Account & Token controllers : creates default accounts and API access tokens. cloud-controller-manager embeds cloud-specific control logic, e.g.: Node controller : checks the cloud provider to determine if a node has been deleted in the cloud after it stops responding Route controller : sets up routes Service controller : creates, updates and deletes cloud provider load balancers Node Components \u00b6 kubelet is an agent running on each node that starts and monitor the container runtime workloads. kube-proxy routes inter-pod and internet requests. Container runtime is responsible for running containers (usually Docker). Objects \u00b6 Pods Set of containers, all containers inside a port share a port-space. An appliciation-specfic \"logical host\". A pod is started on a node: containers in the pod can communicate over localhost. Deployments and ReplicaSets \u00b6 Desired state definition for pods. Deployment strategies on Kubernetes Kubernetes Examples Strategies Kubernetes deployment strategies explained Strategy ZERO DOWNTIME REAL TRAFFIC TESTING TARGETED USER CLOUD COST ROLLBACK DURATION NEGATIVE IMPACT ON USER COMPLEXITY OF SETUP RECREATE Version A is terminated then version B is rolled out \u2717 \u2717 \u2717 \u2b1b\u2b1c\u2b1c \u2b1b\u2b1b\u2b1b \u2b1b\u2b1b\u2b1b \u2b1c\u2b1c\u2b1c RAMPED Version B is slowly rolled out and replacing version A \u2713 \u2717 \u2717 \u2b1b\u2b1c\u2b1c \u2b1b\u2b1b\u2b1b \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c BLUE/GREEN version A and B are released alongside, then traffic switched to B \u2713 \u2717 \u2717 \u2b1b\u2b1b\u2b1b \u2b1c\u2b1c\u2b1c \u2b1b\u2b1b\u2b1c \u2b1b\u2b1b\u2b1c CANARY version B is released to a subset of users before full rollout \u2713 \u2713 \u2717 \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c \u2b1b\u2b1b\u2b1c A/B TESTING version B is released to a subset of users under specific conditions \u2713 \u2713 \u2713 \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c \u2b1b\u2b1b\u2b1b SHADOW version B receives seal world traffic alongside version A and doesn't impact the responce \u2713 \u2713 \u2717 \u2b1b\u2b1b\u2b1b \u2b1c\u2b1c\u2b1c \u2b1c\u2b1c\u2b1c \u2b1b\u2b1b\u2b1b Source Bridge to Kubernetes \u00b6 On Azure Dev Spaces tooling AZDS Connect , repo to extension Outer loop Networking \u00b6 Ingress and Egress flows \u00b6 Ingress enables traffic from outside the cluster. A LoadBalancer service provides the routing to the pod. CNI: Container Network Interface 2 options: - in cluster Ingress Controller - External Ingress Controller Nginx Kong Azure AppGW .. Azure: AGIC (Application Gateway Ingress Controller) DNS operator allow for dynamic configuraiton of DNS records Kubernetes network policy \u00b6 kind: NetworkPolicy (networking.k8s.io/v1) Only ingress controlle is public namespaces for different workloads DMS names automatically maintained by opertaurs network policies for isolatind workloards against each other Securing your identities and secrets \u00b6 identities on Azure: aad-pod-identiy secrets on Azure: kubernetes-keyvault-flextool (today) -> secrets-store-csi-driver (soon) Azure Securtiy Center on AKS: - continuoous discovery of managed AKS instances - actionable recommendations... - ... Policies \u00b6 prevent any publics ips on the load balancer no image from repo xyz ... No native kubernetes solution for this. Giant swarm \u00b6 Cloud native for entreprise Day 2 operation \u00b6 try to ensure everything is: - immutable - automated - declarative - operated Testing \u00b6 conftest helps defining tests against structured configuration data for Kubernetes configuration, Tekton pipeline definitions, Terraform code, Serverless configs or any other config files. Tools \u00b6 GitOps \u00b6 flux2 is constructed with the GitOps Toolkit and is a tool for keeping Kubernetes clusters in sync with sources of configuration (like Git repositories), and automating updates to configuration when there is new code to deploy. Tracing \u00b6 applicaton Insights (Azure) OpenCensus / OpenTelemetry Zipkin (java) Jaeger (go) Others \u00b6 dapr.io is a portable, event-driven, runtime for building distributed applications across cloud and edge. Service invocation over API State management: key/value Publish and subscribe v1.0/publish/","title":"Intro"},{"location":"infrastructure/orchestration/intro/#kubernetes","text":"","title":"Kubernetes"},{"location":"infrastructure/orchestration/intro/#k8s-components","text":"Brendan Burns","title":"K8S components"},{"location":"infrastructure/orchestration/intro/#elements-of-orchestration","text":"Orchestrator role: get a status defined declarativly by the prgrammer.","title":"Elements of orchestration"},{"location":"infrastructure/orchestration/intro/#control-plane-components","text":"kube-apiserver exposes K8S API. etcd is distributed key-value store used to store all cluster data. kube-scheduler watches and decide on why node to run newly created pods. kube-controller-manager Node controller : notices and responds when nodes go down. Replication controller : maintains the correct number of pods for every replication controller object Endpoints controller : populates the Endpoints object (that is, joins Services & Pods). Service Account & Token controllers : creates default accounts and API access tokens. cloud-controller-manager embeds cloud-specific control logic, e.g.: Node controller : checks the cloud provider to determine if a node has been deleted in the cloud after it stops responding Route controller : sets up routes Service controller : creates, updates and deletes cloud provider load balancers","title":"Control Plane Components"},{"location":"infrastructure/orchestration/intro/#node-components","text":"kubelet is an agent running on each node that starts and monitor the container runtime workloads. kube-proxy routes inter-pod and internet requests. Container runtime is responsible for running containers (usually Docker).","title":"Node Components"},{"location":"infrastructure/orchestration/intro/#objects","text":"","title":"Objects"},{"location":"infrastructure/orchestration/intro/#deployments-and-replicasets","text":"Desired state definition for pods. Deployment strategies on Kubernetes Kubernetes Examples","title":"Deployments and ReplicaSets"},{"location":"infrastructure/orchestration/intro/#bridge-to-kubernetes","text":"On Azure Dev Spaces tooling AZDS Connect , repo to extension Outer loop","title":"Bridge to Kubernetes"},{"location":"infrastructure/orchestration/intro/#networking","text":"","title":"Networking"},{"location":"infrastructure/orchestration/intro/#ingress-and-egress-flows","text":"Ingress enables traffic from outside the cluster. A LoadBalancer service provides the routing to the pod. CNI: Container Network Interface 2 options: - in cluster Ingress Controller - External Ingress Controller Nginx Kong Azure AppGW .. Azure: AGIC (Application Gateway Ingress Controller) DNS operator allow for dynamic configuraiton of DNS records","title":"Ingress and Egress flows"},{"location":"infrastructure/orchestration/intro/#kubernetes-network-policy","text":"kind: NetworkPolicy (networking.k8s.io/v1) Only ingress controlle is public namespaces for different workloads DMS names automatically maintained by opertaurs network policies for isolatind workloards against each other","title":"Kubernetes network policy"},{"location":"infrastructure/orchestration/intro/#securing-your-identities-and-secrets","text":"identities on Azure: aad-pod-identiy secrets on Azure: kubernetes-keyvault-flextool (today) -> secrets-store-csi-driver (soon) Azure Securtiy Center on AKS: - continuoous discovery of managed AKS instances - actionable recommendations... - ...","title":"Securing  your identities and secrets"},{"location":"infrastructure/orchestration/intro/#policies","text":"prevent any publics ips on the load balancer no image from repo xyz ... No native kubernetes solution for this.","title":"Policies"},{"location":"infrastructure/orchestration/intro/#giant-swarm","text":"Cloud native for entreprise","title":"Giant swarm"},{"location":"infrastructure/orchestration/intro/#day-2-operation","text":"try to ensure everything is: - immutable - automated - declarative - operated","title":"Day 2 operation"},{"location":"infrastructure/orchestration/intro/#testing","text":"conftest helps defining tests against structured configuration data for Kubernetes configuration, Tekton pipeline definitions, Terraform code, Serverless configs or any other config files.","title":"Testing"},{"location":"infrastructure/orchestration/intro/#tools","text":"","title":"Tools"},{"location":"infrastructure/orchestration/intro/#gitops","text":"flux2 is constructed with the GitOps Toolkit and is a tool for keeping Kubernetes clusters in sync with sources of configuration (like Git repositories), and automating updates to configuration when there is new code to deploy.","title":"GitOps"},{"location":"infrastructure/orchestration/intro/#tracing","text":"applicaton Insights (Azure) OpenCensus / OpenTelemetry Zipkin (java) Jaeger (go)","title":"Tracing"},{"location":"infrastructure/orchestration/intro/#others","text":"dapr.io is a portable, event-driven, runtime for building distributed applications across cloud and edge. Service invocation over API State management: key/value Publish and subscribe v1.0/publish/","title":"Others"},{"location":"infrastructure/orchestration/k8sdist/","text":"Kubernetes distribution \u00b6 Minikube \u00b6 Minikube installs a local kubernetes cluster. Installation \u00b6 Direct download via: curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ && chmod +x minikube Driver: \u00b6 The vmware driver supports virtualization across all VMware based hypervisors. r = https://api.github.com/repos/machine-drivers/docker-machine-driver-vmware curl -LO $( curl -s $r /releases/latest | grep -o 'http.*darwin_amd64' | head -n1 ) \\ && install docker-machine-driver-vmware_darwin_amd64 \\ /usr/local/bin/docker-machine-driver-vmware OpenShift \u00b6 Service accounts \u00b6 List service accounts: oc get serviceaccounts Service accounts can be created with oc create sa <ACCOUNTNAME> , the informations relative to this account can be displayed with oc describe sa <ACCOUNTNAME> . Namespace, labels, annotations, secrets, tokens and events can de parsed, e.g. for a secret cert: oc get secret <ACCOUNTNAME>-token-<RANDOM> -o \"jsonpath={.data['service-ca\\.crt']}\" | base64 -d Resources \u00b6 Quota can be visualized per namespace with oc describe quota Usage can be visualized for resources images , imagestreams , node and pods with oc adm top <RESOURCE> . This one is a built on kubectl top <RESOURCE> . Minishift \u00b6 Minishift is a tool that helps run OpenShift locally by running a single-node OpenShift cluster inside a VM. Note: Install minikube \u21a9","title":"K8S distributions"},{"location":"infrastructure/orchestration/k8sdist/#kubernetes-distribution","text":"","title":"Kubernetes distribution"},{"location":"infrastructure/orchestration/k8sdist/#minikube","text":"Minikube installs a local kubernetes cluster.","title":"Minikube"},{"location":"infrastructure/orchestration/k8sdist/#installation","text":"Direct download via: curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ && chmod +x minikube","title":"Installation"},{"location":"infrastructure/orchestration/k8sdist/#driver","text":"The vmware driver supports virtualization across all VMware based hypervisors. r = https://api.github.com/repos/machine-drivers/docker-machine-driver-vmware curl -LO $( curl -s $r /releases/latest | grep -o 'http.*darwin_amd64' | head -n1 ) \\ && install docker-machine-driver-vmware_darwin_amd64 \\ /usr/local/bin/docker-machine-driver-vmware","title":"Driver:"},{"location":"infrastructure/orchestration/k8sdist/#openshift","text":"","title":"OpenShift"},{"location":"infrastructure/orchestration/k8sdist/#service-accounts","text":"List service accounts: oc get serviceaccounts Service accounts can be created with oc create sa <ACCOUNTNAME> , the informations relative to this account can be displayed with oc describe sa <ACCOUNTNAME> . Namespace, labels, annotations, secrets, tokens and events can de parsed, e.g. for a secret cert: oc get secret <ACCOUNTNAME>-token-<RANDOM> -o \"jsonpath={.data['service-ca\\.crt']}\" | base64 -d","title":"Service accounts"},{"location":"infrastructure/orchestration/k8sdist/#resources","text":"Quota can be visualized per namespace with oc describe quota Usage can be visualized for resources images , imagestreams , node and pods with oc adm top <RESOURCE> . This one is a built on kubectl top <RESOURCE> .","title":"Resources"},{"location":"infrastructure/orchestration/k8sdist/#minishift","text":"Minishift is a tool that helps run OpenShift locally by running a single-node OpenShift cluster inside a VM. Note: Install minikube \u21a9","title":"Minishift"},{"location":"linux/freedesktop/","text":"FreeDesktop \u00b6 https://www.freedesktop.org Specification \u00b6 Basedir specification Base directories, decreasing precedence: $XDG_DATA_HOME : base directory relative to which user specific data files should be stored. Default: $HOME/.local/share should be used. $XDG_CONFIG_HOME : base directory relative to which user specific configuration files should be stored. Default: $HOME/.config should be used. $XDG_DATA_DIRS : preference-ordered set of base directories to search for data files in addition to the $XDG_DATA_HOME base directory. Directories should be seperated with a colon : . Default to /usr/local/share/:/usr/share/ should be used. $XDG_CONFIG_DIRS : preference-ordered set of base directories to search for configuration files in addition to the $XDG_CONFIG_HOME base directory. Directories in should be seperated with a colon : . Default to /etc/xdg should be used. $XDG_CACHE_HOME : base directory relative to which user specific non-essential data files should be stored. Default equal to $HOME/.cache should be used. $XDG_RUNTIME_DIR : defines the base directory relative to which user-specific non-essential runtime files and other file objects (such as sockets, named pipes, ...) should be stored. More information on this on freedesktop home page.","title":"freedesktop"},{"location":"linux/freedesktop/#freedesktop","text":"https://www.freedesktop.org","title":"FreeDesktop"},{"location":"linux/freedesktop/#specification","text":"Basedir specification Base directories, decreasing precedence: $XDG_DATA_HOME : base directory relative to which user specific data files should be stored. Default: $HOME/.local/share should be used. $XDG_CONFIG_HOME : base directory relative to which user specific configuration files should be stored. Default: $HOME/.config should be used. $XDG_DATA_DIRS : preference-ordered set of base directories to search for data files in addition to the $XDG_DATA_HOME base directory. Directories should be seperated with a colon : . Default to /usr/local/share/:/usr/share/ should be used. $XDG_CONFIG_DIRS : preference-ordered set of base directories to search for configuration files in addition to the $XDG_CONFIG_HOME base directory. Directories in should be seperated with a colon : . Default to /etc/xdg should be used. $XDG_CACHE_HOME : base directory relative to which user specific non-essential data files should be stored. Default equal to $HOME/.cache should be used. $XDG_RUNTIME_DIR : defines the base directory relative to which user-specific non-essential runtime files and other file objects (such as sockets, named pipes, ...) should be stored. More information on this on freedesktop home page.","title":"Specification"},{"location":"linux/network/","text":"Network \u00b6 Basics \u00b6 The OSI (Open Systems Interconnection) uses seven layers, - physical layer (layer 1) - network layer (layer 3) - transport layer (layer 4) - application layer (layer 7) SASL/GSSAPI \u00b6 SASL: Simple Authentification and Security Layer Framework authentication and data security in Internet protocols. It decouples authentication mechanisms from application protocols: developpers can implement different authentication mechanisms clients and servers can negociate a mutulaly acceptable exchange mechanism GSSAPI: Generic Secutrity Services Application Program Interface Kerberos \u00b6 From Wikipedia and some python notes : After login on the client machine, the client transform the password into the key of a symmetric cipher The AS becomes the request and uses the password to decrypt the request: the user is verified . User Client-based Login The client authenticates itself to the Authentication Server (AS) : Client sends an unauthenticated request to the server Server sends back a 401 response with a WWW-Authenticate: Negotiate header with no authentication details Client Authentication which forwards the username to a key distribution center (KDC) . The KDC issues a ticket-granting ticket (TGT) , which is time stamped and encrypts it using the ticket-granting service's (TGS) secret key and returns the encrypted result to the user's workstation. The Ticket Granting Ticket (TGT) encrypted with another secret key - Client Authentication Client sends a new request with an Authorization: Negotiate header Server checks the Authorization header against the Kerberos infrastructure and either allows or denies access accordingly. If access is allowed, it should include a WWW-Authenticate: Negotiate header with authentication details in the reply. Client checks the authentication details in the reply to ensure that the request came from the server kinit and klist Utils \u00b6 mtr determines the address of each network hop between the machines, it sends a sequence of ICMP ECHO requests to each one to determine the quality of the link to each machine. Resources \u00b6 Displaying IP address on eth0 interface ifconfig eth0 | grep \"inet ad\" | cut -d ':' -f 2 | cut -d ' ' -f 1 18 commands to monitor network bandwith on Linux server Red Hat blog: Introduction to Linux interfaces for virtual networking","title":"network"},{"location":"linux/network/#network","text":"","title":"Network"},{"location":"linux/network/#basics","text":"The OSI (Open Systems Interconnection) uses seven layers, - physical layer (layer 1) - network layer (layer 3) - transport layer (layer 4) - application layer (layer 7)","title":"Basics"},{"location":"linux/network/#saslgssapi","text":"","title":"SASL/GSSAPI"},{"location":"linux/network/#kerberos","text":"From Wikipedia and some python notes : After login on the client machine, the client transform the password into the key of a symmetric cipher The AS becomes the request and uses the password to decrypt the request: the user is verified . User Client-based Login The client authenticates itself to the Authentication Server (AS) : Client sends an unauthenticated request to the server Server sends back a 401 response with a WWW-Authenticate: Negotiate header with no authentication details Client Authentication which forwards the username to a key distribution center (KDC) . The KDC issues a ticket-granting ticket (TGT) , which is time stamped and encrypts it using the ticket-granting service's (TGS) secret key and returns the encrypted result to the user's workstation. The Ticket Granting Ticket (TGT) encrypted with another secret key - Client Authentication Client sends a new request with an Authorization: Negotiate header Server checks the Authorization header against the Kerberos infrastructure and either allows or denies access accordingly. If access is allowed, it should include a WWW-Authenticate: Negotiate header with authentication details in the reply. Client checks the authentication details in the reply to ensure that the request came from the server","title":"Kerberos"},{"location":"linux/network/#utils","text":"mtr determines the address of each network hop between the machines, it sends a sequence of ICMP ECHO requests to each one to determine the quality of the link to each machine.","title":"Utils"},{"location":"linux/network/#resources","text":"Displaying IP address on eth0 interface ifconfig eth0 | grep \"inet ad\" | cut -d ':' -f 2 | cut -d ' ' -f 1 18 commands to monitor network bandwith on Linux server Red Hat blog: Introduction to Linux interfaces for virtual networking","title":"Resources"},{"location":"linux/services/","text":"Services \u00b6 Init Unix System V - Slackware: init proche de Unix BSD - Ubuntu: upstart until 14.04 then systemd systemd \u00b6 systemctl list-unit-files --type service -all enabled, disabled, masked (inactive until mask is unset), static and generatedl init \u00b6","title":"Services"},{"location":"linux/services/#services","text":"Init Unix System V - Slackware: init proche de Unix BSD - Ubuntu: upstart until 14.04 then systemd","title":"Services"},{"location":"linux/services/#systemd","text":"systemctl list-unit-files --type service -all enabled, disabled, masked (inactive until mask is unset), static and generatedl","title":"systemd"},{"location":"linux/services/#init","text":"","title":"init"},{"location":"linux/ssh/","text":"SSH (OpenSSH) \u00b6 Configuration \u00b6 SSH banner / MOTD \u00b6 The banner is configurable per user. Activation is one by setting Banner in /etc/ssh/sshd_config . MOTD - Message Of The Day - is a text printed on an interactive terminal whereas the banner is sent aas a packet ( SSH2_MSG_USERAUTH_BANNER ). In OpenSSH, option PrintMotd in /etc/ssh/sshd_config . On Debian system, the MOTD is displayed via pam and the configuration is done in /etc/pam.d/sshd . Dynamic MOTD can be configured in /etc/update-motd/","title":"SSH (OpenSSH)"},{"location":"linux/ssh/#ssh-openssh","text":"","title":"SSH (OpenSSH)"},{"location":"linux/ssh/#configuration","text":"","title":"Configuration"},{"location":"linux/ssh/#ssh-banner-motd","text":"The banner is configurable per user. Activation is one by setting Banner in /etc/ssh/sshd_config . MOTD - Message Of The Day - is a text printed on an interactive terminal whereas the banner is sent aas a packet ( SSH2_MSG_USERAUTH_BANNER ). In OpenSSH, option PrintMotd in /etc/ssh/sshd_config . On Debian system, the MOTD is displayed via pam and the configuration is done in /etc/pam.d/sshd . Dynamic MOTD can be configured in /etc/update-motd/","title":"SSH banner / MOTD"},{"location":"linux/terminal/","text":"Terminal \u00b6 Terminal capabilities \u00b6 Terminfo (formerly Termcap) is a database of terminal capabilities and more. For every (well almost) model of terminal it tells application programs what the terminal is capable of doing. Links An introduction to termcap and terminfo in french.","title":"Intro"},{"location":"linux/terminal/#terminal","text":"","title":"Terminal"},{"location":"linux/terminal/#terminal-capabilities","text":"Terminfo (formerly Termcap) is a database of terminal capabilities and more. For every (well almost) model of terminal it tells application programs what the terminal is capable of doing. Links An introduction to termcap and terminfo in french.","title":"Terminal capabilities"},{"location":"linux/pkg_mgt/apk/","text":"Alpine linux \u00b6 CMD Description add Add new packages or upgrade packages to the running system del Delete packages from the running system fix Attempt to repair or upgrade an installed package update Update the index of available packages info Prints information about installed or available packages search Search for packages or descriptions with wildcard patterns upgrade Upgrade the currently installed packages cache Maintenance operations for locally cached package repository version Compare version differences between installed and available packages index create a repository index from a list of packages fetch download (but not install) packages audit List changes to the file system from pristine package install state verify Verify a package signature dot Create a graphviz graph description for a given package policy Display the repository that updates a given package, plus repositories that also offer the package stats Display statistics, including number of packages installed and available, number of directories and files, etc.","title":"Alpine linux"},{"location":"linux/pkg_mgt/apk/#alpine-linux","text":"CMD Description add Add new packages or upgrade packages to the running system del Delete packages from the running system fix Attempt to repair or upgrade an installed package update Update the index of available packages info Prints information about installed or available packages search Search for packages or descriptions with wildcard patterns upgrade Upgrade the currently installed packages cache Maintenance operations for locally cached package repository version Compare version differences between installed and available packages index create a repository index from a list of packages fetch download (but not install) packages audit List changes to the file system from pristine package install state verify Verify a package signature dot Create a graphviz graph description for a given package policy Display the repository that updates a given package, plus repositories that also offer the package stats Display statistics, including number of packages installed and available, number of directories and files, etc.","title":"Alpine linux"},{"location":"ml/bayesianinference/","text":"Bayesian inference \u00b6 Basics \u00b6 Short def. (Wikipedia) The marginal probability is the probability of a single event occurring, independent of other events. \\displaystyle p_{X}(x)=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)] \\displaystyle p_{X}(x)=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)] The conditional probability is a measure of the probability of an event occurring given that another event has (by assumption, presumption, assertion or evidence) occurred. \\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\\frac {P(X=x,Y=y)}{P_{X}(x)}} \\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\\frac {P(X=x,Y=y)}{P_{X}(x)}} Given random variables \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots , that are defined on a probability space, the joint probability for \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots is a probability distribution that gives the probability that each of \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots falls in any particular range or discrete set of values specified for that variable. \u2200 A \u2208 C \\quad P(A/B) = \\frac{P(A \u2229 B)}{P(B)} \u2200 A \u2208 C \\quad P(A/B) = \\frac{P(A \u2229 B)}{P(B)}","title":"Bayesian inference"},{"location":"ml/bayesianinference/#bayesian-inference","text":"","title":"Bayesian inference"},{"location":"ml/bayesianinference/#basics","text":"Short def. (Wikipedia) The marginal probability is the probability of a single event occurring, independent of other events. \\displaystyle p_{X}(x)=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)] \\displaystyle p_{X}(x)=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)] The conditional probability is a measure of the probability of an event occurring given that another event has (by assumption, presumption, assertion or evidence) occurred. \\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\\frac {P(X=x,Y=y)}{P_{X}(x)}} \\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\\frac {P(X=x,Y=y)}{P_{X}(x)}} Given random variables \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots , that are defined on a probability space, the joint probability for \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots is a probability distribution that gives the probability that each of \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots falls in any particular range or discrete set of values specified for that variable. \u2200 A \u2208 C \\quad P(A/B) = \\frac{P(A \u2229 B)}{P(B)} \u2200 A \u2208 C \\quad P(A/B) = \\frac{P(A \u2229 B)}{P(B)}","title":"Basics"},{"location":"ml/data/","text":"Apache Arrow \u00b6","title":"Intro"},{"location":"ml/data/#apache-arrow","text":"","title":"Apache Arrow"},{"location":"ml/descriptivestatistics/","text":"Descriptive statistics \u00b6 Basics: mean, median, mode and quantiles \u00b6 The Arithmetic mean is the sum of a collection of numbers divided by the count of numbers in the collection \\displaystyle {\\overline {x}}={\\frac {1}{n}}\\sum _{i=1}^{n}{x_{i}} \\displaystyle {\\overline {x}}={\\frac {1}{n}}\\sum _{i=1}^{n}{x_{i}} The Median M_e M_e is a value separating the higher half from the lower half of a data sample, a population or a probability distribution. \\displaystyle \\mathrm {median} (x)={\\frac {1}{2}}(x_{\\lfloor (n+1)/2\\rfloor }+x_{\\lceil (n+)/2\\rceil }) \\displaystyle \\mathrm {median} (x)={\\frac {1}{2}}(x_{\\lfloor (n+1)/2\\rfloor }+x_{\\lceil (n+)/2\\rceil }) The Mode M_0 M_0 of a set of data values is the value that appears most often. Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities, or dividing the observations in a sample in the same way. Application: box-plot Standardized way of displaying the dataset based on a five-number summary: Median (Q2 / 50 th percentile) : the middle value of the dataset. First quartile (Q1 / 25 th percentile) : or lower quartile qn(0.25), is the median of the lower half of the dataset. Third quartile (Q3 / 75 th percentile) : or upper quartile qn(0.75), is the median of the upper half of the dataset. Interquartile range (IQR) : is the distance between the upper and lower quartiles. \\displaystyle {\\text{IQR}}=Q_{3}-Q_{1}=q_{n}(0.75)-q_{n}(0.25) \\displaystyle {\\text{IQR}}=Q_{3}-Q_{1}=q_{n}(0.75)-q_{n}(0.25) Minimum : the lowest data point with or wo. any outliers. Maximum : the largest data point with or wo. any outliers. The whiskers can represent several possible alternative values, among them: the minimum and maximum of all of the data (as in figure 2) one standard deviation above and below the mean of the data the 9 th percentile and the 91 st percentile the 2 nd percentile and the 98 th percentile. Example with wiskers with maximum 1.5 IQR: Moment \u00b6 The moment of order r\u2009\u2208\u2009\u2115 is a random variable X, an indicator of the spread of this variable. Raw, central, normalised moment \u00b6 X X is a random variable and \\mathbb{E} \\mathbb{E} the expectation operator. The raw, central and normalised moments are defined if the following exist: \\begin{align} m_{r} & \\triangleq {\\mathbb {E}}(X^{r}) \\\\ \\mu_r & \\triangleq \\mathbb{E}([X - \\mathbb{E}(X)]^r) \\\\ \\beta_{r-2} & \\triangleq \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right )^r \\right ] \\end{align} \\begin{align} m_{r} & \\triangleq {\\mathbb {E}}(X^{r}) \\\\ \\mu_r & \\triangleq \\mathbb{E}([X - \\mathbb{E}(X)]^r) \\\\ \\beta_{r-2} & \\triangleq \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right )^r \\right ] \\end{align} Some moments are commonly used to characterize a random variable X X : the expected value aka the mean, moment of first order: \\displaystyle \\mu \\triangleq m_{1}=\\mathbb {E} (X) \\displaystyle \\mu \\triangleq m_{1}=\\mathbb {E} (X) The second central moment is the variance : \\operatorname {V}(X)\\triangleq {\\mu}_{2}={\\mathbb {E}}[(X-\\mu )^{2}] \\operatorname {V}(X)\\triangleq {\\mu}_{2}={\\mathbb {E}}[(X-\\mu )^{2}] The positive square root of the variance is the standard deviation: \\displaystyle \\sigma \\triangleq {\\sqrt {\\operatorname {V} (X)}}={\\sqrt {\\mu_{2}}} \\displaystyle \\sigma \\triangleq {\\sqrt {\\operatorname {V} (X)}}={\\sqrt {\\mu_{2}}} The third central moment is the measure of the lopsidedness of the distribution: Skewness \\displaystyle {\\gamma}_{1}\\triangleq {\\beta}_{1}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{3}\\right] \\displaystyle {\\gamma}_{1}\\triangleq {\\beta}_{1}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{3}\\right] The fourth central moment is a measure of the heaviness of the tail of the distribution, compared to the normal distribution of the same variance: Kurtosis \\displaystyle \\beta_{2}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{4}\\right] \\displaystyle \\beta_{2}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{4}\\right]","title":"Descriptive statistics"},{"location":"ml/descriptivestatistics/#descriptive-statistics","text":"","title":"Descriptive statistics"},{"location":"ml/descriptivestatistics/#basics-mean-median-mode-and-quantiles","text":"The Arithmetic mean is the sum of a collection of numbers divided by the count of numbers in the collection \\displaystyle {\\overline {x}}={\\frac {1}{n}}\\sum _{i=1}^{n}{x_{i}} \\displaystyle {\\overline {x}}={\\frac {1}{n}}\\sum _{i=1}^{n}{x_{i}} The Median M_e M_e is a value separating the higher half from the lower half of a data sample, a population or a probability distribution. \\displaystyle \\mathrm {median} (x)={\\frac {1}{2}}(x_{\\lfloor (n+1)/2\\rfloor }+x_{\\lceil (n+)/2\\rceil }) \\displaystyle \\mathrm {median} (x)={\\frac {1}{2}}(x_{\\lfloor (n+1)/2\\rfloor }+x_{\\lceil (n+)/2\\rceil }) The Mode M_0 M_0 of a set of data values is the value that appears most often. Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities, or dividing the observations in a sample in the same way. Application: box-plot Standardized way of displaying the dataset based on a five-number summary: Median (Q2 / 50 th percentile) : the middle value of the dataset. First quartile (Q1 / 25 th percentile) : or lower quartile qn(0.25), is the median of the lower half of the dataset. Third quartile (Q3 / 75 th percentile) : or upper quartile qn(0.75), is the median of the upper half of the dataset. Interquartile range (IQR) : is the distance between the upper and lower quartiles. \\displaystyle {\\text{IQR}}=Q_{3}-Q_{1}=q_{n}(0.75)-q_{n}(0.25) \\displaystyle {\\text{IQR}}=Q_{3}-Q_{1}=q_{n}(0.75)-q_{n}(0.25) Minimum : the lowest data point with or wo. any outliers. Maximum : the largest data point with or wo. any outliers. The whiskers can represent several possible alternative values, among them: the minimum and maximum of all of the data (as in figure 2) one standard deviation above and below the mean of the data the 9 th percentile and the 91 st percentile the 2 nd percentile and the 98 th percentile. Example with wiskers with maximum 1.5 IQR:","title":"Basics: mean, median, mode and quantiles"},{"location":"ml/descriptivestatistics/#moment","text":"The moment of order r\u2009\u2208\u2009\u2115 is a random variable X, an indicator of the spread of this variable.","title":"Moment"},{"location":"ml/descriptivestatistics/#raw-central-normalised-moment","text":"X X is a random variable and \\mathbb{E} \\mathbb{E} the expectation operator. The raw, central and normalised moments are defined if the following exist: \\begin{align} m_{r} & \\triangleq {\\mathbb {E}}(X^{r}) \\\\ \\mu_r & \\triangleq \\mathbb{E}([X - \\mathbb{E}(X)]^r) \\\\ \\beta_{r-2} & \\triangleq \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right )^r \\right ] \\end{align} \\begin{align} m_{r} & \\triangleq {\\mathbb {E}}(X^{r}) \\\\ \\mu_r & \\triangleq \\mathbb{E}([X - \\mathbb{E}(X)]^r) \\\\ \\beta_{r-2} & \\triangleq \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right )^r \\right ] \\end{align} Some moments are commonly used to characterize a random variable X X : the expected value aka the mean, moment of first order: \\displaystyle \\mu \\triangleq m_{1}=\\mathbb {E} (X) \\displaystyle \\mu \\triangleq m_{1}=\\mathbb {E} (X) The second central moment is the variance : \\operatorname {V}(X)\\triangleq {\\mu}_{2}={\\mathbb {E}}[(X-\\mu )^{2}] \\operatorname {V}(X)\\triangleq {\\mu}_{2}={\\mathbb {E}}[(X-\\mu )^{2}] The positive square root of the variance is the standard deviation: \\displaystyle \\sigma \\triangleq {\\sqrt {\\operatorname {V} (X)}}={\\sqrt {\\mu_{2}}} \\displaystyle \\sigma \\triangleq {\\sqrt {\\operatorname {V} (X)}}={\\sqrt {\\mu_{2}}} The third central moment is the measure of the lopsidedness of the distribution: Skewness \\displaystyle {\\gamma}_{1}\\triangleq {\\beta}_{1}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{3}\\right] \\displaystyle {\\gamma}_{1}\\triangleq {\\beta}_{1}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{3}\\right] The fourth central moment is a measure of the heaviness of the tail of the distribution, compared to the normal distribution of the same variance: Kurtosis \\displaystyle \\beta_{2}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{4}\\right] \\displaystyle \\beta_{2}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{4}\\right]","title":"Raw, central, normalised moment"},{"location":"ml/features/","text":"Features \u00b6 Featuretools is a python library for automated feature engineering tsfresh automatically calculates a large number of time series characteristics, the so called features. 1D convolutional neural network \u00b6 Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences A Visual Introduction to Machine Learning and AI 1D ConvolutionalNeural Networks andApplications\u2013A Survey Signal Status Recognition Based on 1DCNN and Its Feature Extraction Mechanism Analysis Working with 1D convonlutional neural network in Keras \u00b6 https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/ Example \u00b6","title":"Features"},{"location":"ml/features/#features","text":"Featuretools is a python library for automated feature engineering tsfresh automatically calculates a large number of time series characteristics, the so called features.","title":"Features"},{"location":"ml/features/#1d-convolutional-neural-network","text":"Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences A Visual Introduction to Machine Learning and AI 1D ConvolutionalNeural Networks andApplications\u2013A Survey Signal Status Recognition Based on 1DCNN and Its Feature Extraction Mechanism Analysis","title":"1D convolutional neural network"},{"location":"ml/features/#working-with-1d-convonlutional-neural-network-in-keras","text":"https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/","title":"Working with 1D convonlutional neural network in Keras"},{"location":"ml/features/#example","text":"","title":"Example"},{"location":"ml/pipelines/","text":"Pipelines \u00b6 Pipeline stages \u00b6 Note Scikit-learn A Spark-ml A DVC A Imputation \u00b6 The impute module provides classes for completing missing values. SimpleInputer performs imputation based on missing_values (number, string, np.nan (default) or None), and a strategy (mean, median, most_frequent, constant). Further parameters fill_value for constant strategy and add_indicator that add a MissingIndicator Modules \u00b6 tpot \u00b6 A Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. Source: https://scikit-learn.org","title":"Pipelining"},{"location":"ml/pipelines/#pipelines","text":"","title":"Pipelines"},{"location":"ml/pipelines/#pipeline-stages","text":"Note Scikit-learn A Spark-ml A DVC A","title":"Pipeline stages"},{"location":"ml/pipelines/#imputation","text":"The impute module provides classes for completing missing values. SimpleInputer performs imputation based on missing_values (number, string, np.nan (default) or None), and a strategy (mean, median, most_frequent, constant). Further parameters fill_value for constant strategy and add_indicator that add a MissingIndicator","title":"Imputation"},{"location":"ml/pipelines/#modules","text":"","title":"Modules"},{"location":"ml/pipelines/#tpot","text":"A Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. Source: https://scikit-learn.org","title":"tpot"},{"location":"ml/regression/","text":"Multi linear regression: identify the strength of the effect that the independent variables have on the dependent variable predict the impact of changes, that is, to understand how the dependent variable changes when we change the independent variables","title":"Regression"},{"location":"ml/windowing/","text":"Windowing \u00b6 Machine learning and data exploring: the potential of windowing","title":"Windowing"},{"location":"ml/windowing/#windowing","text":"Machine learning and data exploring: the potential of windowing","title":"Windowing"},{"location":"ml/ndarray/intro/","text":"ND-array \u00b6 The N-dimensional array (ndarray) \u00b6 contiguous one-dimensional segment of computer memory NumPy ndarray internals can be read in source code typedef struct tagPyArrayObject_fields { PyObject_HEAD /* Pointer to the raw data buffer */ char * data ; /* The number of dimensions, also called 'ndim' */ int nd ; /* The size in each dimension, also called 'shape' */ npy_intp * dimensions ; /* * Number of bytes to jump to get to the * next element in each dimension */ npy_intp * strides ; /* * This object is decref'd upon * deletion of array. Except in the * case of WRITEBACKIFCOPY which has * special handling. * * For views it points to the original * array, collapsed so no chains of * views occur. * * For creation from buffer object it * points to an object that should be * decref'd on deletion * * For WRITEBACKIFCOPY flag this is an * array to-be-updated upon calling * PyArray_ResolveWritebackIfCopy */ PyObject * base ; /* Pointer to type structure */ PyArray_Descr * descr ; /* Flags describing array -- see below */ int flags ; /* For weak references */ PyObject * weakreflist ; } PyArrayObject_fields ; Papers: https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html NumPy documentation https://github.com/numpy/numpy/blob/b7c27bd2a3817f59c84b004b87bba5db57d9a9b0/numpy/core/include/numpy/ndarraytypes.h#L1343 ndarray.flags Information about the memory layout of the array. ndarray.shape Tuple of array dimensions. ndarray.strides Tuple of bytes to step in each dimension when traversing an array. ndarray.ndim Number of array dimensions. ndarray.data Python buffer object pointing to the start of the array\u2019s data. ndarray.size Number of elements in the array. ndarray.itemsize Length of one array element in bytes. ndarray.nbytes Total bytes consumed by the elements of the array. ndarray.base Base object if memory is from some other object.","title":"Intro"},{"location":"ml/ndarray/intro/#nd-array","text":"","title":"ND-array"},{"location":"ml/ndarray/intro/#the-n-dimensional-array-ndarray","text":"contiguous one-dimensional segment of computer memory NumPy ndarray internals can be read in source code typedef struct tagPyArrayObject_fields { PyObject_HEAD /* Pointer to the raw data buffer */ char * data ; /* The number of dimensions, also called 'ndim' */ int nd ; /* The size in each dimension, also called 'shape' */ npy_intp * dimensions ; /* * Number of bytes to jump to get to the * next element in each dimension */ npy_intp * strides ; /* * This object is decref'd upon * deletion of array. Except in the * case of WRITEBACKIFCOPY which has * special handling. * * For views it points to the original * array, collapsed so no chains of * views occur. * * For creation from buffer object it * points to an object that should be * decref'd on deletion * * For WRITEBACKIFCOPY flag this is an * array to-be-updated upon calling * PyArray_ResolveWritebackIfCopy */ PyObject * base ; /* Pointer to type structure */ PyArray_Descr * descr ; /* Flags describing array -- see below */ int flags ; /* For weak references */ PyObject * weakreflist ; } PyArrayObject_fields ; Papers: https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html NumPy documentation https://github.com/numpy/numpy/blob/b7c27bd2a3817f59c84b004b87bba5db57d9a9b0/numpy/core/include/numpy/ndarraytypes.h#L1343 ndarray.flags Information about the memory layout of the array. ndarray.shape Tuple of array dimensions. ndarray.strides Tuple of bytes to step in each dimension when traversing an array. ndarray.ndim Number of array dimensions. ndarray.data Python buffer object pointing to the start of the array\u2019s data. ndarray.size Number of elements in the array. ndarray.itemsize Length of one array element in bytes. ndarray.nbytes Total bytes consumed by the elements of the array. ndarray.base Base object if memory is from some other object.","title":"The N-dimensional array (ndarray)"},{"location":"ml/timeseries/_intro/","text":"Time series \u00b6 http://www.timeseriesclassification.com","title":"Intro"},{"location":"ml/timeseries/_intro/#time-series","text":"http://www.timeseriesclassification.com","title":"Time series"},{"location":"ml/timeseries/matrixprofile/","text":"Matrix profile \u00b6 Papers: Efficient Matrix Profile Computation Using DifferentDistance Functions Matrix Profile I: All Pairs Similarity Joins for Time Series:A Unifying View that Includes Motifs, Discords and Shapelets Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred MillionBarrierfor Time Series Motifs and Joins Stumpy \u00b6 Quote At its core, the STUMPY library efficiently computes something called a matrix profile , a vector that stores the z-normalized Euclidean distance between any subsequence within a time series and its nearest neigbor.","title":"Matrix profile"},{"location":"ml/timeseries/matrixprofile/#matrix-profile","text":"Papers: Efficient Matrix Profile Computation Using DifferentDistance Functions Matrix Profile I: All Pairs Similarity Joins for Time Series:A Unifying View that Includes Motifs, Discords and Shapelets Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred MillionBarrierfor Time Series Motifs and Joins","title":"Matrix profile"},{"location":"ml/timeseries/matrixprofile/#stumpy","text":"Quote At its core, the STUMPY library efficiently computes something called a matrix profile , a vector that stores the z-normalized Euclidean distance between any subsequence within a time series and its nearest neigbor.","title":"Stumpy "},{"location":"python/01%20-%20Python%20-%20CPython%20design/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects. Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a \"batteries included\" language due to its comprehensive standard library. [src] Design of CPython\u2019s Compiler [src] Philip Guo CPython internals lectures [src] PyOhio PyCamp 2014 :: The Compiler [src] The missing Python AST docs [src] Visualize program execution High-level \u00b6 In computer science, a high-level programming language is a programming language with strong abstraction from the details of the computer. In contrast to low-level programming languages, it may use natural language elements, be easier to use, or may automate (or even hide entirely) significant areas of computing systems (e.g. memory management), making the process of developing a program simpler and more understandable than when using a lower-level language Wikipedia Interpreted \u00b6 There are three general modes of execution for modern high-level languages: Interpreted : the syntax is read and then executed directly, with no compilation stage. A program called an interpreter reads each program statement, following the program flow, then decides what to do, and does it. Compiled : the code written in a language is compiled, its syntax is transformed into an executable form before running. There are two types of compilation: Machine code generation Intermediate representations : the code written in a language is compiled to an intermediate representation, that representation can be optimized or saved for later execution without the need to re-read the source file. When the intermediate representation is saved, it may be in a form such as bytecode. The intermediate representation must then be interpreted or further compiled to execute it. Source-to-source translated or transcompiled Code structure \u00b6 The code directory structure is described in Python Developer's Guide . Guido van Rossum summarizes it in Yet another guided tour of CPython Include \u2014 header files Objects \u2014 object implementations, from int to type Python \u2014 interpreter, bytecode compiler and other essential infrastructure Parser \u2014 parser, lexer and parser generator Modules \u2014 stdlib extension modules, and main.c Programs \u2014 not much, but has the real main() function raw cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python In CPython, the compilation from source code to bytecode involves several steps [src] Parse source code into a parse tree (Parser/pgen.c) Transform parse tree into an Abstract Syntax Tree (Python/ast.c) Transform AST into a Control Flow Graph (Python/compile.c) Emit bytecode based on the Control Flow Graph (Python/compile.c) AST \u00b6 Doc The code is parsed, i.e. split up into a list of pieces called tokens. These tokens are based on a set of rules for things that should be treated differently. For instance, the keyword if is a different token than a numeric value like 42 . The list of tokens is transformed to build an Abstract Syntax Tree, AST , collection of nodes which are linked together based on the Python language grammar . In python, everything is an object, AST represents logicaly each element as an object. A third pary documentation on AST import ast from ast import PyCF_ONLY_AST # The code is beeing striped to remove # left and right space before parsing # and limit thee size of the tree code = \"\"\" def hello(who: str) -> None: msg = f'Hello {who} ' print(msg) hello(\"world\") \"\"\" code = code . strip () Execute the code exec ( code ) Hello world tree = ast . parse ( code ) The code is seen as two elements in the tree for i , elt in enumerate ( tree . body ): print ( i , elt ) 0 <_ast.FunctionDef object at 0x7f79c9aa0690> 1 <_ast.Expr object at 0x7f79c9ad1890> # Get the FunctionDef fdef = tree . body [ 0 ] # Get the first function argument arg = fdef . args . args [ 0 ] Some informations from the tree can be retrieved: print ( f ' { arg . arg } : { arg . annotation . id } at col # { arg . col_offset } ' ) who: str at col #10 The code can be compiled lines = [ None ] + code . splitlines () # None at [0] so we can index lines from 1 test_namespace = {} for node in tree . body : wrapper = ast . Module ( body = [ node ]) try : co = compile ( wrapper , \"<ast>\" , 'exec' ) exec ( co , test_namespace ) except AssertionError as e : print ( \"Assertion failed on line\" , node . lineno , \":\" ) print ( lines [ node . lineno ]) # If the error has a message, show it. if e . args : print ( e ) print () Hello world code = compile ( tree , filename = \"<ast>\" , mode = \"exec\" ) class FuncLister ( ast . NodeVisitor ): def visit_FunctionDef ( self , node ): print ( node . name ) self . generic_visit ( node ) FuncLister () . visit ( tree ) hello Bytecode \u00b6 From an abstract syntax tree, the interpreter can produce a lower level form of instructions called bytecode . These instructions are things like BINARY_ADD and are meant to be very generic so that a computer can run them. print ( \"Hello, World!\" ) Hello, World! from dis import dis dis ( 'print(\"Hello, World!\")' ) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('Hello, World!') 4 CALL_FUNCTION 1 6 RETURN_VALUE CPython uses a stack-based virtual machine. That is, it's oriented entirely around stack data structures (where you can \"push\" an item onto the \"top\" of the structure, or \"pop\" an item off the \"top\"). With the bytecode instructions available, the interpreter can finally run your code. The bytecode is used to call functions in your operating system which will ultimately interact with a CPU and memory to run the program. Opcodes and main interpreter loop \u00b6 import tempfile from os.path import join as pjoin tmp = tempfile . gettempdir () fName = pjoin ( tmp , 'test.py' ) codeExemple = \"\"\"ppl = ['Alice', 'Bob', 'Carol', 'Doug'] excited_ppl = [e + '!!' for e in ppl] ppl_len = [len(x) for x in ppl]\"\"\" with open ( fName , 'w' ) as f : f . write ( codeExemple ) ! python - m dis { fName } 1 0 LOAD_CONST 0 ('Alice') 2 LOAD_CONST 1 ('Bob') 4 LOAD_CONST 2 ('Carol') 6 LOAD_CONST 3 ('Doug') 8 BUILD_LIST 4 10 STORE_NAME 0 (ppl) 2 12 LOAD_CONST 4 (<code object <listcomp> at 0x7f43f9dc4ed0, file \"/tmp/test.py\", line 2>) 14 LOAD_CONST 5 ('<listcomp>') 16 MAKE_FUNCTION 0 18 LOAD_NAME 0 (ppl) 20 GET_ITER 22 CALL_FUNCTION 1 24 STORE_NAME 1 (excited_ppl) 3 26 LOAD_CONST 6 (<code object <listcomp> at 0x7f43f9dca390, file \"/tmp/test.py\", line 3>) 28 LOAD_CONST 5 ('<listcomp>') 30 MAKE_FUNCTION 0 32 LOAD_NAME 0 (ppl) 34 GET_ITER 36 CALL_FUNCTION 1 38 STORE_NAME 2 (ppl_len) 40 LOAD_CONST 7 (None) 42 RETURN_VALUE Disassembly of <code object <listcomp> at 0x7f43f9dc4ed0, file \"/tmp/test.py\", line 2>: 2 0 BUILD_LIST 0 2 LOAD_FAST 0 (.0) >> 4 FOR_ITER 12 (to 18) 6 STORE_FAST 1 (e) 8 LOAD_FAST 1 (e) 10 LOAD_CONST 0 ('!!') 12 BINARY_ADD 14 LIST_APPEND 2 16 JUMP_ABSOLUTE 4 >> 18 RETURN_VALUE Disassembly of <code object <listcomp> at 0x7f43f9dca390, file \"/tmp/test.py\", line 3>: 3 0 BUILD_LIST 0 2 LOAD_FAST 0 (.0) >> 4 FOR_ITER 12 (to 18) 6 STORE_FAST 1 (x) 8 LOAD_GLOBAL 0 (len) 10 LOAD_FAST 1 (x) 12 CALL_FUNCTION 1 14 LIST_APPEND 2 16 JUMP_ABSOLUTE 4 >> 18 RETURN_VALUE c = compile ( codeExemple , 'test.py' , 'exec' ) c . co_code b'd\\x00d\\x01d\\x02d\\x03g\\x04Z\\x00d\\x04d\\x05\\x84\\x00e\\x00D\\x00\\x83\\x01Z\\x01d\\x06d\\x05\\x84\\x00e\\x00D\\x00\\x83\\x01Z\\x02d\\x07S\\x00' ! cat { fName } ppl = ['Alice', 'Bob', 'Carol', 'Doug'] excited_ppl = [e + '!!' for e in ppl] ppl_len = [len(x) for x in ppl] opcode.h \u00b6 ! wget -- quiet https : // raw . githubusercontent . com / python / cpython / master / Include / opcode . h - O { tmp } / opcode . h ! head - n 30 { tmp } / opcode . h /* Auto-generated by Tools/scripts/generate_opcode_h.py from Lib/opcode.py */ #ifndef Py_OPCODE_H #define Py_OPCODE_H #ifdef __cplusplus extern \"C\" { #endif /* Instruction opcodes for compiled code */ #define POP_TOP 1 #define ROT_TWO 2 #define ROT_THREE 3 #define DUP_TOP 4 #define DUP_TOP_TWO 5 #define ROT_FOUR 6 #define NOP 9 #define UNARY_POSITIVE 10 #define UNARY_NEGATIVE 11 #define UNARY_NOT 12 #define UNARY_INVERT 15 #define BINARY_MATRIX_MULTIPLY 16 #define INPLACE_MATRIX_MULTIPLY 17 #define BINARY_POWER 19 #define BINARY_MULTIPLY 20 #define BINARY_MODULO 22 #define BINARY_ADD 23 #define BINARY_SUBTRACT 24 #define BINARY_SUBSCR 25 #define BINARY_FLOOR_DIVIDE 26 #define BINARY_TRUE_DIVIDE 27 ceval.c \u00b6 ! wget -- quiet https : // raw . githubusercontent . com / python / cpython / master / Python / ceval . c - O { tmp } / ceval . c ! head - n 20 { tmp } / ceval . c /* Execute compiled code */ /* XXX TO DO: XXX speed up searching for keywords by using a dictionary XXX document it! */ /* enable more aggressive intra-module optimizations, where available */ #define PY_LOCAL_AGGRESSIVE #include \"Python.h\" #include \"pycore_call.h\" #include \"pycore_ceval.h\" #include \"pycore_code.h\" #include \"pycore_object.h\" #include \"pycore_pyerrors.h\" #include \"pycore_pylifecycle.h\" #include \"pycore_pystate.h\" #include \"pycore_tupleobject.h\" General purpose \u00b6 https://awesome-python.com/ : References: - Your Guide to the CPython Source Code - Inside The Python Virtual Machine - An introduction to Python bytecode - Deciphering Python: How to use Abstract Syntax Trees (AST) to understand code Garbage collected \u00b6 https://github.com/python/cpython/blob/ce6a070414ed1e1374d1e6212bfbff61b6d5d755/Include/object.h#L104 from sys import getrefcount a = \"un\" getrefcount ( a ) 2 b = a b is a True getrefcount ( a ) 3 del ( b ) getrefcount ( a ) 2","title":"That"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#high-level","text":"In computer science, a high-level programming language is a programming language with strong abstraction from the details of the computer. In contrast to low-level programming languages, it may use natural language elements, be easier to use, or may automate (or even hide entirely) significant areas of computing systems (e.g. memory management), making the process of developing a program simpler and more understandable than when using a lower-level language Wikipedia","title":"High-level"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#interpreted","text":"There are three general modes of execution for modern high-level languages: Interpreted : the syntax is read and then executed directly, with no compilation stage. A program called an interpreter reads each program statement, following the program flow, then decides what to do, and does it. Compiled : the code written in a language is compiled, its syntax is transformed into an executable form before running. There are two types of compilation: Machine code generation Intermediate representations : the code written in a language is compiled to an intermediate representation, that representation can be optimized or saved for later execution without the need to re-read the source file. When the intermediate representation is saved, it may be in a form such as bytecode. The intermediate representation must then be interpreted or further compiled to execute it. Source-to-source translated or transcompiled","title":"Interpreted"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#code-structure","text":"The code directory structure is described in Python Developer's Guide . Guido van Rossum summarizes it in Yet another guided tour of CPython Include \u2014 header files Objects \u2014 object implementations, from int to type Python \u2014 interpreter, bytecode compiler and other essential infrastructure Parser \u2014 parser, lexer and parser generator Modules \u2014 stdlib extension modules, and main.c Programs \u2014 not much, but has the real main() function raw cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python In CPython, the compilation from source code to bytecode involves several steps [src] Parse source code into a parse tree (Parser/pgen.c) Transform parse tree into an Abstract Syntax Tree (Python/ast.c) Transform AST into a Control Flow Graph (Python/compile.c) Emit bytecode based on the Control Flow Graph (Python/compile.c)","title":"Code structure"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#ast","text":"Doc The code is parsed, i.e. split up into a list of pieces called tokens. These tokens are based on a set of rules for things that should be treated differently. For instance, the keyword if is a different token than a numeric value like 42 . The list of tokens is transformed to build an Abstract Syntax Tree, AST , collection of nodes which are linked together based on the Python language grammar . In python, everything is an object, AST represents logicaly each element as an object. A third pary documentation on AST import ast from ast import PyCF_ONLY_AST # The code is beeing striped to remove # left and right space before parsing # and limit thee size of the tree code = \"\"\" def hello(who: str) -> None: msg = f'Hello {who} ' print(msg) hello(\"world\") \"\"\" code = code . strip () Execute the code exec ( code ) Hello world tree = ast . parse ( code ) The code is seen as two elements in the tree for i , elt in enumerate ( tree . body ): print ( i , elt ) 0 <_ast.FunctionDef object at 0x7f79c9aa0690> 1 <_ast.Expr object at 0x7f79c9ad1890> # Get the FunctionDef fdef = tree . body [ 0 ] # Get the first function argument arg = fdef . args . args [ 0 ] Some informations from the tree can be retrieved: print ( f ' { arg . arg } : { arg . annotation . id } at col # { arg . col_offset } ' ) who: str at col #10 The code can be compiled lines = [ None ] + code . splitlines () # None at [0] so we can index lines from 1 test_namespace = {} for node in tree . body : wrapper = ast . Module ( body = [ node ]) try : co = compile ( wrapper , \"<ast>\" , 'exec' ) exec ( co , test_namespace ) except AssertionError as e : print ( \"Assertion failed on line\" , node . lineno , \":\" ) print ( lines [ node . lineno ]) # If the error has a message, show it. if e . args : print ( e ) print () Hello world code = compile ( tree , filename = \"<ast>\" , mode = \"exec\" ) class FuncLister ( ast . NodeVisitor ): def visit_FunctionDef ( self , node ): print ( node . name ) self . generic_visit ( node ) FuncLister () . visit ( tree ) hello","title":"AST"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#bytecode","text":"From an abstract syntax tree, the interpreter can produce a lower level form of instructions called bytecode . These instructions are things like BINARY_ADD and are meant to be very generic so that a computer can run them. print ( \"Hello, World!\" ) Hello, World! from dis import dis dis ( 'print(\"Hello, World!\")' ) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('Hello, World!') 4 CALL_FUNCTION 1 6 RETURN_VALUE CPython uses a stack-based virtual machine. That is, it's oriented entirely around stack data structures (where you can \"push\" an item onto the \"top\" of the structure, or \"pop\" an item off the \"top\"). With the bytecode instructions available, the interpreter can finally run your code. The bytecode is used to call functions in your operating system which will ultimately interact with a CPU and memory to run the program.","title":"Bytecode"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#opcodes-and-main-interpreter-loop","text":"import tempfile from os.path import join as pjoin tmp = tempfile . gettempdir () fName = pjoin ( tmp , 'test.py' ) codeExemple = \"\"\"ppl = ['Alice', 'Bob', 'Carol', 'Doug'] excited_ppl = [e + '!!' for e in ppl] ppl_len = [len(x) for x in ppl]\"\"\" with open ( fName , 'w' ) as f : f . write ( codeExemple ) ! python - m dis { fName } 1 0 LOAD_CONST 0 ('Alice') 2 LOAD_CONST 1 ('Bob') 4 LOAD_CONST 2 ('Carol') 6 LOAD_CONST 3 ('Doug') 8 BUILD_LIST 4 10 STORE_NAME 0 (ppl) 2 12 LOAD_CONST 4 (<code object <listcomp> at 0x7f43f9dc4ed0, file \"/tmp/test.py\", line 2>) 14 LOAD_CONST 5 ('<listcomp>') 16 MAKE_FUNCTION 0 18 LOAD_NAME 0 (ppl) 20 GET_ITER 22 CALL_FUNCTION 1 24 STORE_NAME 1 (excited_ppl) 3 26 LOAD_CONST 6 (<code object <listcomp> at 0x7f43f9dca390, file \"/tmp/test.py\", line 3>) 28 LOAD_CONST 5 ('<listcomp>') 30 MAKE_FUNCTION 0 32 LOAD_NAME 0 (ppl) 34 GET_ITER 36 CALL_FUNCTION 1 38 STORE_NAME 2 (ppl_len) 40 LOAD_CONST 7 (None) 42 RETURN_VALUE Disassembly of <code object <listcomp> at 0x7f43f9dc4ed0, file \"/tmp/test.py\", line 2>: 2 0 BUILD_LIST 0 2 LOAD_FAST 0 (.0) >> 4 FOR_ITER 12 (to 18) 6 STORE_FAST 1 (e) 8 LOAD_FAST 1 (e) 10 LOAD_CONST 0 ('!!') 12 BINARY_ADD 14 LIST_APPEND 2 16 JUMP_ABSOLUTE 4 >> 18 RETURN_VALUE Disassembly of <code object <listcomp> at 0x7f43f9dca390, file \"/tmp/test.py\", line 3>: 3 0 BUILD_LIST 0 2 LOAD_FAST 0 (.0) >> 4 FOR_ITER 12 (to 18) 6 STORE_FAST 1 (x) 8 LOAD_GLOBAL 0 (len) 10 LOAD_FAST 1 (x) 12 CALL_FUNCTION 1 14 LIST_APPEND 2 16 JUMP_ABSOLUTE 4 >> 18 RETURN_VALUE c = compile ( codeExemple , 'test.py' , 'exec' ) c . co_code b'd\\x00d\\x01d\\x02d\\x03g\\x04Z\\x00d\\x04d\\x05\\x84\\x00e\\x00D\\x00\\x83\\x01Z\\x01d\\x06d\\x05\\x84\\x00e\\x00D\\x00\\x83\\x01Z\\x02d\\x07S\\x00' ! cat { fName } ppl = ['Alice', 'Bob', 'Carol', 'Doug'] excited_ppl = [e + '!!' for e in ppl] ppl_len = [len(x) for x in ppl]","title":"Opcodes and main interpreter loop"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#opcodeh","text":"! wget -- quiet https : // raw . githubusercontent . com / python / cpython / master / Include / opcode . h - O { tmp } / opcode . h ! head - n 30 { tmp } / opcode . h /* Auto-generated by Tools/scripts/generate_opcode_h.py from Lib/opcode.py */ #ifndef Py_OPCODE_H #define Py_OPCODE_H #ifdef __cplusplus extern \"C\" { #endif /* Instruction opcodes for compiled code */ #define POP_TOP 1 #define ROT_TWO 2 #define ROT_THREE 3 #define DUP_TOP 4 #define DUP_TOP_TWO 5 #define ROT_FOUR 6 #define NOP 9 #define UNARY_POSITIVE 10 #define UNARY_NEGATIVE 11 #define UNARY_NOT 12 #define UNARY_INVERT 15 #define BINARY_MATRIX_MULTIPLY 16 #define INPLACE_MATRIX_MULTIPLY 17 #define BINARY_POWER 19 #define BINARY_MULTIPLY 20 #define BINARY_MODULO 22 #define BINARY_ADD 23 #define BINARY_SUBTRACT 24 #define BINARY_SUBSCR 25 #define BINARY_FLOOR_DIVIDE 26 #define BINARY_TRUE_DIVIDE 27","title":"opcode.h"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#cevalc","text":"! wget -- quiet https : // raw . githubusercontent . com / python / cpython / master / Python / ceval . c - O { tmp } / ceval . c ! head - n 20 { tmp } / ceval . c /* Execute compiled code */ /* XXX TO DO: XXX speed up searching for keywords by using a dictionary XXX document it! */ /* enable more aggressive intra-module optimizations, where available */ #define PY_LOCAL_AGGRESSIVE #include \"Python.h\" #include \"pycore_call.h\" #include \"pycore_ceval.h\" #include \"pycore_code.h\" #include \"pycore_object.h\" #include \"pycore_pyerrors.h\" #include \"pycore_pylifecycle.h\" #include \"pycore_pystate.h\" #include \"pycore_tupleobject.h\"","title":"ceval.c"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#general-purpose","text":"https://awesome-python.com/ : References: - Your Guide to the CPython Source Code - Inside The Python Virtual Machine - An introduction to Python bytecode - Deciphering Python: How to use Abstract Syntax Trees (AST) to understand code","title":"General purpose"},{"location":"python/01%20-%20Python%20-%20CPython%20design/#garbage-collected","text":"https://github.com/python/cpython/blob/ce6a070414ed1e1374d1e6212bfbff61b6d5d755/Include/object.h#L104 from sys import getrefcount a = \"un\" getrefcount ( a ) 2 b = a b is a True getrefcount ( a ) 3 del ( b ) getrefcount ( a ) 2","title":"Garbage collected"},{"location":"python/04%20%C2%B7%C2%A0Decorators/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import wikipedia from IPython.display import ( HTML , Pretty ) HTML ( wikipedia . summary ( 'Decorator_pattern' )) In object-oriented programming, the decorator pattern is a design pattern that allows behavior to be added to an individual object, dynamically, without affecting the behavior of other objects from the same class. The decorator pattern is often useful for adhering to the Single Responsibility Principle, as it allows functionality to be divided between classes with unique areas of concern. The decorator pattern is structurally nearly identical to the chain of responsibility pattern, the difference being that in a chain of responsibility, exactly one of the classes handles the request, while for the decorator, all classes handle the request. Function decorators \u00b6 A decorator can be defined as a normal function. It receives generaly a function as argument. def simple_decorator_1 ( function ): print ( \"doing decoration\" ) return function Decorate a function_O with simple_decorator_1 is equivalent to execute simple_decorator_1(function_0) def function_0 (): print ( \"inside function\" ) simple_decorator_1 ( function_0 ); doing decoration Therefor, a decorator is executed as it is used after a function definition @simple_decorator_1 def function_1 (): print ( \"inside function\" ) doing decoration Simple decorator \u00b6 A generator is however often used to wrap the function content and adding extra elements to its execution. Exemple of a decorator that initialize and format a plot. import numpy as np import matplotlib.pyplot as plt def decorate_plot ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" def wrapper ( * args , ** kwargs ): size = ( 8 , 4 ) print ( f \"Setting figsize to { size } \" ) with plt . style . context ( 'ggplot' ): plt . figure ( figsize = ( size )) func ( * args , ** kwargs ) plt . xlim ( 0 , 10 ) plt . ylim ( 0 , 10 ) return wrapper @decorate_plot def my_first_decorated_plot ( data ): \"\"\"A simple plot.\"\"\" plt . plot ( data ) my_first_decorated_plot ( np . random . RandomState ( 42 ) . random_sample ( size = 11 ) * 10 ) Setting figsize to (8, 4) my_first_decorated_plot . __doc__ Function documentation is not preserved after applying a decorator. This has to be manualy fixed. def decorated_plot_w_metadata ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" def wrapper ( * args , ** kwargs ): size = ( 8 , 4 ) print ( f \"Setting figsize to { size } \" ) with plt . style . context ( 'ggplot' ): plt . figure ( figsize = ( size )) func ( * args , ** kwargs ) plt . xlim ( 0 , 10 ) plt . ylim ( 0 , 10 ) plt . graphpaper ( dx = 1 , dy = 2 ) wrapper . __name__ = func . __name__ wrapper . __doc__ = func . __doc__ wrapper . __dict__ . update ( func . __dict__ ) return wrapper @decorated_plot_w_metadata def my_first_decorated_plot_w_metadata ( data ): \"\"\"A simple plot.\"\"\" plt . plot ( data ) print ( my_first_decorated_plot_w_metadata . __name__ , my_first_decorated_plot_w_metadata . __doc__ ) my_first_decorated_plot_w_metadata A simple plot. A decorator in functools is available for that purpose. Simple decorator with functools.wraps decorator : preserving metadata \u00b6 from functools import wraps def decorated_plot_2 ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" @wraps ( func ) def wrapper ( * args , ** kwargs ): size = ( 8 , 4 ) print ( f \"Setting figsize to { size } \" ) with plt . style . context ( 'ggplot' ): plt . figure ( figsize = ( size )) func ( * args , ** kwargs ) plt . xlim ( 0 , 10 ) plt . ylim ( 0 , 10 ) return wrapper @decorated_plot_2 def my_plot_2 ( data ): \"\"\"A simple plot.\"\"\" plt . plot ( data ) my_plot_2 ( np . random . random ( 11 ) * 10 ) Setting figsize to (8, 4) from functools import ( WRAPPER_ASSIGNMENTS , WRAPPER_UPDATES ) from pprint import pprint from itertools import chain The optional arguments are tuples to specify which attributes of the original function are assigned directly to the matching attributes on the wrapper function and which attributes of the wrapper function are updated with the corresponding attributes from the original function. The default values for these arguments are the module level constants WRAPPER_ASSIGNMENTS and WRAPPER_UPDATES WRAPPER_ASSIGNMENTS ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__') WRAPPER_UPDATES ('__dict__',) for elt in chain ( WRAPPER_ASSIGNMENTS , WRAPPER_UPDATES ): pprint ( f \" { elt } : { getattr ( my_plot_1 , elt ) } --> { getattr ( my_plot_2 , elt ) } \" , indent = 2 ) '__module__ : __main__ --> __main__' '__name__ : wrapper --> my_plot_2' '__qualname__ : decorated_plot_1.<locals>.wrapper --> my_plot_2' '__doc__ : None --> A simple plot.' '__annotations__ : {} --> {}' \"__dict__ : {} --> {'__wrapped__': <function my_plot_2 at 0x315acb0d0>}\" When wrapped with functools.wraps , the original function is callable with the _ wrapper_ method my_plot_2 . __wrapped__ ( np . random . random ( 11 ) * 10 ) import functools import inspect def my_wrapper ( fn ): def wrapped ( x , y , z ): return my_func ( x , y ) wrapped = functools . update_wrapper ( wrapped , fn ) return wrapped def my_func ( x , y ): pass wrapper = my_wrapper ( my_func ) Chaining decorators \u00b6 def decorated_plot_2 ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" def wrapper ( * args , ** kwargs ): size = ( 8 , 4 ) print ( f \"Inside decorated_plot_2\" ) print ( f \"Setting figsize to { size } \" ) with plt . style . context ( 'ggplot' ): plt . figure ( figsize = ( size )) func ( * args , ** kwargs ) plt . xlim ( 0 , 10 ) plt . ylim ( 0 , 10 ) plt . graphpaper ( dx = 1 , dy = 2 ) return wrapper def decorated_plot_3 ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" def wrapper ( * args , ** kwargs ): print ( f \"Inside decorated_plot_3\" ) func ( * args , ** kwargs ) plt . xlabel ( \"Label\" ) return wrapper @decorated_plot_3 @decorated_plot_2 def my_plot_2 ( data ): plt . plot ( data ) my_plot_2 ( np . random . random ( 11 ) * 10 ) Inside decorated_plot_3 Inside decorated_plot_2 Setting figsize to (8, 4) Sending arguments to decorator \u00b6 Unpacking behavior of decorator def simple_decorator_2 ( * args , ** kwargs ): print ( \"Inside simple_decorator_1_bis\" ) for arg in args : print ( f \"arg: { arg } \" ) for kwarg in kwargs : print ( f \"kwarg: { kwarg } : { kwargs [ kwarg ] } \" ) return def function_2 (): print ( \"inside function\" ) If the decorator function simple_decorator_2 becomes a function, *args contains the function given as argument. type ( simple_decorator_2 ( function_2 )) Inside simple_decorator_1_bis arg: <function function_2 at 0x315acb620> NoneType If the decorator function simple_decorator_2 becomes a function, *args does not contains the function given as argument. type ( simple_decorator_2 ( \"Argument 1\" , argument2 = \"Text\" )) Inside simple_decorator_1_bis arg: Argument 1 kwarg: argument2: Text NoneType def simple_decorator_3 ( * args , ** kwargs ): print ( \"Inside simple_decorator_1_bis\" ) for arg in args : print ( f \"arg: { arg } \" ) for kwarg in kwargs : print ( f \"kwarg: { kwarg } : { kwargs [ kwarg ] } \" ) print ( \"Defining outer wrapper\" ) def wrapper ( func ): print ( \"Inside simple_decorator_1_bis wrapper\" ) func print ( f \"Returning { type ( wrapper ) } \" ) return wrapper The wrapper is being exectued and do not return a function, if the decorated function_3 is executed, TypeError is raised @simple_decorator_3 ( \"Argument 1\" , argument2 = \"Text\" ) def function_3 (): print ( \"inside function\" ) function_3 () Inside simple_decorator_1_bis arg: Argument 1 kwarg: argument2: Text Defining outer wrapper Returning <class 'function'> Inside simple_decorator_1_bis wrapper --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-32-a47b6d10c488> in <module> () 3 print ( \"inside function\" ) 4 ----> 5 function_3 ( ) TypeError : 'NoneType' object is not callable Sending arguments slightly differs from decorators w.o. arguments. The decorating function receives the decorators arguments and defines a first wrapper. The latest will become a function as argument and wraps it again. Note that both wrappers must return the wrapped elements. def decorated_plot_with_arguments_1 ( * dargs , ** dkwargs ): print ( \"Decorator arguments:\" , dargs , dkwargs ) def wrapper ( func ): print ( \"Inside wrap()\" ) def wrapped_func ( * args , ** kwargs ): plt . figure ( ** dkwargs ) print ( f \"Decorator arguments: { dargs } , { dkwargs } , function arguments: { args } , { kwargs } \" ) func ( * args , ** kwargs ) return wrapped_func return wrapper @decorated_plot_with_arguments_1 ( figsize = ( 16 , 9 )) @decorated_plot_2 def my_plot_3 ( data ): plt . plot ( data ) Decorator arguments: () {'figsize': (16, 9)} Inside wrap() my_plot_3 ( np . random . random ( 11 ) * 10 ) Decorator arguments: (), {'figsize': (16, 9)}, function arguments: (array([ 7.82003567, 3.07358292, 5.73103547, 8.38784188, 7.93077441, 1.36289391, 7.83375573, 4.21390851, 1.00164956, 5.32641431, 5.70275008]),), {} Inside decorated_plot_2 Setting figsize to (8, 4) <matplotlib.figure.Figure at 0x31e01ebe0> Decorator with missing arguments \u00b6 If no arguments is given to the decorator, the function is directly passed as argument, the decoration is buggy! @decorated_plot_with_arguments_1 @decorated_plot_2 def my_plot_4 ( data ): plt . plot ( data ) Decorator arguments: (<function decorated_plot_2.<locals>.wrapper at 0x31e4d0268>,) {} my_plot_4 ( np . random . random ( 11 ) * 10 ) Inside wrap() <function __main__.decorated_plot_with_arguments_1.<locals>.wrapper.<locals>.wrapped_func> Fixing a missing value can be done by argument type checking from functools import partial def decorated_plot_with_arguments_2 ( * dargs , ** dkwargs ): try : callable ( dargs [ 0 ]) except IndexError : return partial ( decorated_plot_with_arguments_2 , * dargs [ 1 :], ** dkwargs ) else : print ( \"Decorator arguments:\" , dargs , dkwargs ) func = dargs [ 0 ] # If used with another decorator, @wraps must be the most outter decorator @wraps ( func ) @decorated_plot_2 def wrapped_func ( * args , ** kwargs ): plt . figure ( ** dkwargs ) print ( f \"Decorator arguments: { dargs } , { dkwargs } , function arguments: { args } , { kwargs } \" ) func ( * args , ** kwargs ) return wrapped_func @decorated_plot_with_arguments_2 ( figsize = ( 16 , 9 )) def my_plot_5 ( data ): \"\"\"Plot using a decorator by providing arguments\"\"\" plt . plot ( data ) Decorator arguments: (<function my_plot_5 at 0x31e9c7b70>,) {'figsize': (16, 9)} my_plot_5 ( np . random . random ( 11 ) * 10 ) Inside decorated_plot_2 Setting figsize to (8, 4) Decorator arguments: (<function my_plot_5 at 0x31e9c7b70>,), {'figsize': (16, 9)}, function arguments: (array([ 0.04835086, 2.02728246, 5.59082537, 3.21987326, 4.69476169, 5.48887825, 4.90436293, 4.45523865, 0.22647019, 4.52684968, 7.95890563]),), {} <matplotlib.figure.Figure at 0x31e9c1780> my_plot_5 . __doc__ 'Plot using a decorator by providing arguments' @decorated_plot_with_arguments_2 def my_plot_6 ( data : np . ndarray ): \"\"\"Plot using a decorator omitting arguments\"\"\" plt . plot ( data ) Decorator arguments: (<function my_plot_6 at 0x31e9c71e0>,) {} my_plot_6 ( np . random . random ( 11 ) * 10 ) Inside decorated_plot_2 Setting figsize to (8, 4) Decorator arguments: (<function my_plot_6 at 0x31e9c71e0>,), {}, function arguments: (array([ 0.47367819, 0.29648344, 6.9525169 , 4.41880714, 0.58766086, 0.7499045 , 4.3640292 , 2.75065738, 1.48736178, 5.70814772, 0.22634453]),), {} <matplotlib.figure.Figure at 0x31e881f98> my_plot_6 . __doc__ 'Plot using a decorator omitting arguments' Example \u00b6 Untouched and interesting example from David Beazley's Cookbook . For comments and further explanations on this example, please refer to the book. # %load https://raw.githubusercontent.com/dabeaz/python-cookbook/master/src/9/enforcing_type_checking_on_a_function_using_a_decorator/example.py from inspect import signature from functools import wraps def typeassert ( * ty_args , ** ty_kwargs ): def decorate ( func ): # If in optimized mode, disable type checking if not __debug__ : return func # Map function argument names to supplied types sig = signature ( func ) bound_types = sig . bind_partial ( * ty_args , ** ty_kwargs ) . arguments @wraps ( func ) def wrapper ( * args , ** kwargs ): bound_values = sig . bind ( * args , ** kwargs ) # Enforce type assertions across supplied arguments for name , value in bound_values . arguments . items (): if name in bound_types : if not isinstance ( value , bound_types [ name ]): raise TypeError ( 'Argument {} must be {} ' . format ( name , bound_types [ name ]) ) return func ( * args , ** kwargs ) return wrapper return decorate # Examples @typeassert ( int , int ) def add ( x , y ): return x + y @typeassert ( int , z = int ) def spam ( x , y , z = 42 ): print ( x , y , z ) if __name__ == '__main__' : print ( add ( 2 , 3 )) try : add ( 2 , 'hello' ) except TypeError as e : print ( e ) spam ( 1 , 2 , 3 ) spam ( 1 , 'hello' , 3 ) try : spam ( 1 , 'hello' , 'world' ) except TypeError as e : print ( e ) 5 Argument y must be <class 'int'> 1 2 3 1 hello 3 Argument z must be <class 'int'> A slight modification with type hints usage a = 2 b = 3 c = ( a == 2 | True ) c False ( type ( Any ) is type ( typing . Any )) or False True from inspect import signature from functools import wraps from typing import Any def typeassert ( func ): # If in optimized mode, disable type checking if not __debug__ : return func # Map function argument names to supplied types sig = signature ( func ) bound_types = sig . parameters @wraps ( func ) def wrapper ( * args , ** kwargs ): bound_values = sig . bind ( * args , ** kwargs ) print ( bound_values ) # Enforce type assertions across supplied arguments for name , value in bound_values . arguments . items (): if name in bound_types : if not type ( value ) is bound_types [ name ] . annotation : raise TypeError ( f \"Argument { name } (class { value . __class__ . __name__ } ) \" , f \"must be { bound_types [ name ] . annotation } \" ) return func ( * args , ** kwargs ) return wrapper # Examples @typeassert def add ( x : int , y : int ) -> int : return x + y @typeassert def spam ( x : int , y : Any , str , z : int = 42 ): print ( x , y , z ) if __name__ == '__main__' : print ( add ( 2 , 3 )) try : add ( 2 , 'hello' ) except TypeError as e : print ( e ) spam ( 1 , 2 , 3 ) spam ( 1 , 'hello' , 3 ) try : spam ( 1 , 'hello' , 'world' ) except TypeError as e : print ( e ) <BoundArguments (x=2, y=3)> 5 <BoundArguments (x=2, y='hello')> ('Argument y (class str) ', \"must be <class 'int'>\") <BoundArguments (x=1, y=2, str=3)> --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-47-fac543187e30> in <module> () 44 print ( e ) 45 ---> 46 spam ( 1 , 2 , 3 ) 47 spam ( 1 , 'hello' , 3 ) 48 try : <ipython-input-47-fac543187e30> in wrapper (*args, **kwargs) 22 raise TypeError( 23 f\"Argument {name} (class {value.__class__.__name__}) \" , ---> 24 f\"must be {bound_types[name].annotation}\" 25 ) 26 return func ( * args , ** kwargs ) TypeError : ('Argument y (class int) ', 'must be typing.Any') sig = signature ( add ) sig . return_annotation int add . --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-112-c5390c20ad75> in <module> () ----> 1 add . mro AttributeError : 'function' object has no attribute 'mro' Decorators as class \u00b6 class decorator_class ( object ): def __init__ ( self , arg ): # this method is called in the decorator expression print ( f \"Inside decorator __init__ with arguments \\\" { arg } \\\" \" ) self . arg = arg def __call__ ( self , function ): # this method is called to do the job print ( f \"Inside decorator __call__ with arguments \\\" { self . arg } \\\" \" ) return function deco_instance = decorator_class ( 'foo' ) def function_to_decorate ( * args , ** kwargs ): print ( f \"Inside function with positional arguments \\\" { args } \\\" , \" f \"and keyword arguments \\\" { kwargs } \\\" \" ) function_to_decorate () @decorator_class ( \"bbb\" ) def function ( * args , ** kwargs ): print ( \"in function, %s %s \" % ( args , kwargs )) @decorator_class def function_to_decorate_2 ( * args , ** kwargs ): print ( f \"Inside function with positional arguments \\\" { args } \\\" , \" f \"and keyword arguments \\\" { kwargs } \\\" \" ) function_to_decorate_2 ( 'aze' ) Standard decorators \u00b6 @classmethod Transform a method into a class method. @staticmethod Transform a method into a static method. @property create read-only properties easily using property() as a decorator. getter , setter , and deleter methods are usable as decorators @functools.wraps This is a convenience function for invoking functools.update_wrapper() as a function decorator when defining a wrapper function. @functools.singledispatch Transform a function into a single-dispatch generic function. @functools.lru_cache Decorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can save time when an expensive or I/O bound function is periodically called with the same arguments. @functools.total_ordering Given a class defining one or more rich comparison ordering methods, this class decorator supplies the rest. @contextlib.contextmanager This function is a decorator that can be used to define a factory function for with statement context managers, without needing to create a class or separate __enter__() and __exit__() methods. See also contextlib.ContextDecorator @asyncio.coroutine Decorator to mark generator-based coroutines. This enables the generator use yield from to call async def coroutines, and also enables the generator to be called by async def coroutines, for instance using an await expression. @enum.unique A class decorator specifically for enumerations. It searches an enumeration\u2019s __members__ gathering any aliases it finds; if any are found ValueError is raised. @typing.overload Allow describing functions and methods that support multiple different combinations of argument types. @typing.no_type_check Decorator to indicate that annotations are not type hints. @typing.no_type_check_decorator Decorator to give another decorator the no_type_check() effect. References \u00b6 Scipy Lecture Notes","title":"04 \u00b7\u00a0Decorators"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#function-decorators","text":"A decorator can be defined as a normal function. It receives generaly a function as argument. def simple_decorator_1 ( function ): print ( \"doing decoration\" ) return function Decorate a function_O with simple_decorator_1 is equivalent to execute simple_decorator_1(function_0) def function_0 (): print ( \"inside function\" ) simple_decorator_1 ( function_0 ); doing decoration Therefor, a decorator is executed as it is used after a function definition @simple_decorator_1 def function_1 (): print ( \"inside function\" ) doing decoration","title":"Function decorators"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#simple-decorator","text":"A generator is however often used to wrap the function content and adding extra elements to its execution. Exemple of a decorator that initialize and format a plot. import numpy as np import matplotlib.pyplot as plt def decorate_plot ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" def wrapper ( * args , ** kwargs ): size = ( 8 , 4 ) print ( f \"Setting figsize to { size } \" ) with plt . style . context ( 'ggplot' ): plt . figure ( figsize = ( size )) func ( * args , ** kwargs ) plt . xlim ( 0 , 10 ) plt . ylim ( 0 , 10 ) return wrapper @decorate_plot def my_first_decorated_plot ( data ): \"\"\"A simple plot.\"\"\" plt . plot ( data ) my_first_decorated_plot ( np . random . RandomState ( 42 ) . random_sample ( size = 11 ) * 10 ) Setting figsize to (8, 4) my_first_decorated_plot . __doc__ Function documentation is not preserved after applying a decorator. This has to be manualy fixed. def decorated_plot_w_metadata ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" def wrapper ( * args , ** kwargs ): size = ( 8 , 4 ) print ( f \"Setting figsize to { size } \" ) with plt . style . context ( 'ggplot' ): plt . figure ( figsize = ( size )) func ( * args , ** kwargs ) plt . xlim ( 0 , 10 ) plt . ylim ( 0 , 10 ) plt . graphpaper ( dx = 1 , dy = 2 ) wrapper . __name__ = func . __name__ wrapper . __doc__ = func . __doc__ wrapper . __dict__ . update ( func . __dict__ ) return wrapper @decorated_plot_w_metadata def my_first_decorated_plot_w_metadata ( data ): \"\"\"A simple plot.\"\"\" plt . plot ( data ) print ( my_first_decorated_plot_w_metadata . __name__ , my_first_decorated_plot_w_metadata . __doc__ ) my_first_decorated_plot_w_metadata A simple plot. A decorator in functools is available for that purpose.","title":"Simple decorator"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#simple-decorator-with-functoolswraps-decorator-preserving-metadata","text":"from functools import wraps def decorated_plot_2 ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" @wraps ( func ) def wrapper ( * args , ** kwargs ): size = ( 8 , 4 ) print ( f \"Setting figsize to { size } \" ) with plt . style . context ( 'ggplot' ): plt . figure ( figsize = ( size )) func ( * args , ** kwargs ) plt . xlim ( 0 , 10 ) plt . ylim ( 0 , 10 ) return wrapper @decorated_plot_2 def my_plot_2 ( data ): \"\"\"A simple plot.\"\"\" plt . plot ( data ) my_plot_2 ( np . random . random ( 11 ) * 10 ) Setting figsize to (8, 4) from functools import ( WRAPPER_ASSIGNMENTS , WRAPPER_UPDATES ) from pprint import pprint from itertools import chain The optional arguments are tuples to specify which attributes of the original function are assigned directly to the matching attributes on the wrapper function and which attributes of the wrapper function are updated with the corresponding attributes from the original function. The default values for these arguments are the module level constants WRAPPER_ASSIGNMENTS and WRAPPER_UPDATES WRAPPER_ASSIGNMENTS ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__') WRAPPER_UPDATES ('__dict__',) for elt in chain ( WRAPPER_ASSIGNMENTS , WRAPPER_UPDATES ): pprint ( f \" { elt } : { getattr ( my_plot_1 , elt ) } --> { getattr ( my_plot_2 , elt ) } \" , indent = 2 ) '__module__ : __main__ --> __main__' '__name__ : wrapper --> my_plot_2' '__qualname__ : decorated_plot_1.<locals>.wrapper --> my_plot_2' '__doc__ : None --> A simple plot.' '__annotations__ : {} --> {}' \"__dict__ : {} --> {'__wrapped__': <function my_plot_2 at 0x315acb0d0>}\" When wrapped with functools.wraps , the original function is callable with the _ wrapper_ method my_plot_2 . __wrapped__ ( np . random . random ( 11 ) * 10 ) import functools import inspect def my_wrapper ( fn ): def wrapped ( x , y , z ): return my_func ( x , y ) wrapped = functools . update_wrapper ( wrapped , fn ) return wrapped def my_func ( x , y ): pass wrapper = my_wrapper ( my_func )","title":"Simple decorator with functools.wraps decorator : preserving metadata"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#chaining-decorators","text":"def decorated_plot_2 ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" def wrapper ( * args , ** kwargs ): size = ( 8 , 4 ) print ( f \"Inside decorated_plot_2\" ) print ( f \"Setting figsize to { size } \" ) with plt . style . context ( 'ggplot' ): plt . figure ( figsize = ( size )) func ( * args , ** kwargs ) plt . xlim ( 0 , 10 ) plt . ylim ( 0 , 10 ) plt . graphpaper ( dx = 1 , dy = 2 ) return wrapper def decorated_plot_3 ( func ): \"\"\" Decorate a plot: set the figure size, style and add graphpaper \"\"\" def wrapper ( * args , ** kwargs ): print ( f \"Inside decorated_plot_3\" ) func ( * args , ** kwargs ) plt . xlabel ( \"Label\" ) return wrapper @decorated_plot_3 @decorated_plot_2 def my_plot_2 ( data ): plt . plot ( data ) my_plot_2 ( np . random . random ( 11 ) * 10 ) Inside decorated_plot_3 Inside decorated_plot_2 Setting figsize to (8, 4)","title":"Chaining decorators"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#sending-arguments-to-decorator","text":"Unpacking behavior of decorator def simple_decorator_2 ( * args , ** kwargs ): print ( \"Inside simple_decorator_1_bis\" ) for arg in args : print ( f \"arg: { arg } \" ) for kwarg in kwargs : print ( f \"kwarg: { kwarg } : { kwargs [ kwarg ] } \" ) return def function_2 (): print ( \"inside function\" ) If the decorator function simple_decorator_2 becomes a function, *args contains the function given as argument. type ( simple_decorator_2 ( function_2 )) Inside simple_decorator_1_bis arg: <function function_2 at 0x315acb620> NoneType If the decorator function simple_decorator_2 becomes a function, *args does not contains the function given as argument. type ( simple_decorator_2 ( \"Argument 1\" , argument2 = \"Text\" )) Inside simple_decorator_1_bis arg: Argument 1 kwarg: argument2: Text NoneType def simple_decorator_3 ( * args , ** kwargs ): print ( \"Inside simple_decorator_1_bis\" ) for arg in args : print ( f \"arg: { arg } \" ) for kwarg in kwargs : print ( f \"kwarg: { kwarg } : { kwargs [ kwarg ] } \" ) print ( \"Defining outer wrapper\" ) def wrapper ( func ): print ( \"Inside simple_decorator_1_bis wrapper\" ) func print ( f \"Returning { type ( wrapper ) } \" ) return wrapper The wrapper is being exectued and do not return a function, if the decorated function_3 is executed, TypeError is raised @simple_decorator_3 ( \"Argument 1\" , argument2 = \"Text\" ) def function_3 (): print ( \"inside function\" ) function_3 () Inside simple_decorator_1_bis arg: Argument 1 kwarg: argument2: Text Defining outer wrapper Returning <class 'function'> Inside simple_decorator_1_bis wrapper --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-32-a47b6d10c488> in <module> () 3 print ( \"inside function\" ) 4 ----> 5 function_3 ( ) TypeError : 'NoneType' object is not callable Sending arguments slightly differs from decorators w.o. arguments. The decorating function receives the decorators arguments and defines a first wrapper. The latest will become a function as argument and wraps it again. Note that both wrappers must return the wrapped elements. def decorated_plot_with_arguments_1 ( * dargs , ** dkwargs ): print ( \"Decorator arguments:\" , dargs , dkwargs ) def wrapper ( func ): print ( \"Inside wrap()\" ) def wrapped_func ( * args , ** kwargs ): plt . figure ( ** dkwargs ) print ( f \"Decorator arguments: { dargs } , { dkwargs } , function arguments: { args } , { kwargs } \" ) func ( * args , ** kwargs ) return wrapped_func return wrapper @decorated_plot_with_arguments_1 ( figsize = ( 16 , 9 )) @decorated_plot_2 def my_plot_3 ( data ): plt . plot ( data ) Decorator arguments: () {'figsize': (16, 9)} Inside wrap() my_plot_3 ( np . random . random ( 11 ) * 10 ) Decorator arguments: (), {'figsize': (16, 9)}, function arguments: (array([ 7.82003567, 3.07358292, 5.73103547, 8.38784188, 7.93077441, 1.36289391, 7.83375573, 4.21390851, 1.00164956, 5.32641431, 5.70275008]),), {} Inside decorated_plot_2 Setting figsize to (8, 4) <matplotlib.figure.Figure at 0x31e01ebe0>","title":"Sending arguments to decorator"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#decorator-with-missing-arguments","text":"If no arguments is given to the decorator, the function is directly passed as argument, the decoration is buggy! @decorated_plot_with_arguments_1 @decorated_plot_2 def my_plot_4 ( data ): plt . plot ( data ) Decorator arguments: (<function decorated_plot_2.<locals>.wrapper at 0x31e4d0268>,) {} my_plot_4 ( np . random . random ( 11 ) * 10 ) Inside wrap() <function __main__.decorated_plot_with_arguments_1.<locals>.wrapper.<locals>.wrapped_func> Fixing a missing value can be done by argument type checking from functools import partial def decorated_plot_with_arguments_2 ( * dargs , ** dkwargs ): try : callable ( dargs [ 0 ]) except IndexError : return partial ( decorated_plot_with_arguments_2 , * dargs [ 1 :], ** dkwargs ) else : print ( \"Decorator arguments:\" , dargs , dkwargs ) func = dargs [ 0 ] # If used with another decorator, @wraps must be the most outter decorator @wraps ( func ) @decorated_plot_2 def wrapped_func ( * args , ** kwargs ): plt . figure ( ** dkwargs ) print ( f \"Decorator arguments: { dargs } , { dkwargs } , function arguments: { args } , { kwargs } \" ) func ( * args , ** kwargs ) return wrapped_func @decorated_plot_with_arguments_2 ( figsize = ( 16 , 9 )) def my_plot_5 ( data ): \"\"\"Plot using a decorator by providing arguments\"\"\" plt . plot ( data ) Decorator arguments: (<function my_plot_5 at 0x31e9c7b70>,) {'figsize': (16, 9)} my_plot_5 ( np . random . random ( 11 ) * 10 ) Inside decorated_plot_2 Setting figsize to (8, 4) Decorator arguments: (<function my_plot_5 at 0x31e9c7b70>,), {'figsize': (16, 9)}, function arguments: (array([ 0.04835086, 2.02728246, 5.59082537, 3.21987326, 4.69476169, 5.48887825, 4.90436293, 4.45523865, 0.22647019, 4.52684968, 7.95890563]),), {} <matplotlib.figure.Figure at 0x31e9c1780> my_plot_5 . __doc__ 'Plot using a decorator by providing arguments' @decorated_plot_with_arguments_2 def my_plot_6 ( data : np . ndarray ): \"\"\"Plot using a decorator omitting arguments\"\"\" plt . plot ( data ) Decorator arguments: (<function my_plot_6 at 0x31e9c71e0>,) {} my_plot_6 ( np . random . random ( 11 ) * 10 ) Inside decorated_plot_2 Setting figsize to (8, 4) Decorator arguments: (<function my_plot_6 at 0x31e9c71e0>,), {}, function arguments: (array([ 0.47367819, 0.29648344, 6.9525169 , 4.41880714, 0.58766086, 0.7499045 , 4.3640292 , 2.75065738, 1.48736178, 5.70814772, 0.22634453]),), {} <matplotlib.figure.Figure at 0x31e881f98> my_plot_6 . __doc__ 'Plot using a decorator omitting arguments'","title":"Decorator with missing arguments"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#example","text":"Untouched and interesting example from David Beazley's Cookbook . For comments and further explanations on this example, please refer to the book. # %load https://raw.githubusercontent.com/dabeaz/python-cookbook/master/src/9/enforcing_type_checking_on_a_function_using_a_decorator/example.py from inspect import signature from functools import wraps def typeassert ( * ty_args , ** ty_kwargs ): def decorate ( func ): # If in optimized mode, disable type checking if not __debug__ : return func # Map function argument names to supplied types sig = signature ( func ) bound_types = sig . bind_partial ( * ty_args , ** ty_kwargs ) . arguments @wraps ( func ) def wrapper ( * args , ** kwargs ): bound_values = sig . bind ( * args , ** kwargs ) # Enforce type assertions across supplied arguments for name , value in bound_values . arguments . items (): if name in bound_types : if not isinstance ( value , bound_types [ name ]): raise TypeError ( 'Argument {} must be {} ' . format ( name , bound_types [ name ]) ) return func ( * args , ** kwargs ) return wrapper return decorate # Examples @typeassert ( int , int ) def add ( x , y ): return x + y @typeassert ( int , z = int ) def spam ( x , y , z = 42 ): print ( x , y , z ) if __name__ == '__main__' : print ( add ( 2 , 3 )) try : add ( 2 , 'hello' ) except TypeError as e : print ( e ) spam ( 1 , 2 , 3 ) spam ( 1 , 'hello' , 3 ) try : spam ( 1 , 'hello' , 'world' ) except TypeError as e : print ( e ) 5 Argument y must be <class 'int'> 1 2 3 1 hello 3 Argument z must be <class 'int'> A slight modification with type hints usage a = 2 b = 3 c = ( a == 2 | True ) c False ( type ( Any ) is type ( typing . Any )) or False True from inspect import signature from functools import wraps from typing import Any def typeassert ( func ): # If in optimized mode, disable type checking if not __debug__ : return func # Map function argument names to supplied types sig = signature ( func ) bound_types = sig . parameters @wraps ( func ) def wrapper ( * args , ** kwargs ): bound_values = sig . bind ( * args , ** kwargs ) print ( bound_values ) # Enforce type assertions across supplied arguments for name , value in bound_values . arguments . items (): if name in bound_types : if not type ( value ) is bound_types [ name ] . annotation : raise TypeError ( f \"Argument { name } (class { value . __class__ . __name__ } ) \" , f \"must be { bound_types [ name ] . annotation } \" ) return func ( * args , ** kwargs ) return wrapper # Examples @typeassert def add ( x : int , y : int ) -> int : return x + y @typeassert def spam ( x : int , y : Any , str , z : int = 42 ): print ( x , y , z ) if __name__ == '__main__' : print ( add ( 2 , 3 )) try : add ( 2 , 'hello' ) except TypeError as e : print ( e ) spam ( 1 , 2 , 3 ) spam ( 1 , 'hello' , 3 ) try : spam ( 1 , 'hello' , 'world' ) except TypeError as e : print ( e ) <BoundArguments (x=2, y=3)> 5 <BoundArguments (x=2, y='hello')> ('Argument y (class str) ', \"must be <class 'int'>\") <BoundArguments (x=1, y=2, str=3)> --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-47-fac543187e30> in <module> () 44 print ( e ) 45 ---> 46 spam ( 1 , 2 , 3 ) 47 spam ( 1 , 'hello' , 3 ) 48 try : <ipython-input-47-fac543187e30> in wrapper (*args, **kwargs) 22 raise TypeError( 23 f\"Argument {name} (class {value.__class__.__name__}) \" , ---> 24 f\"must be {bound_types[name].annotation}\" 25 ) 26 return func ( * args , ** kwargs ) TypeError : ('Argument y (class int) ', 'must be typing.Any') sig = signature ( add ) sig . return_annotation int add . --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-112-c5390c20ad75> in <module> () ----> 1 add . mro AttributeError : 'function' object has no attribute 'mro'","title":"Example"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#decorators-as-class","text":"class decorator_class ( object ): def __init__ ( self , arg ): # this method is called in the decorator expression print ( f \"Inside decorator __init__ with arguments \\\" { arg } \\\" \" ) self . arg = arg def __call__ ( self , function ): # this method is called to do the job print ( f \"Inside decorator __call__ with arguments \\\" { self . arg } \\\" \" ) return function deco_instance = decorator_class ( 'foo' ) def function_to_decorate ( * args , ** kwargs ): print ( f \"Inside function with positional arguments \\\" { args } \\\" , \" f \"and keyword arguments \\\" { kwargs } \\\" \" ) function_to_decorate () @decorator_class ( \"bbb\" ) def function ( * args , ** kwargs ): print ( \"in function, %s %s \" % ( args , kwargs )) @decorator_class def function_to_decorate_2 ( * args , ** kwargs ): print ( f \"Inside function with positional arguments \\\" { args } \\\" , \" f \"and keyword arguments \\\" { kwargs } \\\" \" ) function_to_decorate_2 ( 'aze' )","title":"Decorators as class"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#standard-decorators","text":"@classmethod Transform a method into a class method. @staticmethod Transform a method into a static method. @property create read-only properties easily using property() as a decorator. getter , setter , and deleter methods are usable as decorators @functools.wraps This is a convenience function for invoking functools.update_wrapper() as a function decorator when defining a wrapper function. @functools.singledispatch Transform a function into a single-dispatch generic function. @functools.lru_cache Decorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can save time when an expensive or I/O bound function is periodically called with the same arguments. @functools.total_ordering Given a class defining one or more rich comparison ordering methods, this class decorator supplies the rest. @contextlib.contextmanager This function is a decorator that can be used to define a factory function for with statement context managers, without needing to create a class or separate __enter__() and __exit__() methods. See also contextlib.ContextDecorator @asyncio.coroutine Decorator to mark generator-based coroutines. This enables the generator use yield from to call async def coroutines, and also enables the generator to be called by async def coroutines, for instance using an await expression. @enum.unique A class decorator specifically for enumerations. It searches an enumeration\u2019s __members__ gathering any aliases it finds; if any are found ValueError is raised. @typing.overload Allow describing functions and methods that support multiple different combinations of argument types. @typing.no_type_check Decorator to indicate that annotations are not type hints. @typing.no_type_check_decorator Decorator to give another decorator the no_type_check() effect.","title":"Standard decorators"},{"location":"python/04%20%C2%B7%C2%A0Decorators/#references","text":"Scipy Lecture Notes","title":"References"},{"location":"python/05%20%C2%B7%20Descriptors/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); % load_ext autoreload % load_ext watermark % autoreload 2 # from asampy import cdf % watermark - mdu The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload last updated: 2020-02-15 compiler : GCC 7.3.0 system : Linux release : 5.3.0-29-generic machine : x86_64 processor : x86_64 CPU cores : 8 interpreter: 64bit Documentation How-to from Raymond Hettinger In general, a descriptor is an object attribute with \u201cbinding behavior\u201d, one whose attribute access has been overridden by methods in the descriptor protocol. Those methods are __get__() , __set__() , and __delete__() . If any of those methods are defined for an object, it is said to be a descriptor. Descriptors \u00b6 # Example from how-to: class RevealAccess ( object ): \"\"\"A data descriptor that sets and returns values normally and prints a message logging their access. \"\"\" def __init__ ( self , initval = None , name = 'var' ): self . val = initval self . name = name def __get__ ( self , obj , objtype ): print ( 'Retrieving' , self . name ) return self . val def __set__ ( self , obj , val ): print ( 'Updating' , self . name ) self . val = val class MyClass ( object ): x = RevealAccess ( 10 , 'var \"x\"' ) y = 5 m = MyClass () m . x m . x = 20 m . x m . y Retrieving var \"x\" Updating var \"x\" Retrieving var \"x\" 5 class Trait : def __init__ ( self , minimum , maximum ): self . minimum = minimum self . maximum = maximum def __get__ ( self , instance , owner ): return instance . __dict__ [ self . key ] def __set__ ( self , instance , value ): if self . minimum < value < self . maximum : instance . __dict__ [ self . key ] = value else : raise ValueError ( f \" { value } not in range [ { self . minimum } ; { self . maximum } ]\" ) def __set_name__ ( self , owner , name ): self . key = name class ValidatedContainer : att01 = Trait ( 0 , 10 ) att02 = Trait ( 4 , 5 ) # c = ValidatedContainer () c . att01 = 4 try : c . att02 = 6 except ValueError as e : print ( e ) 6 not in range [4;5] Example (from D. Beazley cookbook, 8-12) \u00b6 # %load https://github.com/dabeaz/python-cookbook/blob/master/src/8/implementing_a_data_model_or_type_system/example_clsdec.py?raw=True # Base class. Uses a descriptor to set a value class Descriptor : def __init__ ( self , name = None , ** opts ): self . name = name self . __dict__ . update ( opts ) def __set__ ( self , instance , value ): instance . __dict__ [ self . name ] = value # Types definition: def Typed ( expected_type , cls = None ): if cls is None : return lambda cls : Typed ( expected_type , cls ) super_set = cls . __set__ def __set__ ( self , instance , value ): if not isinstance ( value , expected_type ): raise TypeError ( 'expected ' + str ( expected_type )) super_set ( self , instance , value ) cls . __set__ = __set__ return cls def Unsigned ( cls ): super_set = cls . __set__ def __set__ ( self , instance , value ): if value < 0 : raise ValueError ( 'Expected >= 0' ) super_set ( self , instance , value ) cls . __set__ = __set__ return cls def MaxSized ( cls ): super_init = cls . __init__ def __init__ ( self , name = None , ** opts ): if 'size' not in opts : raise TypeError ( 'missing size option' ) self . size = opts [ 'size' ] super_init ( self , name , ** opts ) cls . __init__ = __init__ super_set = cls . __set__ def __set__ ( self , instance , value ): if len ( value ) >= self . size : raise ValueError ( 'size must be < ' + str ( self . size )) super_set ( self , instance , value ) cls . __set__ = __set__ return cls @Typed ( int ) class Integer ( Descriptor ): pass @Unsigned class UnsignedInteger ( Integer ): pass @Typed ( float ) class Float ( Descriptor ): pass @Unsigned class UnsignedFloat ( Float ): pass @Typed ( str ) class String ( Descriptor ): pass @MaxSized class SizedString ( String ): pass Float ( 1.2 ) <__main__.Float at 0x31332d0f0> # Testing code def test ( s ): print ( s . name ) s . shares = 75 print ( s . shares ) try : s . shares = - 10 except ValueError as e : print ( e ) try : s . price = 'a lot' except TypeError as e : print ( e ) try : s . name = 'ABRACADABRA' except ValueError as e : print ( e ) Test with descriptor \u00b6 print ( \"# --- Class with descriptors\" ) class Stock : # Specify constraints name = SizedString ( 'name' , size = 8 ) shares = UnsignedInteger ( 'shares' ) price = UnsignedFloat ( 'price' ) def __init__ ( self , name , shares , price ): self . name = name self . shares = shares self . price = price s = Stock ( 'ACME' , 50 , 91.1 ) test ( s ) Test with class decorator \u00b6 # Class decorator to apply constraints def check_attributes ( ** kwargs ): def decorate ( cls ): for key , value in kwargs . items (): if isinstance ( value , Descriptor ): value . name = key setattr ( cls , key , value ) else : setattr ( cls , key , value ( key )) return cls return decorate @check_attributes ( name = SizedString ( size = 8 ), shares = UnsignedInteger , price = UnsignedFloat ) class Stock : def __init__ ( self , name , shares , price ): self . name = name self . shares = shares self . price = price s = Stock ( 'ACME' , 50 , 91.1 ) test ( s ) Test with metaclass \u00b6 # A metaclass that applies checking class checkedmeta ( type ): def __new__ ( cls , clsname , bases , methods ): # Attach attribute names to the descriptors for key , value in methods . items (): if isinstance ( value , Descriptor ): value . name = key return type . __new__ ( cls , clsname , bases , methods ) class Stock ( metaclass = checkedmeta ): name = SizedString ( size = 8 ) shares = UnsignedInteger () price = UnsignedFloat () def __init__ ( self , name , shares , price ): self . name = name self . shares = shares self . price = price s = Stock ( 'ACAZE' , 5 , 91.1 ) test ( s ) ACAZE 75 Expected >= 0 '<' not supported between instances of 'str' and 'int' size must be < 8 Usage in a custom container \u00b6 import xml.etree.ElementTree as ET import requests from collections import Sequence from typing import Dict import re # Fetch some data from asam.net and work on a cdfx container url = \"https://www.asam.net/index.php?eID=dumpFile&t=f&f=203&token=0f5b670d38f303b5e18f13b7e58791b630bac3a4\" f = requests . get ( url ) cdfx = f . text def minus2underscore ( name ): s1 = re . sub ( '(.)([A-Z][a-z]+)' , r '\\1_\\2' , name ) return re . sub ( '([a-z0-9])([A-Z])' , r '\\1_\\2' , s1 ) . lower () . replace ( '-' , \"_\" ) class SwSystem : def __init__ ( self ): print ( \"Ajout d'un \u00e9l\u00e9ment\" ) # Types definition: def TypedContainer ( expected_type , cls = None ): if cls is None : return lambda cls : TypedContainer ( expected_type , cls ) super_append = cls . append def append ( self , elt ): if not isinstance ( elt , expected_type ): raise TypeError ( 'expected ' + str ( expected_type )) super_append ( self , elt ) cls . append = append return cls @TypedContainer ( SwSystem ) class SwSystems ( Sequence ): def __init__ ( self ): self . _items = [] def __getitem__ ( self , index ): return self . _items [ index ] def append ( self , elt ): self . _items . append ( elt ) def __len__ ( self ): return len ( self . _items ) class MSRSW ( metaclass = checkedmeta ): \"\"\" <MSRSW> is the root element, which may contains a short name (<SHORT-NAME>) and a category (<CATEGORY>). The category value indicates the standard and version number, e.g. the value \"CDF20\" denotes ASAM CDF V2.0. \"\"\" short_name = String () category = String () sw_systems : Dict [ str , SwSystem ] = SwSystems () def __init__ ( self , elt ): for node in elt : if len ( node ) == 0 : setattr ( self , minus2underscore ( node . tag ), node . text ) for swsystem in elt . iter ( \"SW-SYSTEM\" ): self . sw_systems . append ( SwSystem ()) root = ET . fromstring ( cdfx ) msrsw = MSRSW ( root ) Ajout d'un \u00e9l\u00e9ment elt = msrsw . sw_systems [ 0 ] from asampy import cdf --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-4-529dcc34db6c> in <module> () ----> 1 from asampy import cdf /opt/anaconda/miniconda3/lib/python3.6/site-packages/asampy/cdf.py in <module> () 49 50 @ dataclass ---> 51 class Calib ( object ) : 52 name : str = String ( ) 53 category : str = String ( ) /opt/anaconda/miniconda3/lib/python3.6/site-packages/dataclasses.py in dataclass (_cls, init, repr, eq, order, unsafe_hash, frozen) 956 957 # We're called as @dataclass without parens. --> 958 return wrap ( _cls ) 959 960 /opt/anaconda/miniconda3/lib/python3.6/site-packages/dataclasses.py in wrap (cls) 948 949 def wrap ( cls ) : --> 950 return _process_class ( cls , init , repr , eq , order , unsafe_hash , frozen ) 951 952 # See if we're being called as @dataclass or @dataclass(). /opt/anaconda/miniconda3/lib/python3.6/site-packages/dataclasses.py in _process_class (cls, init, repr, eq, order, unsafe_hash, frozen) 869 # if possible. 870 '__dataclass_self__' if 'self' in fields --> 871 else 'self' , 872 )) 873 /opt/anaconda/miniconda3/lib/python3.6/site-packages/dataclasses.py in _init_fn (fields, frozen, has_post_init, self_name) 458 seen_default = True 459 elif seen_default : --> 460 raise TypeError(f'non-default argument {f.name!r} ' 461 'follows default argument') 462 TypeError : non-default argument 'sw_axis_conts' follows default argument cdfx = cdf . cdfx ( root ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-5-7b043f8e7231> in <module> () ----> 1 cdfx = cdf . cdfx ( root ) NameError : name 'cdf' is not defined swsystem = cdfx . msrsw . sw_systems [ 0 ] swinstance = swsystem . sw_instance_spec . sw_instance_tree . sw_instance cdfx [ 'ASAM.C.CURVE.FIX_AXIS.PAR_DIST' ] <xarray.DataArray (dim_0: 6)> array([-10., -11., -12., -10., -9., -11.]) Coordinates: * dim_0 (dim_0) float64 1.0 2.0 3.0 4.0 5.0 6.0 msrsw . sw_systems . append ( SwSystem ()) Ajout d'un \u00e9l\u00e9ment cdfx . res {'ASAM.C.CURVE.FIX_AXIS.PAR': <xarray.DataArray (dim_0: 6)> array([9., 8., 7., 8., 9., 5.]) Coordinates: * dim_0 (dim_0) float64 0.0 4.0 8.0 12.0 16.0 20.0, 'ASAM.C.CURVE.FIX_AXIS.PAR_DIST': <xarray.DataArray (dim_0: 6)> array([-10., -11., -12., -10., -9., -11.]) Coordinates: * dim_0 (dim_0) float64 1.0 2.0 3.0 4.0 5.0 6.0, 'ASAM.C.CURVE.FIX_AXIS.PAR_LIST': <xarray.DataArray (dim_0: 6)> array([2., 3., 4., 2., 4., 3.]) Coordinates: * dim_0 (dim_0) float64 -1.0 4.0 6.0 8.0 9.0 10.0, 'ASAM.C.CURVE.STD_AXIS': <xarray.DataArray (dim_0: 8)> array([-3., -1., 6., 5., 9., 9., 13., 9.]) Coordinates: * dim_0 (dim_0) float64 -5.0 -1.0 2.0 4.0 5.0 8.0 14.0 22.0, 'ASAM.C.CURVE.STD_AXIS.MONOTONY_STRICT_DECREASE': <xarray.DataArray (dim_0: 8)> array([2708., 759., 690., 2141., 690., 1657., 1312., -56.]) Coordinates: * dim_0 (dim_0) float64 5.0 3.0 1.0 -1.0 -3.0 -5.0 -7.0 -9.0, 'ASAM.C.CURVE.STD_AXIS.MONOTONY_STRICT_INCREASE': <xarray.DataArray (dim_0: 8)> array([-10., 12., 22., 22., 64., 46., 66., 133.]) Coordinates: * dim_0 (dim_0) float64 1.0 4.0 7.0 10.0 13.0 16.0 19.0 22.0, 'ASAM.C.CURVE_AXIS': <xarray.DataArray (dim_0: 8)> array([0., 1., 2., 3., 4., 5., 6., 7.]) Coordinates: * dim_0 (dim_0) float64 -1.0 0.0 2.0 3.0 4.0 5.0 7.0 8.0, 'ASAM.C.DEPENDENT.REF_1.SWORD': <xarray.DataArray ()> array(13.), 'ASAM.C.DEPENDENT.REF_2.UWORD': <xarray.DataArray ()> array(57.), 'ASAM.C.DEPENDENT.REF_3.SWORD': <xarray.DataArray ()> array(70.), 'ASAM.C.DEPENDENT.REF_4.FLOAT64_IEEE': <xarray.DataArray ()> array(9.55), 'ASAM.C.DEPENDENT.REF_5.FLOAT64_IEEE': <xarray.DataArray ()> array(57.1), 'ASAM.C.SCALAR.FLOAT32_IEEE.IDENTICAL': <xarray.DataArray ()> array(0.), 'ASAM.C.SCALAR.FLOAT64_IEEE.IDENTICAL': <xarray.DataArray ()> array(-3.), 'ASAM.C.SCALAR.SBYTE.IDENTICAL': <xarray.DataArray ()> array(8.), 'ASAM.C.SCALAR.SLONG.IDENTICAL': <xarray.DataArray ()> array(86.), 'ASAM.C.SCALAR.SWORD.FORM_X_PLUS_4': <xarray.DataArray ()> array(6.), 'ASAM.C.SCALAR.SWORD.IDENTICAL': <xarray.DataArray ()> array(2.), 'ASAM.C.SCALAR.SWORD.LINEAR_MUL_2': <xarray.DataArray ()> array(4.), 'ASAM.C.SCALAR.SWORD.RAT_FUNC_DIV_10': <xarray.DataArray ()> array(0.2), 'ASAM.C.SCALAR.SWORD.RAT_FUNC_DIV_81_9175': <xarray.DataArray ()> array(0.024415), 'ASAM.C.SCALAR.SWORD.TAB_INTP_DEFAULT_VALUE': <xarray.DataArray ()> array(102.), 'ASAM.C.SCALAR.SWORD.TAB_INTP_NO_DEFAULT_VALUE': <xarray.DataArray ()> array(102.), 'ASAM.C.SCALAR.SWORD.TAB_NOINTP_DEFAULT_VALUE': <xarray.DataArray ()> array(102.), 'ASAM.C.SCALAR.SWORD.TAB_NOINTP_NO_DEFAULT_VALUE': <xarray.DataArray ()> array(102.), 'ASAM.C.SCALAR.UBYTE.IDENTICAL': <xarray.DataArray ()> array(32.), 'ASAM.C.SCALAR.ULONG.IDENTICAL': <xarray.DataArray ()> array(17.), 'ASAM.C.SCALAR.UWORD.IDENTICAL': <xarray.DataArray ()> array(15.), 'ASAM.C.SCALAR.UWORD.IDENTICAL.BITMASK_0FF0': <xarray.DataArray ()> array(0.), 'ASAM.C.VIRTUAL.REF_1.SWORD': <xarray.DataArray ()> array(0.), 'ASAM.C.VIRTUAL.REF_2.UWORD': <xarray.DataArray ()> array(51.), 'ASAM.C.VIRTUAL.REF_3.SWORD': <xarray.DataArray ()> array(51.), 'ASAM.C.VIRTUAL.SYSTEM_CONSTANT_1': <xarray.DataArray ()> array(28.55)} cdfx . res [ 'ASAM.C.CURVE.STD_AXIS.MONOTONY_STRICT_INCREASE' ] . plot () [<matplotlib.lines.Line2D at 0x3134ef7f0>] msrsw . sw_systems [ 1 ] <__main__.SwSystem at 0x313312da0> # Base class. Uses a descriptor to set a value class Descriptor : def __init__ ( self , name = None , ** opts ): self . name = name self . __dict__ . update ( opts ) def __set__ ( self , instance , value ): instance . __dict__ [ self . name ] = value","title":"05 \u00b7 Descriptors"},{"location":"python/05%20%C2%B7%20Descriptors/#descriptors","text":"# Example from how-to: class RevealAccess ( object ): \"\"\"A data descriptor that sets and returns values normally and prints a message logging their access. \"\"\" def __init__ ( self , initval = None , name = 'var' ): self . val = initval self . name = name def __get__ ( self , obj , objtype ): print ( 'Retrieving' , self . name ) return self . val def __set__ ( self , obj , val ): print ( 'Updating' , self . name ) self . val = val class MyClass ( object ): x = RevealAccess ( 10 , 'var \"x\"' ) y = 5 m = MyClass () m . x m . x = 20 m . x m . y Retrieving var \"x\" Updating var \"x\" Retrieving var \"x\" 5 class Trait : def __init__ ( self , minimum , maximum ): self . minimum = minimum self . maximum = maximum def __get__ ( self , instance , owner ): return instance . __dict__ [ self . key ] def __set__ ( self , instance , value ): if self . minimum < value < self . maximum : instance . __dict__ [ self . key ] = value else : raise ValueError ( f \" { value } not in range [ { self . minimum } ; { self . maximum } ]\" ) def __set_name__ ( self , owner , name ): self . key = name class ValidatedContainer : att01 = Trait ( 0 , 10 ) att02 = Trait ( 4 , 5 ) # c = ValidatedContainer () c . att01 = 4 try : c . att02 = 6 except ValueError as e : print ( e ) 6 not in range [4;5]","title":"Descriptors"},{"location":"python/05%20%C2%B7%20Descriptors/#example-from-d-beazley-cookbook-8-12","text":"# %load https://github.com/dabeaz/python-cookbook/blob/master/src/8/implementing_a_data_model_or_type_system/example_clsdec.py?raw=True # Base class. Uses a descriptor to set a value class Descriptor : def __init__ ( self , name = None , ** opts ): self . name = name self . __dict__ . update ( opts ) def __set__ ( self , instance , value ): instance . __dict__ [ self . name ] = value # Types definition: def Typed ( expected_type , cls = None ): if cls is None : return lambda cls : Typed ( expected_type , cls ) super_set = cls . __set__ def __set__ ( self , instance , value ): if not isinstance ( value , expected_type ): raise TypeError ( 'expected ' + str ( expected_type )) super_set ( self , instance , value ) cls . __set__ = __set__ return cls def Unsigned ( cls ): super_set = cls . __set__ def __set__ ( self , instance , value ): if value < 0 : raise ValueError ( 'Expected >= 0' ) super_set ( self , instance , value ) cls . __set__ = __set__ return cls def MaxSized ( cls ): super_init = cls . __init__ def __init__ ( self , name = None , ** opts ): if 'size' not in opts : raise TypeError ( 'missing size option' ) self . size = opts [ 'size' ] super_init ( self , name , ** opts ) cls . __init__ = __init__ super_set = cls . __set__ def __set__ ( self , instance , value ): if len ( value ) >= self . size : raise ValueError ( 'size must be < ' + str ( self . size )) super_set ( self , instance , value ) cls . __set__ = __set__ return cls @Typed ( int ) class Integer ( Descriptor ): pass @Unsigned class UnsignedInteger ( Integer ): pass @Typed ( float ) class Float ( Descriptor ): pass @Unsigned class UnsignedFloat ( Float ): pass @Typed ( str ) class String ( Descriptor ): pass @MaxSized class SizedString ( String ): pass Float ( 1.2 ) <__main__.Float at 0x31332d0f0> # Testing code def test ( s ): print ( s . name ) s . shares = 75 print ( s . shares ) try : s . shares = - 10 except ValueError as e : print ( e ) try : s . price = 'a lot' except TypeError as e : print ( e ) try : s . name = 'ABRACADABRA' except ValueError as e : print ( e )","title":"Example (from D. Beazley cookbook, 8-12)"},{"location":"python/05%20%C2%B7%20Descriptors/#test-with-descriptor","text":"print ( \"# --- Class with descriptors\" ) class Stock : # Specify constraints name = SizedString ( 'name' , size = 8 ) shares = UnsignedInteger ( 'shares' ) price = UnsignedFloat ( 'price' ) def __init__ ( self , name , shares , price ): self . name = name self . shares = shares self . price = price s = Stock ( 'ACME' , 50 , 91.1 ) test ( s )","title":"Test with descriptor"},{"location":"python/05%20%C2%B7%20Descriptors/#test-with-class-decorator","text":"# Class decorator to apply constraints def check_attributes ( ** kwargs ): def decorate ( cls ): for key , value in kwargs . items (): if isinstance ( value , Descriptor ): value . name = key setattr ( cls , key , value ) else : setattr ( cls , key , value ( key )) return cls return decorate @check_attributes ( name = SizedString ( size = 8 ), shares = UnsignedInteger , price = UnsignedFloat ) class Stock : def __init__ ( self , name , shares , price ): self . name = name self . shares = shares self . price = price s = Stock ( 'ACME' , 50 , 91.1 ) test ( s )","title":"Test with class decorator"},{"location":"python/05%20%C2%B7%20Descriptors/#test-with-metaclass","text":"# A metaclass that applies checking class checkedmeta ( type ): def __new__ ( cls , clsname , bases , methods ): # Attach attribute names to the descriptors for key , value in methods . items (): if isinstance ( value , Descriptor ): value . name = key return type . __new__ ( cls , clsname , bases , methods ) class Stock ( metaclass = checkedmeta ): name = SizedString ( size = 8 ) shares = UnsignedInteger () price = UnsignedFloat () def __init__ ( self , name , shares , price ): self . name = name self . shares = shares self . price = price s = Stock ( 'ACAZE' , 5 , 91.1 ) test ( s ) ACAZE 75 Expected >= 0 '<' not supported between instances of 'str' and 'int' size must be < 8","title":"Test with metaclass"},{"location":"python/05%20%C2%B7%20Descriptors/#usage-in-a-custom-container","text":"import xml.etree.ElementTree as ET import requests from collections import Sequence from typing import Dict import re # Fetch some data from asam.net and work on a cdfx container url = \"https://www.asam.net/index.php?eID=dumpFile&t=f&f=203&token=0f5b670d38f303b5e18f13b7e58791b630bac3a4\" f = requests . get ( url ) cdfx = f . text def minus2underscore ( name ): s1 = re . sub ( '(.)([A-Z][a-z]+)' , r '\\1_\\2' , name ) return re . sub ( '([a-z0-9])([A-Z])' , r '\\1_\\2' , s1 ) . lower () . replace ( '-' , \"_\" ) class SwSystem : def __init__ ( self ): print ( \"Ajout d'un \u00e9l\u00e9ment\" ) # Types definition: def TypedContainer ( expected_type , cls = None ): if cls is None : return lambda cls : TypedContainer ( expected_type , cls ) super_append = cls . append def append ( self , elt ): if not isinstance ( elt , expected_type ): raise TypeError ( 'expected ' + str ( expected_type )) super_append ( self , elt ) cls . append = append return cls @TypedContainer ( SwSystem ) class SwSystems ( Sequence ): def __init__ ( self ): self . _items = [] def __getitem__ ( self , index ): return self . _items [ index ] def append ( self , elt ): self . _items . append ( elt ) def __len__ ( self ): return len ( self . _items ) class MSRSW ( metaclass = checkedmeta ): \"\"\" <MSRSW> is the root element, which may contains a short name (<SHORT-NAME>) and a category (<CATEGORY>). The category value indicates the standard and version number, e.g. the value \"CDF20\" denotes ASAM CDF V2.0. \"\"\" short_name = String () category = String () sw_systems : Dict [ str , SwSystem ] = SwSystems () def __init__ ( self , elt ): for node in elt : if len ( node ) == 0 : setattr ( self , minus2underscore ( node . tag ), node . text ) for swsystem in elt . iter ( \"SW-SYSTEM\" ): self . sw_systems . append ( SwSystem ()) root = ET . fromstring ( cdfx ) msrsw = MSRSW ( root ) Ajout d'un \u00e9l\u00e9ment elt = msrsw . sw_systems [ 0 ] from asampy import cdf --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-4-529dcc34db6c> in <module> () ----> 1 from asampy import cdf /opt/anaconda/miniconda3/lib/python3.6/site-packages/asampy/cdf.py in <module> () 49 50 @ dataclass ---> 51 class Calib ( object ) : 52 name : str = String ( ) 53 category : str = String ( ) /opt/anaconda/miniconda3/lib/python3.6/site-packages/dataclasses.py in dataclass (_cls, init, repr, eq, order, unsafe_hash, frozen) 956 957 # We're called as @dataclass without parens. --> 958 return wrap ( _cls ) 959 960 /opt/anaconda/miniconda3/lib/python3.6/site-packages/dataclasses.py in wrap (cls) 948 949 def wrap ( cls ) : --> 950 return _process_class ( cls , init , repr , eq , order , unsafe_hash , frozen ) 951 952 # See if we're being called as @dataclass or @dataclass(). /opt/anaconda/miniconda3/lib/python3.6/site-packages/dataclasses.py in _process_class (cls, init, repr, eq, order, unsafe_hash, frozen) 869 # if possible. 870 '__dataclass_self__' if 'self' in fields --> 871 else 'self' , 872 )) 873 /opt/anaconda/miniconda3/lib/python3.6/site-packages/dataclasses.py in _init_fn (fields, frozen, has_post_init, self_name) 458 seen_default = True 459 elif seen_default : --> 460 raise TypeError(f'non-default argument {f.name!r} ' 461 'follows default argument') 462 TypeError : non-default argument 'sw_axis_conts' follows default argument cdfx = cdf . cdfx ( root ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-5-7b043f8e7231> in <module> () ----> 1 cdfx = cdf . cdfx ( root ) NameError : name 'cdf' is not defined swsystem = cdfx . msrsw . sw_systems [ 0 ] swinstance = swsystem . sw_instance_spec . sw_instance_tree . sw_instance cdfx [ 'ASAM.C.CURVE.FIX_AXIS.PAR_DIST' ] <xarray.DataArray (dim_0: 6)> array([-10., -11., -12., -10., -9., -11.]) Coordinates: * dim_0 (dim_0) float64 1.0 2.0 3.0 4.0 5.0 6.0 msrsw . sw_systems . append ( SwSystem ()) Ajout d'un \u00e9l\u00e9ment cdfx . res {'ASAM.C.CURVE.FIX_AXIS.PAR': <xarray.DataArray (dim_0: 6)> array([9., 8., 7., 8., 9., 5.]) Coordinates: * dim_0 (dim_0) float64 0.0 4.0 8.0 12.0 16.0 20.0, 'ASAM.C.CURVE.FIX_AXIS.PAR_DIST': <xarray.DataArray (dim_0: 6)> array([-10., -11., -12., -10., -9., -11.]) Coordinates: * dim_0 (dim_0) float64 1.0 2.0 3.0 4.0 5.0 6.0, 'ASAM.C.CURVE.FIX_AXIS.PAR_LIST': <xarray.DataArray (dim_0: 6)> array([2., 3., 4., 2., 4., 3.]) Coordinates: * dim_0 (dim_0) float64 -1.0 4.0 6.0 8.0 9.0 10.0, 'ASAM.C.CURVE.STD_AXIS': <xarray.DataArray (dim_0: 8)> array([-3., -1., 6., 5., 9., 9., 13., 9.]) Coordinates: * dim_0 (dim_0) float64 -5.0 -1.0 2.0 4.0 5.0 8.0 14.0 22.0, 'ASAM.C.CURVE.STD_AXIS.MONOTONY_STRICT_DECREASE': <xarray.DataArray (dim_0: 8)> array([2708., 759., 690., 2141., 690., 1657., 1312., -56.]) Coordinates: * dim_0 (dim_0) float64 5.0 3.0 1.0 -1.0 -3.0 -5.0 -7.0 -9.0, 'ASAM.C.CURVE.STD_AXIS.MONOTONY_STRICT_INCREASE': <xarray.DataArray (dim_0: 8)> array([-10., 12., 22., 22., 64., 46., 66., 133.]) Coordinates: * dim_0 (dim_0) float64 1.0 4.0 7.0 10.0 13.0 16.0 19.0 22.0, 'ASAM.C.CURVE_AXIS': <xarray.DataArray (dim_0: 8)> array([0., 1., 2., 3., 4., 5., 6., 7.]) Coordinates: * dim_0 (dim_0) float64 -1.0 0.0 2.0 3.0 4.0 5.0 7.0 8.0, 'ASAM.C.DEPENDENT.REF_1.SWORD': <xarray.DataArray ()> array(13.), 'ASAM.C.DEPENDENT.REF_2.UWORD': <xarray.DataArray ()> array(57.), 'ASAM.C.DEPENDENT.REF_3.SWORD': <xarray.DataArray ()> array(70.), 'ASAM.C.DEPENDENT.REF_4.FLOAT64_IEEE': <xarray.DataArray ()> array(9.55), 'ASAM.C.DEPENDENT.REF_5.FLOAT64_IEEE': <xarray.DataArray ()> array(57.1), 'ASAM.C.SCALAR.FLOAT32_IEEE.IDENTICAL': <xarray.DataArray ()> array(0.), 'ASAM.C.SCALAR.FLOAT64_IEEE.IDENTICAL': <xarray.DataArray ()> array(-3.), 'ASAM.C.SCALAR.SBYTE.IDENTICAL': <xarray.DataArray ()> array(8.), 'ASAM.C.SCALAR.SLONG.IDENTICAL': <xarray.DataArray ()> array(86.), 'ASAM.C.SCALAR.SWORD.FORM_X_PLUS_4': <xarray.DataArray ()> array(6.), 'ASAM.C.SCALAR.SWORD.IDENTICAL': <xarray.DataArray ()> array(2.), 'ASAM.C.SCALAR.SWORD.LINEAR_MUL_2': <xarray.DataArray ()> array(4.), 'ASAM.C.SCALAR.SWORD.RAT_FUNC_DIV_10': <xarray.DataArray ()> array(0.2), 'ASAM.C.SCALAR.SWORD.RAT_FUNC_DIV_81_9175': <xarray.DataArray ()> array(0.024415), 'ASAM.C.SCALAR.SWORD.TAB_INTP_DEFAULT_VALUE': <xarray.DataArray ()> array(102.), 'ASAM.C.SCALAR.SWORD.TAB_INTP_NO_DEFAULT_VALUE': <xarray.DataArray ()> array(102.), 'ASAM.C.SCALAR.SWORD.TAB_NOINTP_DEFAULT_VALUE': <xarray.DataArray ()> array(102.), 'ASAM.C.SCALAR.SWORD.TAB_NOINTP_NO_DEFAULT_VALUE': <xarray.DataArray ()> array(102.), 'ASAM.C.SCALAR.UBYTE.IDENTICAL': <xarray.DataArray ()> array(32.), 'ASAM.C.SCALAR.ULONG.IDENTICAL': <xarray.DataArray ()> array(17.), 'ASAM.C.SCALAR.UWORD.IDENTICAL': <xarray.DataArray ()> array(15.), 'ASAM.C.SCALAR.UWORD.IDENTICAL.BITMASK_0FF0': <xarray.DataArray ()> array(0.), 'ASAM.C.VIRTUAL.REF_1.SWORD': <xarray.DataArray ()> array(0.), 'ASAM.C.VIRTUAL.REF_2.UWORD': <xarray.DataArray ()> array(51.), 'ASAM.C.VIRTUAL.REF_3.SWORD': <xarray.DataArray ()> array(51.), 'ASAM.C.VIRTUAL.SYSTEM_CONSTANT_1': <xarray.DataArray ()> array(28.55)} cdfx . res [ 'ASAM.C.CURVE.STD_AXIS.MONOTONY_STRICT_INCREASE' ] . plot () [<matplotlib.lines.Line2D at 0x3134ef7f0>] msrsw . sw_systems [ 1 ] <__main__.SwSystem at 0x313312da0> # Base class. Uses a descriptor to set a value class Descriptor : def __init__ ( self , name = None , ** opts ): self . name = name self . __dict__ . update ( opts ) def __set__ ( self , instance , value ): instance . __dict__ [ self . name ] = value","title":"Usage in a custom container"},{"location":"python/06%20%C2%B7%20Variable%20scope%2C%20closures/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); % watermark - mduv last updated: 2018-06-25 CPython 3.6.5 IPython 6.4.0 compiler : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final) system : Darwin release : 15.6.0 machine : x86_64 processor : i386 CPU cores : 2 interpreter: 64bit Variable scope \u00b6 Usage of global and nonlocal (see PEP 3104 ) The global statement is a declaration which holds for the entire current code block . It means that the listed identifiers are to be interpreted as globals. It would be impossible to assign to a global variable without global , although free variables may refer to globals without being declared global. The nonlocal statement causes the listed identifiers to refer to previously bound variables in the nearest enclosing scope excluding globals . This is important because the default behavior for binding is to search the local namespace first. The statement allows encapsulated code to rebind variables outside of the local scope besides the global (module) scope. Closures (Statically Nested Scopes) \u00b6 Closures were specified in PEP 227 for Python 2.2. For further informations concerning the execution model and varaible scope, refer to Python Language Reference . Examples \u00b6 No global / nonlocal declaration # example from http://stackoverflow.com/questions/1261875/ x = 0 def outer (): x = 1 def inner (): x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) inner: 2 outer: 1 global: 0 nonlocal declaration in inner closure x = 0 def outer (): x = 1 def inner (): nonlocal x x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) inner: 2 outer: 2 global: 0 globals are excluded so using nonlocal with variable binding outside the function scope leads to a SyntaxError x = 0 def outer (): nonlocal x x = 1 def inner (): x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) File \"<ipython-input-5-e6aa27e8879a>\" , line 3 nonlocal x ^ SyntaxError : no binding for nonlocal 'x' found global declaration in inner closure x = 0 def outer (): global x x = 1 def inner (): x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) inner: 2 outer: 1 global: 1 x = 0 def outer (): global x x = 1 def inner (): global x x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) inner: 2 outer: 2 global: 2 glob = 1 def foo (): loc = 5 print ( 'loc in foo():' , 'loc' in locals ()) print ( 'glob in foo():' , 'glob' in globals ()) foo () print ( 'loc in global:' , 'loc' in globals ()) print ( 'glob in global:' , 'foo' in globals ()) loc in foo(): True glob in foo(): True loc in global: False glob in global: True a = 'global' def outer (): def len ( in_var ): print ( 'called my len() function: ' , end = \"\" ) l = 0 for i in in_var : l += 1 return l a = 'local' def inner (): global len nonlocal a a += ' variable' inner () print ( 'a is' , a ) print ( len ( a )) print ( locals () == globals ()) outer () print ( len ( a )) print ( 'a is' , a ) print ( locals () == globals ()) a is local variable called my len() function: 14 False 6 a is global True globals ()[ '__builtins__' ] <module 'builtins' (built-in)> locals () == globals () True an interesting one: def g (): print ( i ) i = 42 g () 42 %% dis def g (): print ( i ) i = 42 g () 1 0 LOAD_CONST 0 (<code object g at 0x3193936f0, file \"<dis>\", line 1>) 2 LOAD_CONST 1 ('g') 4 MAKE_FUNCTION 0 6 STORE_NAME 0 (g) 3 8 LOAD_CONST 2 (42) 10 STORE_NAME 1 (i) 4 12 LOAD_NAME 0 (g) 14 CALL_FUNCTION 0 16 POP_TOP 18 LOAD_CONST 3 (None) 20 RETURN_VALUE def make_adder ( base ): def adder ( x ): return base + x return adder add5 = make_adder ( 5 ) add5 ( 6 ) 11 if 'x' in globals (): del x print ( \"Deleting x from globals()\" ) def make_adder1 (): x = 2 values = [ x ] def adder (): x = x + 1 values . append ( x ) print ( values ) return x return adder add5 = make_adder1 () add5 () --------------------------------------------------------------------------- UnboundLocalError Traceback (most recent call last) <ipython-input-20-2d467550752e> in <module> () 14 15 add5 = make_adder1 ( ) ---> 16 add5 ( ) <ipython-input-20-2d467550752e> in adder () 7 values = [ x ] 8 def adder ( ) : ----> 9 x = x + 1 10 values . append ( x ) 11 print ( values ) UnboundLocalError : local variable 'x' referenced before assignment make_adder1 . __code__ . co_varnames ('x', 'adder') make_adder2 . __code__ . co_varnames ('adder',) % dis make_adder1 . __code__ . co_code 1 0 LOAD_NAME 0 (make_adder1) 2 LOAD_ATTR 1 (__code__) 4 LOAD_ATTR 2 (co_code) 6 RETURN_VALUE if 'x' in globals (): del x print ( \"Deleting x from globals()\" ) def make_adder2 (): x = 2 values = [ x ] def adder (): nonlocal x x = x + 1 values . append ( x ) print ( values ) return x return adder add5 = make_adder2 () add5 () [2, 3] 3 add5 () [2, 3, 4] 4 dis ( make_adder2 ) 1 0 LOAD_NAME 0 (make_adder2) 2 RETURN_VALUE Recursive closure call \u00b6 def make_fact (): def fact ( n ): if n == 1 : return 1 else : return n * fact ( n - 1 ) return fact fact = make_fact () fact ( 7 ) 5040 def make_wrapper ( obj ): class Wrapper : def __getattr__ ( self , attr ): if attr [ 0 ] != '_' : return getattr ( obj , attr ) else : raise AttributeError ( attr ) return Wrapper () class Test : public = 2 _private = 3 w = make_wrapper ( Test ()) w . public 2 w . _private --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-41-69bcb2c589a0> in <module> () ----> 1 w . _private <ipython-input-27-27dc6e501e8a> in __getattr__ (self, attr) 5 return getattr ( obj , attr ) 6 else : ----> 7 raise AttributeError ( attr ) 8 return Wrapper ( ) AttributeError : _private i = 6 def f ( x ): def g (): print i # ... # skip to the next page # ... for i in x : # ah, i *is* local to f, so this is what g sees pass g () File \"<ipython-input-30-2e5743477a39>\" , line 4 print i ^ SyntaxError : Missing parentheses in call to 'print'","title":"06 \u00b7 Variable scope, closures"},{"location":"python/06%20%C2%B7%20Variable%20scope%2C%20closures/#variable-scope","text":"Usage of global and nonlocal (see PEP 3104 ) The global statement is a declaration which holds for the entire current code block . It means that the listed identifiers are to be interpreted as globals. It would be impossible to assign to a global variable without global , although free variables may refer to globals without being declared global. The nonlocal statement causes the listed identifiers to refer to previously bound variables in the nearest enclosing scope excluding globals . This is important because the default behavior for binding is to search the local namespace first. The statement allows encapsulated code to rebind variables outside of the local scope besides the global (module) scope.","title":"Variable scope"},{"location":"python/06%20%C2%B7%20Variable%20scope%2C%20closures/#closures-statically-nested-scopes","text":"Closures were specified in PEP 227 for Python 2.2. For further informations concerning the execution model and varaible scope, refer to Python Language Reference .","title":"Closures (Statically Nested Scopes)"},{"location":"python/06%20%C2%B7%20Variable%20scope%2C%20closures/#examples","text":"No global / nonlocal declaration # example from http://stackoverflow.com/questions/1261875/ x = 0 def outer (): x = 1 def inner (): x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) inner: 2 outer: 1 global: 0 nonlocal declaration in inner closure x = 0 def outer (): x = 1 def inner (): nonlocal x x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) inner: 2 outer: 2 global: 0 globals are excluded so using nonlocal with variable binding outside the function scope leads to a SyntaxError x = 0 def outer (): nonlocal x x = 1 def inner (): x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) File \"<ipython-input-5-e6aa27e8879a>\" , line 3 nonlocal x ^ SyntaxError : no binding for nonlocal 'x' found global declaration in inner closure x = 0 def outer (): global x x = 1 def inner (): x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) inner: 2 outer: 1 global: 1 x = 0 def outer (): global x x = 1 def inner (): global x x = 2 print ( \"inner:\" , x ) inner () print ( \"outer:\" , x ) outer () print ( \"global:\" , x ) inner: 2 outer: 2 global: 2 glob = 1 def foo (): loc = 5 print ( 'loc in foo():' , 'loc' in locals ()) print ( 'glob in foo():' , 'glob' in globals ()) foo () print ( 'loc in global:' , 'loc' in globals ()) print ( 'glob in global:' , 'foo' in globals ()) loc in foo(): True glob in foo(): True loc in global: False glob in global: True a = 'global' def outer (): def len ( in_var ): print ( 'called my len() function: ' , end = \"\" ) l = 0 for i in in_var : l += 1 return l a = 'local' def inner (): global len nonlocal a a += ' variable' inner () print ( 'a is' , a ) print ( len ( a )) print ( locals () == globals ()) outer () print ( len ( a )) print ( 'a is' , a ) print ( locals () == globals ()) a is local variable called my len() function: 14 False 6 a is global True globals ()[ '__builtins__' ] <module 'builtins' (built-in)> locals () == globals () True an interesting one: def g (): print ( i ) i = 42 g () 42 %% dis def g (): print ( i ) i = 42 g () 1 0 LOAD_CONST 0 (<code object g at 0x3193936f0, file \"<dis>\", line 1>) 2 LOAD_CONST 1 ('g') 4 MAKE_FUNCTION 0 6 STORE_NAME 0 (g) 3 8 LOAD_CONST 2 (42) 10 STORE_NAME 1 (i) 4 12 LOAD_NAME 0 (g) 14 CALL_FUNCTION 0 16 POP_TOP 18 LOAD_CONST 3 (None) 20 RETURN_VALUE def make_adder ( base ): def adder ( x ): return base + x return adder add5 = make_adder ( 5 ) add5 ( 6 ) 11 if 'x' in globals (): del x print ( \"Deleting x from globals()\" ) def make_adder1 (): x = 2 values = [ x ] def adder (): x = x + 1 values . append ( x ) print ( values ) return x return adder add5 = make_adder1 () add5 () --------------------------------------------------------------------------- UnboundLocalError Traceback (most recent call last) <ipython-input-20-2d467550752e> in <module> () 14 15 add5 = make_adder1 ( ) ---> 16 add5 ( ) <ipython-input-20-2d467550752e> in adder () 7 values = [ x ] 8 def adder ( ) : ----> 9 x = x + 1 10 values . append ( x ) 11 print ( values ) UnboundLocalError : local variable 'x' referenced before assignment make_adder1 . __code__ . co_varnames ('x', 'adder') make_adder2 . __code__ . co_varnames ('adder',) % dis make_adder1 . __code__ . co_code 1 0 LOAD_NAME 0 (make_adder1) 2 LOAD_ATTR 1 (__code__) 4 LOAD_ATTR 2 (co_code) 6 RETURN_VALUE if 'x' in globals (): del x print ( \"Deleting x from globals()\" ) def make_adder2 (): x = 2 values = [ x ] def adder (): nonlocal x x = x + 1 values . append ( x ) print ( values ) return x return adder add5 = make_adder2 () add5 () [2, 3] 3 add5 () [2, 3, 4] 4 dis ( make_adder2 ) 1 0 LOAD_NAME 0 (make_adder2) 2 RETURN_VALUE","title":"Examples"},{"location":"python/06%20%C2%B7%20Variable%20scope%2C%20closures/#recursive-closure-call","text":"def make_fact (): def fact ( n ): if n == 1 : return 1 else : return n * fact ( n - 1 ) return fact fact = make_fact () fact ( 7 ) 5040 def make_wrapper ( obj ): class Wrapper : def __getattr__ ( self , attr ): if attr [ 0 ] != '_' : return getattr ( obj , attr ) else : raise AttributeError ( attr ) return Wrapper () class Test : public = 2 _private = 3 w = make_wrapper ( Test ()) w . public 2 w . _private --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-41-69bcb2c589a0> in <module> () ----> 1 w . _private <ipython-input-27-27dc6e501e8a> in __getattr__ (self, attr) 5 return getattr ( obj , attr ) 6 else : ----> 7 raise AttributeError ( attr ) 8 return Wrapper ( ) AttributeError : _private i = 6 def f ( x ): def g (): print i # ... # skip to the next page # ... for i in x : # ah, i *is* local to f, so this is what g sees pass g () File \"<ipython-input-30-2e5743477a39>\" , line 4 print i ^ SyntaxError : Missing parentheses in call to 'print'","title":"Recursive closure call"},{"location":"python/06%20%C2%B7%C2%A0Metaclass/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); % watermark - mdv 2018-11-19 CPython 3.7.1 IPython 7.1.1 compiler : Clang 4.0.1 (tags/RELEASE_401/final) system : Darwin release : 15.6.0 machine : x86_64 processor : i386 CPU cores : 2 interpreter: 64bit Documentation Metaclasses \u00b6 Some example from https://www.learning-python.com/about-lp5e.html import requests from zipfile import ZipFile from io import BytesIO # Retrieve zip file from website zip_url = \"https://www.learning-python.com/lp5e-code-1.0-jun1813.zip\" r = requests . get ( zip_url , stream = True ) # Get zip and get metaclass examples z = ZipFile ( BytesIO ( r . content ), mode = \"r\" ) examples = [ f for f in z . filelist if \"metaclass\" in f . filename ] Simple metaclass \u00b6 def get_code_from_ ( example_number : int ): with z . open ( examples [ example_number ]) as myfile : print ( myfile . read () . decode ()) from abc import ABC , abstractclassmethod class MetaOne ( type ): def __prepare__ ( cls , classname ): # , supers, classdict): print ( 'In MetaOne.__prepare__:' , cls , classname , sep = ' \\n ...' ) return dict () def __new__ ( cls , classname , supers , classdict ): print ( 'In MetaOne.__new__:' , cls , classname , supers , classdict , sep = ' \\n ...' ) return super () . __new__ ( cls , classname , supers , classdict ) def __init__ ( self , classname , supers , classdict ): self . print = print print ( 'In MetaOne.__init__:' , self , classname , supers , classdict , sep = ' \\n ...' ) class myABC ( ABC ): @abstractclassmethod def my_method ( self ): pass print ( 'making class' ) class Spam ( metaclass = MetaOne ): # Inherits from none, instance of MetaOne data = 1 # Class data attribute def meth ( self , arg ): # Class method attribute return self . data + arg def __init__ ( self ): print ( 'In Spam.__init__:' , self , sep = ' \\n ...' ) def my_method ( self ): print ( \"My method\" ) print ( 'making instance' ) X = Spam () print ( 'data:' , X . data , X . meth ( 2 )) print ( Spam . __bases__ , X . __getattribute__ , Spam . __mro__ ) making class In MetaOne.__prepare__: ...Spam ...() In MetaOne.__new__: ...<class '__main__.MetaOne'> ...Spam ...() ...{'__module__': '__main__', '__qualname__': 'Spam', 'data': 1, 'meth': <function Spam.meth at 0x316d05158>, '__init__': <function Spam.__init__ at 0x316d050d0>, 'my_method': <function Spam.my_method at 0x316d05048>} In MetaOne.__init__: ...<class '__main__.Spam'> ...Spam ...() ...{'__module__': '__main__', '__qualname__': 'Spam', 'data': 1, 'meth': <function Spam.meth at 0x316d05158>, '__init__': <function Spam.__init__ at 0x316d050d0>, 'my_method': <function Spam.my_method at 0x316d05048>} making instance In Spam.__init__: ...<__main__.Spam object at 0x316d04668> data: 1 3 (<class 'object'>,) <method-wrapper '__getattribute__' of Spam object at 0x316d04668> (<class '__main__.Spam'>, <class 'object'>) # https://stackoverflow.com/a/1840466 Spam . print ( \"ouasi\" ) ouasi Example 2 \u00b6 class MetaOne ( type ): def __new__ ( meta , classname , supers , classdict ): print ( 'In MetaOne.new:' , meta , classname , supers , classdict , sep = ' \\n ...' ) _super = supers [ 0 ] # _super.data = 100 classdict [ 'data' ] = 5 return type . __new__ ( meta , classname , supers , classdict ) class Eggs ( object ): data = 10 pass print ( 'making class' ) class Spam ( Eggs , metaclass = MetaOne ): # Inherits from Eggs, instance of MetaOne data = 1 # Class data attribute def meth ( self , arg ): # Class method attribute return self . data + arg print ( 'making instance' ) X = Spam () print ( 'data:' , X . data , X . meth ( 2 )) making class In MetaOne.new: ...<class '__main__.MetaOne'> ...Spam ...(<class '__main__.Eggs'>,) ...{'__module__': '__main__', '__qualname__': 'Spam', 'data': 1, 'meth': <function Spam.meth at 0x316dabbf8>} making instance data: 5 7 class QSD ( Eggs ): pass QSD () . data 10 Eggs . data 10 Spam . data 5 get_code_from_ ( 1 ) from __future__ import print_function class MetaOne(type): def __new__(meta, classname, supers, classdict): print('In MetaOne.new:', meta, classname, supers, classdict, sep='\\n...') return type.__new__(meta, classname, supers, classdict) class Eggs(object): pass print('making class') class Spam(Eggs, object): # Inherits from Eggs, instance of MetaOne __metaclass__ = MetaOne data = 1 # Class data attribute def meth(self, arg): # Class method attribute return self.data + arg print('making instance') X = Spam() print('data:', X.data, X.meth(2)) class A ( type ): def __new__ ( cls , clsname , bases , methods ): print ( f \"Dans A { cls . __mro__ } \" ) return super () . __new__ ( cls , clsname , bases , methods ) class B ( metaclass = A ): def __new__ ( cls , arg = \"default\" ): print ( arg ) return super () . __new__ ( cls ) Dans A (<class '__main__.A'>, <class 'type'>, <class 'object'>) B ( arg = \"argument\" ) argument <__main__.B at 0x31ecb1cc0> class B : def __new__ ( cls ): print ( cls . __bases__ ) return super () . __new__ ( cls ) def aze ( self ): print ( \"B\" ) def meth ( self ): print ( \"B\" ) class C : def __new__ ( cls ): return super () . __new__ ( cls ) def aze ( self ): print ( \"C\" ) def meth ( self ): print ( \"C\" ) class A ( B , C ): def __new__ ( cls , arg = \"default\" ): print ( cls . __mro__ ) if arg == \"default\" : return super () . __new__ ( cls ) else : return super () . __new__ ( cls ) def aze ( self ): print ( \"A\" ) a = A ( arg = \"default\" ) (<class '__main__.A'>, <class '__main__.B'>, <class '__main__.C'>, <class 'object'>) (<class '__main__.B'>, <class '__main__.C'>) a . aze () a . meth () A B import itertools class MyMRO ( type ): def mro ( cls ): if hasattr ( cls , \"arg\" ): print ( cls . arg ) print ( \"Enumerating MRO\" ) print ([ b for b in cls . __bases__ ]) return tuple ([ cls ] + list ( itertools . chain . from_iterable ( base . __mro__ [: - 1 ] for base in cls . __bases__ )) + [ object ]) def __new__ ( cls , clsname , bases , methods ): print ( \"Creating my MRO\" ) print ( cls . __dict__ ) return super () . __new__ ( cls , clsname , bases , methods ) class Mixin ( metaclass = MyMRO ): pass Creating my MRO {'__module__': '__main__', 'mro': <function MyMRO.mro at 0x31ec88a60>, '__new__': <staticmethod object at 0x31eda2588>, '__doc__': None} Enumerating MRO [<class 'object'>] class A : pass class B : pass class C ( Mixin , A , B ): def __new__ ( cls , arg = \"default\" ): print ( \"Creating C\" ) print ( cls . __mro__ ) setattr ( cls , \"arg\" , arg ) print ( f \"in C: { cls . __dict__ } \" ) return super () . __new__ ( cls ) def aze ( self ): print ( \"A\" ) Creating my MRO {'__module__': '__main__', 'mro': <function MyMRO.mro at 0x31ec88a60>, '__new__': <staticmethod object at 0x31eda2588>, '__doc__': None} Enumerating MRO [<class '__main__.Mixin'>, <class '__main__.A'>, <class '__main__.B'>] C ( arg = \"A\" ) Creating C (<class '__main__.C'>, <class '__main__.Mixin'>, <class '__main__.A'>, <class '__main__.B'>, <class 'object'>) in C: {'__module__': '__main__', '__new__': <staticmethod object at 0x31eda15c0>, 'aze': <function C.aze at 0x31eccdc80>, '__doc__': None, 'arg': 'A'} <__main__.C at 0x31eda2be0> C . arg 'A' C . __mro__ (__main__.C, __main__.Mixin, __main__.A, __main__.B, object) class D ( A , B ): def __new__ ( cls , arg = \"default\" ): if arg == \"A\" : return type ( 'Person' , tuple ( list ( A . __mro__ )), dict ( A . __dict__ )) else : return type ( 'Person' , ( B ) + B . __mro__ , dict ( B . __dict__ )) def aze ( self ): print ( \"D\" ) D ( arg = \"A\" ) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-297-793615b73ba6> in <module> () ----> 1 D ( arg = \"A\" ) . aze ( ) AttributeError : type object 'Person' has no attribute 'aze' super() \u00b6 See https://rhettinger.wordpress.com/2011/05/26/super-considered-super/ from collections import OrderedDict class LoggingDict ( dict ): def __setitem__ ( self , key , value ): logging . info ( 'Setting %r to %r ' % ( key , value )) super () . __setitem__ ( key , value ) class LoggingOD ( LoggingDict , OrderedDict ): pass LoggingOD . __mro__ (__main__.LoggingOD, __main__.LoggingDict, collections.OrderedDict, dict, object) The MRO shown above is the one order that follows from those constraints: LoggingOD precedes its parents, LoggingDict and OrderedDict LoggingDict precedes OrderedDict because LoggingOD. bases is (LoggingDict, OrderedDict) LoggingDict precedes its parent which is dict OrderedDict precedes its parent which is dict dict precedes its parent which is object","title":"06 \u00b7\u00a0Metaclass"},{"location":"python/06%20%C2%B7%C2%A0Metaclass/#metaclasses","text":"Some example from https://www.learning-python.com/about-lp5e.html import requests from zipfile import ZipFile from io import BytesIO # Retrieve zip file from website zip_url = \"https://www.learning-python.com/lp5e-code-1.0-jun1813.zip\" r = requests . get ( zip_url , stream = True ) # Get zip and get metaclass examples z = ZipFile ( BytesIO ( r . content ), mode = \"r\" ) examples = [ f for f in z . filelist if \"metaclass\" in f . filename ]","title":"Metaclasses"},{"location":"python/06%20%C2%B7%C2%A0Metaclass/#simple-metaclass","text":"def get_code_from_ ( example_number : int ): with z . open ( examples [ example_number ]) as myfile : print ( myfile . read () . decode ()) from abc import ABC , abstractclassmethod class MetaOne ( type ): def __prepare__ ( cls , classname ): # , supers, classdict): print ( 'In MetaOne.__prepare__:' , cls , classname , sep = ' \\n ...' ) return dict () def __new__ ( cls , classname , supers , classdict ): print ( 'In MetaOne.__new__:' , cls , classname , supers , classdict , sep = ' \\n ...' ) return super () . __new__ ( cls , classname , supers , classdict ) def __init__ ( self , classname , supers , classdict ): self . print = print print ( 'In MetaOne.__init__:' , self , classname , supers , classdict , sep = ' \\n ...' ) class myABC ( ABC ): @abstractclassmethod def my_method ( self ): pass print ( 'making class' ) class Spam ( metaclass = MetaOne ): # Inherits from none, instance of MetaOne data = 1 # Class data attribute def meth ( self , arg ): # Class method attribute return self . data + arg def __init__ ( self ): print ( 'In Spam.__init__:' , self , sep = ' \\n ...' ) def my_method ( self ): print ( \"My method\" ) print ( 'making instance' ) X = Spam () print ( 'data:' , X . data , X . meth ( 2 )) print ( Spam . __bases__ , X . __getattribute__ , Spam . __mro__ ) making class In MetaOne.__prepare__: ...Spam ...() In MetaOne.__new__: ...<class '__main__.MetaOne'> ...Spam ...() ...{'__module__': '__main__', '__qualname__': 'Spam', 'data': 1, 'meth': <function Spam.meth at 0x316d05158>, '__init__': <function Spam.__init__ at 0x316d050d0>, 'my_method': <function Spam.my_method at 0x316d05048>} In MetaOne.__init__: ...<class '__main__.Spam'> ...Spam ...() ...{'__module__': '__main__', '__qualname__': 'Spam', 'data': 1, 'meth': <function Spam.meth at 0x316d05158>, '__init__': <function Spam.__init__ at 0x316d050d0>, 'my_method': <function Spam.my_method at 0x316d05048>} making instance In Spam.__init__: ...<__main__.Spam object at 0x316d04668> data: 1 3 (<class 'object'>,) <method-wrapper '__getattribute__' of Spam object at 0x316d04668> (<class '__main__.Spam'>, <class 'object'>) # https://stackoverflow.com/a/1840466 Spam . print ( \"ouasi\" ) ouasi","title":"Simple metaclass"},{"location":"python/06%20%C2%B7%C2%A0Metaclass/#example-2","text":"class MetaOne ( type ): def __new__ ( meta , classname , supers , classdict ): print ( 'In MetaOne.new:' , meta , classname , supers , classdict , sep = ' \\n ...' ) _super = supers [ 0 ] # _super.data = 100 classdict [ 'data' ] = 5 return type . __new__ ( meta , classname , supers , classdict ) class Eggs ( object ): data = 10 pass print ( 'making class' ) class Spam ( Eggs , metaclass = MetaOne ): # Inherits from Eggs, instance of MetaOne data = 1 # Class data attribute def meth ( self , arg ): # Class method attribute return self . data + arg print ( 'making instance' ) X = Spam () print ( 'data:' , X . data , X . meth ( 2 )) making class In MetaOne.new: ...<class '__main__.MetaOne'> ...Spam ...(<class '__main__.Eggs'>,) ...{'__module__': '__main__', '__qualname__': 'Spam', 'data': 1, 'meth': <function Spam.meth at 0x316dabbf8>} making instance data: 5 7 class QSD ( Eggs ): pass QSD () . data 10 Eggs . data 10 Spam . data 5 get_code_from_ ( 1 ) from __future__ import print_function class MetaOne(type): def __new__(meta, classname, supers, classdict): print('In MetaOne.new:', meta, classname, supers, classdict, sep='\\n...') return type.__new__(meta, classname, supers, classdict) class Eggs(object): pass print('making class') class Spam(Eggs, object): # Inherits from Eggs, instance of MetaOne __metaclass__ = MetaOne data = 1 # Class data attribute def meth(self, arg): # Class method attribute return self.data + arg print('making instance') X = Spam() print('data:', X.data, X.meth(2)) class A ( type ): def __new__ ( cls , clsname , bases , methods ): print ( f \"Dans A { cls . __mro__ } \" ) return super () . __new__ ( cls , clsname , bases , methods ) class B ( metaclass = A ): def __new__ ( cls , arg = \"default\" ): print ( arg ) return super () . __new__ ( cls ) Dans A (<class '__main__.A'>, <class 'type'>, <class 'object'>) B ( arg = \"argument\" ) argument <__main__.B at 0x31ecb1cc0> class B : def __new__ ( cls ): print ( cls . __bases__ ) return super () . __new__ ( cls ) def aze ( self ): print ( \"B\" ) def meth ( self ): print ( \"B\" ) class C : def __new__ ( cls ): return super () . __new__ ( cls ) def aze ( self ): print ( \"C\" ) def meth ( self ): print ( \"C\" ) class A ( B , C ): def __new__ ( cls , arg = \"default\" ): print ( cls . __mro__ ) if arg == \"default\" : return super () . __new__ ( cls ) else : return super () . __new__ ( cls ) def aze ( self ): print ( \"A\" ) a = A ( arg = \"default\" ) (<class '__main__.A'>, <class '__main__.B'>, <class '__main__.C'>, <class 'object'>) (<class '__main__.B'>, <class '__main__.C'>) a . aze () a . meth () A B import itertools class MyMRO ( type ): def mro ( cls ): if hasattr ( cls , \"arg\" ): print ( cls . arg ) print ( \"Enumerating MRO\" ) print ([ b for b in cls . __bases__ ]) return tuple ([ cls ] + list ( itertools . chain . from_iterable ( base . __mro__ [: - 1 ] for base in cls . __bases__ )) + [ object ]) def __new__ ( cls , clsname , bases , methods ): print ( \"Creating my MRO\" ) print ( cls . __dict__ ) return super () . __new__ ( cls , clsname , bases , methods ) class Mixin ( metaclass = MyMRO ): pass Creating my MRO {'__module__': '__main__', 'mro': <function MyMRO.mro at 0x31ec88a60>, '__new__': <staticmethod object at 0x31eda2588>, '__doc__': None} Enumerating MRO [<class 'object'>] class A : pass class B : pass class C ( Mixin , A , B ): def __new__ ( cls , arg = \"default\" ): print ( \"Creating C\" ) print ( cls . __mro__ ) setattr ( cls , \"arg\" , arg ) print ( f \"in C: { cls . __dict__ } \" ) return super () . __new__ ( cls ) def aze ( self ): print ( \"A\" ) Creating my MRO {'__module__': '__main__', 'mro': <function MyMRO.mro at 0x31ec88a60>, '__new__': <staticmethod object at 0x31eda2588>, '__doc__': None} Enumerating MRO [<class '__main__.Mixin'>, <class '__main__.A'>, <class '__main__.B'>] C ( arg = \"A\" ) Creating C (<class '__main__.C'>, <class '__main__.Mixin'>, <class '__main__.A'>, <class '__main__.B'>, <class 'object'>) in C: {'__module__': '__main__', '__new__': <staticmethod object at 0x31eda15c0>, 'aze': <function C.aze at 0x31eccdc80>, '__doc__': None, 'arg': 'A'} <__main__.C at 0x31eda2be0> C . arg 'A' C . __mro__ (__main__.C, __main__.Mixin, __main__.A, __main__.B, object) class D ( A , B ): def __new__ ( cls , arg = \"default\" ): if arg == \"A\" : return type ( 'Person' , tuple ( list ( A . __mro__ )), dict ( A . __dict__ )) else : return type ( 'Person' , ( B ) + B . __mro__ , dict ( B . __dict__ )) def aze ( self ): print ( \"D\" ) D ( arg = \"A\" ) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-297-793615b73ba6> in <module> () ----> 1 D ( arg = \"A\" ) . aze ( ) AttributeError : type object 'Person' has no attribute 'aze'","title":"Example 2"},{"location":"python/06%20%C2%B7%C2%A0Metaclass/#super","text":"See https://rhettinger.wordpress.com/2011/05/26/super-considered-super/ from collections import OrderedDict class LoggingDict ( dict ): def __setitem__ ( self , key , value ): logging . info ( 'Setting %r to %r ' % ( key , value )) super () . __setitem__ ( key , value ) class LoggingOD ( LoggingDict , OrderedDict ): pass LoggingOD . __mro__ (__main__.LoggingOD, __main__.LoggingDict, collections.OrderedDict, dict, object) The MRO shown above is the one order that follows from those constraints: LoggingOD precedes its parents, LoggingDict and OrderedDict LoggingDict precedes OrderedDict because LoggingOD. bases is (LoggingDict, OrderedDict) LoggingDict precedes its parent which is dict OrderedDict precedes its parent which is dict dict precedes its parent which is object","title":"super()"},{"location":"python/08%20%C2%B7%20Memoization/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); % watermark - mvp numpy , scipy , sklearn , matplotlib UsageError: Line magic function `%watermark` not found. # benchmark.py import time class benchmark ( object ): def __init__ ( self , name ): self . name = name def __enter__ ( self ): self . start = time . time () def __exit__ ( self , ty , val , tb ): end = time . time () print ( f \" { self . name } : { end - self . start : 0.3f } seconds\" ) return False Memoization \u00b6 Memoization is a way to lower a function's time cost in exchange for space cost; that is, memoized functions become optimized for speed in exchange for a higher use of computer memory space. Manual implementation \u00b6 Create a memoize fuction used as decorator and test on a funtion simulating long calculation Source: decorator documentation import functools def memoize_uw ( func ): func . cache = {} def memoize ( * args , ** kw ): if kw : # frozenset is used to ensure hashability key = args , frozenset ( kw . items ()) else : key = args if key not in func . cache : func . cache [ key ] = func ( * args , ** kw ) return func . cache [ key ] return functools . update_wrapper ( memoize , func ) import time @memoize_uw def f1 ( x ): \"Simulate some long computation\" time . sleep ( 1 ) return x On the second call, the benefit of caching is sensible. with benchmark ( \"f1(40), first pass\" ): f1 ( 40 ) with benchmark ( \"f1(40), second pass\" ): f1 ( 40 ) f1(40), first pass : 1.001 seconds f1(40), second pass : 0.000 seconds functools.lru_cache \u00b6 Python 3.2 introduces such a decorator in the functools module. Methods are available: cache_clear() cache_info() from functools import lru_cache @lru_cache ( maxsize = 32 ) def f2 ( x ): \"Simulate some long computation\" time . sleep ( 1 ) return x with benchmark ( \"f2(40), first pass\" ): f2 ( 40 ) with benchmark ( \"f2(40), second pass\" ): f2 ( 40 ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-2-a155123a1975> in <module> ----> 1 with benchmark ( \"f2(40), first pass\" ) : 2 f2 ( 40 ) 3 with benchmark ( \"f2(40), second pass\" ) : 4 f2 ( 40 ) NameError : name 'benchmark' is not defined f2 . cache_info () CacheInfo(hits=1, misses=1, maxsize=32, currsize=1) f2 ( 40 ) 40 f2 . cache_info () CacheInfo(hits=2, misses=1, maxsize=32, currsize=1) f2 ( 50 ) 50 f2 . cache_info () CacheInfo(hits=2, misses=2, maxsize=32, currsize=2) f2 . __doc__ 'Simulate some long computation'","title":"08 \u00b7 Memoization"},{"location":"python/08%20%C2%B7%20Memoization/#memoization","text":"Memoization is a way to lower a function's time cost in exchange for space cost; that is, memoized functions become optimized for speed in exchange for a higher use of computer memory space.","title":"Memoization"},{"location":"python/08%20%C2%B7%20Memoization/#manual-implementation","text":"Create a memoize fuction used as decorator and test on a funtion simulating long calculation Source: decorator documentation import functools def memoize_uw ( func ): func . cache = {} def memoize ( * args , ** kw ): if kw : # frozenset is used to ensure hashability key = args , frozenset ( kw . items ()) else : key = args if key not in func . cache : func . cache [ key ] = func ( * args , ** kw ) return func . cache [ key ] return functools . update_wrapper ( memoize , func ) import time @memoize_uw def f1 ( x ): \"Simulate some long computation\" time . sleep ( 1 ) return x On the second call, the benefit of caching is sensible. with benchmark ( \"f1(40), first pass\" ): f1 ( 40 ) with benchmark ( \"f1(40), second pass\" ): f1 ( 40 ) f1(40), first pass : 1.001 seconds f1(40), second pass : 0.000 seconds","title":"Manual implementation"},{"location":"python/08%20%C2%B7%20Memoization/#functoolslru_cache","text":"Python 3.2 introduces such a decorator in the functools module. Methods are available: cache_clear() cache_info() from functools import lru_cache @lru_cache ( maxsize = 32 ) def f2 ( x ): \"Simulate some long computation\" time . sleep ( 1 ) return x with benchmark ( \"f2(40), first pass\" ): f2 ( 40 ) with benchmark ( \"f2(40), second pass\" ): f2 ( 40 ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-2-a155123a1975> in <module> ----> 1 with benchmark ( \"f2(40), first pass\" ) : 2 f2 ( 40 ) 3 with benchmark ( \"f2(40), second pass\" ) : 4 f2 ( 40 ) NameError : name 'benchmark' is not defined f2 . cache_info () CacheInfo(hits=1, misses=1, maxsize=32, currsize=1) f2 ( 40 ) 40 f2 . cache_info () CacheInfo(hits=2, misses=1, maxsize=32, currsize=1) f2 ( 50 ) 50 f2 . cache_info () CacheInfo(hits=2, misses=2, maxsize=32, currsize=2) f2 . __doc__ 'Simulate some long computation'","title":"functools.lru_cache"},{"location":"python/09%20%C2%B7%20Functional%20programming/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); https://github.com/pytoolz/cytoolz # A pure function def min ( x , y ): if x < y : return x else : return y # An impure function exponent = 2 def powers ( L ): for i in range ( len ( L )): L [ i ] = L [ i ] ** exponent return L L = [ 1 , 2 , 3 ] powers ( L ) [1, 4, 9] L [1, 4, 9] from toolz import groupby names = [ 'Alice' , 'Bob' , 'Charlie' , 'Dan' , 'Edith' , 'Frank' ] groupby ( len , names ) {3: ['Bob', 'Dan'], 5: ['Alice', 'Edith', 'Frank'], 7: ['Charlie']} import toolz import cytoolz % timeit toolz . groupby ( len , names ) 4.61 \u00b5s \u00b1 13.7 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) % timeit cytoolz . groupby ( len , names ) 1.07 \u00b5s \u00b1 4.1 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each) def pick ( whitelist , d ): return toolz . keyfilter ( lambda k : k in whitelist , d ) def cypick ( whitelist , d ): return cytoolz . keyfilter ( lambda k : k in whitelist , d ) alphabet = { 'a' : 1 , 'b' : 2 , 'c' : 3 , 'd' : 4 } % timeit pick ([ 'a' , 'b' ], alphabet ) 2.79 \u00b5s \u00b1 41.3 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) % timeit cypick ([ 'a' , 'b' ], alphabet ) 1.82 \u00b5s \u00b1 13.9 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) % timeit list ( toolz . diff ([ 1 , 2 , 3 ], [ 1 , 2 , 10 , 100 ])) 3.18 \u00b5s \u00b1 83.8 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) np . random . seed ( 123 ) % timeit set ( np . random . randint ( 0 , 1000 , 345 )) & set ( np . random . randint ( 0 , 1000 , 456 )) 179 \u00b5s \u00b1 1.45 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) % timeit list ( cytoolz . diff ( np . random . randint ( 0 , 1000 , 345 ), np . random . randint ( 0 , 1000 , 456 ))) 125 \u00b5s \u00b1 807 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each) % timeit list ( cytoolz . diff ([ 1 , 2 , 3 ], [ 1 , 2 , 10 , 100 ])) 2.11 \u00b5s \u00b1 28.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) double = lambda i : 2 * i % timeit cytoolz . pipe ( 354658754 , double , str ) 823 ns \u00b1 8.48 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each) % timeit str ( double ( 354658754 )) 583 ns \u00b1 2.68 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)","title":"09 \u00b7 Functional programming"},{"location":"python/10%20%C2%B7%20Typing/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); PEP 483 -- The Theory of Type Hints PEP 484 -- Type Hints PEP 526 -- Syntax for Variable Annotations a type is a concept for the type checker, while a class is a runtime concept There are many definitions of the concept of type in the literature. Here we assume that type is a set of values and a set of functions that one can apply to these values. from typing import * class A ( object ): def __init__ ( self , value : int ) -> None : self . value = value a = A ( 2 ) c = 5 type ( c ) int def append_pi ( lst : List [ int ]) -> None : lst += [ 3.14 ] my_list = [ 1 , 3 , 5 ] # type: List[int] append_pi ( my_list ) # Naively, this should be safe... my_list [1, 3, 5, 3.14] a = [ 1 , 2 ] a += [ 23 ] a [1, 2, 23] my_list = [ 1 , 3 , 5 , 3.14 ] my_list [ - 1 ] << 5 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-18-b866a7d87c73> in <module> ----> 1 my_list [ - 1 ] << 5 TypeError : unsupported operand type(s) for <<: 'float' and 'int' Types vs. Classes \u00b6 In Python, classes are object factories defined by the class statement, and returned by the type(obj) built-in function. Class is a dynamic, runtime concept. Type concept is described above, types appear in variable and function type annotations, can be constructed from building blocks described below, and are used by static type checkers. Every class is a type as discussed above. But it is tricky and error prone to implement a class that exactly represents semantics of a given type, and it is not a goal of PEP 484. The static types described in PEP 484, should not be confused with the runtime classes. S = TypeVar ( 'Sa' , str , bytes ) def longest ( first : S , second : S ) -> S : return first if len ( first ) >= len ( second ) else second result = longest ( 'a' , 'abc' ) # The inferred type for result is str result = longest ( 'a' , b 'abc' ) # Fails static type check longest . __annotations__ [ 'return' ] ~Sa np . random . randint ( 0 , 100 , 32 ) array([51, 57, 73, 2, 36, 51, 31, 40, 91, 30, 40, 86, 48, 14, 18, 67, 39, 93, 65, 28, 47, 19, 39, 17, 77, 28, 99, 43, 64, 91, 86, 47])","title":"10 \u00b7 Typing"},{"location":"python/10%20%C2%B7%20Typing/#types-vs-classes","text":"In Python, classes are object factories defined by the class statement, and returned by the type(obj) built-in function. Class is a dynamic, runtime concept. Type concept is described above, types appear in variable and function type annotations, can be constructed from building blocks described below, and are used by static type checkers. Every class is a type as discussed above. But it is tricky and error prone to implement a class that exactly represents semantics of a given type, and it is not a goal of PEP 484. The static types described in PEP 484, should not be confused with the runtime classes. S = TypeVar ( 'Sa' , str , bytes ) def longest ( first : S , second : S ) -> S : return first if len ( first ) >= len ( second ) else second result = longest ( 'a' , 'abc' ) # The inferred type for result is str result = longest ( 'a' , b 'abc' ) # Fails static type check longest . __annotations__ [ 'return' ] ~Sa np . random . randint ( 0 , 100 , 32 ) array([51, 57, 73, 2, 36, 51, 31, 40, 91, 30, 40, 86, 48, 14, 18, 67, 39, 93, 65, 28, 47, 19, 39, 17, 77, 28, 99, 43, 64, 91, 86, 47])","title":"Types vs. Classes"},{"location":"python/11%20Descriptors/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); % watermark - mvd 2020-11-05 CPython 3.9.0 IPython 7.19.0 compiler : GCC 9.2.1 20191008 system : Linux release : 5.3.0-64-generic machine : x86_64 processor : x86_64 CPU cores : 8 interpreter: 64bit How to https://www.python.org/dev/peps/pep-0487/#implementation-details https://github.com/tecki/metaclasses Descriptor Protocol\u00b6 descr.__get__(self, obj, type=None) -> value descr.__set__(self, obj, value) -> None descr.__delete__(self, obj) -> None object.__set_name__(self, owner, name) -> None __get__ ( self , instance , owner = None ) class Trait : def __init__ ( self , minimum , maximum ): self . minimum = minimum self . maximum = maximum def __get__ ( self , instance , owner ): return instance . __dict__ [ self . key ] def __set__ ( self , instance , value ): if self . minimum < value < self . maximum : instance . __dict__ [ self . key ] = value else : raise ValueError ( \"value not in range\" ) def __set_name__ ( self , owner , name ): self . key = name from dataclasses import dataclass @dataclass class A : a = Trait ( 3 , 4 ) a = A () a . a = 3.4 a . a 3.4 class QuestBase : def __init_subclass__ ( cls , swallow , ** kwargs ): cls . swallow = swallow super () . __init_subclass__ ( ** kwargs ) class Quest ( QuestBase , swallow = \"african\" ): pass Quest . swallow 'african' class BigThing : def __init_subclass__ ( cls , a , b ): cls . A = Trait ( * a ) cls . B = Trait ( * b ) super () . __init_subclass__ () BigThing (( 1 , 2 ), ( 3 , 5 )) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-6-a91d96a5a0f3> in <module> ----> 1 BigThing ( ( 1 , 2 ) , ( 3 , 5 ) ) TypeError : BigThing() takes no arguments","title":"11 Descriptors"},{"location":"python/11%20%C2%B7%20Collections%20-%20sortedcontainers/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); from sortedcontainers import ( SortedDict , SortedItemsView , SortedKeyList , SortedList , SortedKeysView , SortedListWithKey , SortedSet , SortedValuesView ) % watermark - mdvp sortedcontainers 2018-06-15 CPython 3.6.5 IPython 6.4.0 sortedcontainers 2.0.4 compiler : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final) system : Darwin release : 15.6.0 machine : x86_64 processor : i386 CPU cores : 2 interpreter: 64bit Documentation: http://www.grantjenks.com/docs/sortedcontainers/index.html SortedDict \u00b6 d = { 'c' : 1 , 'b' : 2 , 'a' : 3 } sd = SortedDict ( d ) d {'c': 1, 'b': 2, 'a': 3} sd SortedDict({'a': 3, 'b': 2, 'c': 1}) list ( sd . keys ()) ['a', 'b', 'c'] list ( d . keys ()) ['c', 'b', 'a'] d . keys ()[ 0 ] --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-29-8ea809e8b798> in <module> () ----> 1 d . keys ( ) [ 0 ] TypeError : 'dict_keys' object does not support indexing sd . keys ()[ 0 ] 'a'","title":"11 \u00b7 Collections   sortedcontainers"},{"location":"python/11%20%C2%B7%20Collections%20-%20sortedcontainers/#sorteddict","text":"d = { 'c' : 1 , 'b' : 2 , 'a' : 3 } sd = SortedDict ( d ) d {'c': 1, 'b': 2, 'a': 3} sd SortedDict({'a': 3, 'b': 2, 'c': 1}) list ( sd . keys ()) ['a', 'b', 'c'] list ( d . keys ()) ['c', 'b', 'a'] d . keys ()[ 0 ] --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-29-8ea809e8b798> in <module> () ----> 1 d . keys ( ) [ 0 ] TypeError : 'dict_keys' object does not support indexing sd . keys ()[ 0 ] 'a'","title":"SortedDict"},{"location":"python/13.%20enum%20%E2%80%94%20Support%20for%20enumerations/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); An enumeration is a set of symbolic names (members) bound to unique, constant values. Within an enumeration, the members can be compared by identity, and the enumeration itself can be iterated over. As reported in https://stackoverflow.com/questions/702834/, enumerations can be creatded using a simple class, assigning attributes to a range class Materials : Shaded , Shiny , Transparent , Matte = range ( 1 , 5 ) Materials . Shaded 1 Module enum \u00b6 The module provides 4 enumeration classes : Enum , IntEnum , IntFlag , Flag , a decorator @unique and a helper function auto() enum are created using the class statement, subclassing Enum enum values can be anything. If value is unimportant, use the module provided enum.auto from enum import Enum , IntEnum , IntFlag , Flag , auto , unique Enum members values can be anything: int , str , etc.. IntEnum are strict int . A ValueError in raised if attempting to set anything else class URL0 ( Enum ): CULTURE = \"http://www.franceculture.fr\" INTER = \"http://www.franceinter.fr\" MUSIQUE = \"https://www.francemusique.fr\" INFO = \"https://www.francetvinfo.fr\" URL0 . CULTURE <URL0.CULTURE: 'http://www.franceculture.fr'> # Enum are iterable for station in URL0 : print ( f \" { station : 12 } \" , f \"name: { station . name : 8 } / value: { station . value } \" , sep = \" -> \" ) URL0.CULTURE -> name: CULTURE / value: http://www.franceculture.fr URL0.INTER -> name: INTER / value: http://www.franceinter.fr URL0.MUSIQUE -> name: MUSIQUE / value: https://www.francemusique.fr URL0.INFO -> name: INFO / value: https://www.francetvinfo.fr Call of an Enum passing by value returns the Enum element URL0 ( \"http://www.franceculture.fr\" ) <URL0.CULTURE: 'http://www.franceculture.fr'> Enum derived class: IntEnum \u00b6 With usage of auto() for automatic value completion class URL1 ( IntEnum ): CULTURE = 1 INTER = 2 MUSIQUE = auto () INFO = auto () Comparison to int is granted URL1 . INFO <URL1.INFO: 4> URL1 . INFO == 1 False IntEnum can very easily recreated IntEnum ?? Init signature: IntEnum ( value , names = None , * , module = None , qualname = None , type = None , start = 1 , ) Source: class IntEnum ( int , Enum ) : \"\"\"Enum where members are also (and must be) ints\"\"\" File: /opt/conda/lib/python3.7/enum.py Type: EnumMeta Subclasses: Signals, Handlers, Sigmasks, _ParameterKind, AddressFamily, SocketKind, _SSLMethod, AlertDescription, SSLErrorNumber, VerifyMode, ... Subclassing an enumeration is allowed only if the enumeration does not define any members. class StrEnum ( str , Enum ): \"\"\"Enum where members are str\"\"\" class URL2 ( StrEnum ): CULTURE = \"http://www.franceculture.fr\" INTER = \"http://www.franceinter.fr\" MUSIQUE = \"https://www.francemusique.fr\" INFO = \"https://www.francetvinfo.fr\" Direct comparison to str is possible URL2 . CULTURE == \"http://www.franceculture.fr\" True Programmatic access to enumeration members and their attributes \u00b6 class URL3 ( Enum ): CULTURE = \"http://www.franceculture.fr\" INTER = \"http://www.franceinter.fr\" MUSIQUE = \"https://www.francemusique.fr\" INFO = \"https://www.francetvinfo.fr\" def __init__ ( self , * pargs , ** kwargs ): print ( f \"__init__ is ran with postional arguments { pargs } and keyword arguments { kwargs } \" ) self . scheme = pargs [ 0 ] . split ( \":\" )[ 0 ] def method ( self ): print ( f \"A method is called, applied on { self } with value { self . value } \" ) @property def prop ( self ): print ( f \"A dynamic property, applied on { self } with value { self . value } \" ) @classmethod def favorite_station ( cls ): # cls here is the enumeration return cls . CULTURE __init__ is ran with postional arguments ('http://www.franceculture.fr',) and keyword arguments {} __init__ is ran with postional arguments ('http://www.franceinter.fr',) and keyword arguments {} __init__ is ran with postional arguments ('https://www.francemusique.fr',) and keyword arguments {} __init__ is ran with postional arguments ('https://www.francetvinfo.fr',) and keyword arguments {} URL3 . CULTURE . scheme 'http' URL3 . CULTURE . method () A method is called, applied on URL3.CULTURE with value http://www.franceculture.fr URL3 . CULTURE . prop A dynamic property, applied on URL3.CULTURE with value http://www.franceculture.fr URL3 . favorite_station () <URL3.CULTURE: 'http://www.franceculture.fr'> Some more complex subclass with programmatic access to attributes from urllib.parse import urlparse class URLEnum ( str , Enum ): \"\"\"Enum where members are also (and must be) URL\"\"\" def __init__ ( self , url ): \"scheme://netloc/path;parameters?query#fragment\" for ( attr , value ) in zip ( \"scheme netloc path parameters query fragment\" . split ( \" \" ), list ( urlparse ( url ))): setattr ( self , attr , value ) assert self . scheme in [ 'http' , 'https' ], f \"URL { self } provides neither http nor https scheme\" class URLEnum ( str , Enum ): def __new__ ( cls , value ): obj = str . __new__ ( cls ) obj . _value_ = urlparse ( value ) return obj class URL5 ( URLEnum ): CULTURE = \"http://www.franceculture.fr\" INTER = \"http://www.franceinter.fr\" MUSIQUE = \"https://www.francemusique.fr\" INFO = \"https://www.francetvinfo.fr\" URL5 . CULTURE . value . scheme 'http' URL5 . CULTURE == \"http://www.franceculture.fr\" False Flag \u00b6 Flag have __bool__ , __or__ , __and__ , __xorr__ , __invert__ methods class Color ( Flag ): RED = auto () BLUE = auto () GREEN = auto () Color . RED <Color.RED: 1> Color . RED & Color . GREEN <Color.0: 0> bool ( Color . RED & Color . GREEN ) False IntFlag \u00b6 IntFlag subclasses Int and Flag . Members can be combined using the bitwise operators (&, |, ^, ~) and the result is still an IntFlag class Perm ( IntFlag ): R = 4 W = 2 X = 1 Perm . R | Perm . W <Perm.R|W: 6> Perm . R + Perm . W 6 RW = Perm . R | Perm . W Perm . R in RW True Functional API \u00b6 Enum ? Init signature: Enum ( value , names = None , * , module = None , qualname = None , type = None , start = 1 ) Docstring: Generic enumeration. Derive from this class to define new enumerations. File: /opt/conda/lib/python3.7/enum.py Type: EnumMeta Subclasses: IntEnum, Flag, Purpose, _SendfileMode, SelectionType, PasteMode, EditingMode, Priority, ColorDepth, MouseEventType, ... URL6 = Enum ( 'Radio' , 'Culture Inter Musique Info' , type = str , start = 20 ) URL6 . Inter <Radio.Inter: '21'>","title":"13. enum \u2014 Support for enumerations"},{"location":"python/13.%20enum%20%E2%80%94%20Support%20for%20enumerations/#module-enum","text":"The module provides 4 enumeration classes : Enum , IntEnum , IntFlag , Flag , a decorator @unique and a helper function auto() enum are created using the class statement, subclassing Enum enum values can be anything. If value is unimportant, use the module provided enum.auto from enum import Enum , IntEnum , IntFlag , Flag , auto , unique Enum members values can be anything: int , str , etc.. IntEnum are strict int . A ValueError in raised if attempting to set anything else class URL0 ( Enum ): CULTURE = \"http://www.franceculture.fr\" INTER = \"http://www.franceinter.fr\" MUSIQUE = \"https://www.francemusique.fr\" INFO = \"https://www.francetvinfo.fr\" URL0 . CULTURE <URL0.CULTURE: 'http://www.franceculture.fr'> # Enum are iterable for station in URL0 : print ( f \" { station : 12 } \" , f \"name: { station . name : 8 } / value: { station . value } \" , sep = \" -> \" ) URL0.CULTURE -> name: CULTURE / value: http://www.franceculture.fr URL0.INTER -> name: INTER / value: http://www.franceinter.fr URL0.MUSIQUE -> name: MUSIQUE / value: https://www.francemusique.fr URL0.INFO -> name: INFO / value: https://www.francetvinfo.fr Call of an Enum passing by value returns the Enum element URL0 ( \"http://www.franceculture.fr\" ) <URL0.CULTURE: 'http://www.franceculture.fr'>","title":"Module enum"},{"location":"python/13.%20enum%20%E2%80%94%20Support%20for%20enumerations/#enum-derived-class-intenum","text":"With usage of auto() for automatic value completion class URL1 ( IntEnum ): CULTURE = 1 INTER = 2 MUSIQUE = auto () INFO = auto () Comparison to int is granted URL1 . INFO <URL1.INFO: 4> URL1 . INFO == 1 False IntEnum can very easily recreated IntEnum ?? Init signature: IntEnum ( value , names = None , * , module = None , qualname = None , type = None , start = 1 , ) Source: class IntEnum ( int , Enum ) : \"\"\"Enum where members are also (and must be) ints\"\"\" File: /opt/conda/lib/python3.7/enum.py Type: EnumMeta Subclasses: Signals, Handlers, Sigmasks, _ParameterKind, AddressFamily, SocketKind, _SSLMethod, AlertDescription, SSLErrorNumber, VerifyMode, ... Subclassing an enumeration is allowed only if the enumeration does not define any members. class StrEnum ( str , Enum ): \"\"\"Enum where members are str\"\"\" class URL2 ( StrEnum ): CULTURE = \"http://www.franceculture.fr\" INTER = \"http://www.franceinter.fr\" MUSIQUE = \"https://www.francemusique.fr\" INFO = \"https://www.francetvinfo.fr\" Direct comparison to str is possible URL2 . CULTURE == \"http://www.franceculture.fr\" True","title":"Enum derived class: IntEnum"},{"location":"python/13.%20enum%20%E2%80%94%20Support%20for%20enumerations/#programmatic-access-to-enumeration-members-and-their-attributes","text":"class URL3 ( Enum ): CULTURE = \"http://www.franceculture.fr\" INTER = \"http://www.franceinter.fr\" MUSIQUE = \"https://www.francemusique.fr\" INFO = \"https://www.francetvinfo.fr\" def __init__ ( self , * pargs , ** kwargs ): print ( f \"__init__ is ran with postional arguments { pargs } and keyword arguments { kwargs } \" ) self . scheme = pargs [ 0 ] . split ( \":\" )[ 0 ] def method ( self ): print ( f \"A method is called, applied on { self } with value { self . value } \" ) @property def prop ( self ): print ( f \"A dynamic property, applied on { self } with value { self . value } \" ) @classmethod def favorite_station ( cls ): # cls here is the enumeration return cls . CULTURE __init__ is ran with postional arguments ('http://www.franceculture.fr',) and keyword arguments {} __init__ is ran with postional arguments ('http://www.franceinter.fr',) and keyword arguments {} __init__ is ran with postional arguments ('https://www.francemusique.fr',) and keyword arguments {} __init__ is ran with postional arguments ('https://www.francetvinfo.fr',) and keyword arguments {} URL3 . CULTURE . scheme 'http' URL3 . CULTURE . method () A method is called, applied on URL3.CULTURE with value http://www.franceculture.fr URL3 . CULTURE . prop A dynamic property, applied on URL3.CULTURE with value http://www.franceculture.fr URL3 . favorite_station () <URL3.CULTURE: 'http://www.franceculture.fr'> Some more complex subclass with programmatic access to attributes from urllib.parse import urlparse class URLEnum ( str , Enum ): \"\"\"Enum where members are also (and must be) URL\"\"\" def __init__ ( self , url ): \"scheme://netloc/path;parameters?query#fragment\" for ( attr , value ) in zip ( \"scheme netloc path parameters query fragment\" . split ( \" \" ), list ( urlparse ( url ))): setattr ( self , attr , value ) assert self . scheme in [ 'http' , 'https' ], f \"URL { self } provides neither http nor https scheme\" class URLEnum ( str , Enum ): def __new__ ( cls , value ): obj = str . __new__ ( cls ) obj . _value_ = urlparse ( value ) return obj class URL5 ( URLEnum ): CULTURE = \"http://www.franceculture.fr\" INTER = \"http://www.franceinter.fr\" MUSIQUE = \"https://www.francemusique.fr\" INFO = \"https://www.francetvinfo.fr\" URL5 . CULTURE . value . scheme 'http' URL5 . CULTURE == \"http://www.franceculture.fr\" False","title":"Programmatic access to enumeration members and their attributes"},{"location":"python/13.%20enum%20%E2%80%94%20Support%20for%20enumerations/#flag","text":"Flag have __bool__ , __or__ , __and__ , __xorr__ , __invert__ methods class Color ( Flag ): RED = auto () BLUE = auto () GREEN = auto () Color . RED <Color.RED: 1> Color . RED & Color . GREEN <Color.0: 0> bool ( Color . RED & Color . GREEN ) False","title":"Flag"},{"location":"python/13.%20enum%20%E2%80%94%20Support%20for%20enumerations/#intflag","text":"IntFlag subclasses Int and Flag . Members can be combined using the bitwise operators (&, |, ^, ~) and the result is still an IntFlag class Perm ( IntFlag ): R = 4 W = 2 X = 1 Perm . R | Perm . W <Perm.R|W: 6> Perm . R + Perm . W 6 RW = Perm . R | Perm . W Perm . R in RW True","title":"IntFlag"},{"location":"python/13.%20enum%20%E2%80%94%20Support%20for%20enumerations/#functional-api","text":"Enum ? Init signature: Enum ( value , names = None , * , module = None , qualname = None , type = None , start = 1 ) Docstring: Generic enumeration. Derive from this class to define new enumerations. File: /opt/conda/lib/python3.7/enum.py Type: EnumMeta Subclasses: IntEnum, Flag, Purpose, _SendfileMode, SelectionType, PasteMode, EditingMode, Priority, ColorDepth, MouseEventType, ... URL6 = Enum ( 'Radio' , 'Culture Inter Musique Info' , type = str , start = 20 ) URL6 . Inter <Radio.Inter: '21'>","title":"Functional API"},{"location":"python/5.%20heapq%20%E2%80%94%20Heap%20queue%20algorithm/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import wikipedia from IPython.display import ( HTML , Pretty ) HTML ( wikipedia . summary ( 'Heap_(data_structure)' , sentences = 1 )) In computer science, a heap is a specialized tree-based data structure that satisfies the heap property: if P is a parent node of C, then the key (the value) of P is either greater than or equal to (in a max heap) or less than or equal to (in a min heap) the key of C. The node at the \"top\" of the heap (with no parents) is called the root node. heapq module documentation from heapq import heappush , heappop import itertools pq = [] # list of entries arranged in a heap entry_finder = {} # mapping of tasks to entries REMOVED = '<removed-task>' # placeholder for a removed task counter = itertools . count () # unique sequence count def add_task ( task , priority = 0 ): 'Add a new task or update the priority of an existing task' if task in entry_finder : remove_task ( task ) count = next ( counter ) entry = [ priority , count , task ] entry_finder [ task ] = entry heappush ( pq , entry ) def remove_task ( task ): 'Mark an existing task as REMOVED. Raise KeyError if not found.' entry = entry_finder . pop ( task ) entry [ - 1 ] = REMOVED def pop_task (): 'Remove and return the lowest priority task. Raise KeyError if empty.' while pq : priority , count , task = heappop ( pq ) if task is not REMOVED : del entry_finder [ task ] return task raise KeyError ( 'pop from an empty priority queue' ) add_task ( \"Tache 1\" , priority = 4 ) add_task ( \"Tache 2\" , priority = 20 ) add_task ( \"Tache 3\" , priority = 3 ) pop_task () 'Tache 3' from dataclasses import dataclass , field from typing import Any @dataclass ( order = True ) class PrioritizedItem : priority : int item : Any = field ( compare = False ) h = [] heappush ( h , PrioritizedItem ( 5 , 'write code' )) heappush ( h , PrioritizedItem ( 7 , 'release product' )) heappush ( h , PrioritizedItem ( 1 , 'write spec' )) heappush ( h , PrioritizedItem ( 3 , 'create tests' )) while h : print ( heappop ( h )) PrioritizedItem(priority=1, item='write spec') PrioritizedItem(priority=3, item='create tests') PrioritizedItem(priority=5, item='write code') PrioritizedItem(priority=7, item='release product')","title":"5. heapq \u2014 Heap queue algorithm"},{"location":"python/A%20Python%20Interpreter%20Written%20in%20Python/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Source: CPython internals: A ten-hour codewalk through the Python interpreter source code A Python Interpreter Written in Python Building an Interpreter \u00b6 A Tiny Interpreter \u00b6 class Interpreter ( object ): def __init__ ( self ): self . stack = [] def LOAD_VALUE ( self , number ): self . stack . append ( number ) def PRINT_ANSWER ( self ): answer = self . stack . pop () print ( answer ) def ADD_TWO_VALUES ( self ): first_num = self . stack . pop () second_num = self . stack . pop () total = first_num + second_num self . stack . append ( total ) def run_code ( self , what_to_execute ): instructions = what_to_execute [ \"instructions\" ] numbers = what_to_execute [ \"numbers\" ] for each_step in instructions : instruction , argument = each_step if instruction == \"LOAD_VALUE\" : number = numbers [ argument ] self . LOAD_VALUE ( number ) elif instruction == \"ADD_TWO_VALUES\" : self . ADD_TWO_VALUES () elif instruction == \"PRINT_ANSWER\" : self . PRINT_ANSWER () myInterpreter1 = Interpreter () what_to_execute = { \"instructions\" : [( \"LOAD_VALUE\" , 0 ), # the first number ( \"LOAD_VALUE\" , 1 ), # the second number ( \"ADD_TWO_VALUES\" , None ), ( \"PRINT_ANSWER\" , None )], \"numbers\" : [ 7 , 5 ] } myInterpreter1 . run_code ( what_to_execute ) 12 what_to_execute = { \"instructions\" : [( \"LOAD_VALUE\" , 0 ), ( \"LOAD_VALUE\" , 1 ), ( \"ADD_TWO_VALUES\" , None ), ( \"LOAD_VALUE\" , 2 ), ( \"ADD_TWO_VALUES\" , None ), ( \"PRINT_ANSWER\" , None )], \"numbers\" : [ 7 , 5 , 8 ] } myInterpreter1 . run_code ( what_to_execute ) 20 Variables \u00b6 class Interpreter2 ( Interpreter ): def __init__ ( self ): Interpreter . __init__ ( self ) self . environment = {} def __call__ ( self , * pargs , ** kwargs ): self . execute ( * pargs , ** kwargs ) def STORE_NAME ( self , name ): val = self . stack . pop () self . environment [ name ] = val def LOAD_NAME ( self , name ): val = self . environment [ name ] self . stack . append ( val ) def parse_argument ( self , instruction , argument , what_to_execute ): \"\"\" Understand what the argument to each instruction means.\"\"\" numbers = [ \"LOAD_VALUE\" ] names = [ \"LOAD_NAME\" , \"STORE_NAME\" ] if instruction in numbers : argument = what_to_execute [ \"numbers\" ][ argument ] elif instruction in names : argument = what_to_execute [ \"names\" ][ argument ] return argument def run_code ( self , what_to_execute ): instructions = what_to_execute [ \"instructions\" ] for each_step in instructions : instruction , argument = each_step argument = self . parse_argument ( instruction , argument , what_to_execute ) if instruction == \"LOAD_VALUE\" : self . LOAD_VALUE ( argument ) elif instruction == \"ADD_TWO_VALUES\" : self . ADD_TWO_VALUES () elif instruction == \"PRINT_ANSWER\" : self . PRINT_ANSWER () elif instruction == \"STORE_NAME\" : self . STORE_NAME ( argument ) elif instruction == \"LOAD_NAME\" : self . LOAD_NAME ( argument ) # Implementation of run_code using # Python's dynamic method lookup def execute ( self , what_to_execute ): instructions = what_to_execute [ \"instructions\" ] for each_step in instructions : instruction , argument = each_step argument = self . parse_argument ( instruction , argument , what_to_execute ) bytecode_method = getattr ( self , instruction ) if argument is None : bytecode_method () else : bytecode_method ( argument ) myInterpreter2 = Interpreter2 () what_to_execute = { \"instructions\" : [( \"LOAD_VALUE\" , 0 ), ( \"STORE_NAME\" , 0 ), ( \"LOAD_VALUE\" , 1 ), ( \"STORE_NAME\" , 1 ), ( \"LOAD_NAME\" , 0 ), ( \"LOAD_NAME\" , 1 ), ( \"ADD_TWO_VALUES\" , None ), ( \"PRINT_ANSWER\" , None )], \"numbers\" : [ 1 , 2 ], \"names\" : [ \"a\" , \"b\" ] } myInterpreter2 . run_code ( what_to_execute ) 3 myInterpreter2 ( what_to_execute ) 3 Real Python Bytecode \u00b6 from dis import dis , opname def cond (): x = 3 if x < 5 : return 'yes' else : return 'no' cond._ code_ is the code object associated to cond cond . __code__ <code object cond at 0x180fa91300, file \"<ipython-input-82-322d0ec9f2b5>\", line 1> cond._ code_ .co_code is the bytecode cond . __code__ . co_code # the bytecode as raw bytes b'd\\x01}\\x00|\\x00d\\x02k\\x00r\\x10d\\x03S\\x00d\\x04S\\x00d\\x00S\\x00' print ( list ( cond . __code__ . co_code )) # the bytecode as numbers [100, 1, 125, 0, 124, 0, 100, 2, 107, 0, 114, 16, 100, 3, 83, 0, 100, 4, 83, 0, 100, 0, 83, 0] {k: v for k, v in cond. code .co_code} list ( cond . __code__ . co_code )[:: 2 ] [100, 125, 124, 100, 107, 114, 100, 83, 100, 83, 100, 83] Include/opcode.h contains import urllib3 urllib3 . disable_warnings () http = urllib3 . PoolManager () r = http . request ( 'GET' , 'https://raw.githubusercontent.com/python/cpython/master/Include/opcode.h' ) for _l in r . data . decode () . split ( \" \\n \" ): _split = _l . strip () . split () try : if _split and int ( _split [ - 1 ]) in list ( cond . __code__ . co_code )[:: 2 ]: print ( f \" { _split [ 2 ] : 3 } : { _split [ 1 ] } \" ) except ValueError : pass 83 : RETURN_VALUE 100 : LOAD_CONST 107 : COMPARE_OP 114 : POP_JUMP_IF_FALSE 124 : LOAD_FAST 125 : STORE_FAST dis ( cond ) 2 0 LOAD_CONST 1 (3) 2 STORE_FAST 0 (x) 3 4 LOAD_FAST 0 (x) 6 LOAD_CONST 2 (5) 8 COMPARE_OP 0 (<) 10 POP_JUMP_IF_FALSE 16 4 12 LOAD_CONST 3 ('yes') 14 RETURN_VALUE 6 >> 16 LOAD_CONST 4 ('no') 18 RETURN_VALUE 20 LOAD_CONST 0 (None) 22 RETURN_VALUE set ( list ( cond . __code__ . co_code )[:: 2 ]) {83, 100, 107, 114, 124, 125} for _c in set ( sorted ( list ( cond . __code__ . co_code )[:: 2 ])): print ( f \" { _c : 3 } : { opname [ _c ] } \" ) 100 : LOAD_CONST 107 : COMPARE_OP 114 : POP_JUMP_IF_FALSE 83 : RETURN_VALUE 124 : LOAD_FAST 125 : STORE_FAST list ( set ( list ( cond . __code__ . co_code )[:: 2 ])) [100, 107, 114, 83, 124, 125]","title":"A Python Interpreter Written in Python"},{"location":"python/A%20Python%20Interpreter%20Written%20in%20Python/#building-an-interpreter","text":"","title":"Building an Interpreter"},{"location":"python/A%20Python%20Interpreter%20Written%20in%20Python/#a-tiny-interpreter","text":"class Interpreter ( object ): def __init__ ( self ): self . stack = [] def LOAD_VALUE ( self , number ): self . stack . append ( number ) def PRINT_ANSWER ( self ): answer = self . stack . pop () print ( answer ) def ADD_TWO_VALUES ( self ): first_num = self . stack . pop () second_num = self . stack . pop () total = first_num + second_num self . stack . append ( total ) def run_code ( self , what_to_execute ): instructions = what_to_execute [ \"instructions\" ] numbers = what_to_execute [ \"numbers\" ] for each_step in instructions : instruction , argument = each_step if instruction == \"LOAD_VALUE\" : number = numbers [ argument ] self . LOAD_VALUE ( number ) elif instruction == \"ADD_TWO_VALUES\" : self . ADD_TWO_VALUES () elif instruction == \"PRINT_ANSWER\" : self . PRINT_ANSWER () myInterpreter1 = Interpreter () what_to_execute = { \"instructions\" : [( \"LOAD_VALUE\" , 0 ), # the first number ( \"LOAD_VALUE\" , 1 ), # the second number ( \"ADD_TWO_VALUES\" , None ), ( \"PRINT_ANSWER\" , None )], \"numbers\" : [ 7 , 5 ] } myInterpreter1 . run_code ( what_to_execute ) 12 what_to_execute = { \"instructions\" : [( \"LOAD_VALUE\" , 0 ), ( \"LOAD_VALUE\" , 1 ), ( \"ADD_TWO_VALUES\" , None ), ( \"LOAD_VALUE\" , 2 ), ( \"ADD_TWO_VALUES\" , None ), ( \"PRINT_ANSWER\" , None )], \"numbers\" : [ 7 , 5 , 8 ] } myInterpreter1 . run_code ( what_to_execute ) 20","title":"A Tiny Interpreter"},{"location":"python/A%20Python%20Interpreter%20Written%20in%20Python/#variables","text":"class Interpreter2 ( Interpreter ): def __init__ ( self ): Interpreter . __init__ ( self ) self . environment = {} def __call__ ( self , * pargs , ** kwargs ): self . execute ( * pargs , ** kwargs ) def STORE_NAME ( self , name ): val = self . stack . pop () self . environment [ name ] = val def LOAD_NAME ( self , name ): val = self . environment [ name ] self . stack . append ( val ) def parse_argument ( self , instruction , argument , what_to_execute ): \"\"\" Understand what the argument to each instruction means.\"\"\" numbers = [ \"LOAD_VALUE\" ] names = [ \"LOAD_NAME\" , \"STORE_NAME\" ] if instruction in numbers : argument = what_to_execute [ \"numbers\" ][ argument ] elif instruction in names : argument = what_to_execute [ \"names\" ][ argument ] return argument def run_code ( self , what_to_execute ): instructions = what_to_execute [ \"instructions\" ] for each_step in instructions : instruction , argument = each_step argument = self . parse_argument ( instruction , argument , what_to_execute ) if instruction == \"LOAD_VALUE\" : self . LOAD_VALUE ( argument ) elif instruction == \"ADD_TWO_VALUES\" : self . ADD_TWO_VALUES () elif instruction == \"PRINT_ANSWER\" : self . PRINT_ANSWER () elif instruction == \"STORE_NAME\" : self . STORE_NAME ( argument ) elif instruction == \"LOAD_NAME\" : self . LOAD_NAME ( argument ) # Implementation of run_code using # Python's dynamic method lookup def execute ( self , what_to_execute ): instructions = what_to_execute [ \"instructions\" ] for each_step in instructions : instruction , argument = each_step argument = self . parse_argument ( instruction , argument , what_to_execute ) bytecode_method = getattr ( self , instruction ) if argument is None : bytecode_method () else : bytecode_method ( argument ) myInterpreter2 = Interpreter2 () what_to_execute = { \"instructions\" : [( \"LOAD_VALUE\" , 0 ), ( \"STORE_NAME\" , 0 ), ( \"LOAD_VALUE\" , 1 ), ( \"STORE_NAME\" , 1 ), ( \"LOAD_NAME\" , 0 ), ( \"LOAD_NAME\" , 1 ), ( \"ADD_TWO_VALUES\" , None ), ( \"PRINT_ANSWER\" , None )], \"numbers\" : [ 1 , 2 ], \"names\" : [ \"a\" , \"b\" ] } myInterpreter2 . run_code ( what_to_execute ) 3 myInterpreter2 ( what_to_execute ) 3","title":"Variables"},{"location":"python/A%20Python%20Interpreter%20Written%20in%20Python/#real-python-bytecode","text":"from dis import dis , opname def cond (): x = 3 if x < 5 : return 'yes' else : return 'no' cond._ code_ is the code object associated to cond cond . __code__ <code object cond at 0x180fa91300, file \"<ipython-input-82-322d0ec9f2b5>\", line 1> cond._ code_ .co_code is the bytecode cond . __code__ . co_code # the bytecode as raw bytes b'd\\x01}\\x00|\\x00d\\x02k\\x00r\\x10d\\x03S\\x00d\\x04S\\x00d\\x00S\\x00' print ( list ( cond . __code__ . co_code )) # the bytecode as numbers [100, 1, 125, 0, 124, 0, 100, 2, 107, 0, 114, 16, 100, 3, 83, 0, 100, 4, 83, 0, 100, 0, 83, 0] {k: v for k, v in cond. code .co_code} list ( cond . __code__ . co_code )[:: 2 ] [100, 125, 124, 100, 107, 114, 100, 83, 100, 83, 100, 83] Include/opcode.h contains import urllib3 urllib3 . disable_warnings () http = urllib3 . PoolManager () r = http . request ( 'GET' , 'https://raw.githubusercontent.com/python/cpython/master/Include/opcode.h' ) for _l in r . data . decode () . split ( \" \\n \" ): _split = _l . strip () . split () try : if _split and int ( _split [ - 1 ]) in list ( cond . __code__ . co_code )[:: 2 ]: print ( f \" { _split [ 2 ] : 3 } : { _split [ 1 ] } \" ) except ValueError : pass 83 : RETURN_VALUE 100 : LOAD_CONST 107 : COMPARE_OP 114 : POP_JUMP_IF_FALSE 124 : LOAD_FAST 125 : STORE_FAST dis ( cond ) 2 0 LOAD_CONST 1 (3) 2 STORE_FAST 0 (x) 3 4 LOAD_FAST 0 (x) 6 LOAD_CONST 2 (5) 8 COMPARE_OP 0 (<) 10 POP_JUMP_IF_FALSE 16 4 12 LOAD_CONST 3 ('yes') 14 RETURN_VALUE 6 >> 16 LOAD_CONST 4 ('no') 18 RETURN_VALUE 20 LOAD_CONST 0 (None) 22 RETURN_VALUE set ( list ( cond . __code__ . co_code )[:: 2 ]) {83, 100, 107, 114, 124, 125} for _c in set ( sorted ( list ( cond . __code__ . co_code )[:: 2 ])): print ( f \" { _c : 3 } : { opname [ _c ] } \" ) 100 : LOAD_CONST 107 : COMPARE_OP 114 : POP_JUMP_IF_FALSE 83 : RETURN_VALUE 124 : LOAD_FAST 125 : STORE_FAST list ( set ( list ( cond . __code__ . co_code )[:: 2 ])) [100, 107, 114, 83, 124, 125]","title":"Real Python Bytecode"},{"location":"python/ElementTree%2C%20BeatufulSoup/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import bs4 from IPython.display import HTML % watermark - dtv - p numpy , matplotlib , pandas , bs4 2017-10-12 19:55:23 CPython 3.6.2 IPython 6.1.0 numpy 1.13.1 matplotlib 2.0.2 pandas 0.20.3 bs4 4.6.0 myMesh = mesh1d ( np . arange ( 20 ) * 10 ) ElementTree \u00b6 def bench_ET (): import xml.etree.ElementTree as ET from itertools import islice from lerp.core.config import get_option max_rows = get_option ( \"display.max_rows\" ) _html_style = { 'table' : 'border: 0px none;' , 'th' : 'color:LightGrey;border:0px none;' 'text-align:center;background:none;' , 'tr' : 'border:0px none; border-bottom:1px solid #C0C0C0;' 'background:none;' , 'none' : 'border:0px none;background:none;' , } def _StyledSubElement ( parent , child ): return ET . SubElement ( parent , child , { 'style' : _html_style [ child ]}) ET . StyledSubElement = _StyledSubElement root = ET . Element ( 'div' ) pre = ET . SubElement ( root , 'p' ) ET . SubElement ( pre , 'code' ) . text = myMesh . __class__ . __name__ ET . SubElement ( pre , 'span' ) . text = \": \" ET . SubElement ( pre , 'b' ) . text = myMesh . label or \"Label\" ET . SubElement ( pre , 'span' ) . text = \" [ {} ]\" . format ( myMesh . unit or \"unit\" ) ET . SubElement ( pre , 'br' ) res = ET . SubElement ( pre , 'p' ) if myMesh . size == 1 : res . text = str ( myMesh ) else : table = ET . StyledSubElement ( res , 'table' ) tbody = ET . SubElement ( table , 'tbody' ) for _i in range ( 2 ): if not _i : tr = ET . StyledSubElement ( tbody , 'tr' ) for _node in islice ( np . arange ( len ( myMesh )), max_rows - 1 ): ET . StyledSubElement ( tr , 'th' ) . text = str ( _node ) if len ( myMesh ) > max_rows : ET . StyledSubElement ( tr , 'th' ) . text = \"...\" ET . StyledSubElement ( tr , 'th' ) . text = str ( len ( myMesh ) - 1 ) elif len ( myMesh ) > max_rows - 1 : ET . StyledSubElement ( tr , 'th' ) . text = str ( len ( myMesh ) - 1 ) else : tr = ET . SubElement ( tbody , 'tr' , { 'style' : 'border: 0px solid' }) for _node in islice ( myMesh , max_rows - 1 ): ET . SubElement ( tr , 'td' ) . text = str ( _node ) if len ( myMesh ) > max_rows : ET . SubElement ( tr , 'td' ) . text = \"...\" ET . SubElement ( tr , 'td' ) . text = str ( myMesh [ - 1 ]) elif len ( myMesh ) > max_rows - 1 : ET . SubElement ( tr , 'td' ) . text = str ( myMesh [ - 1 ]) return str ( ET . tostring ( root , encoding = 'utf-8' ), 'utf-8' ) % timeit bench_ET () 747 \u00b5s \u00b1 16.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) HTML ( bench_ET ()) BreakPoints : Label [unit] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 ... 19 0 10 20 30 40 50 60 70 80 90 100 110 120 130 ... 190 soup = bs4 . BeautifulSoup ( '<div/>' , 'html.parser' ) soup . div . append ( soup . new_tag ( name = 'p' )) soup . div . p . append ( soup . new_tag ( name = 'code' )) soup . div . p . code . string = myMesh . __class__ . __name__ soup . div . p . append ( soup . new_tag ( name = 'span' )) soup . div . span . string = \": \" soup . div . p . append ( soup . new_tag ( name = 'b' )) soup . div . b . string = myMesh . label or \"Label\" soup . div . p . append ( soup . new_tag ( name = 'span' )) soup . div . span #1].string = \" [{}]\".format(myMesh.unit or \"unit\") #soup <span>: </span> span = ET . SubElement ( pre , 'span' ) span . text = \" [ {} ]\" . format ( myMesh . unit or \"unit\" ) ET . SubElement ( pre , 'br' ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-1-5d0c173f600c> in <module> () ----> 1 get_ipython ( ) . run_cell_magic ( 'timeit' , '' , 'pre = ET.SubElement(root, \\'p\\')\\ncode = ET.SubElement(pre, \\'code\\')\\ncode.text = myMesh.__class__.__name__\\nspan = ET.SubElement(pre, \\'span\\').text = \": \"\\nb = ET.SubElement(pre, \\'b\\')\\nb.text = myMesh.label or \"Label\"\\nspan = ET.SubElement(pre, \\'span\\')\\nspan.text = \" [{}]\".format(myMesh.unit or \"unit\")\\nET.SubElement(pre, \\'br\\')' ) ~/Documents/Developpement/python/anaconda/anaconda3-5.0.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell_magic (self, magic_name, line, cell) 2101 magic_arg_s = self . var_expand ( line , stack_depth ) 2102 with self . builtin_trap : -> 2103 result = fn ( magic_arg_s , cell ) 2104 return result 2105 <decorator-gen-61> in timeit (self, line, cell) ~/Documents/Developpement/python/anaconda/anaconda3-5.0.0/lib/python3.6/site-packages/IPython/core/magic.py in <lambda> (f, *a, **k) 185 # but it's overkill for just that one bit of state. 186 def magic_deco ( arg ) : --> 187 call = lambda f , * a , ** k : f ( * a , ** k ) 188 189 if callable ( arg ) : ~/Documents/Developpement/python/anaconda/anaconda3-5.0.0/lib/python3.6/site-packages/IPython/core/magics/execution.py in timeit (self, line, cell) 1078 for index in range ( 0 , 10 ) : 1079 number = 10 ** index -> 1080 time_number = timer . timeit ( number ) 1081 if time_number >= 0.2 : 1082 break ~/Documents/Developpement/python/anaconda/anaconda3-5.0.0/lib/python3.6/site-packages/IPython/core/magics/execution.py in timeit (self, number) 158 gc . disable ( ) 159 try : --> 160 timing = self . inner ( it , self . timer ) 161 finally : 162 if gcold : <magic-timeit> in inner (_it, _timer) NameError : name 'ET' is not defined div . append ( soup . new_tag ( name = 'table' )) soup <div><table></table></div>","title":"ElementTree, BeatufulSoup"},{"location":"python/ElementTree%2C%20BeatufulSoup/#elementtree","text":"def bench_ET (): import xml.etree.ElementTree as ET from itertools import islice from lerp.core.config import get_option max_rows = get_option ( \"display.max_rows\" ) _html_style = { 'table' : 'border: 0px none;' , 'th' : 'color:LightGrey;border:0px none;' 'text-align:center;background:none;' , 'tr' : 'border:0px none; border-bottom:1px solid #C0C0C0;' 'background:none;' , 'none' : 'border:0px none;background:none;' , } def _StyledSubElement ( parent , child ): return ET . SubElement ( parent , child , { 'style' : _html_style [ child ]}) ET . StyledSubElement = _StyledSubElement root = ET . Element ( 'div' ) pre = ET . SubElement ( root , 'p' ) ET . SubElement ( pre , 'code' ) . text = myMesh . __class__ . __name__ ET . SubElement ( pre , 'span' ) . text = \": \" ET . SubElement ( pre , 'b' ) . text = myMesh . label or \"Label\" ET . SubElement ( pre , 'span' ) . text = \" [ {} ]\" . format ( myMesh . unit or \"unit\" ) ET . SubElement ( pre , 'br' ) res = ET . SubElement ( pre , 'p' ) if myMesh . size == 1 : res . text = str ( myMesh ) else : table = ET . StyledSubElement ( res , 'table' ) tbody = ET . SubElement ( table , 'tbody' ) for _i in range ( 2 ): if not _i : tr = ET . StyledSubElement ( tbody , 'tr' ) for _node in islice ( np . arange ( len ( myMesh )), max_rows - 1 ): ET . StyledSubElement ( tr , 'th' ) . text = str ( _node ) if len ( myMesh ) > max_rows : ET . StyledSubElement ( tr , 'th' ) . text = \"...\" ET . StyledSubElement ( tr , 'th' ) . text = str ( len ( myMesh ) - 1 ) elif len ( myMesh ) > max_rows - 1 : ET . StyledSubElement ( tr , 'th' ) . text = str ( len ( myMesh ) - 1 ) else : tr = ET . SubElement ( tbody , 'tr' , { 'style' : 'border: 0px solid' }) for _node in islice ( myMesh , max_rows - 1 ): ET . SubElement ( tr , 'td' ) . text = str ( _node ) if len ( myMesh ) > max_rows : ET . SubElement ( tr , 'td' ) . text = \"...\" ET . SubElement ( tr , 'td' ) . text = str ( myMesh [ - 1 ]) elif len ( myMesh ) > max_rows - 1 : ET . SubElement ( tr , 'td' ) . text = str ( myMesh [ - 1 ]) return str ( ET . tostring ( root , encoding = 'utf-8' ), 'utf-8' ) % timeit bench_ET () 747 \u00b5s \u00b1 16.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) HTML ( bench_ET ()) BreakPoints : Label [unit] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 ... 19 0 10 20 30 40 50 60 70 80 90 100 110 120 130 ... 190 soup = bs4 . BeautifulSoup ( '<div/>' , 'html.parser' ) soup . div . append ( soup . new_tag ( name = 'p' )) soup . div . p . append ( soup . new_tag ( name = 'code' )) soup . div . p . code . string = myMesh . __class__ . __name__ soup . div . p . append ( soup . new_tag ( name = 'span' )) soup . div . span . string = \": \" soup . div . p . append ( soup . new_tag ( name = 'b' )) soup . div . b . string = myMesh . label or \"Label\" soup . div . p . append ( soup . new_tag ( name = 'span' )) soup . div . span #1].string = \" [{}]\".format(myMesh.unit or \"unit\") #soup <span>: </span> span = ET . SubElement ( pre , 'span' ) span . text = \" [ {} ]\" . format ( myMesh . unit or \"unit\" ) ET . SubElement ( pre , 'br' ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-1-5d0c173f600c> in <module> () ----> 1 get_ipython ( ) . run_cell_magic ( 'timeit' , '' , 'pre = ET.SubElement(root, \\'p\\')\\ncode = ET.SubElement(pre, \\'code\\')\\ncode.text = myMesh.__class__.__name__\\nspan = ET.SubElement(pre, \\'span\\').text = \": \"\\nb = ET.SubElement(pre, \\'b\\')\\nb.text = myMesh.label or \"Label\"\\nspan = ET.SubElement(pre, \\'span\\')\\nspan.text = \" [{}]\".format(myMesh.unit or \"unit\")\\nET.SubElement(pre, \\'br\\')' ) ~/Documents/Developpement/python/anaconda/anaconda3-5.0.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell_magic (self, magic_name, line, cell) 2101 magic_arg_s = self . var_expand ( line , stack_depth ) 2102 with self . builtin_trap : -> 2103 result = fn ( magic_arg_s , cell ) 2104 return result 2105 <decorator-gen-61> in timeit (self, line, cell) ~/Documents/Developpement/python/anaconda/anaconda3-5.0.0/lib/python3.6/site-packages/IPython/core/magic.py in <lambda> (f, *a, **k) 185 # but it's overkill for just that one bit of state. 186 def magic_deco ( arg ) : --> 187 call = lambda f , * a , ** k : f ( * a , ** k ) 188 189 if callable ( arg ) : ~/Documents/Developpement/python/anaconda/anaconda3-5.0.0/lib/python3.6/site-packages/IPython/core/magics/execution.py in timeit (self, line, cell) 1078 for index in range ( 0 , 10 ) : 1079 number = 10 ** index -> 1080 time_number = timer . timeit ( number ) 1081 if time_number >= 0.2 : 1082 break ~/Documents/Developpement/python/anaconda/anaconda3-5.0.0/lib/python3.6/site-packages/IPython/core/magics/execution.py in timeit (self, number) 158 gc . disable ( ) 159 try : --> 160 timing = self . inner ( it , self . timer ) 161 finally : 162 if gcold : <magic-timeit> in inner (_it, _timer) NameError : name 'ET' is not defined div . append ( soup . new_tag ( name = 'table' )) soup <div><table></table></div>","title":"ElementTree"},{"location":"python/IterGen/","text":"Iterators, generators and coroutines \u00b6 Python standard library: Itertools David Beazley's PyCon'14 presentation","title":"Iterators, generators and coroutines"},{"location":"python/IterGen/#iterators-generators-and-coroutines","text":"Python standard library: Itertools David Beazley's PyCon'14 presentation","title":"Iterators, generators and coroutines"},{"location":"python/Lazy%20classes/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); # https://stackoverflow.com/questions/2496930 class Base ( object ): def _lazy_eval ( self , attr ): #Do complex stuff here return attr def lazyclass ( cls ): for attr in cls . _myattrs : setattr ( cls , attr , property ( lambda self : self . _lazy_eval ( attr ))) return cls @lazyclass class Child ( Base ): _myattrs = [ 'foo' , 'bar' ] class Child ( Base ): _myattrs = [ 'foo' , 'bar' ] Child = lazyclass ( Child ) Child . foo <property at 0x180bf1f548> class LazyMeta ( type ): def __init__ ( cls , name , bases , attr ): super ( LazyMeta , cls ) . __init__ ( name , bases , attr ) def prop ( x ): return property ( lambda self : self . _lazy_eval ( x )) for x in attr [ 'lazyattrs' ]: setattr ( cls , x , prop ( x )) class Base ( metaclass = LazyMeta ): lazyattrs = [] def _lazy_eval ( self , attr ): #Do complex stuff here return attr class Child ( Base ): lazyattrs = [ 'foo' , 'bar' ] me = Child () print ( me . bar ) bar class Mesh ( object ): def __new__ ( cls , * pargs , ** kwargs ): cls . axes = set ( \"xyzvw\" ) & set ( kwargs ) cls . ndim = len ( cls . axes ) cls . _options = { \"extrapolate\" : True , \"step\" : False , \"deepcopy\" : False } def get_value ( self , axis = None ): # if \"_NDTable\" in self.__dict__: # del self._NDTable return getattr ( self , f \"_ { axis } \" ) def set_value ( self , value , axis = None ): obj = getattr ( self , f \"_ { axis } \" ) setattr ( self , f \"_ { axis } \" , obj . __class__ ( value , ** obj . __dict__ )) def setd ( self , obj ): self . _d = obj cls . d = property ( fget = partial ( get_value , axis = \"d\" ), fset = setd ) for axe in cls . axes : print ( f \"Got : { axe } -> { kwargs [ axe ] } \" ) setattr ( cls , f \"_ { axe } \" , BreakPoints ( kwargs [ axe ])) setattr ( cls , axe , property ( fget = partial ( get_value , axis = axe ), fset = partial ( set_value , axis = axe ))) # dynamicaly write special methods setattr ( cls , \"__neg__\" , lambda self : self . __class__ ( ** { ax : getattr ( self , f \"_ { ax } \" ) for ax in cls . axes }, d =- self . d , label = cls . label , unit = self . unit )) for method in [ \"argmax\" , \"argmin\" , \"unique\" , \"min\" , \"max\" , \"mean\" , \"median\" ]: setattr ( cls , method , lambda cls , * args , ** kwargs : getattr ( np , method )( cls . _d , * args , ** kwargs )) if cls . axes : if \"_d\" not in dir ( cls ): cls . _d = np . zeros ([ len ( getattr ( cls , f \"_ { axe } \" )) for axe in cls . axes ]) return cls class lazy ( object ): # This class is heavily inspired by the werkzeug.utils.cached_property # decorator. It transforms a class method to a lazy property, evaluated # the first time the property is accessed. _missing = object def __init__ ( self , func , name = None ): self . __name__ = name or func . __name__ self . __module__ = func . __module__ self . __doc__ = func . __doc__ self . func = func def __get__ ( self , instance , type = None ): if instance is None : return self value = instance . __dict__ . get ( self . __name__ , self . _missing ) if value is self . _missing : value = self . func ( instance ) instance . __dict__ [ self . __name__ ] = value return value class WrapperBase ( type ): # This metaclass is heavily inspired by the Object Proxying python recipe # (http://code.activestate.com/recipes/496741/). It adds special methods # to the wrapper class so it can proxy the wrapped class. In addition, it # adds a field __overrides__ in the wrapper class dictionary, containing # all attributes decorated to be overriden. _special_names = [ '__abs__' , '__add__' , '__and__' , '__call__' , '__cmp__' , '__coerce__' , '__contains__' , '__delitem__' , '__delslice__' , '__div__' , '__divmod__' , '__eq__' , '__float__' , '__floordiv__' , '__ge__' , '__getitem__' , '__getslice__' , '__gt__' , '__hash__' , '__hex__' , '__iadd__' , '__iand__' , '__idiv__' , '__idivmod__' , '__ifloordiv__' , '__ilshift__' , '__imod__' , '__imul__' , '__int__' , '__invert__' , '__ior__' , '__ipow__' , '__irshift__' , '__isub__' , '__iter__' , '__itruediv__' , '__ixor__' , '__le__' , '__len__' , '__long__' , '__lshift__' , '__lt__' , '__mod__' , '__mul__' , '__ne__' , '__neg__' , '__oct__' , '__or__' , '__pos__' , '__pow__' , '__radd__' , '__rand__' , '__rdiv__' , '__rdivmod__' , '__reduce__' , '__reduce_ex__' , '__repr__' , '__reversed__' , '__rfloorfiv__' , '__rlshift__' , '__rmod__' , '__rmul__' , '__ror__' , '__rpow__' , '__rrshift__' , '__rshift__' , '__rsub__' , '__rtruediv__' , '__rxor__' , '__setitem__' , '__setslice__' , '__sub__' , '__truediv__' , '__xor__' , 'next' , ] def __new__ ( cls , classname , bases , attrs ): def make_method ( name ): def method ( self , * args , ** kwargs ): mtd = getattr ( object . __getattribute__ ( self , \"_wrapped\" ), name ) return mtd ( * args , ** kwargs ) return method for name in cls . _special_names : attrs [ name ] = make_method ( name ) overrides = attrs . get ( '__overrides__' , []) overrides . extend ( k for k , v in attrs . items () if isinstance ( v , lazy )) attrs [ '__overrides__' ] = overrides return type . __new__ ( cls , classname , bases , attrs ) class Wrapper ( metaclass = WrapperBase ): # This class acts as a proxy for the wrapped instance it is passed. All # access to its attributes are delegated to the wrapped class, except # those contained in __overrides__. __slots__ = [ '_wrapped' , '__weakref__' ] def __init__ ( self , wrapped ): object . __setattr__ ( self , '_wrapped' , wrapped ) def __getattribute__ ( self , attr ): if attr in object . __getattribute__ ( self , '__overrides__' ): return object . __getattribute__ ( self , attr ) # If the requested attribute wasn't overriden, then we delegate to # the wrapped class. return getattr ( object . __getattribute__ ( self , '_wrapped' ), attr ) def __setattr__ ( self , attr , value ): setattr ( object . __getattribute__ ( self , '_wrapped' ), attr , value ) def __nonzero__ ( self ): return bool ( object . __getattribute__ ( self , '_wrapped' )) def __str__ ( self ): return str ( object . __getattribute__ ( self , '_wrapped' )) def __repr__ ( self ): return repr ( object . __getattribute__ ( self , '_wrapped' )) # ============================================================================= class MyClass ( object ): def __init__ ( self , foo = None , bar = None ): self . setattr_unless_none ( 'foo' , foo ) self . setattr_unless_none ( 'bar' , bar ) def setattr_unless_none ( self , name , value ): if value is not None : setattr ( self , name , value ) def __lt__ ( self , rhs ): return id ( self ) < id ( rhs ) class MyWrapper ( Wrapper ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( MyClass ( * args , ** kwargs )) @lazy def foo ( self ): return 'lazy evaluated' a = MyWrapper () b = MyWrapper ( foo = 'defined in kwargs' ) print ( a . foo ) # prints \"lazy evaluated\" print ( b . foo ) # prints \"defined in kwargs\" print ( a < b ) # prints id(a) < id(b) lazy evaluated defined in kwargs False","title":"Lazy classes"},{"location":"python/Tutorial_trio/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Documentation at https://trio.readthedocs.io/en/latest/tutorial.html # A regular function def regular_double ( x ): return 2 * x # An async function async def async_double ( x ): return 2 * x async def print_double ( x ): print ( await async_double ( x )) # <-- OK! % pip install trio Collecting trio Downloading https://files.pythonhosted.org/packages/ae/0a/3b6080c2aeeeef0e0133dd0f3df50601e1cd4edd9b44f3e1d66f40cd7154/trio-0.13.0-py3-none-any.whl (320kB) |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 327kB 522kB/s eta 0:00:01 Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from trio) (19.3.0) Requirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from trio) (2.8) Collecting outcome Downloading https://files.pythonhosted.org/packages/ff/c7/c4ac99243794a6159ae9335bb26b021e104215390e12e95e40d51007c79b/outcome-1.0.1-py2.py3-none-any.whl Requirement already satisfied: async-generator>=1.9 in /opt/conda/lib/python3.7/site-packages (from trio) (1.10) Collecting sniffio Downloading https://files.pythonhosted.org/packages/b3/82/4bd4b7d9c0d1dc0fbfbc2a1e00138e7f3ab85bc239358fe9b78aa2ab586d/sniffio-1.1.0-py3-none-any.whl Requirement already satisfied: sortedcontainers in /opt/conda/lib/python3.7/site-packages (from trio) (2.1.0) Installing collected packages: outcome, sniffio, trio Successfully installed outcome-1.0.1 sniffio-1.1.0 trio-0.13.0 Note: you may need to restart the kernel to use updated packages. import trio async def async_double ( x ): return 2 * x trio . run ( async_double , 3 ) # returns 6 6 import trio async def double_sleep ( x ): await trio . sleep ( 2 * x ) trio . run ( double_sleep , 3 ) print ( \"Waiting\" ) Waiting % pip install -- pre jupyterlab Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.7/site-packages (1.2.4) Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.7/site-packages (from jupyterlab) (2.10.3) Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in /opt/conda/lib/python3.7/site-packages (from jupyterlab) (6.0.3) Requirement already satisfied: notebook>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from jupyterlab) (6.0.0) Requirement already satisfied: jupyterlab-server~=1.0.0 in /opt/conda/lib/python3.7/site-packages (from jupyterlab) (1.0.6) Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2>=2.10->jupyterlab) (1.1.1) Requirement already satisfied: traitlets>=4.2.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (4.3.3) Requirement already satisfied: ipykernel in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (5.1.3) Requirement already satisfied: nbformat in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (4.4.0) Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (0.7.1) Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (18.1.1) Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (0.8.3) Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (5.6.1) Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (0.2.0) Requirement already satisfied: jupyter-core>=4.4.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (4.6.1) Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (1.5.0) Requirement already satisfied: jupyter-client>=5.3.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.3.1->jupyterlab) (5.3.3) Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from jupyterlab-server~=1.0.0->jupyterlab) (3.2.0) Requirement already satisfied: json5 in /opt/conda/lib/python3.7/site-packages (from jupyterlab-server~=1.0.0->jupyterlab) (0.8.5) Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab) (1.13.0) Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab) (4.4.1) Requirement already satisfied: ipython>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->notebook>=4.3.1->jupyterlab) (7.10.1) Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.8.4) Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (3.1.0) Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (1.4.2) Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.3) Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.6.0) Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (2.5.2) Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.4.4) Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.3.1->notebook>=4.3.1->jupyterlab) (2.8.1) Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (0.15.6) Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (42.0.2.post20191201) Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (19.3.0) Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (1.3.0) Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (3.0.2) Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.7.5) Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.15.2) Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (4.7.0) Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.1.0) Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab) (0.5.1) Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (0.6.0) Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.1.7) Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.5.2) Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.6.0) Requirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (8.0.2) Note: you may need to restart the kernel to use updated packages. zae = 4 import asyncio import random import time async def worker ( name , queue ): while True : # Get a \"work item\" out of the queue. sleep_for = await queue . get () # Sleep for the \"sleep_for\" seconds. await asyncio . sleep ( sleep_for ) # Notify the queue that the \"work item\" has been processed. queue . task_done () print ( f ' { name } has slept for { sleep_for : .2f } seconds' ) # Create a queue that we will use to store our \"workload\". queue = asyncio . Queue () # Generate random timings and put them into the queue. total_sleep_time = 0 for _ in range ( 20 ): sleep_for = random . uniform ( 0.05 , 1.0 ) total_sleep_time += sleep_for queue . put_nowait ( sleep_for ) # Create three worker tasks to process the queue concurrently. tasks = [] for i in range ( 3 ): task = asyncio . create_task ( worker ( f 'worker- { i } ' , queue )) tasks . append ( task ) # Wait until the queue is fully processed. started_at = time . monotonic () await queue . join () total_slept_for = time . monotonic () - started_at # Cancel our worker tasks. for task in tasks : task . cancel () # Wait until all worker tasks are cancelled. await asyncio . gather ( * tasks , return_exceptions = True ) print ( '====' ) print ( f '3 workers slept in parallel for { total_slept_for : .2f } seconds' ) print ( f 'total expected sleep time: { total_sleep_time : .2f } seconds' ) worker-0 has slept for 0.06 seconds worker-2 has slept for 0.47 seconds worker-1 has slept for 0.53 seconds worker-2 has slept for 0.19 seconds worker-2 has slept for 0.06 seconds worker-0 has slept for 0.73 seconds worker-1 has slept for 0.28 seconds worker-2 has slept for 0.20 seconds worker-0 has slept for 0.60 seconds worker-1 has slept for 0.60 seconds worker-2 has slept for 0.60 seconds worker-0 has slept for 0.24 seconds worker-1 has slept for 0.65 seconds worker-0 has slept for 0.75 seconds worker-2 has slept for 0.90 seconds worker-1 has slept for 0.44 seconds worker-1 has slept for 0.25 seconds worker-2 has slept for 0.55 seconds worker-0 has slept for 0.64 seconds worker-1 has slept for 0.65 seconds ==== 3 workers slept in parallel for 3.40 seconds total expected sleep time: 9.41 seconds","title":"Tutorial trio"},{"location":"python/asyncio/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Objects \u00b6 Awaitable objects - Coroutines , Tasks , and Futures - can be used in an await expression. Coroutines \u00b6 Computer program components that generalize subroutines for non-preemptive multitasking, by allowing execution to be suspended and resumed ( Wikipedia ) Coroutines vs threads Coroutines are very similar to threads. However, coroutines are cooperatively multitasked, whereas threads are typically preemptively multitasked. This means that coroutines provide concurrency but not parallelism. [...] There is no need for synchronisation primitives such as mutexes, semaphores, etc. in order to guard critical sections, and there is no need for support from the operating system. Source: Wikipedia Python Coroutines run in an event loop . Coroutines are a backbone of asyncio and third party async frameworks like Curio or trio Tasks (and Futures) \u00b6 Futures represent a placeholder for an action that return a result (or not). Tasks are a subclass of Futures . Tasks wraps Coroutines and are used to schedule coroutines concurrently. They are created with asyncio.create_task() or by wrapping a Future object with asyncio.ensure_future() Danger Future doesn't necessarily wrap a coroutine. e.g.: loop.create_future() creates a Future, future.set_result(result) sets its results. Such a future can be awaited by a coroutine, or even run using loop.run_until_complete(future) , but there is no coroutine behind it. Source: http://disq.us/p/1r7l8th Event loops use cooperative scheduling: an event loop runs one Task at a time. If a coroutine awaits on a Future, the Task suspends the execution of the coroutine and waits for the completion of the Future, the event loop runs meanwhile other Tasks, callbacks, or performs IO operations. When the Future is done, the execution of the wrapped coroutine resumes. Both are not thread-safe. Execution \u00b6 Event loop \u00b6","title":"ASyncio"},{"location":"python/asyncio/#objects","text":"Awaitable objects - Coroutines , Tasks , and Futures - can be used in an await expression.","title":"Objects"},{"location":"python/asyncio/#coroutines","text":"Computer program components that generalize subroutines for non-preemptive multitasking, by allowing execution to be suspended and resumed ( Wikipedia ) Coroutines vs threads Coroutines are very similar to threads. However, coroutines are cooperatively multitasked, whereas threads are typically preemptively multitasked. This means that coroutines provide concurrency but not parallelism. [...] There is no need for synchronisation primitives such as mutexes, semaphores, etc. in order to guard critical sections, and there is no need for support from the operating system. Source: Wikipedia Python Coroutines run in an event loop . Coroutines are a backbone of asyncio and third party async frameworks like Curio or trio","title":"Coroutines"},{"location":"python/asyncio/#tasks-and-futures","text":"Futures represent a placeholder for an action that return a result (or not). Tasks are a subclass of Futures . Tasks wraps Coroutines and are used to schedule coroutines concurrently. They are created with asyncio.create_task() or by wrapping a Future object with asyncio.ensure_future() Danger Future doesn't necessarily wrap a coroutine. e.g.: loop.create_future() creates a Future, future.set_result(result) sets its results. Such a future can be awaited by a coroutine, or even run using loop.run_until_complete(future) , but there is no coroutine behind it. Source: http://disq.us/p/1r7l8th Event loops use cooperative scheduling: an event loop runs one Task at a time. If a coroutine awaits on a Future, the Task suspends the execution of the coroutine and waits for the completion of the Future, the event loop runs meanwhile other Tasks, callbacks, or performs IO operations. When the Future is done, the execution of the wrapped coroutine resumes. Both are not thread-safe.","title":"Tasks (and Futures)"},{"location":"python/asyncio/#execution","text":"","title":"Execution"},{"location":"python/asyncio/#event-loop","text":"","title":"Event loop"},{"location":"python/asyncio/","text":"Objects \u00b6 Awaitable objects - Coroutines , Tasks , and Futures - can be used in an await expression. Coroutines \u00b6 Computer program components that generalize subroutines for non-preemptive multitasking, by allowing execution to be suspended and resumed ( Wikipedia ) Coroutines vs threads Coroutines are very similar to threads. However, coroutines are cooperatively multitasked, whereas threads are typically preemptively multitasked. This means that coroutines provide concurrency but not parallelism. [...] There is no need for synchronisation primitives such as mutexes, semaphores, etc. in order to guard critical sections, and there is no need for support from the operating system. Source: Wikipedia Python Coroutines run in an event loop . Coroutines are a backbone of asyncio and third party async frameworks like Curio or trio Tasks (and Futures) \u00b6 Futures represent a placeholder for an action that return a result (or not). Tasks are a subclass of Futures . Tasks wraps Coroutines and are used to schedule coroutines concurrently. They are created with asyncio.create_task() or by wrapping a Future object with asyncio.ensure_future() Danger Future doesn't necessarily wrap a coroutine. e.g.: loop.create_future() creates a Future, future.set_result(result) sets its results. Such a future can be awaited by a coroutine, or even run using loop.run_until_complete(future) , but there is no coroutine behind it. Source: http://disq.us/p/1r7l8th Event loops use cooperative scheduling: an event loop runs one Task at a time. If a coroutine awaits on a Future, the Task suspends the execution of the coroutine and waits for the completion of the Future, the event loop runs meanwhile other Tasks, callbacks, or performs IO operations. When the Future is done, the execution of the wrapped coroutine resumes. Both are not thread-safe. Execution \u00b6 Event loop \u00b6","title":"Asyncio"},{"location":"python/asyncio/#objects","text":"Awaitable objects - Coroutines , Tasks , and Futures - can be used in an await expression.","title":"Objects"},{"location":"python/asyncio/#coroutines","text":"Computer program components that generalize subroutines for non-preemptive multitasking, by allowing execution to be suspended and resumed ( Wikipedia ) Coroutines vs threads Coroutines are very similar to threads. However, coroutines are cooperatively multitasked, whereas threads are typically preemptively multitasked. This means that coroutines provide concurrency but not parallelism. [...] There is no need for synchronisation primitives such as mutexes, semaphores, etc. in order to guard critical sections, and there is no need for support from the operating system. Source: Wikipedia Python Coroutines run in an event loop . Coroutines are a backbone of asyncio and third party async frameworks like Curio or trio","title":"Coroutines"},{"location":"python/asyncio/#tasks-and-futures","text":"Futures represent a placeholder for an action that return a result (or not). Tasks are a subclass of Futures . Tasks wraps Coroutines and are used to schedule coroutines concurrently. They are created with asyncio.create_task() or by wrapping a Future object with asyncio.ensure_future() Danger Future doesn't necessarily wrap a coroutine. e.g.: loop.create_future() creates a Future, future.set_result(result) sets its results. Such a future can be awaited by a coroutine, or even run using loop.run_until_complete(future) , but there is no coroutine behind it. Source: http://disq.us/p/1r7l8th Event loops use cooperative scheduling: an event loop runs one Task at a time. If a coroutine awaits on a Future, the Task suspends the execution of the coroutine and waits for the completion of the Future, the event loop runs meanwhile other Tasks, callbacks, or performs IO operations. When the Future is done, the execution of the wrapped coroutine resumes. Both are not thread-safe.","title":"Tasks (and Futures)"},{"location":"python/asyncio/#execution","text":"","title":"Execution"},{"location":"python/asyncio/#event-loop","text":"","title":"Event loop"},{"location":"python/click/","text":"Click \u00b6 Click is a Python package for creating command line interfaces in a composable way with as little code as necessary. Decorator based functionality \u00b6 Commands and groups \u00b6 A hierarchy of command and subcommands can be achieved with @click.command and @click.group . Both decorates a function and use it as callback. When using a function as group and latter on an other as command, the last one will be decorated with the first one that inherits from click . Example import click @click . group () @click . version_option () def acl (): \"\"\"Asam Command Line.\"\"\" ... @acl . group () def mdf (): \"\"\"Manages mdf and is called with `acl mdf`\"\"\" ... @mdf . group () def create (): \"\"\"Create mdf and is called with `acl mdf create`\"\"\" ... Parameters \u00b6 parameters are of two types: options , usually optional passed with or without value as flags, e.g. --debug : @click.option('--debug/--no-debug', default=False) arguments : are positional parameters to a command, generally provide fewer features than options but can have infinite nargs and are required by default. Ex: @click.argument(\"x\", type=float) API \u00b6 Decorators \u00b6 click .command( name=None, cls=None, **attrs ) click .group( name=None, **attrs ) click .argument( *param_decls, **attrs ) click .option( *param_decls, **attrs ) click .password_option( *param_decls, **attrs ) click .confirmation_option( *param_decls, **attrs ) click .version_option( version=None, *param_decls, **attrs ) click .help_option( *param_decls, **attrs ) click .pass_context( f ) click .pass_obj( f ) click .make_pass_decorator( object_type, ensure=False ) Utilities \u00b6 click .echo( message=None, file=None, nl=True, err=False, color=None ) click .echo_via_pager( text_or_generator, color=None ) click .prompt( text, default=None, hide_input=False, confirmation_prompt=False, type=None, value_proc=None, prompt_suffix=': ', show_default=True, err=False, show_choices=True ) click .confirm( text, default=False, abort=False, prompt_suffix=': ', show_default=True, err=False ) click .progressbar( iterable=None, length=None, label=None, show_eta=True, show_percent=None, show_pos=False, item_show_func=None, fill_char='#', empty_char='-', bar_template='%(label ) [%(bar)s] %(info)s', info_sep=' ', width=36, file=None, color=None)\u00b6 click .clear() click .style( text, fg=None, bg=None, bold=None, dim=None, underline=None, blink=None, reverse=None, reset=True ) click .unstyle( text ) click .secho( message=None, file=None, nl=True, err=False, color=None, **styles ) click .edit( text=None, editor=None, env=None, require_save=True, extension='.txt', filename=None ) click .launch( url, wait=False, locate=False ) click .getchar( echo=False ) click .pause( info='Press any key to continue ...', err=False ) click .get_terminal_size() click .get_binary_stream( name ) click .get_text_stream( name, encoding=None, errors='strict' ) click .open_file( filename, mode='r', encoding=None, errors='strict', lazy=False, atomic=False ) click .get_app_dir( app_name, roaming=True, force_posix=False ) click .format_filename( filename, shorten=False )","title":"Click"},{"location":"python/click/#click","text":"Click is a Python package for creating command line interfaces in a composable way with as little code as necessary.","title":"Click"},{"location":"python/click/#decorator-based-functionality","text":"","title":"Decorator based functionality"},{"location":"python/click/#commands-and-groups","text":"A hierarchy of command and subcommands can be achieved with @click.command and @click.group . Both decorates a function and use it as callback. When using a function as group and latter on an other as command, the last one will be decorated with the first one that inherits from click . Example import click @click . group () @click . version_option () def acl (): \"\"\"Asam Command Line.\"\"\" ... @acl . group () def mdf (): \"\"\"Manages mdf and is called with `acl mdf`\"\"\" ... @mdf . group () def create (): \"\"\"Create mdf and is called with `acl mdf create`\"\"\" ...","title":"Commands and groups"},{"location":"python/click/#parameters","text":"parameters are of two types: options , usually optional passed with or without value as flags, e.g. --debug : @click.option('--debug/--no-debug', default=False) arguments : are positional parameters to a command, generally provide fewer features than options but can have infinite nargs and are required by default. Ex: @click.argument(\"x\", type=float)","title":"Parameters"},{"location":"python/click/#api","text":"","title":"API"},{"location":"python/click/#decorators","text":"click .command( name=None, cls=None, **attrs ) click .group( name=None, **attrs ) click .argument( *param_decls, **attrs ) click .option( *param_decls, **attrs ) click .password_option( *param_decls, **attrs ) click .confirmation_option( *param_decls, **attrs ) click .version_option( version=None, *param_decls, **attrs ) click .help_option( *param_decls, **attrs ) click .pass_context( f ) click .pass_obj( f ) click .make_pass_decorator( object_type, ensure=False )","title":"Decorators"},{"location":"python/click/#utilities","text":"click .echo( message=None, file=None, nl=True, err=False, color=None ) click .echo_via_pager( text_or_generator, color=None ) click .prompt( text, default=None, hide_input=False, confirmation_prompt=False, type=None, value_proc=None, prompt_suffix=': ', show_default=True, err=False, show_choices=True ) click .confirm( text, default=False, abort=False, prompt_suffix=': ', show_default=True, err=False ) click .progressbar( iterable=None, length=None, label=None, show_eta=True, show_percent=None, show_pos=False, item_show_func=None, fill_char='#', empty_char='-', bar_template='%(label ) [%(bar)s] %(info)s', info_sep=' ', width=36, file=None, color=None)\u00b6 click .clear() click .style( text, fg=None, bg=None, bold=None, dim=None, underline=None, blink=None, reverse=None, reset=True ) click .unstyle( text ) click .secho( message=None, file=None, nl=True, err=False, color=None, **styles ) click .edit( text=None, editor=None, env=None, require_save=True, extension='.txt', filename=None ) click .launch( url, wait=False, locate=False ) click .getchar( echo=False ) click .pause( info='Press any key to continue ...', err=False ) click .get_terminal_size() click .get_binary_stream( name ) click .get_text_stream( name, encoding=None, errors='strict' ) click .open_file( filename, mode='r', encoding=None, errors='strict', lazy=False, atomic=False ) click .get_app_dir( app_name, roaming=True, force_posix=False ) click .format_filename( filename, shorten=False )","title":"Utilities"},{"location":"python/collections/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); collections \u2014 Container datatypes \u00b6 namedtuple() factory function for creating tuple subclasses with named fields deque list-like container with fast appends and pops on either end ChainMap dict-like class for creating a single view of multiple mappings Counter dict subclass for counting hashable objects OrderedDict dict subclass that remembers the order entries were added defaultdict dict subclass that calls a factory function to supply missing values UserDict wrapper around dictionary objects for easier dict subclassing UserList wrapper around list objects for easier list subclassing UserString wrapper around string objects for easier string subclassing ChainMap objects \u00b6 A ChainMap class is provided for quickly linking a number of mappings so they can be treated as a single unit. It is often much faster than creating a new dictionary and running multiple update() calls. from collections import ChainMap d1 = { 'a' : 10 , 'b' : 20 , 'c' : 30 } d2 = { 'a' : 15 , 'd' : 50 } cm = ChainMap ( d1 , d2 ) cm ChainMap({'a': 10, 'b': 20, 'c': 30}, {'a': 15, 'd': 50}) cm . keys () KeysView(ChainMap({'a': 10, 'b': 20, 'c': 30}, {'a': 15, 'd': 50}))","title":"Collections"},{"location":"python/collections/#collections-container-datatypes","text":"namedtuple() factory function for creating tuple subclasses with named fields deque list-like container with fast appends and pops on either end ChainMap dict-like class for creating a single view of multiple mappings Counter dict subclass for counting hashable objects OrderedDict dict subclass that remembers the order entries were added defaultdict dict subclass that calls a factory function to supply missing values UserDict wrapper around dictionary objects for easier dict subclassing UserList wrapper around list objects for easier list subclassing UserString wrapper around string objects for easier string subclassing","title":"collections \u2014 Container datatypes"},{"location":"python/collections/#chainmap-objects","text":"A ChainMap class is provided for quickly linking a number of mappings so they can be treated as a single unit. It is often much faster than creating a new dictionary and running multiple update() calls. from collections import ChainMap d1 = { 'a' : 10 , 'b' : 20 , 'c' : 30 } d2 = { 'a' : 15 , 'd' : 50 } cm = ChainMap ( d1 , d2 ) cm ChainMap({'a': 10, 'b': 20, 'c': 30}, {'a': 15, 'd': 50}) cm . keys () KeysView(ChainMap({'a': 10, 'b': 20, 'c': 30}, {'a': 15, 'd': 50}))","title":"ChainMap objects"},{"location":"python/itertools/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import collections tee \u00b6 A = range ( 10 ) it = iter ( A ) def tee ( iterable , n = 2 ): it = iter ( iterable ) deques = [ collections . deque () for i in range ( n )] def gen ( mydeque ): while True : if not mydeque : # when the local deque is empty try : newval = next ( it ) # fetch a new value and except StopIteration : return for d in deques : # load it to all the deques d . append ( newval ) yield mydeque . popleft () return tuple ( gen ( d ) for d in deques ) n = 2 deques = [ collections . deque () for i in range ( n )] def gen ( mydeque ): while True : if not mydeque : # when the local deque is empty try : newval = next ( it ) # fetch a new value and except StopIteration : return for d in deques : # load it to all the deques d . append ( newval ) yield mydeque . popleft () _gen = gen ( collections . deque ()) list ( tee ( A )) [<generator object tee.<locals>.gen at 0x30f19eb48>, <generator object tee.<locals>.gen at 0x30f19eaf0>]","title":"Itertools"},{"location":"python/itertools/#tee","text":"A = range ( 10 ) it = iter ( A ) def tee ( iterable , n = 2 ): it = iter ( iterable ) deques = [ collections . deque () for i in range ( n )] def gen ( mydeque ): while True : if not mydeque : # when the local deque is empty try : newval = next ( it ) # fetch a new value and except StopIteration : return for d in deques : # load it to all the deques d . append ( newval ) yield mydeque . popleft () return tuple ( gen ( d ) for d in deques ) n = 2 deques = [ collections . deque () for i in range ( n )] def gen ( mydeque ): while True : if not mydeque : # when the local deque is empty try : newval = next ( it ) # fetch a new value and except StopIteration : return for d in deques : # load it to all the deques d . append ( newval ) yield mydeque . popleft () _gen = gen ( collections . deque ()) list ( tee ( A )) [<generator object tee.<locals>.gen at 0x30f19eb48>, <generator object tee.<locals>.gen at 0x30f19eaf0>]","title":"tee"},{"location":"python/jupyter/","text":"Jupyter \u00b6 Introduction \u00b6 Jupyter Core contains base application classes and configuration inherited by other projects. The jupyter root command is defined here . Jupyter Client provides the Python API for starting, managing and communicating with Jupyter kernels Jupyter Server provides the backend (i.e. the core services, APIs, and REST endpoints) for Jupyter web applications like Jupyter notebook, JupyterLab, and Voila. Jupyterlab Server IPykernel Traitlets \u00b6 Traitlets is a framework that lets Python classes have attributes with type checking , dynamically calculated default values, and \u2018on change\u2019 callbacks ( observer pattern ). Traitlets defines its own classes, resp. support creation of user specific types but do not rely on python's typing system as e.g. pydantic Types ( C -prefixed type are casted): Numbers : Int (aliased as Integer ), Long , Float , Complex , CInt , CLong , CFloat , CComplex Strings : Unicode , Bytes , Cunicode , CBytes , ObjectName , DottedObjectName Containers : List , Set , Tuple , Dict Classes and Instances : Instance , Type , This , ForwardDeclaredInstance , ForwardDeclaredType Misc : Bool , CBool , Enum , CaselessStrEnum , UseEnum , TCPAddress , CRegExp , Union , Callable , Any Example Messaging in Jupyter \u00b6","title":"Jupyter"},{"location":"python/jupyter/#jupyter","text":"","title":"Jupyter"},{"location":"python/jupyter/#introduction","text":"Jupyter Core contains base application classes and configuration inherited by other projects. The jupyter root command is defined here . Jupyter Client provides the Python API for starting, managing and communicating with Jupyter kernels Jupyter Server provides the backend (i.e. the core services, APIs, and REST endpoints) for Jupyter web applications like Jupyter notebook, JupyterLab, and Voila. Jupyterlab Server IPykernel","title":"Introduction"},{"location":"python/jupyter/#traitlets","text":"Traitlets is a framework that lets Python classes have attributes with type checking , dynamically calculated default values, and \u2018on change\u2019 callbacks ( observer pattern ). Traitlets defines its own classes, resp. support creation of user specific types but do not rely on python's typing system as e.g. pydantic Types ( C -prefixed type are casted): Numbers : Int (aliased as Integer ), Long , Float , Complex , CInt , CLong , CFloat , CComplex Strings : Unicode , Bytes , Cunicode , CBytes , ObjectName , DottedObjectName Containers : List , Set , Tuple , Dict Classes and Instances : Instance , Type , This , ForwardDeclaredInstance , ForwardDeclaredType Misc : Bool , CBool , Enum , CaselessStrEnum , UseEnum , TCPAddress , CRegExp , Union , Callable , Any Example","title":"Traitlets"},{"location":"python/jupyter/#messaging-in-jupyter","text":"","title":"Messaging in Jupyter"},{"location":"python/plistlib/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); PList manual page %load_ext autoreload %autoreload 2 cd ~/ Documents / Developpement / gist / /Users/manu/Documents/Developpement/gist import SafariBookmarkEditor from os.path import ( expanduser , isfile ) _path = expanduser ( '/tmp/BookmarksCorrupt.plist' ) _path _path = expanduser ( '/tmp/Bookmarks.plist' ) if not isfile ( _path ): print ( \"Bookmarks.plist doesn't appear to exist.\" \"Generating new Bookmarks.plist.\" ) import plistlib from plistlib import InvalidFileException with open(_path, 'rb') as plist: plist = plistlib.load(plist) plist['Children'] bmks = SafariBookmarkEditor . SafariBookmarks () bmks . read () bmks.add(\"myWebsite\", \"http://www.mywebsite.com\") bmks . titles ['p', 'MaDoc', 'Le Monde', 'Zeit', 'Arte', 'France Culture', 'Wetter Stuttgart', 'L\u00e9o\\xa0F-D', 'FRITZ!Box'] import datetime import json def datetime_handler ( x ): if isinstance ( x , datetime . datetime ): return x . isoformat () raise TypeError ( \"Unknown type\" ) data = json . dumps ( bmks . plist , default = datetime_handler ) ! ls SafariBookmarkEditor.py SafariBookmarksViewer.html SafariBookmarks.json __pycache__ with open ( 'SafariBookmarks.json' , 'w' ) as outfile : json . dump ( bmks . plist , outfile , default = datetime_handler ) from IPython.display import Javascript %% javascript require . config ({ paths : { d3 : '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min' }, }); var element = $('#a172b431-d2f4-4729-bc73-d3d71a8883af'); require.config({ paths: { d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min' }, }); %% javascript require ([ 'd3' ], function ( d3 ){ //a weird idempotency thing $ ( \"#chart1\" ). remove (); //create canvas element . append ( \"<div id='chart1'></div>\" ); $ ( \"#chart1\" ). width ( \"660px\" ); $ ( \"#chart1\" ). height ( \"600px\" ); var margin = { top : 20 , right : 20 , bottom : 30 , left : 40 }; var width = 880 - margin . left - margin . right ; var height = 500 - margin . top - margin . bottom ; var svg = d3 . select ( \"#chart1\" ). append ( \"svg\" ) . style ( \"position\" , \"relative\" ) . style ( \"max-width\" , \"960px\" ) . attr ( \"width\" , width + \"px\" ) . attr ( \"height\" , ( height + 50 ) + \"px\" ) . append ( \"g\" ) . attr ( \"transform\" , \"translate(\" + margin . left + \",\" + margin . top + \")\" ); //set data var data = convertPlotData ( window . headwayVsRidership ); var xVals = function ( d ){ return d . purpleHeadway ;}; var yVals = function ( d ){ return d . purpleAverage ;}; var xScale = d3 . scale . linear (). range ([ 0 , width ]); var xAxis = d3 . svg . axis (). scale ( xScale ). orient ( \"bottom\" ); var xMap = function ( d ) { return xScale ( xVals ( d ));}; var yScale = d3 . scale . linear (). range ([ height , 0 ]); var yAxis = d3 . svg . axis (). scale ( yScale ). orient ( \"left\" ); var yMap = function ( d ) { return yScale ( yVals ( d ));}; xScale . domain ([ d3 . min ( data , xVals ) - 1 , d3 . max ( data , xVals ) + 1 ]); yScale . domain ([ d3 . min ( data , yVals ) - 1 , d3 . max ( data , yVals ) + 1 ]); var cValue = function ( d ) { if ( d . day == \"Saturday\" || d . day == \"Sunday\" ){ return \"Weekend\" ; } return \"Weekday\" ; } var color = d3 . scale . category10 (); // x-axis svg . append ( \"g\" ) . attr ( \"class\" , \"x axis\" ) . attr ( \"transform\" , \"translate(0,\" + height + \")\" ) . call ( xAxis ) . append ( \"text\" ) . attr ( \"class\" , \"label\" ) . attr ( \"x\" , width - 80 ) . attr ( \"y\" , - 15 ) . style ( \"text-anchor\" , \"end\" ) . text ( \"Average Headway\" ); // y-axis svg . append ( \"g\" ) . attr ( \"class\" , \"y axis\" ) . call ( yAxis ) . append ( \"text\" ) . attr ( \"class\" , \"label\" ) . attr ( \"transform\" , \"rotate(-90)\" ) . attr ( \"y\" , 0 ) . attr ( \"dy\" , \"1em\" ) . style ( \"text-anchor\" , \"end\" ) . text ( \"Average Riders\" ); //NEW: TOOLTIP. var tooltip = d3 . select ( \"body\" ). append ( \"div\" ) . attr ( \"class\" , \"tooltip\" ) . style ( \"opacity\" , 0 ) . style ( \"background-color\" , \"white\" ); svg . selectAll ( \".dot\" ) . data ( data ) . enter (). append ( \"circle\" ) . attr ( \"class\" , \"dot\" ) . attr ( \"r\" , 3.5 ) . attr ( \"cx\" , xMap ) . attr ( \"cy\" , yMap ) . style ( \"fill\" , function ( d ) { return color ( cValue ( d ));}) //D3 does the magic! . on ( \"mouseover\" , function ( d ) { //much like jquery, an event listener tooltip . transition () . duration ( 200 ) . style ( \"opacity\" , .9 ); tooltip . html ( d [ \"day\" ] + \" : \" + d [ 'date' ]) . style ( \"left\" , ( d3 . event . pageX + 5 ) + \"px\" ) . style ( \"top\" , ( d3 . event . pageY - 28 ) + \"px\" ); }) . on ( \"mouseout\" , function ( d ) { tooltip . transition () . duration ( 500 ) . style ( \"opacity\" , 0 ); }); var legend = svg . selectAll ( \".legend\" ) . data ( color . domain ()) //stores the color <-> label mappings . enter (). append ( \"g\" ) . attr ( \"class\" , \"legend\" ) . attr ( \"transform\" , function ( d , i ) { return \"translate(0,\" + i * 20 + \")\" ; }); legend . append ( \"rect\" ) . attr ( \"x\" , width - 60 ) . attr ( \"width\" , 18 ) . attr ( \"height\" , 18 ) . style ( \"fill\" , color ); legend . append ( \"text\" ) . attr ( \"x\" , width - 70 ) . attr ( \"y\" , 9 ) . attr ( \"dy\" , \".35em\" ) . style ( \"text-anchor\" , \"end\" ) . text ( function ( d ) { return d ;}) }); var element = $('#599e6ed4-485f-4681-a656-c898266d2a22'); require(['d3'], function(d3){ //a weird idempotency thing $(\"#chart1\").remove(); //create canvas element.append(\"<div id='chart1'></div>\"); $(\"#chart1\").width(\"660px\"); $(\"#chart1\").height(\"600px\"); var margin = {top: 20, right: 20, bottom: 30, left: 40}; var width = 880 - margin.left - margin.right; var height = 500 - margin.top - margin.bottom; var svg = d3.select(\"#chart1\").append(\"svg\") .style(\"position\", \"relative\") .style(\"max-width\", \"960px\") .attr(\"width\", width + \"px\") .attr(\"height\", (height + 50) + \"px\") .append(\"g\") .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\"); //set data var data = convertPlotData(window.headwayVsRidership); var xVals = function(d){return d.purpleHeadway;}; var yVals = function(d){return d.purpleAverage;}; var xScale = d3.scale.linear().range([0, width]); var xAxis = d3.svg.axis().scale(xScale).orient(\"bottom\"); var xMap = function(d) { return xScale(xVals(d));}; var yScale = d3.scale.linear().range([height, 0]); var yAxis = d3.svg.axis().scale(yScale).orient(\"left\"); var yMap = function(d) { return yScale(yVals(d));}; xScale.domain([d3.min(data, xVals)-1, d3.max(data, xVals)+1]); yScale.domain([d3.min(data, yVals)-1, d3.max(data, yVals)+1]); var cValue = function(d) { if(d.day == \"Saturday\" || d.day == \"Sunday\"){ return \"Weekend\"; } return \"Weekday\"; } var color = d3.scale.category10(); // x-axis svg.append(\"g\") .attr(\"class\", \"x axis\") .attr(\"transform\", \"translate(0,\" + height + \")\") .call(xAxis) .append(\"text\") .attr(\"class\", \"label\") .attr(\"x\", width - 80) .attr(\"y\", -15) .style(\"text-anchor\", \"end\") .text(\"Average Headway\"); // y-axis svg.append(\"g\") .attr(\"class\", \"y axis\") .call(yAxis) .append(\"text\") .attr(\"class\", \"label\") .attr(\"transform\", \"rotate(-90)\") .attr(\"y\", 0) .attr(\"dy\", \"1em\") .style(\"text-anchor\", \"end\") .text(\"Average Riders\"); //NEW: TOOLTIP. var tooltip = d3.select(\"body\").append(\"div\") .attr(\"class\", \"tooltip\") .style(\"opacity\", 0) .style(\"background-color\", \"white\"); svg.selectAll(\".dot\") .data(data) .enter().append(\"circle\") .attr(\"class\", \"dot\") .attr(\"r\", 3.5) .attr(\"cx\", xMap) .attr(\"cy\", yMap) .style(\"fill\", function(d) { return color(cValue(d));}) //D3 does the magic! .on(\"mouseover\", function(d) { //much like jquery, an event listener tooltip.transition() .duration(200) .style(\"opacity\", .9); tooltip.html(d[\"day\"] + \" : \" + d['date']) .style(\"left\", (d3.event.pageX + 5) + \"px\") .style(\"top\", (d3.event.pageY - 28) + \"px\"); }) .on(\"mouseout\", function(d) { tooltip.transition() .duration(500) .style(\"opacity\", 0); }); var legend = svg.selectAll(\".legend\") .data(color.domain()) //stores the color <-> label mappings .enter().append(\"g\") .attr(\"class\", \"legend\") .attr(\"transform\", function(d, i) { return \"translate(0,\" + i * 20 + \")\"; }); legend.append(\"rect\") .attr(\"x\", width - 60) .attr(\"width\", 18) .attr(\"height\", 18) .style(\"fill\", color); legend.append(\"text\") .attr(\"x\", width - 70) .attr(\"y\", 9) .attr(\"dy\", \".35em\") .style(\"text-anchor\", \"end\") .text(function(d) { return d;}) }); for k in bmks . plist . keys (): print ( type ( bmks . plist [ k ])) # print(len(bmks.plist[k])) <class 'str'> <class 'list'> <class 'str'> <class 'str'> <class 'int'> from bs4 import BeautifulSoup from urllib.request import urlopen from os.path import ( dirname , join ) root = \"https://docs.python.org/3/library/index.html\" doc = urlopen ( root ) . read () soup = BeautifulSoup ( doc , \"lxml\" ) li = soup . find_all ( \"li\" , class_ = 'toctree-l1' ) for i , l1 in enumerate ( li ): a = l1 . find_next ( \"a\" ) print ( i , join ( dirname ( root ), a . attrs [ 'href' ]), a . contents [ 0 ]) for j , l2 in enumerate ( l1 . find_all ( \"li\" , class_ = 'toctree-l2' )): a2 = l2 . find_next ( \"a\" ) print ( \" \" , j , join ( dirname ( root ), a2 . attrs [ 'href' ]), a2 . contents [ 0 ]) 0 https://docs.python.org/3/library/intro.html 1. Introduction 1 https://docs.python.org/3/library/functions.html 2. Built-in Functions 2 https://docs.python.org/3/library/constants.html 3. Built-in Constants 0 https://docs.python.org/3/library/constants.html#constants-added-by-the-site-module 3.1. Constants added by the 3 https://docs.python.org/3/library/stdtypes.html 4. Built-in Types 0 https://docs.python.org/3/library/stdtypes.html#truth-value-testing 4.1. Truth Value Testing 1 https://docs.python.org/3/library/stdtypes.html#boolean-operations-and-or-not 4.2. Boolean Operations \u2014 2 https://docs.python.org/3/library/stdtypes.html#comparisons 4.3. Comparisons 3 https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex 4.4. Numeric Types \u2014 4 https://docs.python.org/3/library/stdtypes.html#iterator-types 4.5. Iterator Types 5 https://docs.python.org/3/library/stdtypes.html#sequence-types-list-tuple-range 4.6. Sequence Types \u2014 6 https://docs.python.org/3/library/stdtypes.html#text-sequence-type-str 4.7. Text Sequence Type \u2014 7 https://docs.python.org/3/library/stdtypes.html#binary-sequence-types-bytes-bytearray-memoryview 4.8. Binary Sequence Types \u2014 8 https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset 4.9. Set Types \u2014 9 https://docs.python.org/3/library/stdtypes.html#mapping-types-dict 4.10. Mapping Types \u2014 10 https://docs.python.org/3/library/stdtypes.html#context-manager-types 4.11. Context Manager Types 11 https://docs.python.org/3/library/stdtypes.html#other-built-in-types 4.12. Other Built-in Types 12 https://docs.python.org/3/library/stdtypes.html#special-attributes 4.13. Special Attributes 4 https://docs.python.org/3/library/exceptions.html 5. Built-in Exceptions 0 https://docs.python.org/3/library/exceptions.html#base-classes 5.1. Base classes 1 https://docs.python.org/3/library/exceptions.html#concrete-exceptions 5.2. Concrete exceptions 2 https://docs.python.org/3/library/exceptions.html#warnings 5.3. Warnings 3 https://docs.python.org/3/library/exceptions.html#exception-hierarchy 5.4. Exception hierarchy 5 https://docs.python.org/3/library/text.html 6. Text Processing Services 0 https://docs.python.org/3/library/string.html 6.1. 1 https://docs.python.org/3/library/re.html 6.2. 2 https://docs.python.org/3/library/difflib.html 6.3. 3 https://docs.python.org/3/library/textwrap.html 6.4. 4 https://docs.python.org/3/library/unicodedata.html 6.5. 5 https://docs.python.org/3/library/stringprep.html 6.6. 6 https://docs.python.org/3/library/readline.html 6.7. 7 https://docs.python.org/3/library/rlcompleter.html 6.8. 6 https://docs.python.org/3/library/binary.html 7. Binary Data Services 0 https://docs.python.org/3/library/struct.html 7.1. 1 https://docs.python.org/3/library/codecs.html 7.2. 7 https://docs.python.org/3/library/datatypes.html 8. Data Types 0 https://docs.python.org/3/library/datetime.html 8.1. 1 https://docs.python.org/3/library/calendar.html 8.2. 2 https://docs.python.org/3/library/collections.html 8.3. 3 https://docs.python.org/3/library/collections.abc.html 8.4. 4 https://docs.python.org/3/library/heapq.html 8.5. 5 https://docs.python.org/3/library/bisect.html 8.6. 6 https://docs.python.org/3/library/array.html 8.7. 7 https://docs.python.org/3/library/weakref.html 8.8. 8 https://docs.python.org/3/library/types.html 8.9. 9 https://docs.python.org/3/library/copy.html 8.10. 10 https://docs.python.org/3/library/pprint.html 8.11. 11 https://docs.python.org/3/library/reprlib.html 8.12. 12 https://docs.python.org/3/library/enum.html 8.13. 8 https://docs.python.org/3/library/numeric.html 9. Numeric and Mathematical Modules 0 https://docs.python.org/3/library/numbers.html 9.1. 1 https://docs.python.org/3/library/math.html 9.2. 2 https://docs.python.org/3/library/cmath.html 9.3. 3 https://docs.python.org/3/library/decimal.html 9.4. 4 https://docs.python.org/3/library/fractions.html 9.5. 5 https://docs.python.org/3/library/random.html 9.6. 6 https://docs.python.org/3/library/statistics.html 9.7. 9 https://docs.python.org/3/library/functional.html 10. Functional Programming Modules 0 https://docs.python.org/3/library/itertools.html 10.1. 1 https://docs.python.org/3/library/functools.html 10.2. 2 https://docs.python.org/3/library/operator.html 10.3. 10 https://docs.python.org/3/library/filesys.html 11. File and Directory Access 0 https://docs.python.org/3/library/pathlib.html 11.1. 1 https://docs.python.org/3/library/os.path.html 11.2. 2 https://docs.python.org/3/library/fileinput.html 11.3. 3 https://docs.python.org/3/library/stat.html 11.4. 4 https://docs.python.org/3/library/filecmp.html 11.5. 5 https://docs.python.org/3/library/tempfile.html 11.6. 6 https://docs.python.org/3/library/glob.html 11.7. 7 https://docs.python.org/3/library/fnmatch.html 11.8. 8 https://docs.python.org/3/library/linecache.html 11.9. 9 https://docs.python.org/3/library/shutil.html 11.10. 10 https://docs.python.org/3/library/macpath.html 11.11. 11 https://docs.python.org/3/library/persistence.html 12. Data Persistence 0 https://docs.python.org/3/library/pickle.html 12.1. 1 https://docs.python.org/3/library/copyreg.html 12.2. 2 https://docs.python.org/3/library/shelve.html 12.3. 3 https://docs.python.org/3/library/marshal.html 12.4. 4 https://docs.python.org/3/library/dbm.html 12.5. 5 https://docs.python.org/3/library/sqlite3.html 12.6. 12 https://docs.python.org/3/library/archiving.html 13. Data Compression and Archiving 0 https://docs.python.org/3/library/zlib.html 13.1. 1 https://docs.python.org/3/library/gzip.html 13.2. 2 https://docs.python.org/3/library/bz2.html 13.3. 3 https://docs.python.org/3/library/lzma.html 13.4. 4 https://docs.python.org/3/library/zipfile.html 13.5. 5 https://docs.python.org/3/library/tarfile.html 13.6. 13 https://docs.python.org/3/library/fileformats.html 14. File Formats 0 https://docs.python.org/3/library/csv.html 14.1. 1 https://docs.python.org/3/library/configparser.html 14.2. 2 https://docs.python.org/3/library/netrc.html 14.3. 3 https://docs.python.org/3/library/xdrlib.html 14.4. 4 https://docs.python.org/3/library/plistlib.html 14.5. 14 https://docs.python.org/3/library/crypto.html 15. Cryptographic Services 0 https://docs.python.org/3/library/hashlib.html 15.1. 1 https://docs.python.org/3/library/hmac.html 15.2. 2 https://docs.python.org/3/library/secrets.html 15.3. 15 https://docs.python.org/3/library/allos.html 16. Generic Operating System Services 0 https://docs.python.org/3/library/os.html 16.1. 1 https://docs.python.org/3/library/io.html 16.2. 2 https://docs.python.org/3/library/time.html 16.3. 3 https://docs.python.org/3/library/argparse.html 16.4. 4 https://docs.python.org/3/library/getopt.html 16.5. 5 https://docs.python.org/3/library/logging.html 16.6. 6 https://docs.python.org/3/library/logging.config.html 16.7. 7 https://docs.python.org/3/library/logging.handlers.html 16.8. 8 https://docs.python.org/3/library/getpass.html 16.9. 9 https://docs.python.org/3/library/curses.html 16.10. 10 https://docs.python.org/3/library/curses.html#module-curses.textpad 16.11. 11 https://docs.python.org/3/library/curses.ascii.html 16.12. 12 https://docs.python.org/3/library/curses.panel.html 16.13. 13 https://docs.python.org/3/library/platform.html 16.14. 14 https://docs.python.org/3/library/errno.html 16.15. 15 https://docs.python.org/3/library/ctypes.html 16.16. 16 https://docs.python.org/3/library/concurrency.html 17. Concurrent Execution 0 https://docs.python.org/3/library/threading.html 17.1. 1 https://docs.python.org/3/library/multiprocessing.html 17.2. 2 https://docs.python.org/3/library/concurrent.html 17.3. The 3 https://docs.python.org/3/library/concurrent.futures.html 17.4. 4 https://docs.python.org/3/library/subprocess.html 17.5. 5 https://docs.python.org/3/library/sched.html 17.6. 6 https://docs.python.org/3/library/queue.html 17.7. 7 https://docs.python.org/3/library/dummy_threading.html 17.8. 8 https://docs.python.org/3/library/_thread.html 17.9. 9 https://docs.python.org/3/library/_dummy_thread.html 17.10. 17 https://docs.python.org/3/library/ipc.html 18. Interprocess Communication and Networking 0 https://docs.python.org/3/library/socket.html 18.1. 1 https://docs.python.org/3/library/ssl.html 18.2. 2 https://docs.python.org/3/library/select.html 18.3. 3 https://docs.python.org/3/library/selectors.html 18.4. 4 https://docs.python.org/3/library/asyncio.html 18.5. 5 https://docs.python.org/3/library/asyncore.html 18.6. 6 https://docs.python.org/3/library/asynchat.html 18.7. 7 https://docs.python.org/3/library/signal.html 18.8. 8 https://docs.python.org/3/library/mmap.html 18.9. 18 https://docs.python.org/3/library/netdata.html 19. Internet Data Handling 0 https://docs.python.org/3/library/email.html 19.1. 1 https://docs.python.org/3/library/json.html 19.2. 2 https://docs.python.org/3/library/mailcap.html 19.3. 3 https://docs.python.org/3/library/mailbox.html 19.4. 4 https://docs.python.org/3/library/mimetypes.html 19.5. 5 https://docs.python.org/3/library/base64.html 19.6. 6 https://docs.python.org/3/library/binhex.html 19.7. 7 https://docs.python.org/3/library/binascii.html 19.8. 8 https://docs.python.org/3/library/quopri.html 19.9. 9 https://docs.python.org/3/library/uu.html 19.10. 19 https://docs.python.org/3/library/markup.html 20. Structured Markup Processing Tools 0 https://docs.python.org/3/library/html.html 20.1. 1 https://docs.python.org/3/library/html.parser.html 20.2. 2 https://docs.python.org/3/library/html.entities.html 20.3. 3 https://docs.python.org/3/library/xml.html 20.4. XML Processing Modules 4 https://docs.python.org/3/library/xml.etree.elementtree.html 20.5. 5 https://docs.python.org/3/library/xml.dom.html 20.6. 6 https://docs.python.org/3/library/xml.dom.minidom.html 20.7. 7 https://docs.python.org/3/library/xml.dom.pulldom.html 20.8. 8 https://docs.python.org/3/library/xml.sax.html 20.9. 9 https://docs.python.org/3/library/xml.sax.handler.html 20.10. 10 https://docs.python.org/3/library/xml.sax.utils.html 20.11. 11 https://docs.python.org/3/library/xml.sax.reader.html 20.12. 12 https://docs.python.org/3/library/pyexpat.html 20.13. 20 https://docs.python.org/3/library/internet.html 21. Internet Protocols and Support 0 https://docs.python.org/3/library/webbrowser.html 21.1. 1 https://docs.python.org/3/library/cgi.html 21.2. 2 https://docs.python.org/3/library/cgitb.html 21.3. 3 https://docs.python.org/3/library/wsgiref.html 21.4. 4 https://docs.python.org/3/library/urllib.html 21.5. 5 https://docs.python.org/3/library/urllib.request.html 21.6. 6 https://docs.python.org/3/library/urllib.request.html#module-urllib.response 21.7. 7 https://docs.python.org/3/library/urllib.parse.html 21.8. 8 https://docs.python.org/3/library/urllib.error.html 21.9. 9 https://docs.python.org/3/library/urllib.robotparser.html 21.10. 10 https://docs.python.org/3/library/http.html 21.11. 11 https://docs.python.org/3/library/http.client.html 21.12. 12 https://docs.python.org/3/library/ftplib.html 21.13. 13 https://docs.python.org/3/library/poplib.html 21.14. 14 https://docs.python.org/3/library/imaplib.html 21.15. 15 https://docs.python.org/3/library/nntplib.html 21.16. 16 https://docs.python.org/3/library/smtplib.html 21.17. 17 https://docs.python.org/3/library/smtpd.html 21.18. 18 https://docs.python.org/3/library/telnetlib.html 21.19. 19 https://docs.python.org/3/library/uuid.html 21.20. 20 https://docs.python.org/3/library/socketserver.html 21.21. 21 https://docs.python.org/3/library/http.server.html 21.22. 22 https://docs.python.org/3/library/http.cookies.html 21.23. 23 https://docs.python.org/3/library/http.cookiejar.html 21.24. 24 https://docs.python.org/3/library/xmlrpc.html 21.25. 25 https://docs.python.org/3/library/xmlrpc.client.html 21.26. 26 https://docs.python.org/3/library/xmlrpc.server.html 21.27. 27 https://docs.python.org/3/library/ipaddress.html 21.28. 21 https://docs.python.org/3/library/mm.html 22. Multimedia Services 0 https://docs.python.org/3/library/audioop.html 22.1. 1 https://docs.python.org/3/library/aifc.html 22.2. 2 https://docs.python.org/3/library/sunau.html 22.3. 3 https://docs.python.org/3/library/wave.html 22.4. 4 https://docs.python.org/3/library/chunk.html 22.5. 5 https://docs.python.org/3/library/colorsys.html 22.6. 6 https://docs.python.org/3/library/imghdr.html 22.7. 7 https://docs.python.org/3/library/sndhdr.html 22.8. 8 https://docs.python.org/3/library/ossaudiodev.html 22.9. 22 https://docs.python.org/3/library/i18n.html 23. Internationalization 0 https://docs.python.org/3/library/gettext.html 23.1. 1 https://docs.python.org/3/library/locale.html 23.2. 23 https://docs.python.org/3/library/frameworks.html 24. Program Frameworks 0 https://docs.python.org/3/library/turtle.html 24.1. 1 https://docs.python.org/3/library/cmd.html 24.2. 2 https://docs.python.org/3/library/shlex.html 24.3. 24 https://docs.python.org/3/library/tk.html 25. Graphical User Interfaces with Tk 0 https://docs.python.org/3/library/tkinter.html 25.1. 1 https://docs.python.org/3/library/tkinter.ttk.html 25.2. 2 https://docs.python.org/3/library/tkinter.tix.html 25.3. 3 https://docs.python.org/3/library/tkinter.scrolledtext.html 25.4. 4 https://docs.python.org/3/library/idle.html 25.5. IDLE 5 https://docs.python.org/3/library/othergui.html 25.6. Other Graphical User Interface Packages 25 https://docs.python.org/3/library/development.html 26. Development Tools 0 https://docs.python.org/3/library/typing.html 26.1. 1 https://docs.python.org/3/library/pydoc.html 26.2. 2 https://docs.python.org/3/library/doctest.html 26.3. 3 https://docs.python.org/3/library/unittest.html 26.4. 4 https://docs.python.org/3/library/unittest.mock.html 26.5. 5 https://docs.python.org/3/library/unittest.mock-examples.html 26.6. 6 https://docs.python.org/3/library/2to3.html 26.7. 2to3 - Automated Python 2 to 3 code translation 7 https://docs.python.org/3/library/test.html 26.8. 8 https://docs.python.org/3/library/test.html#module-test.support 26.9. 26 https://docs.python.org/3/library/debug.html 27. Debugging and Profiling 0 https://docs.python.org/3/library/bdb.html 27.1. 1 https://docs.python.org/3/library/faulthandler.html 27.2. 2 https://docs.python.org/3/library/pdb.html 27.3. 3 https://docs.python.org/3/library/profile.html 27.4. The Python Profilers 4 https://docs.python.org/3/library/timeit.html 27.5. 5 https://docs.python.org/3/library/trace.html 27.6. 6 https://docs.python.org/3/library/tracemalloc.html 27.7. 27 https://docs.python.org/3/library/distribution.html 28. Software Packaging and Distribution 0 https://docs.python.org/3/library/distutils.html 28.1. 1 https://docs.python.org/3/library/ensurepip.html 28.2. 2 https://docs.python.org/3/library/venv.html 28.3. 3 https://docs.python.org/3/library/zipapp.html 28.4. 28 https://docs.python.org/3/library/python.html 29. Python Runtime Services 0 https://docs.python.org/3/library/sys.html 29.1. 1 https://docs.python.org/3/library/sysconfig.html 29.2. 2 https://docs.python.org/3/library/builtins.html 29.3. 3 https://docs.python.org/3/library/__main__.html 29.4. 4 https://docs.python.org/3/library/warnings.html 29.5. 5 https://docs.python.org/3/library/contextlib.html 29.6. 6 https://docs.python.org/3/library/abc.html 29.7. 7 https://docs.python.org/3/library/atexit.html 29.8. 8 https://docs.python.org/3/library/traceback.html 29.9. 9 https://docs.python.org/3/library/__future__.html 29.10. 10 https://docs.python.org/3/library/gc.html 29.11. 11 https://docs.python.org/3/library/inspect.html 29.12. 12 https://docs.python.org/3/library/site.html 29.13. 13 https://docs.python.org/3/library/fpectl.html 29.14. 29 https://docs.python.org/3/library/custominterp.html 30. Custom Python Interpreters 0 https://docs.python.org/3/library/code.html 30.1. 1 https://docs.python.org/3/library/codeop.html 30.2. 30 https://docs.python.org/3/library/modules.html 31. Importing Modules 0 https://docs.python.org/3/library/zipimport.html 31.1. 1 https://docs.python.org/3/library/pkgutil.html 31.2. 2 https://docs.python.org/3/library/modulefinder.html 31.3. 3 https://docs.python.org/3/library/runpy.html 31.4. 4 https://docs.python.org/3/library/importlib.html 31.5. 31 https://docs.python.org/3/library/language.html 32. Python Language Services 0 https://docs.python.org/3/library/parser.html 32.1. 1 https://docs.python.org/3/library/ast.html 32.2. 2 https://docs.python.org/3/library/symtable.html 32.3. 3 https://docs.python.org/3/library/symbol.html 32.4. 4 https://docs.python.org/3/library/token.html 32.5. 5 https://docs.python.org/3/library/keyword.html 32.6. 6 https://docs.python.org/3/library/tokenize.html 32.7. 7 https://docs.python.org/3/library/tabnanny.html 32.8. 8 https://docs.python.org/3/library/pyclbr.html 32.9. 9 https://docs.python.org/3/library/py_compile.html 32.10. 10 https://docs.python.org/3/library/compileall.html 32.11. 11 https://docs.python.org/3/library/dis.html 32.12. 12 https://docs.python.org/3/library/pickletools.html 32.13. 32 https://docs.python.org/3/library/misc.html 33. Miscellaneous Services 0 https://docs.python.org/3/library/formatter.html 33.1. 33 https://docs.python.org/3/library/windows.html 34. MS Windows Specific Services 0 https://docs.python.org/3/library/msilib.html 34.1. 1 https://docs.python.org/3/library/msvcrt.html 34.2. 2 https://docs.python.org/3/library/winreg.html 34.3. 3 https://docs.python.org/3/library/winsound.html 34.4. 34 https://docs.python.org/3/library/unix.html 35. Unix Specific Services 0 https://docs.python.org/3/library/posix.html 35.1. 1 https://docs.python.org/3/library/pwd.html 35.2. 2 https://docs.python.org/3/library/spwd.html 35.3. 3 https://docs.python.org/3/library/grp.html 35.4. 4 https://docs.python.org/3/library/crypt.html 35.5. 5 https://docs.python.org/3/library/termios.html 35.6. 6 https://docs.python.org/3/library/tty.html 35.7. 7 https://docs.python.org/3/library/pty.html 35.8. 8 https://docs.python.org/3/library/fcntl.html 35.9. 9 https://docs.python.org/3/library/pipes.html 35.10. 10 https://docs.python.org/3/library/resource.html 35.11. 11 https://docs.python.org/3/library/nis.html 35.12. 12 https://docs.python.org/3/library/syslog.html 35.13. 35 https://docs.python.org/3/library/superseded.html 36. Superseded Modules 0 https://docs.python.org/3/library/optparse.html 36.1. 1 https://docs.python.org/3/library/imp.html 36.2. 36 https://docs.python.org/3/library/undoc.html 37. Undocumented Modules 0 https://docs.python.org/3/library/undoc.html#platform-specific-modules 37.1. Platform specific modules '37. Undocumented Modules'","title":"Plistlib"},{"location":"python/profiling/","text":"Profiling \u00b6 Py-spy \u00b6 py-spy","title":"Profiling"},{"location":"python/profiling/#profiling","text":"","title":"Profiling"},{"location":"python/profiling/#py-spy","text":"py-spy","title":"Py-spy"},{"location":"python/py_dev_env/","text":"Python packaging and development environment \u00b6 The Python packaging user guide contains numerous resources, including: A list of key projects tutorials: installing packages managing app. dependencies packaging projects creating documentation Packaging \u00b6 distutils \u00b6 Collection of utilities from the standard library for packaging and distributing Python packages, including compilation of native extension modules. deprecates its usage, removal planed for python 3.12. Setuptools \u00b6 Setuptools is a collection of enhancements to the Python distutils . pyproject.toml \u00b6 This file, topic of lists the minimal dependencies of the build system of a project in a declarative fashion. add precisions on the build system interface, by default setuptools . In this case, and if setup.py is missing , setuptools emulates a dummy setup.py file containing only a setuptools.setup() call. defines stored metadata. defines defined dependencies. About PEP 0518 distutils When Python first developed its tooling for building distributions of software for projects, was the chosen solution. As time went on, setuptools gained popularity to add some features on top of distutils. Both used the concept of a setup.py file. Tables build-system [build-system] table is used to store build-related data. Initially only one key of the table will be valid and is mandatory for the table: requires . A build frontend is a tool that users might run that takes arbitrary source trees or source distributions and builds wheels from them. The actual building is done by each source tree's build backend . In a command like pip wheel some-directory/, pip is acting as a build frontend. Example Usage with setuptools [build-system] # Minimum requirements for the build system to execute. requires = [\"setuptools\", \"wheel\"] # PEP 508 specifications. # This key is not mandatory as setuptools is default build-backend = \"setuptools.build_meta\" Usage with poetry [build-system] requires = [\"poetry_core>=1.0.0\"] build-backend = \"poetry.core.masonry.api\" Tools should not require the existence of the [build-system] table. A pyproject.toml file may be used to store configuration details other than build-related data and thus lack a [build-system] table legitimately. Build backend interface In case a custom build backend interface is specified, mandatory hooks - build_wheel and build_sdist - must be specified. Optional hooks tool The [tool] table is where any tool related to your Python project, not just build tools, can have users specify configuration data as long as they use a sub-table within [tool] , e.g. the flit tool would store its configuration in [tool.flit] . Packaging Blog post Pip \u00b6 Pip is the package installer for Python. Wheel \u00b6 This library is the reference implementation of the Python wheel packaging standard, as defined in PEP 427. It has two different roles: A setuptools extension for building wheels that provides the bdist_wheel setuptools command A command line tool for working with wheel files PyOxyder \u00b6 PyOxyder is a utility for producing binaries that embed Python. It can be used in case of virtualenv with symlink to the python interpreter (e.g. in the case of pipx) PyInstaller \u00b6 PyInstaller bundles a Python application and all its dependencies into a single package. Python version management: pyenv \u00b6 Pyenv intercepts Python commands using shim executables injected into your PATH, determines which Python version has been specified by your application, and passes the commands along to the correct Python installation. Installation \u00b6 Installation can be perfomed with a git checkout: git clone https://github.com/pyenv/pyenv.git ~/.opt/pyenv Path to pyenv must be set in PATH , prompt is disabled export PYENV_VIRTUALENV_DISABLE_PROMPT=1 export PYENV_ROOT=$HOME/.opt/pyenv export PATH=$PYENV_ROOT/shims:$PYENV_ROOT/bin:$PATH Before installing python runtimes, dependencies must be installed. CONFIGURE_OPTS as well as http_proxy and https_proxy can be passed to installation. Completion can be installed for zsh from the checked-out repository. install -m 644 completions/pyenv.zsh ~/.zsh/completion/_pyenv Version management \u00b6 Global and local python version are supported. Multiple version support can be enabled: # Ensure those versions will have precedence pyenv global 3.8.7 3.9.1 3.7.8 miniconda3-4.7.12 python3.8 --version # Returns 3.8.7 Version superseed is made with: # set this version in .python-version pyenv local 3.9.0 # or export PYENV_VERSION=3.9.0 Application Dependency management: poetry \u00b6 is a tool for dependency management and packaging. basic usage : Example # Create a new project poetry new <PROJECT_NAME> # Or init from an existing project poetry init # Add dependencies poetry add <DEP> # Install the dependencies poetry install # Run a command inside the env poetry run <COMMAND> <PARAMETERS> If already in a virtualenv, poetry will reuse it and will not create a new env. Linked environments can be displayed with poetry env list . Shell completion (zsh) poetry completions zsh > ~/.zsh/completion/_poetry Virtual environments Pipenv editable-dependencies pipenv install --dev -e . Application manager: pipx \u00b6 pipx installs and run python applications in isolated environments. Update \u00b6 Update packages: upgrade pipx upgrade jupyterlab # with injected dependencies pipx upgrade --include-injected jupyterlab Update python version: reinstall Python version can be updated with the reinstall subcommand pipx list --json \\ | jq -r '''.venvs | with_entries(select(.value | .metadata.python_version==\"Python 3.9.2\")) | keys | .[] ''' ' \\ | while read line ; do pipx reinstall --python python3.9 $line ; done","title":"Development env"},{"location":"python/py_dev_env/#python-packaging-and-development-environment","text":"The Python packaging user guide contains numerous resources, including: A list of key projects tutorials: installing packages managing app. dependencies packaging projects creating documentation","title":"Python packaging and development environment"},{"location":"python/py_dev_env/#packaging","text":"","title":"Packaging"},{"location":"python/py_dev_env/#distutils","text":"Collection of utilities from the standard library for packaging and distributing Python packages, including compilation of native extension modules. deprecates its usage, removal planed for python 3.12.","title":"distutils"},{"location":"python/py_dev_env/#setuptools","text":"Setuptools is a collection of enhancements to the Python distutils .","title":"Setuptools"},{"location":"python/py_dev_env/#pyprojecttoml","text":"This file, topic of lists the minimal dependencies of the build system of a project in a declarative fashion. add precisions on the build system interface, by default setuptools . In this case, and if setup.py is missing , setuptools emulates a dummy setup.py file containing only a setuptools.setup() call. defines stored metadata. defines defined dependencies. About PEP 0518 distutils When Python first developed its tooling for building distributions of software for projects, was the chosen solution. As time went on, setuptools gained popularity to add some features on top of distutils. Both used the concept of a setup.py file.","title":"pyproject.toml"},{"location":"python/py_dev_env/#pip","text":"Pip is the package installer for Python.","title":"Pip"},{"location":"python/py_dev_env/#wheel","text":"This library is the reference implementation of the Python wheel packaging standard, as defined in PEP 427. It has two different roles: A setuptools extension for building wheels that provides the bdist_wheel setuptools command A command line tool for working with wheel files","title":"Wheel"},{"location":"python/py_dev_env/#pyoxyder","text":"PyOxyder is a utility for producing binaries that embed Python. It can be used in case of virtualenv with symlink to the python interpreter (e.g. in the case of pipx)","title":"PyOxyder"},{"location":"python/py_dev_env/#pyinstaller","text":"PyInstaller bundles a Python application and all its dependencies into a single package.","title":"PyInstaller"},{"location":"python/py_dev_env/#python-version-management-pyenv","text":"Pyenv intercepts Python commands using shim executables injected into your PATH, determines which Python version has been specified by your application, and passes the commands along to the correct Python installation.","title":"Python version management: pyenv"},{"location":"python/py_dev_env/#installation","text":"Installation can be perfomed with a git checkout: git clone https://github.com/pyenv/pyenv.git ~/.opt/pyenv Path to pyenv must be set in PATH , prompt is disabled export PYENV_VIRTUALENV_DISABLE_PROMPT=1 export PYENV_ROOT=$HOME/.opt/pyenv export PATH=$PYENV_ROOT/shims:$PYENV_ROOT/bin:$PATH Before installing python runtimes, dependencies must be installed. CONFIGURE_OPTS as well as http_proxy and https_proxy can be passed to installation. Completion can be installed for zsh from the checked-out repository. install -m 644 completions/pyenv.zsh ~/.zsh/completion/_pyenv","title":"Installation"},{"location":"python/py_dev_env/#version-management","text":"Global and local python version are supported. Multiple version support can be enabled: # Ensure those versions will have precedence pyenv global 3.8.7 3.9.1 3.7.8 miniconda3-4.7.12 python3.8 --version # Returns 3.8.7 Version superseed is made with: # set this version in .python-version pyenv local 3.9.0 # or export PYENV_VERSION=3.9.0","title":"Version management"},{"location":"python/py_dev_env/#application-dependency-management-poetry","text":"is a tool for dependency management and packaging. basic usage : Example # Create a new project poetry new <PROJECT_NAME> # Or init from an existing project poetry init # Add dependencies poetry add <DEP> # Install the dependencies poetry install # Run a command inside the env poetry run <COMMAND> <PARAMETERS> If already in a virtualenv, poetry will reuse it and will not create a new env. Linked environments can be displayed with poetry env list . Shell completion (zsh) poetry completions zsh > ~/.zsh/completion/_poetry","title":"Application Dependency management: poetry"},{"location":"python/py_dev_env/#application-manager-pipx","text":"pipx installs and run python applications in isolated environments.","title":"Application manager: pipx"},{"location":"python/py_dev_env/#update","text":"","title":"Update"},{"location":"python/typing/","text":"Typing \u00b6 History \u00b6 PEPS: Literature Overview for Type Hints Theory of Type Hints Type Hints Syntax for Variable Annotations Protocols: Structural subtyping Distributing and Packaging Type Information Postponed Evaluation of Annotations Literal types TypedDict Final qualifier Flexible variable annotation Complementary syntax for unions Parameter specification variable Explicit type aliases Structural pattern matching Indexing with leyword arguments Variadic generics User-defined type guargs Required typed dictionary items Nominal/Structural subtyping PEP 544 does not suppress nominal subtyping (explicit declaration of base classes), instead propose usage of protocol classes (static duck typing). Nominal subtyping from collections.abc import Sized , Iterable , Iterator class Bucket ( Sized , Iterable [ int ]): ... def __len__ ( self ) -> int : ... def __iter__ ( self ) -> Iterator [ int ]: ... Structural subtyping from collections.abc import Iterator , Iterable class Bucket : # Note: no base classes ... def __len__ ( self ) -> int : ... def __iter__ ( self ) -> Iterator [ int ]: ... Stubs \u00b6 Info A library stub defines a skeleton of the public interface of the library, including classes, variables and functions, and their types. typeshed is a collection of library stubs for Python, with static types. Those are distributed with and used by MyPy to determine the types of standard library and third-party library functions, classes, and other definitions. Stubs files can be generated using mypy's utility stugen . Distribution and packaging are described in . And type stubs for third party packages and modules can be installed from PyPI, e.g.: # pip install types-<PKG> pip install types-six types-requests Generic concrete collections \u00b6 Dict List Set FrozenSet DefaultDict OrderedDict ChainMap Counter Deque IO TextIO BinaryIO Pattern Match Text Abstract Base Class \u00b6 ClassVar ContextManager Counter DefaultDict Deque final Final Literal NewType NoReturn overload (note that older versions of typing only let you use overload in stubs) Protocol (except on Python 3.5.0) runtime (except on Python 3.5.0) Text Type TypedDict TYPE_CHECKING Static type checker \u00b6 pytype \u00b6 Pytype , not an official google project, checks and infers types for your Python code - without requiring type annotations Package providing: pydantic Link: https://www.pythonsheets.com/notes/python-typing.html","title":"Typing"},{"location":"python/typing/#typing","text":"","title":"Typing"},{"location":"python/typing/#history","text":"PEPS: Literature Overview for Type Hints Theory of Type Hints Type Hints Syntax for Variable Annotations Protocols: Structural subtyping Distributing and Packaging Type Information Postponed Evaluation of Annotations Literal types TypedDict Final qualifier Flexible variable annotation Complementary syntax for unions Parameter specification variable Explicit type aliases Structural pattern matching Indexing with leyword arguments Variadic generics User-defined type guargs Required typed dictionary items Nominal/Structural subtyping PEP 544 does not suppress nominal subtyping (explicit declaration of base classes), instead propose usage of protocol classes (static duck typing). Nominal subtyping from collections.abc import Sized , Iterable , Iterator class Bucket ( Sized , Iterable [ int ]): ... def __len__ ( self ) -> int : ... def __iter__ ( self ) -> Iterator [ int ]: ... Structural subtyping from collections.abc import Iterator , Iterable class Bucket : # Note: no base classes ... def __len__ ( self ) -> int : ... def __iter__ ( self ) -> Iterator [ int ]: ...","title":"History"},{"location":"python/typing/#stubs","text":"Info A library stub defines a skeleton of the public interface of the library, including classes, variables and functions, and their types. typeshed is a collection of library stubs for Python, with static types. Those are distributed with and used by MyPy to determine the types of standard library and third-party library functions, classes, and other definitions. Stubs files can be generated using mypy's utility stugen . Distribution and packaging are described in . And type stubs for third party packages and modules can be installed from PyPI, e.g.: # pip install types-<PKG> pip install types-six types-requests","title":"Stubs"},{"location":"python/typing/#generic-concrete-collections","text":"Dict List Set FrozenSet DefaultDict OrderedDict ChainMap Counter Deque IO TextIO BinaryIO Pattern Match Text","title":"Generic concrete collections"},{"location":"python/typing/#abstract-base-class","text":"ClassVar ContextManager Counter DefaultDict Deque final Final Literal NewType NoReturn overload (note that older versions of typing only let you use overload in stubs) Protocol (except on Python 3.5.0) runtime (except on Python 3.5.0) Text Type TypedDict TYPE_CHECKING","title":"Abstract Base Class"},{"location":"python/typing/#static-type-checker","text":"","title":"Static type checker"},{"location":"python/typing/#pytype","text":"Pytype , not an official google project, checks and infers types for your Python code - without requiring type annotations Package providing: pydantic Link: https://www.pythonsheets.com/notes/python-typing.html","title":"pytype"},{"location":"python/base/02%20-%20Python%20-%20intro/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The Python Interpreter \u00b6 $ python Python 3.7 . 3 ( default , Apr 3 2019 , 05 : 39 : 12 ) [ GCC 8.3 . 0 ] on linux Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information . >>> >>> a = 1 >>> print ( a ) 1 >>> exit () %% writefile hello_world . py print ( \"Hello world\" ) Overwriting hello_world.py $ python hello_world . py Hello world $ ipython Python 3 .6.0 | packaged by conda-forge | ( default, Jan 13 2017 , 23 :17:12 ) Type \"copyright\" , \"credits\" or \"license\" for more information. IPython 5 .1.0 -- An enhanced Interactive Python. ? -> Introduction and overview of IPython 's features. %quickref -> Quick reference. help -> Python' s own help system. object? -> Details about 'object' , use 'object??' for extra details. In [ 1 ] : %run hello_world.py Hello world In [ 2 ] : IPython Basics \u00b6 Running the IPython Shell \u00b6 from numpy.random import randn data = {i : randn() for i in range(7)} print(data) {0: -1.5948255432744511, 1: 0.10569006472787983, 2: 1.972367135977295, 3: 0.15455217573074576, 4: -0.24058577449429575, 5: -1.2904897053651216, 6: 0.3308507317325902} Running the Jupyter Notebook \u00b6 $ jupyter notebook [ I 15 :20:52.739 NotebookApp ] Serving notebooks from local directory: /home/wesm/code/pydata-book [ I 15 :20:52.739 NotebookApp ] 0 active kernels [ I 15 :20:52.739 NotebookApp ] The Jupyter Notebook is running at: http://localhost:8888/ [ I 15 :20:52.740 NotebookApp ] Use Control-C to stop this server and shut down all kernels ( twice to skip confirmation ) . Created new window in existing browser session. Introspection \u00b6 In [8]: b = [1, 2, 3] In [9]: b? Type: list String Form:[1, 2, 3] Length: 3 Docstring: list() -> new empty list list(iterable) -> new list initialized from iterable's items In [10]: print? Docstring: print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) Prints the values to a stream, or to sys.stdout by default. Optional keyword arguments: file: a file-like object (stream); defaults to the current sys.stdout. sep: string inserted between values, default a space. end: string appended after the last value, default a newline. flush: whether to forcibly flush the stream. Type: builtin_function_or_method def add_numbers ( a , b ): \"\"\" Add two numbers together Returns ------- the_sum : type of arguments \"\"\" return a + b In [ 11 ]: add_numbers ? Signature : add_numbers ( a , b ) Docstring : Add two numbers together Returns ------- the_sum : type of arguments File : < ipython - input - 9 - 6 a548a216e27 > Type : function In [ 12 ]: add_numbers ?? Signature : add_numbers ( a , b ) Source : def add_numbers ( a , b ): \"\"\" Add two numbers together Returns ------- the_sum : type of arguments \"\"\" return a + b File : < ipython - input - 9 - 6 a548a216e27 > Type : function In [ 13 ]: np .* load * ? np . __loader__ np . load np . loads np . loadtxt np . pkgload Interrupting running code Python Language Basics \u00b6 %% javascript ( new Array ([ 1 , 2 ])) var element = $('#7fde1b82-da82-4a3a-b4a6-d09315336df8'); (new Array([1, 2])) Everything is an object A = dict ( first = 1 , second = 2 ) A {'first': 1, 'second': 2} type ( A ) dict type ( type ( A )) type type ( type ( type ( A ))) type Comments results = [] for line in file_handle : # keep the empty lines for now # if len(line) == 0: # continue results . append ( line . replace ( 'foo' , 'bar' )) print ( \"Reached this line\" ) # Simple status report Function and object method calls result = f(x, y, z) g() obj.some_method(x, y, z) result = f ( a , b , c , d = 5 , e = 'foo' ) Variables and argument passing a = [ 1 , 2 , 3 ] b = a a . append ( 4 ) b [1, 2, 3, 4] a [1, 2, 3, 4] def append_element ( some_list , element ): some_list . append ( element ) In [ 27 ]: data = [ 1 , 2 , 3 ] In [ 28 ]: append_element ( data , 4 ) In [ 29 ]: data Out [ 29 ]: [ 1 , 2 , 3 , 4 ] Dynamic references, strong types a = 5 type ( a ) int a = 'foo' type ( a ) str '5' + 5 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-73-4dd8efb5fac1> in <module> ----> 1 '5' + 5 TypeError : can only concatenate str (not \"int\") to str a = 4.5 b = 2 # String formatting, to be visited later print ( f 'a is { type ( a ) } , b is { type ( b ) } ' ) a / b a is <class 'float'>, b is <class 'int'> 2.25 a = 5 isinstance ( a , int ) True a = 5 ; b = 4.5 isinstance ( a , ( int , float )) True isinstance ( b , ( int , float )) True Attributes and methods In [ 1 ]: a = 'foo' In [ 2 ]: a .< Press Tab > a . capitalize a . format a . isupper a . rindex a . strip a . center a . index a . join a . rjust a . swapcase a . count a . isalnum a . ljust a . rpartition a . title a . decode a . isalpha a . lower a . rsplit a . translate a . encode a . isdigit a . lstrip a . rstrip a . upper a . endswith a . islower a . partition a . split a . zfill a . expandtabs a . isspace a . replace a . splitlines a . find a . istitle a . rfind a . startswith a = 'foo' getattr ( a , 'split' ) <function str.split(sep=None, maxsplit=-1)> Duck typing def isiterable ( obj ): try : iter ( obj ) return True except TypeError : # not iterable return False isiterable ( 'a string' ) isiterable ([ 1 , 2 , 3 ]) isiterable ( 5 ) False if not isinstance(x, list) and isiterable(x): x = list(x) Imports # some_module.py PI = 3.14159 def f ( x ): return x + 2 def g ( a , b ): return a + b import some_module result = some_module.f(5) pi = some_module.PI from some_module import f, g, PI result = g(5, PI) import some_module as sm from some_module import PI as pi, g as gf r1 = sm.f(pi) r2 = gf(6, pi) Binary operators and comparisons 5 - 7 12 + 21.5 5 <= 2 a = [ 1 , 2 , 3 ] b = a c = list ( a ) a is b a is not c a == c a = None a is None Mutable and immutable objects a_list = [ 'foo' , 2 , [ 4 , 5 ]] a_list [ 2 ] = ( 3 , 4 ) a_list a_tuple = ( 3 , 5 , ( 4 , 5 )) a_tuple [ 1 ] = 'four' Scalar Types \u00b6 Numeric types ival = 17239871 ival ** 6 fval = 7.243 fval2 = 6.78e-5 3 / 2 3 // 2 Strings a = 'one way of writing a string' b = \"another way\" c = \"\"\" This is a longer string that spans multiple lines \"\"\" c . count ( ' \\n ' ) a = 'this is a string' a [ 10 ] = 'f' b = a . replace ( 'string' , 'longer string' ) b a a = 5.6 s = str ( a ) print ( s ) s = 'python' list ( s ) s [: 3 ] s = '12 \\\\ 34' print ( s ) s = r 'this\\has\\no\\special\\characters' s a = 'this is the first half ' b = 'and this is the second half' a + b template = ' {0:.2f} {1:s} are worth US$ {2:d} ' template . format ( 4.5560 , 'Argentine Pesos' , 1 ) Bytes and Unicode val = \"espa\u00f1ol\" val val_utf8 = val . encode ( 'utf-8' ) val_utf8 type ( val_utf8 ) val_utf8 . decode ( 'utf-8' ) val . encode ( 'latin1' ) val . encode ( 'utf-16' ) val . encode ( 'utf-16le' ) bytes_val = b 'this is bytes' bytes_val decoded = bytes_val . decode ( 'utf8' ) decoded # this is str (Unicode) now Booleans True and True False or True Type casting s = '3.14159' fval = float ( s ) type ( fval ) int ( fval ) bool ( fval ) bool ( 0 ) None a = None a is None b = 5 b is not None def add_and_maybe_multiply(a, b, c=None): result = a + b if c is not None: result = result * c return result type ( None ) Dates and times from datetime import datetime , date , time dt = datetime ( 2011 , 10 , 29 , 20 , 30 , 21 ) dt . day dt . minute dt . date () dt . time () dt . strftime ( '%m/ %d /%Y %H:%M' ) datetime . strptime ( '20091031' , '%Y%m %d ' ) dt . replace ( minute = 0 , second = 0 ) dt2 = datetime ( 2011 , 11 , 15 , 22 , 30 ) delta = dt2 - dt delta type ( delta ) dt dt + delta Control Flow \u00b6 if, elif, and else if x < 0: print('It's negative') if x < 0: print('It's negative') elif x == 0: print('Equal to zero') elif 0 < x < 5: print('Positive but smaller than 5') else: print('Positive and larger than or equal to 5') a = 5 ; b = 7 c = 8 ; d = 4 if a < b or c > d : print ( 'Made it' ) 4 > 3 > 2 > 1 for loops for value in collection: # do something with value sequence = [1, 2, None, 4, None, 5] total = 0 for value in sequence: if value is None: continue total += value sequence = [1, 2, 0, 4, 6, 5, 2, 1] total_until_5 = 0 for value in sequence: if value == 5: break total_until_5 += value for i in range ( 4 ): for j in range ( 4 ): if j > i : break print (( i , j )) for a, b, c in iterator: # do something while loops x = 256 total = 0 while x > 0: if total > 500: break total += x x = x // 2 pass if x < 0: print('negative!') elif x == 0: # TODO: put something smart here pass else: print('positive!') range range ( 10 ) list ( range ( 10 )) list ( range ( 0 , 20 , 2 )) list ( range ( 5 , 0 , - 1 )) seq = [1, 2, 3, 4] for i in range(len(seq)): val = seq[i] sum = 0 for i in range(100000): # % is the modulo operator if i % 3 == 0 or i % 5 == 0: sum += i Ternary expressions value = if x = 5 'Non-negative' if x >= 0 else 'Negative' References: - Python for Data Analysis\" by Wes McKinney, published by O'Reilly Media","title":"02   Python   intro"},{"location":"python/base/02%20-%20Python%20-%20intro/#the-python-interpreter","text":"$ python Python 3.7 . 3 ( default , Apr 3 2019 , 05 : 39 : 12 ) [ GCC 8.3 . 0 ] on linux Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information . >>> >>> a = 1 >>> print ( a ) 1 >>> exit () %% writefile hello_world . py print ( \"Hello world\" ) Overwriting hello_world.py $ python hello_world . py Hello world $ ipython Python 3 .6.0 | packaged by conda-forge | ( default, Jan 13 2017 , 23 :17:12 ) Type \"copyright\" , \"credits\" or \"license\" for more information. IPython 5 .1.0 -- An enhanced Interactive Python. ? -> Introduction and overview of IPython 's features. %quickref -> Quick reference. help -> Python' s own help system. object? -> Details about 'object' , use 'object??' for extra details. In [ 1 ] : %run hello_world.py Hello world In [ 2 ] :","title":"The Python Interpreter"},{"location":"python/base/02%20-%20Python%20-%20intro/#ipython-basics","text":"","title":"IPython Basics"},{"location":"python/base/02%20-%20Python%20-%20intro/#running-the-ipython-shell","text":"from numpy.random import randn data = {i : randn() for i in range(7)} print(data) {0: -1.5948255432744511, 1: 0.10569006472787983, 2: 1.972367135977295, 3: 0.15455217573074576, 4: -0.24058577449429575, 5: -1.2904897053651216, 6: 0.3308507317325902}","title":"Running the IPython Shell"},{"location":"python/base/02%20-%20Python%20-%20intro/#running-the-jupyter-notebook","text":"$ jupyter notebook [ I 15 :20:52.739 NotebookApp ] Serving notebooks from local directory: /home/wesm/code/pydata-book [ I 15 :20:52.739 NotebookApp ] 0 active kernels [ I 15 :20:52.739 NotebookApp ] The Jupyter Notebook is running at: http://localhost:8888/ [ I 15 :20:52.740 NotebookApp ] Use Control-C to stop this server and shut down all kernels ( twice to skip confirmation ) . Created new window in existing browser session.","title":"Running the Jupyter Notebook"},{"location":"python/base/02%20-%20Python%20-%20intro/#introspection","text":"In [8]: b = [1, 2, 3] In [9]: b? Type: list String Form:[1, 2, 3] Length: 3 Docstring: list() -> new empty list list(iterable) -> new list initialized from iterable's items In [10]: print? Docstring: print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) Prints the values to a stream, or to sys.stdout by default. Optional keyword arguments: file: a file-like object (stream); defaults to the current sys.stdout. sep: string inserted between values, default a space. end: string appended after the last value, default a newline. flush: whether to forcibly flush the stream. Type: builtin_function_or_method def add_numbers ( a , b ): \"\"\" Add two numbers together Returns ------- the_sum : type of arguments \"\"\" return a + b In [ 11 ]: add_numbers ? Signature : add_numbers ( a , b ) Docstring : Add two numbers together Returns ------- the_sum : type of arguments File : < ipython - input - 9 - 6 a548a216e27 > Type : function In [ 12 ]: add_numbers ?? Signature : add_numbers ( a , b ) Source : def add_numbers ( a , b ): \"\"\" Add two numbers together Returns ------- the_sum : type of arguments \"\"\" return a + b File : < ipython - input - 9 - 6 a548a216e27 > Type : function In [ 13 ]: np .* load * ? np . __loader__ np . load np . loads np . loadtxt np . pkgload","title":"Introspection"},{"location":"python/base/02%20-%20Python%20-%20intro/#python-language-basics","text":"%% javascript ( new Array ([ 1 , 2 ])) var element = $('#7fde1b82-da82-4a3a-b4a6-d09315336df8'); (new Array([1, 2]))","title":"Python Language Basics"},{"location":"python/base/02%20-%20Python%20-%20intro/#scalar-types","text":"","title":"Scalar Types"},{"location":"python/base/02%20-%20Python%20-%20intro/#control-flow","text":"","title":"Control Flow"},{"location":"python/base/04%20-%20Generators/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); from itertools import dropwhile file = \"/Users/manu/Documents/Developpement/github/asampy/doc/Test_DCM2.dcm\" TYPES = [ \"FestKennfeld\" , \"KennFeld\" , \"FestKennlinie\" , \"Kennlinie\" , \"FestWertBlock\" , \"FestWert\" , \"TextString\" , \"GruppenKennlinie\" , \"GruppenKennfeld\" , \"StuetzStellenVerteilung\" ] def got ( buffer ): l = next ( buffer ) while not l . strip () . startswith ( \"END\" ): yield l l = next ( buffer ) with open ( file ) as f : for l in got ( f ): #dropwhile(lambda x : x.strip().startswith(\"*\"), f): #got(f) print ( l . strip ()) * DAMOS format * Created by ASCET * Creation date: 21.11.2012 17:06:25 * * DamosDataFilePath: 'c:\\ETASData\\ASCET6.1\\Test_DCM2.dcm' * DamosExtensionForOutput: 'dcm' * DamosFormatVersion: '2' * DamosCaseSensitiveNames: true * DamosIncludeBooleans: true * DamosIncludeDependentParameter: true * DamosBooleanFormat: 'String' * DamosEnumerationFormat: 'String' * DamosShowInputLogFile: true * DamosInputLogFile: 'c:\\ETAS\\LogFiles\\ASCET\\filein.log' * DamosShowOutputLogFile: false * DamosOutputLogFile: 'c:\\ETAS\\LogFiles\\ASCET\\fileout.log' KONSERVIERUNG_FORMAT 2.0 FESTWERTEBLOCK array 4 LANGNAME \"sample temperatures\" EINHEIT_W \"\u00b0 C\" WERT 0.75 -0.25 0.5 1.5","title":"04   Generators"},{"location":"python/base/Data%20types/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Based on WikiPedia list of data structure Primitive types \u00b6 Boolean True or False. type ( True ), True , type ( True ) is bool (bool, True, True) Floating-point / Double Single-precision real number values / wider floating-point size. No special distinction by python type ( 6.5 ) float type ( 6.5765135497145765974355785269472565842578617574875 ) float Integer Integral or fixed-precision values. Character / String Sequence of characters. Reference \u00b6 (also called a pointer or handle), a small value referring to another object's address in memory, possibly a much larger one. Enumerated type \u00b6 Small set of uniquely-named values. Composite types or Non-primitive type \u00b6 Array \u00b6 Record (also called tuple or structure) \u00b6 Union \u00b6 Tagged union (also called variant, variant record, discriminated union, or disjoint union) \u00b6 Abstract data types \u00b6 Container \u00b6 List \u00b6 Associative array \u00b6 multimap \u00b6 HTML ( wikipedia . summary ( 'multimap' , sentences = 1 )) In computer science, a multimap (sometimes also multihash or multidict) is a generalization of a map or associative array abstract data type in which more than one value may be associated with and returned for a given key. Multimap are not implemented naively in Python. However, based on the type defaultdict , its behavior can be easily reproduced. Note that defaultdict is directly coded in C from collections import defaultdict class MultiMap ( defaultdict ): \"\"\"Simple implemnation of a multimap using defaultdict from collection module\"\"\" def __init__ ( self , * args , ** kwargs ): super ( multimap , self ) . __init__ ( list , * args , ** kwargs ) def __setitem__ ( self , key , value ): assert type ( value ) is list , TypeError ( \"Setting an item to something else that a list\" ) super ( multimap , self ) . __setitem__ ( key , value ) a = MultiMap () a [ 0 ] . append ( 2 ) a [ 1 ] = \"A strind\" --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) <ipython-input-15-b952db637518> in <module> () ----> 1 a [ 1 ] = \"A strind\" <ipython-input-12-57034b56aed3> in __setitem__ (self, key, value) 6 super ( multimap , self ) . __init__ ( list , * args , ** kwargs ) 7 def __setitem__ ( self , key , value ) : ----> 8 assert type ( value ) is list , TypeError ( \"Setting an item to something else that a list\" ) 9 super ( multimap , self ) . __setitem__ ( key , value ) AssertionError : Setting an item to something else that a list a [ 0 ] . append ( 42 ) a [ 0 ] [2, 42] a multimap(list, {0: [2, 42]}) a [ 1 ] [] Set \u00b6 Multiset (Bag) \u00b6 Stack \u00b6 Queue \u00b6 Double-ended queue \u00b6 Priority queue \u00b6 Tree \u00b6 Graph \u00b6 See the networkx package. # https://stackoverflow.com/questions/19472530 from collections import defaultdict class Graph ( object ): \"\"\" Graph data structure, undirected by default. \"\"\" def __init__ ( self , connections , directed = False ): self . _graph = defaultdict ( set ) self . _directed = directed self . add_connections ( connections ) def add_connections ( self , connections ): \"\"\" Add connections (list of tuple pairs) to graph \"\"\" for node1 , node2 in connections : self . add ( node1 , node2 ) def add ( self , node1 , node2 ): \"\"\" Add connection between node1 and node2 \"\"\" self . _graph [ node1 ] . add ( node2 ) if not self . _directed : self . _graph [ node2 ] . add ( node1 ) def remove ( self , node ): \"\"\" Remove all references to node \"\"\" for n , cxns in self . _graph . iteritems (): try : cxns . remove ( node ) except KeyError : pass try : del self . _graph [ node ] except KeyError : pass def is_connected ( self , node1 , node2 ): \"\"\" Is node1 directly connected to node2 \"\"\" return node1 in self . _graph and node2 in self . _graph [ node1 ] def find_path ( self , node1 , node2 , path = []): \"\"\" Find any path between node1 and node2 (may not be shortest) \"\"\" path = path + [ node1 ] if node1 == node2 : return path if node1 not in self . _graph : return None for node in self . _graph [ node1 ]: if node not in path : new_path = self . find_path ( node , node2 , path ) if new_path : return new_path return None def __str__ ( self ): return ' {} ( {} )' . format ( self . __class__ . __name__ , dict ( self . _graph )) Structure Order Unique List yes no Associative array no yes Set no yes Multiset no no Types from third party packages \u00b6 NumPy \u00b6 import numpy as np np . typecodes {'Character': 'c', 'Integer': 'bhilqp', 'UnsignedInteger': 'BHILQP', 'Float': 'efdg', 'Complex': 'FDG', 'AllInteger': 'bBhHiIlLqQpP', 'AllFloat': 'efdgFDG', 'Datetime': 'Mm', 'All': '?bhilqpBHILQPefdgFDGSUVOMm'} from itertools import filterfalse for t in sorted(filterfalse(lambda x : \"All\" in x, np.typecodes)): for ut in sorted(np.typecodes[t]): print(f\"{t}, {ut}\") from itertools import product for t in np . typecodes [ 'Float' ]: arr = np . array ([ 1 , 2 ], dtype = t ) print ( t , arr . dtype , arr ) e float16 [ 1. 2.] f float32 [ 1. 2.] d float64 [ 1. 2.] g float128 [ 1.0 2.0] for t in np . typecodes [ 'UnsignedInteger' ]: arr = np . array ([ 1 , 2 ], dtype = t ) #arr -= 1e6 print ( t , arr . dtype , arr ) B uint8 [1 2] H uint16 [1 2] I uint32 [1 2] L uint64 [1 2] Q uint64 [1 2] P uint64 [1 2]","title":"Data types"},{"location":"python/base/Data%20types/#primitive-types","text":"Boolean True or False. type ( True ), True , type ( True ) is bool (bool, True, True) Floating-point / Double Single-precision real number values / wider floating-point size. No special distinction by python type ( 6.5 ) float type ( 6.5765135497145765974355785269472565842578617574875 ) float Integer Integral or fixed-precision values. Character / String Sequence of characters.","title":"Primitive types"},{"location":"python/base/Data%20types/#reference","text":"(also called a pointer or handle), a small value referring to another object's address in memory, possibly a much larger one.","title":"Reference"},{"location":"python/base/Data%20types/#enumerated-type","text":"Small set of uniquely-named values.","title":"Enumerated type"},{"location":"python/base/Data%20types/#composite-types-or-non-primitive-type","text":"","title":"Composite types or Non-primitive type"},{"location":"python/base/Data%20types/#array","text":"","title":"Array"},{"location":"python/base/Data%20types/#record-also-called-tuple-or-structure","text":"","title":"Record (also called tuple or structure)"},{"location":"python/base/Data%20types/#union","text":"","title":"Union"},{"location":"python/base/Data%20types/#tagged-union-also-called-variant-variant-record-discriminated-union-or-disjoint-union","text":"","title":"Tagged union (also called variant, variant record, discriminated union, or disjoint union)"},{"location":"python/base/Data%20types/#abstract-data-types","text":"","title":"Abstract data types"},{"location":"python/base/Data%20types/#container","text":"","title":"Container"},{"location":"python/base/Data%20types/#list","text":"","title":"List"},{"location":"python/base/Data%20types/#associative-array","text":"","title":"Associative array"},{"location":"python/base/Data%20types/#multimap","text":"HTML ( wikipedia . summary ( 'multimap' , sentences = 1 )) In computer science, a multimap (sometimes also multihash or multidict) is a generalization of a map or associative array abstract data type in which more than one value may be associated with and returned for a given key. Multimap are not implemented naively in Python. However, based on the type defaultdict , its behavior can be easily reproduced. Note that defaultdict is directly coded in C from collections import defaultdict class MultiMap ( defaultdict ): \"\"\"Simple implemnation of a multimap using defaultdict from collection module\"\"\" def __init__ ( self , * args , ** kwargs ): super ( multimap , self ) . __init__ ( list , * args , ** kwargs ) def __setitem__ ( self , key , value ): assert type ( value ) is list , TypeError ( \"Setting an item to something else that a list\" ) super ( multimap , self ) . __setitem__ ( key , value ) a = MultiMap () a [ 0 ] . append ( 2 ) a [ 1 ] = \"A strind\" --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) <ipython-input-15-b952db637518> in <module> () ----> 1 a [ 1 ] = \"A strind\" <ipython-input-12-57034b56aed3> in __setitem__ (self, key, value) 6 super ( multimap , self ) . __init__ ( list , * args , ** kwargs ) 7 def __setitem__ ( self , key , value ) : ----> 8 assert type ( value ) is list , TypeError ( \"Setting an item to something else that a list\" ) 9 super ( multimap , self ) . __setitem__ ( key , value ) AssertionError : Setting an item to something else that a list a [ 0 ] . append ( 42 ) a [ 0 ] [2, 42] a multimap(list, {0: [2, 42]}) a [ 1 ] []","title":"multimap"},{"location":"python/base/Data%20types/#set","text":"","title":"Set"},{"location":"python/base/Data%20types/#multiset-bag","text":"","title":"Multiset (Bag)"},{"location":"python/base/Data%20types/#stack","text":"","title":"Stack"},{"location":"python/base/Data%20types/#queue","text":"","title":"Queue"},{"location":"python/base/Data%20types/#double-ended-queue","text":"","title":"Double-ended queue"},{"location":"python/base/Data%20types/#priority-queue","text":"","title":"Priority queue"},{"location":"python/base/Data%20types/#tree","text":"","title":"Tree"},{"location":"python/base/Data%20types/#graph","text":"See the networkx package. # https://stackoverflow.com/questions/19472530 from collections import defaultdict class Graph ( object ): \"\"\" Graph data structure, undirected by default. \"\"\" def __init__ ( self , connections , directed = False ): self . _graph = defaultdict ( set ) self . _directed = directed self . add_connections ( connections ) def add_connections ( self , connections ): \"\"\" Add connections (list of tuple pairs) to graph \"\"\" for node1 , node2 in connections : self . add ( node1 , node2 ) def add ( self , node1 , node2 ): \"\"\" Add connection between node1 and node2 \"\"\" self . _graph [ node1 ] . add ( node2 ) if not self . _directed : self . _graph [ node2 ] . add ( node1 ) def remove ( self , node ): \"\"\" Remove all references to node \"\"\" for n , cxns in self . _graph . iteritems (): try : cxns . remove ( node ) except KeyError : pass try : del self . _graph [ node ] except KeyError : pass def is_connected ( self , node1 , node2 ): \"\"\" Is node1 directly connected to node2 \"\"\" return node1 in self . _graph and node2 in self . _graph [ node1 ] def find_path ( self , node1 , node2 , path = []): \"\"\" Find any path between node1 and node2 (may not be shortest) \"\"\" path = path + [ node1 ] if node1 == node2 : return path if node1 not in self . _graph : return None for node in self . _graph [ node1 ]: if node not in path : new_path = self . find_path ( node , node2 , path ) if new_path : return new_path return None def __str__ ( self ): return ' {} ( {} )' . format ( self . __class__ . __name__ , dict ( self . _graph )) Structure Order Unique List yes no Associative array no yes Set no yes Multiset no no","title":"Graph"},{"location":"python/base/Data%20types/#types-from-third-party-packages","text":"","title":"Types from third party packages"},{"location":"python/base/Data%20types/#numpy","text":"import numpy as np np . typecodes {'Character': 'c', 'Integer': 'bhilqp', 'UnsignedInteger': 'BHILQP', 'Float': 'efdg', 'Complex': 'FDG', 'AllInteger': 'bBhHiIlLqQpP', 'AllFloat': 'efdgFDG', 'Datetime': 'Mm', 'All': '?bhilqpBHILQPefdgFDGSUVOMm'} from itertools import filterfalse for t in sorted(filterfalse(lambda x : \"All\" in x, np.typecodes)): for ut in sorted(np.typecodes[t]): print(f\"{t}, {ut}\") from itertools import product for t in np . typecodes [ 'Float' ]: arr = np . array ([ 1 , 2 ], dtype = t ) print ( t , arr . dtype , arr ) e float16 [ 1. 2.] f float32 [ 1. 2.] d float64 [ 1. 2.] g float128 [ 1.0 2.0] for t in np . typecodes [ 'UnsignedInteger' ]: arr = np . array ([ 1 , 2 ], dtype = t ) #arr -= 1e6 print ( t , arr . dtype , arr ) B uint8 [1 2] H uint16 [1 2] I uint32 [1 2] L uint64 [1 2] Q uint64 [1 2] P uint64 [1 2]","title":"NumPy"},{"location":"python/base/date%20manipulation/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Python standard library \u00b6 First some environment variables must be set in order to set localtime from os import environ environ [ 'LC_ALL' ] = 'fr_FR.UTF-8' environ [ 'TZ' ] = 'Europe/Paris' time module \u00b6 import time This module provides various time-related functions. It is based on sys/times.h and coded in C. Important terminology and conventions from the python documentation : The epoch is the point where the time starts, and is platform dependent. UTC is Coordinated Universal Time, compromise between English and French. DST is Daylight Saving Time, an adjustment of the timezone during part of the year. time specificities: To find out what the epoch is on a given platform, look at time.gmtime(0) . For Unix, the epoch is January 1, 1970, 00:00:00 (UTC). DST rules are determined by local law and can change from year to year. The C library has a table containing those and is the only source of True Wisdom in this respect. The functions in this module may not handle dates and times before the epoch or far in the future. The cut-off point in the future is determined by the C library; for 32-bit systems, it is typically in 2038. Function strptime() can parse 2-digit years when given %y format code. When 2-digit years are parsed, they are converted according to the POSIX and ISO C standards: values 69\u201399 are mapped to 1969\u20131999, and values 0\u201368 are mapped to 2000\u20132068. The precision of the various real-time functions may be less than suggested by the units in which their value or argument is expressed. E.g. on most Unix systems, the clock \u201cticks\u201d only 50 or 100 times a second. On the other hand, the precision of time() and sleep() is better than their Unix equivalents: times are expressed as floating point numbers, time() returns the most accurate time available (using Unix gettimeofday() where available), and sleep() will accept a time with a nonzero fraction (Unix select() is used to implement this, where available). The time value as returned by gmtime() , localtime() , and strptime() , and accepted by asctime() , mktime() and strftime() , is a sequence of 9 integers. The return values of gmtime() , localtime() , and strptime() also offer attribute names for individual fields. Use the following functions to convert between time representations: From To Use seconds since the epoch struct_time in UTC gmtime() seconds since the epoch struct_time in local time localtime() struct_time in UTC seconds since the epoch calendar.timegm() struct_time in local time seconds since the epoch mktime() import sys time . gmtime ( 0 ) time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0) Naive/Aware time zone \u00b6 Python/Pandas timestamp types without a associated time zone are referred to as \u201cTime Zone Naive\u201d. Python/Pandas timestamp types with an associated time zone are referred to as \u201cTime Zone Aware\u201d. locale \u00b6 Locale are usually set at the operating system level, in containerized system, the must be eventualy set manualy Understanding locale environment variables and table . Example: Environment Variable and Category Names Value of Environment Variables Value of Category after Call to setlocale (LC_ALL,\"\") LC_COLLATE de_DE de_DE LC_CTYPE de_DE de_DE LC_MONETARY en_US en_US LC_NUMERIC (unset) da_DK LC_TIME (unset) da_DK LC_MESSAGES (unset) da_DK LC_ALL (unset) (not applicable) LANG da_DK (not applicable) import locale locale . getdefaultlocale () ('fr_FR', 'UTF-8') locale . getlocale () (None, None) locale . setlocale ( locale . LC_ALL , 'fr_FR.UTF-8' ) 'fr_FR.UTF-8' Time zone is beeing set according to TZ environment variable time . tzset () time . localtime () time.struct_time(tm_year=2020, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=23, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0) time . localtime () . tm_zone 'CET' time . time_ns () 1582104223312507367 time . ctime () 'Wed Feb 19 10:23:43 2020' datetime module \u00b6 The datetime module uses the time module, is coded in Python and supplies classes for manipulating dates and times. ISO 8601 Python official documentation import datetime as dt from datetime import datetime Subclasses \u00b6 Subclass relationships: object timedelta tzinfo timezone time date datetime Python/Pandas timestamp types without a associated time zone are referred to as \u201cTime Zone Naive\u201d. Python/Pandas timestamp types with an associated time zone are referred to as \u201cTime Zone Aware\u201d. All these types are immuables date objects are always naives time or datetime types can be either naive or aware (such an object d must success (d.tzinfo != None) & (d.tzinfo.utcoffset(d) ! None) dt . timedelta ? Init signature: dt . timedelta ( self , / , * args , ** kwargs ) Docstring: Difference between two datetime values. timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0) All arguments are optional and default to 0. Arguments may be integers or floats, and may be positive or negative. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: dt . tzinfo ? Init signature: dt . tzinfo ( self , / , * args , ** kwargs ) Docstring: Abstract base class for time zone info objects. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: timezone, _tzinfo, tzutc, tzoffset dt . timezone ? Init signature: dt . timezone ( self , / , * args , ** kwargs ) Docstring: Fixed offset from UTC implementation of tzinfo. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: dt . date ? Init signature: dt . date ( self , / , * args , ** kwargs ) Docstring: date(year, month, day) --> date object File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: datetime dt . datetime ? Init signature: dt . datetime ( self , / , * args , ** kwargs ) Docstring: datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]]) The year, month and day arguments are required. tzinfo may be None, or an instance of a tzinfo subclass. The remaining arguments may be ints. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: dt . time ? Init signature: dt . time ( self , / , * args , ** kwargs ) Docstring: time([hour[, minute[, second[, microsecond[, tzinfo]]]]]) --> a time object All arguments are optional. tzinfo may be None, or an instance of a tzinfo subclass. The remaining arguments may be ints. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: datetime constructors \u00b6 Constructors are: - datetime.datetime(*pargs, **kwargs) - datetime.today(*pargs, **kwargs) - datetime.now(*pargs, **kwargs) - datetime.utcnow(*pargs, **kwargs) - datetime.fromtimestamp(*pargs, **kwargs) - datetime.fromordinal(*pargs, **kwargs) - datetime.combine(*pargs, **kwargs) - datetime.fromisoformat(*pargs, **kwargs) - datetime.strptime(*pargs, **kwargs) Datetime objects have: - class attributes min , max an resolution - instance attributes year , month , day , hour , minute , second , microsecond , tzinfo , fold See the documentation for usage. t1 = dt . datetime ( 2019 , 1 , 1 , 0 , 0 , 0 , 0 ) t1 datetime.datetime(2019, 1, 1, 0, 0) now = dt . datetime . now () now datetime.datetime(2020, 2, 19, 10, 23, 43, 452652) now - t1 datetime.timedelta(days=414, seconds=37423, microseconds=452652) today = dt . datetime . today () today datetime.datetime(2020, 2, 19, 10, 23, 43, 469193) today . strftime ( ' %d .%m.%Y' ) '19.02.2020' Numpy datetime64 \u00b6 The data type is called \u201cdatetime64\u201d, so named because \u201cdatetime\u201d is already taken by the datetime library included in Python. ISO 8601 Datetimes and Timedeltas Datetime Support Functions import numpy as np from numpy import datetime64 d0 = datetime64 ( '2002-10-27T04:30' , '10s' ) d0 + 1 numpy.datetime64('2002-10-27T04:30:10','10s') np . datetime_data ( d0 ) ('s', 10) a = np . array ([ '1979-03-22T12' ], dtype = 'M8[h]' ) b = np . array ([ 3 * 60 ], dtype = 'm8[m]' ) a + b array(['1979-03-22T15:00'], dtype='datetime64[m]') a = np . timedelta64 ( 1 , 'Y' ) a numpy.timedelta64(1,'Y') np . datetime_data ( a ) ('Y', 1) d0 + b array(['2002-10-27T07:30:00'], dtype='datetime64[10s]') from warnings import try : d0 + a except TypeError as e : warn ( str ( e ), UserWarning ) /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Cannot get a common metadata divisor for NumPy datetime metadata [10s] and [Y] because they have incompatible nonlinear base time units after removing the cwd from sys.path. c = np . timedelta64 ( 1 , 's' ) d0 + c numpy.datetime64('2002-10-27T04:30:01') d0 . astype ( int ) 103569300 datetime . utcfromtimestamp ( d0 . astype ( int )) datetime.datetime(1973, 4, 13, 17, 15) datetime . utcfromtimestamp ( d0 . astype ( int )) datetime.datetime(1973, 4, 13, 17, 15) d = np . arange ( '2002-10-27T04:30' , 10 , 1 , dtype = 'M8[ns]' ) date2int = lambda elt : np . datetime64 ( elt , 's' , dtype = 'datetime64[s]' ) . astype ( np . int64 ) randomDates = np . random . RandomState ( 42 ) . randint ( date2int ( '2002-10-27T04:30' ), date2int ( '2003-10-27T04:30' ), 10 , dtype = 'i8' ) dates = np . sort ( randomDates ) . astype ( 'datetime64[s]' ) dates array(['2002-11-22T01:11:29', '2003-03-30T07:08:12', '2003-04-14T00:13:06', '2003-05-01T11:11:18', '2003-06-28T04:33:08', '2003-07-22T17:06:44', '2003-07-24T04:27:30', '2003-08-27T14:34:58', '2003-09-01T15:07:10', '2003-09-03T01:12:47'], dtype='datetime64[s]') d [ 1 ] . astype ( int ) . astype ( 'M8[ns]' ) numpy.datetime64('2002-10-27T04:30:00.000000001') # equals d.size * d.itemsize d . nbytes 80 Pandas \u00b6 Pandas time series documentation import pandas as pd from pandas import ( date_range , DataFrame , Timestamp ) from datetime import ( timezone , timedelta ) dti = date_range ( '2018-01-01' , periods = 3 , freq = 'H' ) date_range ( '1/1/2012' , freq = '0.1ms' , periods = 1000 ) DatetimeIndex([ '2012-01-01 00:00:00', '2012-01-01 00:00:00.000100', '2012-01-01 00:00:00.000200', '2012-01-01 00:00:00.000300', '2012-01-01 00:00:00.000400', '2012-01-01 00:00:00.000500', '2012-01-01 00:00:00.000600', '2012-01-01 00:00:00.000700', '2012-01-01 00:00:00.000800', '2012-01-01 00:00:00.000900', ... '2012-01-01 00:00:00.099000', '2012-01-01 00:00:00.099100', '2012-01-01 00:00:00.099200', '2012-01-01 00:00:00.099300', '2012-01-01 00:00:00.099400', '2012-01-01 00:00:00.099500', '2012-01-01 00:00:00.099600', '2012-01-01 00:00:00.099700', '2012-01-01 00:00:00.099800', '2012-01-01 00:00:00.099900'], dtype='datetime64[ns]', length=1000, freq='100U') pdf = DataFrame ({ 'naive' : [ datetime ( 2019 , 1 , 1 , 0 )], 'aware' : [ Timestamp ( year = 2019 , month = 1 , day = 1 , nanosecond = 500 , tz = dt . timezone ( dt . timedelta ( hours =- 8 )))]}) pdf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } naive aware 0 2019-01-01 2019-01-01 00:00:00.000000500-08:00 Pyarrow \u00b6 https://arrow.apache.org/docs/python/timestamps.html https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#datetime-types Spark \u00b6 Spark stores timestamps as 64-bit integers representing microseconds since the UNIX epoch. It does not store any metadata about time zones with its timestamps. Spark interprets timestamps with the session local time zone, (i.e. spark.sql.session.timeZone ). If that time zone is undefined, Spark turns to the default system time zone. from pyspark.sql import SparkSession from pyarrow import TimestampValue spark = ( SparkSession . builder . master ( \"local\" ) . appName ( \"time\" ) . getOrCreate () ) sc = spark . sparkContext coll = sc . parallelize ( np . arange ( 100_000 )) coll . count () 100000 coll . stats () (count: 100000, mean: 49999.5, stdev: 28867.513458037913, max: 99999.0, min: 0.0) coll2 = coll . flatMap ( lambda x : ( x * 2 , 1 )) coll2 . stats () (count: 200000, mean: 50000.0, stdev: 64548.94784193651, max: 199998.0, min: 0.0)","title":"Date manipulation"},{"location":"python/base/date%20manipulation/#python-standard-library","text":"First some environment variables must be set in order to set localtime from os import environ environ [ 'LC_ALL' ] = 'fr_FR.UTF-8' environ [ 'TZ' ] = 'Europe/Paris'","title":"Python standard library"},{"location":"python/base/date%20manipulation/#time-module","text":"import time This module provides various time-related functions. It is based on sys/times.h and coded in C. Important terminology and conventions from the python documentation : The epoch is the point where the time starts, and is platform dependent. UTC is Coordinated Universal Time, compromise between English and French. DST is Daylight Saving Time, an adjustment of the timezone during part of the year. time specificities: To find out what the epoch is on a given platform, look at time.gmtime(0) . For Unix, the epoch is January 1, 1970, 00:00:00 (UTC). DST rules are determined by local law and can change from year to year. The C library has a table containing those and is the only source of True Wisdom in this respect. The functions in this module may not handle dates and times before the epoch or far in the future. The cut-off point in the future is determined by the C library; for 32-bit systems, it is typically in 2038. Function strptime() can parse 2-digit years when given %y format code. When 2-digit years are parsed, they are converted according to the POSIX and ISO C standards: values 69\u201399 are mapped to 1969\u20131999, and values 0\u201368 are mapped to 2000\u20132068. The precision of the various real-time functions may be less than suggested by the units in which their value or argument is expressed. E.g. on most Unix systems, the clock \u201cticks\u201d only 50 or 100 times a second. On the other hand, the precision of time() and sleep() is better than their Unix equivalents: times are expressed as floating point numbers, time() returns the most accurate time available (using Unix gettimeofday() where available), and sleep() will accept a time with a nonzero fraction (Unix select() is used to implement this, where available). The time value as returned by gmtime() , localtime() , and strptime() , and accepted by asctime() , mktime() and strftime() , is a sequence of 9 integers. The return values of gmtime() , localtime() , and strptime() also offer attribute names for individual fields. Use the following functions to convert between time representations: From To Use seconds since the epoch struct_time in UTC gmtime() seconds since the epoch struct_time in local time localtime() struct_time in UTC seconds since the epoch calendar.timegm() struct_time in local time seconds since the epoch mktime() import sys time . gmtime ( 0 ) time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0)","title":"time module"},{"location":"python/base/date%20manipulation/#naiveaware-time-zone","text":"Python/Pandas timestamp types without a associated time zone are referred to as \u201cTime Zone Naive\u201d. Python/Pandas timestamp types with an associated time zone are referred to as \u201cTime Zone Aware\u201d.","title":"Naive/Aware time zone"},{"location":"python/base/date%20manipulation/#locale","text":"Locale are usually set at the operating system level, in containerized system, the must be eventualy set manualy Understanding locale environment variables and table . Example: Environment Variable and Category Names Value of Environment Variables Value of Category after Call to setlocale (LC_ALL,\"\") LC_COLLATE de_DE de_DE LC_CTYPE de_DE de_DE LC_MONETARY en_US en_US LC_NUMERIC (unset) da_DK LC_TIME (unset) da_DK LC_MESSAGES (unset) da_DK LC_ALL (unset) (not applicable) LANG da_DK (not applicable) import locale locale . getdefaultlocale () ('fr_FR', 'UTF-8') locale . getlocale () (None, None) locale . setlocale ( locale . LC_ALL , 'fr_FR.UTF-8' ) 'fr_FR.UTF-8' Time zone is beeing set according to TZ environment variable time . tzset () time . localtime () time.struct_time(tm_year=2020, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=23, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0) time . localtime () . tm_zone 'CET' time . time_ns () 1582104223312507367 time . ctime () 'Wed Feb 19 10:23:43 2020'","title":"locale"},{"location":"python/base/date%20manipulation/#datetime-module","text":"The datetime module uses the time module, is coded in Python and supplies classes for manipulating dates and times. ISO 8601 Python official documentation import datetime as dt from datetime import datetime","title":"datetime module"},{"location":"python/base/date%20manipulation/#subclasses","text":"Subclass relationships: object timedelta tzinfo timezone time date datetime Python/Pandas timestamp types without a associated time zone are referred to as \u201cTime Zone Naive\u201d. Python/Pandas timestamp types with an associated time zone are referred to as \u201cTime Zone Aware\u201d. All these types are immuables date objects are always naives time or datetime types can be either naive or aware (such an object d must success (d.tzinfo != None) & (d.tzinfo.utcoffset(d) ! None) dt . timedelta ? Init signature: dt . timedelta ( self , / , * args , ** kwargs ) Docstring: Difference between two datetime values. timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0) All arguments are optional and default to 0. Arguments may be integers or floats, and may be positive or negative. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: dt . tzinfo ? Init signature: dt . tzinfo ( self , / , * args , ** kwargs ) Docstring: Abstract base class for time zone info objects. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: timezone, _tzinfo, tzutc, tzoffset dt . timezone ? Init signature: dt . timezone ( self , / , * args , ** kwargs ) Docstring: Fixed offset from UTC implementation of tzinfo. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: dt . date ? Init signature: dt . date ( self , / , * args , ** kwargs ) Docstring: date(year, month, day) --> date object File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: datetime dt . datetime ? Init signature: dt . datetime ( self , / , * args , ** kwargs ) Docstring: datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]]) The year, month and day arguments are required. tzinfo may be None, or an instance of a tzinfo subclass. The remaining arguments may be ints. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses: dt . time ? Init signature: dt . time ( self , / , * args , ** kwargs ) Docstring: time([hour[, minute[, second[, microsecond[, tzinfo]]]]]) --> a time object All arguments are optional. tzinfo may be None, or an instance of a tzinfo subclass. The remaining arguments may be ints. File: /opt/conda/lib/python3.7/datetime.py Type: type Subclasses:","title":"Subclasses"},{"location":"python/base/date%20manipulation/#datetime-constructors","text":"Constructors are: - datetime.datetime(*pargs, **kwargs) - datetime.today(*pargs, **kwargs) - datetime.now(*pargs, **kwargs) - datetime.utcnow(*pargs, **kwargs) - datetime.fromtimestamp(*pargs, **kwargs) - datetime.fromordinal(*pargs, **kwargs) - datetime.combine(*pargs, **kwargs) - datetime.fromisoformat(*pargs, **kwargs) - datetime.strptime(*pargs, **kwargs) Datetime objects have: - class attributes min , max an resolution - instance attributes year , month , day , hour , minute , second , microsecond , tzinfo , fold See the documentation for usage. t1 = dt . datetime ( 2019 , 1 , 1 , 0 , 0 , 0 , 0 ) t1 datetime.datetime(2019, 1, 1, 0, 0) now = dt . datetime . now () now datetime.datetime(2020, 2, 19, 10, 23, 43, 452652) now - t1 datetime.timedelta(days=414, seconds=37423, microseconds=452652) today = dt . datetime . today () today datetime.datetime(2020, 2, 19, 10, 23, 43, 469193) today . strftime ( ' %d .%m.%Y' ) '19.02.2020'","title":"datetime constructors"},{"location":"python/base/date%20manipulation/#numpy-datetime64","text":"The data type is called \u201cdatetime64\u201d, so named because \u201cdatetime\u201d is already taken by the datetime library included in Python. ISO 8601 Datetimes and Timedeltas Datetime Support Functions import numpy as np from numpy import datetime64 d0 = datetime64 ( '2002-10-27T04:30' , '10s' ) d0 + 1 numpy.datetime64('2002-10-27T04:30:10','10s') np . datetime_data ( d0 ) ('s', 10) a = np . array ([ '1979-03-22T12' ], dtype = 'M8[h]' ) b = np . array ([ 3 * 60 ], dtype = 'm8[m]' ) a + b array(['1979-03-22T15:00'], dtype='datetime64[m]') a = np . timedelta64 ( 1 , 'Y' ) a numpy.timedelta64(1,'Y') np . datetime_data ( a ) ('Y', 1) d0 + b array(['2002-10-27T07:30:00'], dtype='datetime64[10s]') from warnings import try : d0 + a except TypeError as e : warn ( str ( e ), UserWarning ) /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Cannot get a common metadata divisor for NumPy datetime metadata [10s] and [Y] because they have incompatible nonlinear base time units after removing the cwd from sys.path. c = np . timedelta64 ( 1 , 's' ) d0 + c numpy.datetime64('2002-10-27T04:30:01') d0 . astype ( int ) 103569300 datetime . utcfromtimestamp ( d0 . astype ( int )) datetime.datetime(1973, 4, 13, 17, 15) datetime . utcfromtimestamp ( d0 . astype ( int )) datetime.datetime(1973, 4, 13, 17, 15) d = np . arange ( '2002-10-27T04:30' , 10 , 1 , dtype = 'M8[ns]' ) date2int = lambda elt : np . datetime64 ( elt , 's' , dtype = 'datetime64[s]' ) . astype ( np . int64 ) randomDates = np . random . RandomState ( 42 ) . randint ( date2int ( '2002-10-27T04:30' ), date2int ( '2003-10-27T04:30' ), 10 , dtype = 'i8' ) dates = np . sort ( randomDates ) . astype ( 'datetime64[s]' ) dates array(['2002-11-22T01:11:29', '2003-03-30T07:08:12', '2003-04-14T00:13:06', '2003-05-01T11:11:18', '2003-06-28T04:33:08', '2003-07-22T17:06:44', '2003-07-24T04:27:30', '2003-08-27T14:34:58', '2003-09-01T15:07:10', '2003-09-03T01:12:47'], dtype='datetime64[s]') d [ 1 ] . astype ( int ) . astype ( 'M8[ns]' ) numpy.datetime64('2002-10-27T04:30:00.000000001') # equals d.size * d.itemsize d . nbytes 80","title":"Numpy datetime64"},{"location":"python/base/date%20manipulation/#pandas","text":"Pandas time series documentation import pandas as pd from pandas import ( date_range , DataFrame , Timestamp ) from datetime import ( timezone , timedelta ) dti = date_range ( '2018-01-01' , periods = 3 , freq = 'H' ) date_range ( '1/1/2012' , freq = '0.1ms' , periods = 1000 ) DatetimeIndex([ '2012-01-01 00:00:00', '2012-01-01 00:00:00.000100', '2012-01-01 00:00:00.000200', '2012-01-01 00:00:00.000300', '2012-01-01 00:00:00.000400', '2012-01-01 00:00:00.000500', '2012-01-01 00:00:00.000600', '2012-01-01 00:00:00.000700', '2012-01-01 00:00:00.000800', '2012-01-01 00:00:00.000900', ... '2012-01-01 00:00:00.099000', '2012-01-01 00:00:00.099100', '2012-01-01 00:00:00.099200', '2012-01-01 00:00:00.099300', '2012-01-01 00:00:00.099400', '2012-01-01 00:00:00.099500', '2012-01-01 00:00:00.099600', '2012-01-01 00:00:00.099700', '2012-01-01 00:00:00.099800', '2012-01-01 00:00:00.099900'], dtype='datetime64[ns]', length=1000, freq='100U') pdf = DataFrame ({ 'naive' : [ datetime ( 2019 , 1 , 1 , 0 )], 'aware' : [ Timestamp ( year = 2019 , month = 1 , day = 1 , nanosecond = 500 , tz = dt . timezone ( dt . timedelta ( hours =- 8 )))]}) pdf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } naive aware 0 2019-01-01 2019-01-01 00:00:00.000000500-08:00","title":"Pandas"},{"location":"python/base/date%20manipulation/#pyarrow","text":"https://arrow.apache.org/docs/python/timestamps.html https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#datetime-types","title":"Pyarrow"},{"location":"python/base/date%20manipulation/#spark","text":"Spark stores timestamps as 64-bit integers representing microseconds since the UNIX epoch. It does not store any metadata about time zones with its timestamps. Spark interprets timestamps with the session local time zone, (i.e. spark.sql.session.timeZone ). If that time zone is undefined, Spark turns to the default system time zone. from pyspark.sql import SparkSession from pyarrow import TimestampValue spark = ( SparkSession . builder . master ( \"local\" ) . appName ( \"time\" ) . getOrCreate () ) sc = spark . sparkContext coll = sc . parallelize ( np . arange ( 100_000 )) coll . count () 100000 coll . stats () (count: 100000, mean: 49999.5, stdev: 28867.513458037913, max: 99999.0, min: 0.0) coll2 = coll . flatMap ( lambda x : ( x * 2 , 1 )) coll2 . stats () (count: 200000, mean: 50000.0, stdev: 64548.94784193651, max: 199998.0, min: 0.0)","title":"Spark"},{"location":"python/base/iter_gen_coro/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Iterators, generators and coroutines \u00b6 Python standard library: Itertools David Beazley's PyCon'14 presentation Simple Generators The proposal for adding generators and the yield statement to Python. Coroutines via Enhanced Generators The proposal to enhance the API and syntax of generators, making them usable as simple coroutines. Syntax for Delegating to a Subgenerator The proposal to introduce the yield_from syntax, making delegation to sub-generators easy. def echo ( value = None ): print ( \"Execution starts when 'next()' is called for the first time.\" ) try : while True : try : value = ( yield value ) except Exception as e : value = e finally : print ( \"Don't forget to clean up when 'close()' is called.\" ) generator = echo ( 1 ) print ( next ( generator )) Execution starts when 'next()' is called for the first time. 1 print ( next ( generator )) None print ( generator . send ( 2 )) 2 generator . throw ( TypeError , \"spam\" ) TypeError('spam') generator . close () Don't forget to clean up when 'close()' is called. def gen (): # defines a generator function yield 123 async def agen (): # defines an asynchronous generator function (PEP 525) yield 123 j % timeit list ( gen ()) 709 ns \u00b1 8.22 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each) await agen () --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-13-e5f4d3dfdbad> in <module> ----> 1 await agen ( ) TypeError : object async_generator can't be used in 'await' expression import asyncio async def hello (): await asyncio . sleep ( 3 ) print ( \"hello\" ) await hello () print ( \"Finished\" ) Finished from asyncio import get_running_loop loop = get_running_loop () loop . --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) <ipython-input-12-67c20df64121> in <module> ----> 1 loop . run_until_complete ( agen ) ~/.opt/pyenv/versions/3.9.0/lib/python3.9/asyncio/base_events.py in run_until_complete (self, future) 616 \"\"\" 617 self . _check_closed ( ) --> 618 self . _check_running ( ) 619 620 new_task = not futures . isfuture ( future ) ~/.opt/pyenv/versions/3.9.0/lib/python3.9/asyncio/base_events.py in _check_running (self) 576 def _check_running ( self ) : 577 if self . is_running ( ) : --> 578 raise RuntimeError ( 'This event loop is already running' ) 579 if events . _get_running_loop ( ) is not None : 580 raise RuntimeError( RuntimeError : This event loop is already running % autoawait agen () IPython autoawait is `on`, and set to use `asyncio` --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-8-4930c2bf4233> in <module> 1 get_ipython ( ) . run_line_magic ( 'autoawait' , '' ) ----> 2 await agen ( ) TypeError : object async_generator can't be used in 'await' expression Simple Generators \u00b6 def echo ( value = None ): print ( \"Execution starts when 'next()' is called for the first time.\" ) try : while True : try : value = ( yield value ) except Exception as e : value = e finally : print ( \"Don't forget to clean up when 'close()' is called.\" ) generator = echo ( 1 ) next ( generator ) Execution starts when 'next()' is called for the first time. 1 generator . close () Don't forget to clean up when 'close()' is called. next ( generator ) --------------------------------------------------------------------------- StopIteration Traceback (most recent call last) <ipython-input-70-323ce5d717bb> in <module> () ----> 1 next ( generator ) StopIteration : Generator have to be first initialized by next statement unless a TypeError is raised. The idea in initializing the generator is to get it reach first the yield statement. From that on, next() function and .send() method can be used. generator = echo ( 1 ) generator . send ( 2 ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-73-0a3f5cee3555> in <module> () 1 generator = echo ( 1 ) ----> 2 generator . send ( 2 ) TypeError : can't send non-None value to a just-started generator generator . throw ( TypeError , \"spam\" ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-74-96652ada1238> in <module> () ----> 1 generator . throw ( TypeError , \"spam\" ) <ipython-input-65-002f3dd94c24> in echo (value) ----> 1 def echo ( value = None ) : 2 print ( \"Execution starts when 'next()' is called for the first time.\" ) 3 try : 4 while True : 5 try : TypeError : spam Simple decorator for initializing a generator def initgen ( func ): def wrapper ( * args , ** kwargs ): gen = func ( * args , ** kwargs ) next ( gen ) return gen return wrapper @initgen def echo2 ( value = None ): print ( \"Execution starts when 'next()' is called for the first time.\" ) try : while True : try : value = ( yield value ) except Exception as e : value = e finally : print ( \"Don't forget to clean up when 'close()' is called.\" ) generator = echo2 ( 1 ) r = generator . send ( 2 ) print ( r ) Execution starts when 'next()' is called for the first time. 2 r = generator . send ( 4 ) print ( r ) 4 print ( _ ) Moyenne 13.0 @initgen def echo3 ( value = None ): print ( \"Execution starts when 'next()' is called for the first time.\" ) try : while True : try : A = ( yield value ) + 10 except Exception as e : value = e finally : print ( \"Don't forget to clean up when 'close()' is called.\" ) generator = echo3 ( 1 ) r = generator . send ( 2 ) print ( r ) Execution starts when 'next()' is called for the first time. Don't forget to clean up when 'close()' is called. 1 generator . send ( 4 ) 1 @initgen def moyenne (): _sum = 0 _i = 0 _moy = 0 while True : elt = ( yield f \"Moyenne { _moy } \" ) _sum += elt _i += 1 _moy = _sum / _i m = moyenne () m . send ( 4 ) 'Moyenne 4.0' m . send ( 20 ) 'Moyenne 12.0' @initgen def moyenne2 (): _sum = 0 _i = 0 _moy = 0 while True : elt = ( yield f \"Moyenne { _moy } \" + \"...\" ) + 10 _sum += elt _i += 1 _moy = _sum / _i m2 = moyenne2 () m2 . send ( 4 ) 'Moyenne 14.0...' m2 . send ( 2 ) 'Moyenne 13.0...' m2 . close () def fibonacci ( n ): \"\"\" A generator for creating the Fibonacci numbers \"\"\" a , b , counter = ( 0 , 1 , 0 ) while True : if ( counter > n ): return yield a a , b = b , a + b counter += 1 f = fibonacci ( 5 ) for x in f : print ( x , \"-> \" , end = \"\" , flush = True ) 0 -> 1 -> 1 -> 2 -> 3 -> 5 ->","title":"Iterators, generators and coroutines"},{"location":"python/base/iter_gen_coro/#iterators-generators-and-coroutines","text":"Python standard library: Itertools David Beazley's PyCon'14 presentation Simple Generators The proposal for adding generators and the yield statement to Python. Coroutines via Enhanced Generators The proposal to enhance the API and syntax of generators, making them usable as simple coroutines. Syntax for Delegating to a Subgenerator The proposal to introduce the yield_from syntax, making delegation to sub-generators easy. def echo ( value = None ): print ( \"Execution starts when 'next()' is called for the first time.\" ) try : while True : try : value = ( yield value ) except Exception as e : value = e finally : print ( \"Don't forget to clean up when 'close()' is called.\" ) generator = echo ( 1 ) print ( next ( generator )) Execution starts when 'next()' is called for the first time. 1 print ( next ( generator )) None print ( generator . send ( 2 )) 2 generator . throw ( TypeError , \"spam\" ) TypeError('spam') generator . close () Don't forget to clean up when 'close()' is called. def gen (): # defines a generator function yield 123 async def agen (): # defines an asynchronous generator function (PEP 525) yield 123 j % timeit list ( gen ()) 709 ns \u00b1 8.22 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each) await agen () --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-13-e5f4d3dfdbad> in <module> ----> 1 await agen ( ) TypeError : object async_generator can't be used in 'await' expression import asyncio async def hello (): await asyncio . sleep ( 3 ) print ( \"hello\" ) await hello () print ( \"Finished\" ) Finished from asyncio import get_running_loop loop = get_running_loop () loop . --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) <ipython-input-12-67c20df64121> in <module> ----> 1 loop . run_until_complete ( agen ) ~/.opt/pyenv/versions/3.9.0/lib/python3.9/asyncio/base_events.py in run_until_complete (self, future) 616 \"\"\" 617 self . _check_closed ( ) --> 618 self . _check_running ( ) 619 620 new_task = not futures . isfuture ( future ) ~/.opt/pyenv/versions/3.9.0/lib/python3.9/asyncio/base_events.py in _check_running (self) 576 def _check_running ( self ) : 577 if self . is_running ( ) : --> 578 raise RuntimeError ( 'This event loop is already running' ) 579 if events . _get_running_loop ( ) is not None : 580 raise RuntimeError( RuntimeError : This event loop is already running % autoawait agen () IPython autoawait is `on`, and set to use `asyncio` --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-8-4930c2bf4233> in <module> 1 get_ipython ( ) . run_line_magic ( 'autoawait' , '' ) ----> 2 await agen ( ) TypeError : object async_generator can't be used in 'await' expression","title":"Iterators, generators and coroutines"},{"location":"python/base/iter_gen_coro/#simple-generators","text":"def echo ( value = None ): print ( \"Execution starts when 'next()' is called for the first time.\" ) try : while True : try : value = ( yield value ) except Exception as e : value = e finally : print ( \"Don't forget to clean up when 'close()' is called.\" ) generator = echo ( 1 ) next ( generator ) Execution starts when 'next()' is called for the first time. 1 generator . close () Don't forget to clean up when 'close()' is called. next ( generator ) --------------------------------------------------------------------------- StopIteration Traceback (most recent call last) <ipython-input-70-323ce5d717bb> in <module> () ----> 1 next ( generator ) StopIteration : Generator have to be first initialized by next statement unless a TypeError is raised. The idea in initializing the generator is to get it reach first the yield statement. From that on, next() function and .send() method can be used. generator = echo ( 1 ) generator . send ( 2 ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-73-0a3f5cee3555> in <module> () 1 generator = echo ( 1 ) ----> 2 generator . send ( 2 ) TypeError : can't send non-None value to a just-started generator generator . throw ( TypeError , \"spam\" ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-74-96652ada1238> in <module> () ----> 1 generator . throw ( TypeError , \"spam\" ) <ipython-input-65-002f3dd94c24> in echo (value) ----> 1 def echo ( value = None ) : 2 print ( \"Execution starts when 'next()' is called for the first time.\" ) 3 try : 4 while True : 5 try : TypeError : spam Simple decorator for initializing a generator def initgen ( func ): def wrapper ( * args , ** kwargs ): gen = func ( * args , ** kwargs ) next ( gen ) return gen return wrapper @initgen def echo2 ( value = None ): print ( \"Execution starts when 'next()' is called for the first time.\" ) try : while True : try : value = ( yield value ) except Exception as e : value = e finally : print ( \"Don't forget to clean up when 'close()' is called.\" ) generator = echo2 ( 1 ) r = generator . send ( 2 ) print ( r ) Execution starts when 'next()' is called for the first time. 2 r = generator . send ( 4 ) print ( r ) 4 print ( _ ) Moyenne 13.0 @initgen def echo3 ( value = None ): print ( \"Execution starts when 'next()' is called for the first time.\" ) try : while True : try : A = ( yield value ) + 10 except Exception as e : value = e finally : print ( \"Don't forget to clean up when 'close()' is called.\" ) generator = echo3 ( 1 ) r = generator . send ( 2 ) print ( r ) Execution starts when 'next()' is called for the first time. Don't forget to clean up when 'close()' is called. 1 generator . send ( 4 ) 1 @initgen def moyenne (): _sum = 0 _i = 0 _moy = 0 while True : elt = ( yield f \"Moyenne { _moy } \" ) _sum += elt _i += 1 _moy = _sum / _i m = moyenne () m . send ( 4 ) 'Moyenne 4.0' m . send ( 20 ) 'Moyenne 12.0' @initgen def moyenne2 (): _sum = 0 _i = 0 _moy = 0 while True : elt = ( yield f \"Moyenne { _moy } \" + \"...\" ) + 10 _sum += elt _i += 1 _moy = _sum / _i m2 = moyenne2 () m2 . send ( 4 ) 'Moyenne 14.0...' m2 . send ( 2 ) 'Moyenne 13.0...' m2 . close () def fibonacci ( n ): \"\"\" A generator for creating the Fibonacci numbers \"\"\" a , b , counter = ( 0 , 1 , 0 ) while True : if ( counter > n ): return yield a a , b = b , a + b counter += 1 f = fibonacci ( 5 ) for x in f : print ( x , \"-> \" , end = \"\" , flush = True ) 0 -> 1 -> 1 -> 2 -> 3 -> 5 ->","title":"Simple Generators"},{"location":"python/test/intro/","text":"Tests \u00b6 Unit testing \u00b6 See unittest and pytest Property-based testing \u00b6 This kind of testing is used in Haskell in QuickCheck . Hypothesis makes it easer to write parametrized tests by describing a range of scenarios. Automation \u00b6 tox provides a way to run arbitrary commands in isolated environments to serve as a single entry point for build, test and release activities.","title":"Intro"},{"location":"python/test/intro/#tests","text":"","title":"Tests"},{"location":"python/test/intro/#unit-testing","text":"See unittest and pytest","title":"Unit testing"},{"location":"python/test/intro/#property-based-testing","text":"This kind of testing is used in Haskell in QuickCheck . Hypothesis makes it easer to write parametrized tests by describing a range of scenarios.","title":"Property-based testing"},{"location":"python/test/intro/#automation","text":"tox provides a way to run arbitrary commands in isolated environments to serve as a single entry point for build, test and release activities.","title":"Automation"},{"location":"python/test/pytest/","text":"Pytest \u00b6 Configuration \u00b6 Three files: pytest.ini tox.ini setup.cfg this part of the configuration can be put in pyproject.toml sections [pytest] or [tool:pytest] . can be superseded at the cli with the flag -o . Test discovery \u00b6 If no argument at cli, Fixture \u00b6 Documentation \u00b6 import pytest @pytest . fixture def myfixture (): '''Declare my fixture for my test purpose''' return Object ()","title":"pytest"},{"location":"python/test/pytest/#pytest","text":"","title":"Pytest"},{"location":"python/test/pytest/#configuration","text":"Three files: pytest.ini tox.ini setup.cfg this part of the configuration can be put in pyproject.toml sections [pytest] or [tool:pytest] . can be superseded at the cli with the flag -o .","title":"Configuration"},{"location":"python/test/pytest/#test-discovery","text":"If no argument at cli,","title":"Test discovery"},{"location":"python/test/pytest/#fixture","text":"","title":"Fixture"},{"location":"python/test/pytest/#documentation","text":"import pytest @pytest . fixture def myfixture (): '''Declare my fixture for my test purpose''' return Object ()","title":"Documentation"},{"location":"python/test/unittest/","text":"Unittest \u00b6 The basic building blocks of unit testing are test cases: entirely self contained subclasses of TestCase or use FunctionTestCase . initialization performed by the setUp method.","title":"unittest"},{"location":"python/test/unittest/#unittest","text":"The basic building blocks of unit testing are test cases: entirely self contained subclasses of TestCase or use FunctionTestCase . initialization performed by the setUp method.","title":"Unittest"},{"location":"shell/bats/","text":"Bash Testing: bats \u00b6 is a TAM-compliant testing framework for Bash. Test Anything Protocol TAP , the Test Anything Protocol, is a simple text-based interface between testing modules in a test harness. It decouples the reporting of errors from the presentation of the reports. Installation \u00b6 git based \u00b6 git submodule add https://github.com/bats-core/bats-core.git test/bats git submodule add https://github.com/bats-core/bats-support.git test/test_helper/bats-support git submodule add https://github.com/bats-core/bats-assert.git test/test_helper/bats-assert Basic commands \u00b6 run \u00b6 run invokes its arguments as a command in a subshell, saves the exit status and output into global variables: $status and $output . run returns with a 0 status code so you can continue to make assertions in your test case The $lines array is available for easily accessing individual lines of output. Example @test \"invoking foo without arguments prints usage\" { run foo [ \" $status \" -eq 1 ] [ \" $output \" = \"foo: no such file 'nonexistent_filename'\" ] [ \" ${ lines [0] } \" = \"usage: foo <filename>\" ] } load \u00b6 load sources a Bash source file relative to the location of the current test file. Example load test_helper.bash skip \u00b6 Tests can be skipped by using the skip command at the point in a test you wish to skip. Example @test \"A test which should run\" { if [ foo ! = bar ] ; then skip \"foo isn't bar\" fi run foo [ \" $status \" -eq 0 ] } setup and teardown \u00b6 Pre- and post-test hooks have two scopes: setup and teardown functions run before and after each test case, respectively. setup_file and teardown_file run once before the first test\u2019s setup and after the last test\u2019s teardown for the containing file. Print to terminal \u00b6 Text that is output directly to stdout or stderr (file descriptor 1 or 2), ie echo 'text' is considered part of the test function output and is printed only on test failures. To have text printed unconditionally from within a test function you need to redirect the output to file descriptor 3, eg echo 'text' >&3 . Environment variables \u00b6 Environment variable Description $BATS_TEST_FILENAME Fully expanded path to the Bats test file. $BATS_TEST_DIRNAME Directory in which the Bats test file is located. $BATS_TEST_NAMES Array of function names for each test case. $BATS_TEST_NAME Name of the function containing the current test case. $BATS_TEST_DESCRIPTION Description of the current test case. $BATS_TEST_NUMBER (1-based) index of the current test case in the test file. $BATS_SUITE_TEST_NUMBER (1-based) index of the current test case in the test suite (over all files). $BATS_TMPDIR Base temporary directory for temporary files / directories. Default: $TMPDIR , or /tmp if not set. $BATS_RUN_TMPDIR Location to the temporary directory used by bats to store all its internal temporary files during the tests. (default: $BATS_TMPDIR/bats-run-$BATS_ROOT_PID-XXXXXX ) $BATS_FILE_EXTENSION (default: bats ) specifies the extension of test files that should be found when running a suite (via bats [-r] suite_folder/ ) $BATS_SUITE_TMPDIR Temporary directory common to all tests of a suite. Could be used to create files required by multiple tests. $BATS_FILE_TMPDIR Temporary directory common to all tests of a test file. Could be used to create files required by multiple tests in the same test file. $BATS_TEST_TMPDIR Temporary directory unique for each test. Could be used to create files required only for specific tests. Common assertions \u00b6 bats-assert is a helper library providing common assertions: assert / refute : a given expression evaluates to true or false. assert_equal : two parameters are equal. assert_success / assert_failure : exit status is 0 or 1. assert_output / refute_output : output does (not) contain given content. assert_line / refute_line : a specific line of output does (not) contain given content. Common functions \u00b6 bats-support is a supporting library providing common functions to test helper libraries: Error reporting Output formatting Language and Execution","title":"test (bats)"},{"location":"shell/bats/#bash-testing-bats","text":"is a TAM-compliant testing framework for Bash. Test Anything Protocol TAP , the Test Anything Protocol, is a simple text-based interface between testing modules in a test harness. It decouples the reporting of errors from the presentation of the reports.","title":"Bash Testing: bats"},{"location":"shell/bats/#installation","text":"","title":"Installation"},{"location":"shell/bats/#git-based","text":"git submodule add https://github.com/bats-core/bats-core.git test/bats git submodule add https://github.com/bats-core/bats-support.git test/test_helper/bats-support git submodule add https://github.com/bats-core/bats-assert.git test/test_helper/bats-assert","title":"git based"},{"location":"shell/bats/#basic-commands","text":"","title":"Basic commands"},{"location":"shell/bats/#run","text":"run invokes its arguments as a command in a subshell, saves the exit status and output into global variables: $status and $output . run returns with a 0 status code so you can continue to make assertions in your test case The $lines array is available for easily accessing individual lines of output. Example @test \"invoking foo without arguments prints usage\" { run foo [ \" $status \" -eq 1 ] [ \" $output \" = \"foo: no such file 'nonexistent_filename'\" ] [ \" ${ lines [0] } \" = \"usage: foo <filename>\" ] }","title":"run"},{"location":"shell/bats/#load","text":"load sources a Bash source file relative to the location of the current test file. Example load test_helper.bash","title":"load"},{"location":"shell/bats/#skip","text":"Tests can be skipped by using the skip command at the point in a test you wish to skip. Example @test \"A test which should run\" { if [ foo ! = bar ] ; then skip \"foo isn't bar\" fi run foo [ \" $status \" -eq 0 ] }","title":"skip"},{"location":"shell/bats/#setup-and-teardown","text":"Pre- and post-test hooks have two scopes: setup and teardown functions run before and after each test case, respectively. setup_file and teardown_file run once before the first test\u2019s setup and after the last test\u2019s teardown for the containing file.","title":"setup and teardown"},{"location":"shell/bats/#print-to-terminal","text":"Text that is output directly to stdout or stderr (file descriptor 1 or 2), ie echo 'text' is considered part of the test function output and is printed only on test failures. To have text printed unconditionally from within a test function you need to redirect the output to file descriptor 3, eg echo 'text' >&3 .","title":"Print to terminal"},{"location":"shell/bats/#environment-variables","text":"Environment variable Description $BATS_TEST_FILENAME Fully expanded path to the Bats test file. $BATS_TEST_DIRNAME Directory in which the Bats test file is located. $BATS_TEST_NAMES Array of function names for each test case. $BATS_TEST_NAME Name of the function containing the current test case. $BATS_TEST_DESCRIPTION Description of the current test case. $BATS_TEST_NUMBER (1-based) index of the current test case in the test file. $BATS_SUITE_TEST_NUMBER (1-based) index of the current test case in the test suite (over all files). $BATS_TMPDIR Base temporary directory for temporary files / directories. Default: $TMPDIR , or /tmp if not set. $BATS_RUN_TMPDIR Location to the temporary directory used by bats to store all its internal temporary files during the tests. (default: $BATS_TMPDIR/bats-run-$BATS_ROOT_PID-XXXXXX ) $BATS_FILE_EXTENSION (default: bats ) specifies the extension of test files that should be found when running a suite (via bats [-r] suite_folder/ ) $BATS_SUITE_TMPDIR Temporary directory common to all tests of a suite. Could be used to create files required by multiple tests. $BATS_FILE_TMPDIR Temporary directory common to all tests of a test file. Could be used to create files required by multiple tests in the same test file. $BATS_TEST_TMPDIR Temporary directory unique for each test. Could be used to create files required only for specific tests.","title":"Environment variables"},{"location":"shell/bats/#common-assertions","text":"bats-assert is a helper library providing common assertions: assert / refute : a given expression evaluates to true or false. assert_equal : two parameters are equal. assert_success / assert_failure : exit status is 0 or 1. assert_output / refute_output : output does (not) contain given content. assert_line / refute_line : a specific line of output does (not) contain given content.","title":"Common assertions"},{"location":"shell/bats/#common-functions","text":"bats-support is a supporting library providing common functions to test helper libraries: Error reporting Output formatting Language and Execution","title":"Common functions"},{"location":"shell/intro/","text":"Shell \u00b6 Initialization \u00b6 bash Interactive login Interactive non-login Script /etc/profile A /etc/bash.bashrc A ~/.bashrc B ~/.bash_profile B1 ~/.bash_login B2 ~/.profile B3 BASH_ENV A ~/.bash_logout C zsh Interactive login Interactive non-login Script /etc/profile A /etc/zshenv A A A ~/.zshenv B B B /etc/zprofile C ~/.zprofile D /etc/zshrc E C ~/.zshrc F D /etc/zlogin G ~/.zlogin H ~/.zlogout I /etc/zlogout J Souce Configuration \u00b6 Line edition and keybindings \u00b6 GNU Readline is a software library that provides line-editing and history capabilities for interactive programs with a command-line interface. Bash typically uses this library (same original author ). Emacs-like keybindings are default but readline enables configuration files at /etc/inputrc or ~/.inputrc . A lot of program not specifically written in C rely on readline , e.g. the impala-shell through python's readline module . Zsh does not use readline, instead uses an own development Zsh Line Editor (ZLE) . Keybindings in inputrc are not read, rely instead on an internal command bindkey that can be coupled to terminfo . LS_COLORS \u00b6 vivid is a generator for the LS_COLORS environment variable export LS_COLORS = \" $( vivid generate molokai ) \" GNU Stow \u00b6 GNU Stow is a symlink farm manager which takes distinct packages of software and/or data located in separate directories on the filesystem, and makes them appear to be installed in the same place. The software can be used to manage dotfiles. GNU envsubst (Gettext package) \u00b6 GNU envsubst substitutes the values of environment variables. Autojump \u00b6 These utilities give the most visited directory for the shortest search term typed. jump is written in go. autojump is written in python. zoxide is written in rust. zsh-z is a native zsh port of z.sh Finding files \u00b6 nnn is another vi-inspired filemanager for the console, lightweight, written in C. Ranger , vim-inspired filemanager for the console, written in python. Install with pipx install ranger-fm exa is a replacement for ls written in Rust. Directory content \u00b6 dust is a rust application printing a similar output to du with additional bar chart. fuzzy finder \u00b6 fzf is a go fuzzy finder Search syntax Token Match type Description sbtrkt fuzzy-match Items that match sbtrkt 'wild exact-match (quoted) Items that include wild ^music prefix-exact-match Items that start with music .mp3$ suffix-exact-match Items that end with .mp3 !fire inverse-exact-match Items that do not include fire !^music inverse-prefix-exact-match Items that do not start with music !.mp3$ inverse-suffix-exact-match Items that do not end with .mp3 fzf provides bindings : Ctrl T paste the selected files and directories onto the command-line Ctrl R paste the selected command from history onto the command-line. A second press on Ctrl R sorts relevant entries in chronological order Alt C cd into the selected directory fuzzy competion is activated with ** , e.g. vim **<TAB> completes all files in the cwd. fzy is written in C File content search \u00b6 Search can be efficiently performed by the silver search ( ag ) and ripgrep ( rg ) , written resp. in C and rust. rg tends to be one of the quickest. Ripgrep Usage rg [ OPTIONS ] PATTERN [ PATH ... ] rg [ OPTIONS ] [ -e PATTERN ... ] [ -f PATTERNFILE ... ] [ PATH ... ] rg [ OPTIONS ] --files [ PATH ... ] rg [ OPTIONS ] --type-list command | rg [ OPTIONS ] PATTERN --type <TYPE> where <TYPE> is part of the registered types, can be displayed with rg --list-types Search with substitution \u00b6 In respect of DOTADIW , rg does not support natively search and replacement. This can be achieved with a pipe. Prepare cookiecutter templates from molecule init outputs rg ROLE --files-with-matches | xargs sed -e \"s/ROLE/\\{\\{ cookiecutter.role_name \\}\\}/g\" Link: https://learnbyexample.github.io/substitution-with-ripgrep/ Manual filtering: globs \u00b6 Exclude path 'pack' from search rg -g '!/pack/**' g:ale Working with structured data \u00b6 JSON \u00b6 jq JQ cheatsheet Prepare cookiecutter templates from molecule init outputs bash URL=$(you-get --json \"https://www.youtube.com/watch?v=ZzfHjytDceU\" | jq -s 'sort_by(.streams.__default__.size) | reverse | .[0].streams.__default__.src[0]' | sed -e s/\\\"//g) YAML \u00b6 yq Workflows \u00b6 desk makes it easy to flip back and forth between different project contexts in your favorite shell. Change directory, activate a virtualenv or rvm, load in domain-specific aliases, environment variables, functions, arbitrary shell files, all in a single command. direnv augments existing shells with a new feature that can load and unload environment variables depending on the current directory. Modules is a tool that simplify shell initialization and lets users easily modify their environment during the session with modulefiles. zsh-autoenv automatically sources (known/whitelisted) .autoenv.zsh files, handles \"enter\" and leave\" events, nesting, and stashing of variables (overwriting and restoring). asdf manage multiple runtime versions with a single CLI tool, extendable via plugins. Others \u00b6 nutshell is a new kind of shell, currently under heavy development. Style guide \u00b6 google shell style Linting \u00b6 shellcheck , can be used by ALE in vim.","title":"shell"},{"location":"shell/intro/#shell","text":"","title":"Shell"},{"location":"shell/intro/#initialization","text":"bash Interactive login Interactive non-login Script /etc/profile A /etc/bash.bashrc A ~/.bashrc B ~/.bash_profile B1 ~/.bash_login B2 ~/.profile B3 BASH_ENV A ~/.bash_logout C zsh Interactive login Interactive non-login Script /etc/profile A /etc/zshenv A A A ~/.zshenv B B B /etc/zprofile C ~/.zprofile D /etc/zshrc E C ~/.zshrc F D /etc/zlogin G ~/.zlogin H ~/.zlogout I /etc/zlogout J Souce","title":"Initialization"},{"location":"shell/intro/#configuration","text":"","title":"Configuration"},{"location":"shell/intro/#line-edition-and-keybindings","text":"GNU Readline is a software library that provides line-editing and history capabilities for interactive programs with a command-line interface. Bash typically uses this library (same original author ). Emacs-like keybindings are default but readline enables configuration files at /etc/inputrc or ~/.inputrc . A lot of program not specifically written in C rely on readline , e.g. the impala-shell through python's readline module . Zsh does not use readline, instead uses an own development Zsh Line Editor (ZLE) . Keybindings in inputrc are not read, rely instead on an internal command bindkey that can be coupled to terminfo .","title":"Line edition and keybindings"},{"location":"shell/intro/#ls_colors","text":"vivid is a generator for the LS_COLORS environment variable export LS_COLORS = \" $( vivid generate molokai ) \"","title":"LS_COLORS"},{"location":"shell/intro/#gnu-stow","text":"GNU Stow is a symlink farm manager which takes distinct packages of software and/or data located in separate directories on the filesystem, and makes them appear to be installed in the same place. The software can be used to manage dotfiles.","title":"GNU Stow"},{"location":"shell/intro/#gnu-envsubst-gettext-package","text":"GNU envsubst substitutes the values of environment variables.","title":"GNU envsubst (Gettext package)"},{"location":"shell/intro/#autojump","text":"These utilities give the most visited directory for the shortest search term typed. jump is written in go. autojump is written in python. zoxide is written in rust. zsh-z is a native zsh port of z.sh","title":"Autojump"},{"location":"shell/intro/#finding-files","text":"nnn is another vi-inspired filemanager for the console, lightweight, written in C. Ranger , vim-inspired filemanager for the console, written in python. Install with pipx install ranger-fm exa is a replacement for ls written in Rust.","title":"Finding files"},{"location":"shell/intro/#directory-content","text":"dust is a rust application printing a similar output to du with additional bar chart.","title":"Directory content"},{"location":"shell/intro/#fuzzy-finder","text":"fzf is a go fuzzy finder Search syntax Token Match type Description sbtrkt fuzzy-match Items that match sbtrkt 'wild exact-match (quoted) Items that include wild ^music prefix-exact-match Items that start with music .mp3$ suffix-exact-match Items that end with .mp3 !fire inverse-exact-match Items that do not include fire !^music inverse-prefix-exact-match Items that do not start with music !.mp3$ inverse-suffix-exact-match Items that do not end with .mp3 fzf provides bindings : Ctrl T paste the selected files and directories onto the command-line Ctrl R paste the selected command from history onto the command-line. A second press on Ctrl R sorts relevant entries in chronological order Alt C cd into the selected directory fuzzy competion is activated with ** , e.g. vim **<TAB> completes all files in the cwd. fzy is written in C","title":"fuzzy finder"},{"location":"shell/intro/#file-content-search","text":"Search can be efficiently performed by the silver search ( ag ) and ripgrep ( rg ) , written resp. in C and rust. rg tends to be one of the quickest. Ripgrep Usage rg [ OPTIONS ] PATTERN [ PATH ... ] rg [ OPTIONS ] [ -e PATTERN ... ] [ -f PATTERNFILE ... ] [ PATH ... ] rg [ OPTIONS ] --files [ PATH ... ] rg [ OPTIONS ] --type-list command | rg [ OPTIONS ] PATTERN --type <TYPE> where <TYPE> is part of the registered types, can be displayed with rg --list-types","title":"File content search"},{"location":"shell/intro/#search-with-substitution","text":"In respect of DOTADIW , rg does not support natively search and replacement. This can be achieved with a pipe. Prepare cookiecutter templates from molecule init outputs rg ROLE --files-with-matches | xargs sed -e \"s/ROLE/\\{\\{ cookiecutter.role_name \\}\\}/g\" Link: https://learnbyexample.github.io/substitution-with-ripgrep/","title":"Search with substitution"},{"location":"shell/intro/#manual-filtering-globs","text":"Exclude path 'pack' from search rg -g '!/pack/**' g:ale","title":"Manual filtering: globs"},{"location":"shell/intro/#working-with-structured-data","text":"","title":"Working with structured data"},{"location":"shell/intro/#json","text":"jq JQ cheatsheet Prepare cookiecutter templates from molecule init outputs bash URL=$(you-get --json \"https://www.youtube.com/watch?v=ZzfHjytDceU\" | jq -s 'sort_by(.streams.__default__.size) | reverse | .[0].streams.__default__.src[0]' | sed -e s/\\\"//g)","title":"JSON"},{"location":"shell/intro/#yaml","text":"yq","title":"YAML"},{"location":"shell/intro/#workflows","text":"desk makes it easy to flip back and forth between different project contexts in your favorite shell. Change directory, activate a virtualenv or rvm, load in domain-specific aliases, environment variables, functions, arbitrary shell files, all in a single command. direnv augments existing shells with a new feature that can load and unload environment variables depending on the current directory. Modules is a tool that simplify shell initialization and lets users easily modify their environment during the session with modulefiles. zsh-autoenv automatically sources (known/whitelisted) .autoenv.zsh files, handles \"enter\" and leave\" events, nesting, and stashing of variables (overwriting and restoring). asdf manage multiple runtime versions with a single CLI tool, extendable via plugins.","title":"Workflows"},{"location":"shell/intro/#others","text":"nutshell is a new kind of shell, currently under heavy development.","title":"Others"},{"location":"shell/intro/#style-guide","text":"google shell style","title":"Style guide"},{"location":"shell/intro/#linting","text":"shellcheck , can be used by ALE in vim.","title":"Linting"},{"location":"shell/tmux/","text":"tmux \u00b6 Panes \u00b6 Layout \u00b6 Change layout : select-layout has five predefined layouts : even-horizontal , even-vertical , main-horizontal , main-vertical , or tiled . Move panes move-pane [-t dst-pane] Plugins \u00b6 tpm Installation if \"test ! -d ~/.tmux/plugins/tpm\" \\ \"run 'git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm && ~/.tmux/plugins/tpm/bin/install_plugins'\" tpm tpm tpm tpm","title":"tmux"},{"location":"shell/tmux/#tmux","text":"","title":"tmux"},{"location":"shell/tmux/#panes","text":"","title":"Panes"},{"location":"shell/tmux/#layout","text":"Change layout : select-layout has five predefined layouts : even-horizontal , even-vertical , main-horizontal , main-vertical , or tiled . Move panes move-pane [-t dst-pane]","title":"Layout"},{"location":"shell/tmux/#plugins","text":"tpm Installation if \"test ! -d ~/.tmux/plugins/tpm\" \\ \"run 'git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm && ~/.tmux/plugins/tpm/bin/install_plugins'\" tpm tpm tpm tpm","title":"Plugins"},{"location":"shell/version_manager/","text":"Version manager \u00b6 Bash: C:","title":"Version manager"},{"location":"shell/version_manager/#version-manager","text":"Bash: C:","title":"Version manager"},{"location":"shell/zsh/","text":"Zsh \u00b6 The Z-shell Initialisation \u00b6 Shell initilization performs operations depending on the execution context, these operations can be mainly separated on login and interactive property. An short summary can be found at pyenv wiki . Basically: login : e.g. when user logs in to a system with non-graphical interface or via SSH; interactive : shell that has a prompt and whose standard input and error are both connected to terminals. If $ZDOTDIR , $RCS or $GLOABL_RCS are not set, Zsh performs initialiation in the following order: /etc/zsh/zshenv ~/.zshenv login mode: /etc/zsh/zprofile ~/.zprofile interactive: /etc/zsh/zshrc ~/.zshrc login mode: /etc/zsh/login ~/.zlogin .zlogout and /etc/zsh/zshlogout are called when exiting, not when opening. See this post for a complementary information. Readline capability: ZLE \u00b6 Zsh does not use readline, instead uses an own development Zsh Line Editor (ZLE) . Keybindings in inputrc are not read, rely instead on an internal command bindkey that can be coupled to terminfo . All actions in the editor are performed by widgets . Bindings are affected to keymaps . The current used keymap is main . Initially, there are eight keymaps: emacs EMACS emulation viins vi emulation - insert mode vicmd vi emulation - command mode viopp vi emulation - operator pending visual vi emulation - selection active isearch incremental search mode command read a command name .safe fallback keymap These keymaps can be accessed l Keymap can be created and must be affected to main to be in use: bindkey -N mymap viins bindkey -A mymap main New bindings are affected to the current ( main ) keymap . bindkey -lL shows which keymap is linked to `main'. zle -la list all existing keymap names in the form of bindkey commands to create or link the keymaps. Links an intro on widgets Prompt \u00b6 Prompt sequences undergo a special form of expansion . Some modules make it easier to personalize the prompt. The prompt system must be loaded (performed by extensions): autoload -U promptinit; promptinit . A theme can be applied with the prompt cmd. \u276f prompt <TAB> -- prompt theme -- adam1 bigfade elite fire pure restore zefram adam2 clint elite2 off pws suse bart default fade oliver redhat walters Third party modules: spaceshift is a pure zsh prompt providing VCS integration, language version, job indicator and more. starshift is a port of spaceshift in rust. pure is a lighweight prompt in pure zsh. Parameters \u00b6 Parameters set by the shell Parameter Description ! The process ID of the last command started in the background with &, put into the background with the bg builtin, or spawned with coproc. # The number of positional parameters in decimal. Note that some confusion may occur with the syntax $#param which substitutes the length of param. Use ${#} to resolve ambiguities. In particular, the sequence \u2018$#-...\u2019 in an arithmetic expression is interpreted as the length of the parameter -, q.v. ARGC Same as #. $ The process ID of this shell. Note that this indicates the original shell started by invoking zsh; all processes forked from the shells without executing a new program, such as subshells started by (...), substitute the same value. - Flags supplied to the shell on invocation or by the set or setopt commands. * An array containing the positional parameters. argv Same as *. Assigning to argv changes the local positional parameters, but argv is not itself a local parameter. Deleting argv with unset in any function deletes it everywhere, although only the innermost positional parameter array is deleted (so * and @ in other scopes are not affected). @ Same as argv[@], even when argv is not set. ? The exit status returned by the last command. 0 The name used to invoke the current shell, or as set by the -c command line option upon invocation. If the FUNCTION_ARGZERO option is set, $0 is set upon entry to a shell function to the name of the function, and upon entry to a sourced script to the name of the script, and reset to its previous value when the function or script returns. status Same as ?. pipestatus An array containing the exit statuses returned by all commands in the last pipeline. _ The last argument of the previous command. Also, this parameter is set in the environment of every command executed to the full pathname of the command. CPUTYPE The machine type (microprocessor class or machine model), as determined at run time. EGID The effective group ID of the shell process. If you have sufficient privileges, you may change the effective group ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command with a different effective group ID by \u2018(EGID=gid; command)\u2019 EUID The effective user ID of the shell process. If you have sufficient privileges, you may change the effective user ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command with a different effective user ID by \u2018(EUID=uid; command)\u2019 ERRNO The value of errno (see man page errno(3)) as set by the most recently failed system call. This value is system dependent and is intended for debugging purposes. It is also useful with the zsh/system module which allows the number to be turned into a name or message. FUNCNEST Integer. If greater than or equal to zero, the maximum nesting depth of shell functions. When it is exceeded, an error is raised at the point where a function is called. The default value is determined when the shell is configured, but is typically 500. Increasing the value increases the danger of a runaway function recursion causing the shell to crash. Setting a negative value turns off the check. GID The real group ID of the shell process. If you have sufficient privileges, you may change the group ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command under a different group ID by \u2018(GID=gid; command)\u2019 HISTCMD The current history event number in an interactive shell, in other words the event number for the command that caused $HISTCMD to be read. If the current history event modifies the history, HISTCMD changes to the new maximum history event number. HOST The current hostname. LINENO The line number of the current line within the current script, sourced file, or shell function being executed, whichever was started most recently. Note that in the case of shell functions the line number refers to the function as it appeared in the original definition, not necessarily as displayed by the functions builtin. LOGNAME If the corresponding variable is not set in the environment of the shell, it is initialized to the login name corresponding to the current login session. This parameter is exported by default but this can be disabled using the typeset builtin. The value is set to the string returned by the man page getlogin(3) system call if that is available. MACHTYPE The machine type (microprocessor class or machine model), as determined at compile time. OLDPWD The previous working directory. This is set when the shell initializes and whenever the directory changes. OPTARG The value of the last option argument processed by the getopts command. OPTIND The index of the last option argument processed by the getopts command. OSTYPE The operating system, as determined at compile time. PPID The process ID of the parent of the shell. PWD The present working directory. This is set when the shell initializes and whenever the directory changes. RANDOM A pseudo-random integer from 0 to 32767. SECONDS The number of seconds since shell invocation. SHLVL Incremented by one each time a new shell is started. signals An array containing the names of the signals. TRY_BLOCK_ERROR In an always block, indicates whether the preceding list of code caused an error. The value is 1 to indicate an error, 0 otherwise. It may be reset, clearing the error condition. See Complex Commands TRY_BLOCK_INTERRUPT This variable works in a similar way to TRY_BLOCK_ERROR , but represents the status of an interrupt from the signal SIGINT, which typically comes from the keyboard when the user types ^C. If set to 0, any such interrupt will be reset; otherwise, the interrupt is propagated after the always block. TTY The name of the tty associated with the shell, if any. TTYIDLE The idle time of the tty associated with the shell in seconds or -1 if there is no such tty. UID <S> The real user ID of the shell process. USERNAME The username corresponding to the real user ID of the shell process. If you have sufficient privileges, you may change the username (and also the user ID and group ID) of the shell by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command under a different username (and user ID and group ID) by \u2018(USERNAME=username; command)\u2019 VENDOR The vendor, as determined at compile time. zsh_eval_context ( ZSH_EVAL_CONTEXT ) An array (colon-separated list) indicating the context of shell code that is being run. See documentation for details. ZSH_ARGZERO If zsh was invoked to run a script, this is the name of the script. Otherwise, it is the name used to invoke the current shell. This is the same as the value of $0 when the POSIX_ARGZERO option is set, but is always available. ZSH_EXECUTION_STRING If the shell was started with the option -c, this contains the argument passed to the option. Otherwise it is not set. ZSH_NAME Expands to the basename of the command used to invoke this instance of zsh. ZSH_PATCHLEVEL The output of \u2018git describe \u2013tags \u2013long\u2019 for the zsh repository used to build the shell. This is most useful in order to keep track of versions of the shell during development between releases; hence most users should not use it and should instead rely on $ZSH_VERSION. zsh_scheduled_events See The zsh/sched Module. ZSH_SCRIPT If zsh was invoked to run a script, this is the name of the script, otherwise it is unset. ZSH_SUBSHELL Readonly integer. Initially zero, incremented each time the shell forks to create a subshell for executing code. Hence \u2018(print $ZSH_SUBSHELL)\u2019 and \u2018print $(print $ZSH_SUBSHELL)\u2019 output 1, while \u2018( (print $ZSH_SUBSHELL) )\u2019 outputs 2. ZSH_VERSION The version number of the release of zsh. Data structures \u00b6 Associative arrays \u00b6 Declared with declare -A <ARRAY> or typeset -A <ARRAY> Associative arrays can not be nested Functions \u00b6 Hook functions \u00b6 It is possible to define an array that has the same name as the function with _functions appended. Any element in such an array is taken as the name of a function to execute; it is executed in the same context and with the same arguments as the basic function. Example \u276f echo $precmd_functions _zsh_autosuggest_start _zsh_highlight_main__precmd_hook _zshz_precmd prompt_pure_precmd # Show the definition of a function: # it is possible to use `which` or nearly identical to bash `type -f` \u276f whence -f _zsh_autosuggest_start chpwd : executed whenever the current working directory is changed. periodic : if the parameter PERIOD is set, this function is executed every $PERIOD seconds, just before a prompt. precmd : executed before each prompt. preexec : executed just after a command has been read and is about to be executed. zshaddhistory : executed when a history line has been read interactively, but before it is executed. zshexit : executed at the point where the main shell is about to exit normally. Display user configuration of hooks functions Expansion \u00b6 This section is a cheatsheet on expansion, based on the manual and reads, especially this blog post . The examples hereunder are taken from the latest and to be run, interactive comments must be enabled in zsh ( setopt interactive_comments ). The following types of expansions are performed in the indicated order in five steps: History Expansion is performed only in interactive shells. Alias Expansion Aliases are expanded immediately. Process Substitution , Parameter Expansion , Command Substitution , Arithmetic Expansion , Brace Expansion These five are performed in left-to-right fashion. On each argument, any of the five steps that are needed are performed one after the other. Hence, for example, all the parts of parameter expansion are completed before command substitution is started. After these expansions, all unquoted occurrences of the characters \u2018\\\u2019,\u2018\u2019\u2019 and \u2018\"\u2019 are removed. Filename Expansion If the SH_FILE_EXPANSION option is set, the order of expansion is modified for compatibility with sh and ksh: filename expansion is performed immediately after alias expansion. Filename Generation , commonly referred to as globbing, always done last. Filename generation (globbing) \u00b6 glob operators * matches any string, including the null string. ? matches any character. [...] matches any of the enclosed characters: ranges of characters can be specified by separating two characters by a - or classes as [:alnum:] , [:alpha:] , [:ascii:] , ..., [:xdigit:] ! or ^ negates the class <[x]-[y]> matches any number in the range x to y, inclusive. (...) matches the enclosed pattern. x|y matches either x or y. ^x matches anything except the pattern x. Requires EXTENDED_GLOB to be set. x~y match anything that matches the pattern x but does not match y. Requires EXTENDED_GLOB to be set. x# Matches zero or more occurrences of the pattern x. Requires EXTENDED_GLOB to be set. x## Matches one or more occurrences of the pattern x. Requires EXTENDED_GLOB to be set. The precedence of the operators given above is (highest) \u2018^\u2019, \u2018/\u2019, \u2018~\u2019, \u2018|\u2019 (lowest) # list text files that end in a number from 1 to 10 \u276f ls -l zsh_demo/**/*< 1 -10>.txt # list text files that start with the letter a \u276f ls -l zsh_demo/**/ [ a ] *.txt # list text files that start with either ab or bc \u276f ls -l zsh_demo/**/ ( ab | bc ) *.txt # list text files that don't start with a lower or uppercase c \u276f ls -l zsh_demo/**/ [ ^cC ] *.txt # Remove all but go.mod \u276f setopt extended_glob \u276f rm -Rf -- ^go.mod glob flag i case insensitive. l lower case characters in the pattern match upper or lower case characters. Upper case characters behvior unchanged. I case sensitive: locally negates the effect of i or l from that point on. ... glob qualifiers Furthers qualifiers Qualifiers Scope / directories F \u2018full\u2019 (i.e. non-empty) directories. . plain files @ symbolic links = sockets p named pipes (FIFOs) * executable plain files (0100 or 0010 or 0001) % device files (character or block special) %b block special files %c character special files r owner-readable files (0400) w owner-writable files (0200) x owner-executable files (0100) A group-readable files (0040) I group-writable files (0020) E group-executable files (0010) R world-readable files (0004) W world-writable files (0002) X world-executable files (0001) s setuid files (04000) S setgid files (02000) t files with the sticky bit (01000) fspec files with access rights matching spec. estring +cmd The string will be executed as shell code. ddev files on the device dev l[-|+]ct files having a link count less than ct (-), greater than ct (+), or equal to ct U files owned by the effective user ID G files owned by the effective group ID uid files owned by user ID id if that is a number. gid like uid but with group IDs or names a[Mwhms][-|+]n files accessed exactly n days ago. m[Mwhms][-|+]n like the file access qualifier, except that it uses the file modification time. c[Mwhms][-|+]n like the file access qualifier, except that it uses the file inode change time. L[+|-]n files less than n bytes (-), more than n bytes (+), or exactly n bytes in length. ^ negates all qualifiers following it - toggles between making the qualifiers work on symbolic links (the default) and the files they point to M sets the MARK_DIRS option for the current pattern T appends a trailing qualifier mark to the filenames, analogous to the LIST_TYPES option, for the current pattern (overrides M) N sets the NULL_GLOB option for the current pattern D sets the GLOB_DOTS option for the current pattern n sets the NUMERIC_GLOB_SORT option for the current pattern Yn enables short-circuit mode: the pattern will expand to at most n filenames. # show only directories \u276f print -l zsh_demo/**/* ( / ) # because the expression is expanded, # can be used with editors, e.g. vim # will open a lot of files (36) \u276f vim zsh_demo/**/* ( . ) # show empty files \u276f ls -l zsh_demo/**/* ( L0 ) # show files greater than 3 KB \u276f ls -l zsh_demo/**/* ( Lk+3 ) # show files modified in the last hour \u276f print -l zsh_demo/**/* ( mh-1 ) # sort files from most to least recently modified and show the last 3 \u276f ls -l zsh_demo/**/* ( om [ 1 ,3 ]) # keep it simple \u276f ls -l zsh_demo/**/* ( .Lm-2mh-1om [ 1 ,3 ]) Completion \u00b6 Initialization \u00b6 # menu-select widget, part of the zsh/complist module # must be loaded before the call to compinit zmodload -i zsh/complist # Use modern completion system autoload -U compinit compinit Cache reset \u00b6 rm -f ~/.zcompdump% compinit\u2029 Behind the hood Completion is provided by files named as the command name prefixed by an underscore: _cmd contains the completion logic for cmd . The location of this file must be in $fpath . Addition of a path can be done with fpath+=<PATH TO COMPLETION FILE> . When compinit is run, the first line of accessible files in $fpath is read. Those containing one of the tags #compdef or #autoload will be autoloaded. The declaration can be done for multiple commands, function aliases can be referenced too, e.g. slogin to ssh hereunder: #compdef ssh slogin=ssh scp ssh-add ssh-agent ssh-copy-id ssh-keygen ssh-keyscan sftp As an alternative, compdef may be called directly Configuration \u00b6 \ud83d\udd17 User defined completion \u00b6 Some utility functions Sources: zsh-completion how to: \ud83d\udd17 Modules \u00b6 Modules are loaded with zmodload ZSH modules ZSH modules are loaded with the prefix zsh/ , e.g. for net/tcl \u276f zmodload zsh/net/tcp Modules Description attr Builtins for manipulating extended attributes (xattr). cap Builtins for manipulating POSIX.1e (POSIX.6) capability (privilege) sets. clone A builtin that can clone a running shell onto another terminal. compctl The compctl builtin for controlling completion. complete The basic completion code. complist Completion listing extensions. computil A module with utility builtins needed for the shell function based completion system. curses curses windowing commands datetime Some date/time commands and parameters. deltochar A ZLE function duplicating EMACS' zap-to-char. example An example of how to write a module. files Some basic file manipulation commands as builtins. mapfile Access to external files via a special associative array. mathfunc Standard scientific functions for use in mathematical evaluations. net/socket Manipulation of Unix domain sockets net/tcp Manipulation of TCP sockets newuser Arrange for files for new users to be installed. parameter Access to internal hash tables via special associative arrays. pcre Interface to the PCRE library. regex Interface to the POSIX regex library. sched A builtin that provides a timed execution facility within the shell. stat A builtin command interface to the stat system call. system A builtin interface to various low-level system features. termcap Interface to the termcap database. terminfo Interface to the terminfo database. zftp A builtin FTP client. zle The Zsh Line Editor, including the bindkey and vared builtins. zleparameter Access to internals of the Zsh Line Editor via parameters. zprof A module allowing profiling for shell functions. zpty A builtin for starting a command in a pseudo-terminal. zselect Block and return when file descriptors are ready. zutil Some utility builtins, e.g. the one for supporting configuration via styles. zsh/zutil \u00b6 The zsh/zutil module adds some builtins: zstyle is used to define and lookup styles. zformat provides two different forms of formatting. zregexparse implements some internals of the _regex_arguments function zparseopts simplifies the parsing of options in positional parameters zsh/net/tcp \u00b6 # list all open file descriptors ($$ refers to the current process) \u276f ls -la /proc/ $$ /fd \u276f ztcp File descriptors Wikipedia: \ud83d\udd17 Send to stdout of the current terminal echo \"hello\" >> /proc/ $$ /fd/2 Plugins \u00b6 zsh-z Jump quickly to directories that you have visited \"frecently.\" zsh-autosuggestions Fish-like autosuggestions for zsh Other links \u00b6 Adding Vi to your Zsh Moving to Zsh Introduction \u00e0 la programmation parall\u00e8le avec Open MPI et Open MP: \ud83d\udd17","title":"zsh"},{"location":"shell/zsh/#zsh","text":"The Z-shell","title":"Zsh"},{"location":"shell/zsh/#initialisation","text":"Shell initilization performs operations depending on the execution context, these operations can be mainly separated on login and interactive property. An short summary can be found at pyenv wiki . Basically: login : e.g. when user logs in to a system with non-graphical interface or via SSH; interactive : shell that has a prompt and whose standard input and error are both connected to terminals. If $ZDOTDIR , $RCS or $GLOABL_RCS are not set, Zsh performs initialiation in the following order: /etc/zsh/zshenv ~/.zshenv login mode: /etc/zsh/zprofile ~/.zprofile interactive: /etc/zsh/zshrc ~/.zshrc login mode: /etc/zsh/login ~/.zlogin .zlogout and /etc/zsh/zshlogout are called when exiting, not when opening. See this post for a complementary information.","title":"Initialisation"},{"location":"shell/zsh/#readline-capability-zle","text":"Zsh does not use readline, instead uses an own development Zsh Line Editor (ZLE) . Keybindings in inputrc are not read, rely instead on an internal command bindkey that can be coupled to terminfo . All actions in the editor are performed by widgets . Bindings are affected to keymaps . The current used keymap is main . Initially, there are eight keymaps: emacs EMACS emulation viins vi emulation - insert mode vicmd vi emulation - command mode viopp vi emulation - operator pending visual vi emulation - selection active isearch incremental search mode command read a command name .safe fallback keymap These keymaps can be accessed l Keymap can be created and must be affected to main to be in use: bindkey -N mymap viins bindkey -A mymap main New bindings are affected to the current ( main ) keymap . bindkey -lL shows which keymap is linked to `main'. zle -la list all existing keymap names in the form of bindkey commands to create or link the keymaps. Links an intro on widgets","title":"Readline capability: ZLE"},{"location":"shell/zsh/#prompt","text":"Prompt sequences undergo a special form of expansion . Some modules make it easier to personalize the prompt. The prompt system must be loaded (performed by extensions): autoload -U promptinit; promptinit . A theme can be applied with the prompt cmd. \u276f prompt <TAB> -- prompt theme -- adam1 bigfade elite fire pure restore zefram adam2 clint elite2 off pws suse bart default fade oliver redhat walters Third party modules: spaceshift is a pure zsh prompt providing VCS integration, language version, job indicator and more. starshift is a port of spaceshift in rust. pure is a lighweight prompt in pure zsh.","title":"Prompt"},{"location":"shell/zsh/#parameters","text":"Parameters set by the shell Parameter Description ! The process ID of the last command started in the background with &, put into the background with the bg builtin, or spawned with coproc. # The number of positional parameters in decimal. Note that some confusion may occur with the syntax $#param which substitutes the length of param. Use ${#} to resolve ambiguities. In particular, the sequence \u2018$#-...\u2019 in an arithmetic expression is interpreted as the length of the parameter -, q.v. ARGC Same as #. $ The process ID of this shell. Note that this indicates the original shell started by invoking zsh; all processes forked from the shells without executing a new program, such as subshells started by (...), substitute the same value. - Flags supplied to the shell on invocation or by the set or setopt commands. * An array containing the positional parameters. argv Same as *. Assigning to argv changes the local positional parameters, but argv is not itself a local parameter. Deleting argv with unset in any function deletes it everywhere, although only the innermost positional parameter array is deleted (so * and @ in other scopes are not affected). @ Same as argv[@], even when argv is not set. ? The exit status returned by the last command. 0 The name used to invoke the current shell, or as set by the -c command line option upon invocation. If the FUNCTION_ARGZERO option is set, $0 is set upon entry to a shell function to the name of the function, and upon entry to a sourced script to the name of the script, and reset to its previous value when the function or script returns. status Same as ?. pipestatus An array containing the exit statuses returned by all commands in the last pipeline. _ The last argument of the previous command. Also, this parameter is set in the environment of every command executed to the full pathname of the command. CPUTYPE The machine type (microprocessor class or machine model), as determined at run time. EGID The effective group ID of the shell process. If you have sufficient privileges, you may change the effective group ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command with a different effective group ID by \u2018(EGID=gid; command)\u2019 EUID The effective user ID of the shell process. If you have sufficient privileges, you may change the effective user ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command with a different effective user ID by \u2018(EUID=uid; command)\u2019 ERRNO The value of errno (see man page errno(3)) as set by the most recently failed system call. This value is system dependent and is intended for debugging purposes. It is also useful with the zsh/system module which allows the number to be turned into a name or message. FUNCNEST Integer. If greater than or equal to zero, the maximum nesting depth of shell functions. When it is exceeded, an error is raised at the point where a function is called. The default value is determined when the shell is configured, but is typically 500. Increasing the value increases the danger of a runaway function recursion causing the shell to crash. Setting a negative value turns off the check. GID The real group ID of the shell process. If you have sufficient privileges, you may change the group ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command under a different group ID by \u2018(GID=gid; command)\u2019 HISTCMD The current history event number in an interactive shell, in other words the event number for the command that caused $HISTCMD to be read. If the current history event modifies the history, HISTCMD changes to the new maximum history event number. HOST The current hostname. LINENO The line number of the current line within the current script, sourced file, or shell function being executed, whichever was started most recently. Note that in the case of shell functions the line number refers to the function as it appeared in the original definition, not necessarily as displayed by the functions builtin. LOGNAME If the corresponding variable is not set in the environment of the shell, it is initialized to the login name corresponding to the current login session. This parameter is exported by default but this can be disabled using the typeset builtin. The value is set to the string returned by the man page getlogin(3) system call if that is available. MACHTYPE The machine type (microprocessor class or machine model), as determined at compile time. OLDPWD The previous working directory. This is set when the shell initializes and whenever the directory changes. OPTARG The value of the last option argument processed by the getopts command. OPTIND The index of the last option argument processed by the getopts command. OSTYPE The operating system, as determined at compile time. PPID The process ID of the parent of the shell. PWD The present working directory. This is set when the shell initializes and whenever the directory changes. RANDOM A pseudo-random integer from 0 to 32767. SECONDS The number of seconds since shell invocation. SHLVL Incremented by one each time a new shell is started. signals An array containing the names of the signals. TRY_BLOCK_ERROR In an always block, indicates whether the preceding list of code caused an error. The value is 1 to indicate an error, 0 otherwise. It may be reset, clearing the error condition. See Complex Commands TRY_BLOCK_INTERRUPT This variable works in a similar way to TRY_BLOCK_ERROR , but represents the status of an interrupt from the signal SIGINT, which typically comes from the keyboard when the user types ^C. If set to 0, any such interrupt will be reset; otherwise, the interrupt is propagated after the always block. TTY The name of the tty associated with the shell, if any. TTYIDLE The idle time of the tty associated with the shell in seconds or -1 if there is no such tty. UID <S> The real user ID of the shell process. USERNAME The username corresponding to the real user ID of the shell process. If you have sufficient privileges, you may change the username (and also the user ID and group ID) of the shell by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command under a different username (and user ID and group ID) by \u2018(USERNAME=username; command)\u2019 VENDOR The vendor, as determined at compile time. zsh_eval_context ( ZSH_EVAL_CONTEXT ) An array (colon-separated list) indicating the context of shell code that is being run. See documentation for details. ZSH_ARGZERO If zsh was invoked to run a script, this is the name of the script. Otherwise, it is the name used to invoke the current shell. This is the same as the value of $0 when the POSIX_ARGZERO option is set, but is always available. ZSH_EXECUTION_STRING If the shell was started with the option -c, this contains the argument passed to the option. Otherwise it is not set. ZSH_NAME Expands to the basename of the command used to invoke this instance of zsh. ZSH_PATCHLEVEL The output of \u2018git describe \u2013tags \u2013long\u2019 for the zsh repository used to build the shell. This is most useful in order to keep track of versions of the shell during development between releases; hence most users should not use it and should instead rely on $ZSH_VERSION. zsh_scheduled_events See The zsh/sched Module. ZSH_SCRIPT If zsh was invoked to run a script, this is the name of the script, otherwise it is unset. ZSH_SUBSHELL Readonly integer. Initially zero, incremented each time the shell forks to create a subshell for executing code. Hence \u2018(print $ZSH_SUBSHELL)\u2019 and \u2018print $(print $ZSH_SUBSHELL)\u2019 output 1, while \u2018( (print $ZSH_SUBSHELL) )\u2019 outputs 2. ZSH_VERSION The version number of the release of zsh.","title":"Parameters"},{"location":"shell/zsh/#data-structures","text":"","title":"Data structures"},{"location":"shell/zsh/#associative-arrays","text":"Declared with declare -A <ARRAY> or typeset -A <ARRAY> Associative arrays can not be nested","title":"Associative arrays"},{"location":"shell/zsh/#functions","text":"","title":"Functions"},{"location":"shell/zsh/#hook-functions","text":"It is possible to define an array that has the same name as the function with _functions appended. Any element in such an array is taken as the name of a function to execute; it is executed in the same context and with the same arguments as the basic function. Example \u276f echo $precmd_functions _zsh_autosuggest_start _zsh_highlight_main__precmd_hook _zshz_precmd prompt_pure_precmd # Show the definition of a function: # it is possible to use `which` or nearly identical to bash `type -f` \u276f whence -f _zsh_autosuggest_start chpwd : executed whenever the current working directory is changed. periodic : if the parameter PERIOD is set, this function is executed every $PERIOD seconds, just before a prompt. precmd : executed before each prompt. preexec : executed just after a command has been read and is about to be executed. zshaddhistory : executed when a history line has been read interactively, but before it is executed. zshexit : executed at the point where the main shell is about to exit normally. Display user configuration of hooks functions","title":"Hook functions "},{"location":"shell/zsh/#expansion","text":"This section is a cheatsheet on expansion, based on the manual and reads, especially this blog post . The examples hereunder are taken from the latest and to be run, interactive comments must be enabled in zsh ( setopt interactive_comments ). The following types of expansions are performed in the indicated order in five steps: History Expansion is performed only in interactive shells. Alias Expansion Aliases are expanded immediately. Process Substitution , Parameter Expansion , Command Substitution , Arithmetic Expansion , Brace Expansion These five are performed in left-to-right fashion. On each argument, any of the five steps that are needed are performed one after the other. Hence, for example, all the parts of parameter expansion are completed before command substitution is started. After these expansions, all unquoted occurrences of the characters \u2018\\\u2019,\u2018\u2019\u2019 and \u2018\"\u2019 are removed. Filename Expansion If the SH_FILE_EXPANSION option is set, the order of expansion is modified for compatibility with sh and ksh: filename expansion is performed immediately after alias expansion. Filename Generation , commonly referred to as globbing, always done last.","title":"Expansion"},{"location":"shell/zsh/#filename-generation-globbing","text":"","title":"Filename generation (globbing)"},{"location":"shell/zsh/#completion","text":"","title":"Completion"},{"location":"shell/zsh/#initialization","text":"# menu-select widget, part of the zsh/complist module # must be loaded before the call to compinit zmodload -i zsh/complist # Use modern completion system autoload -U compinit compinit","title":"Initialization"},{"location":"shell/zsh/#cache-reset","text":"rm -f ~/.zcompdump% compinit","title":"Cache reset"},{"location":"shell/zsh/#configuration","text":"\ud83d\udd17","title":"Configuration"},{"location":"shell/zsh/#user-defined-completion","text":"Some utility functions","title":"User defined completion"},{"location":"shell/zsh/#modules","text":"Modules are loaded with zmodload ZSH modules ZSH modules are loaded with the prefix zsh/ , e.g. for net/tcl \u276f zmodload zsh/net/tcp Modules Description attr Builtins for manipulating extended attributes (xattr). cap Builtins for manipulating POSIX.1e (POSIX.6) capability (privilege) sets. clone A builtin that can clone a running shell onto another terminal. compctl The compctl builtin for controlling completion. complete The basic completion code. complist Completion listing extensions. computil A module with utility builtins needed for the shell function based completion system. curses curses windowing commands datetime Some date/time commands and parameters. deltochar A ZLE function duplicating EMACS' zap-to-char. example An example of how to write a module. files Some basic file manipulation commands as builtins. mapfile Access to external files via a special associative array. mathfunc Standard scientific functions for use in mathematical evaluations. net/socket Manipulation of Unix domain sockets net/tcp Manipulation of TCP sockets newuser Arrange for files for new users to be installed. parameter Access to internal hash tables via special associative arrays. pcre Interface to the PCRE library. regex Interface to the POSIX regex library. sched A builtin that provides a timed execution facility within the shell. stat A builtin command interface to the stat system call. system A builtin interface to various low-level system features. termcap Interface to the termcap database. terminfo Interface to the terminfo database. zftp A builtin FTP client. zle The Zsh Line Editor, including the bindkey and vared builtins. zleparameter Access to internals of the Zsh Line Editor via parameters. zprof A module allowing profiling for shell functions. zpty A builtin for starting a command in a pseudo-terminal. zselect Block and return when file descriptors are ready. zutil Some utility builtins, e.g. the one for supporting configuration via styles.","title":"Modules"},{"location":"shell/zsh/#zshzutil","text":"The zsh/zutil module adds some builtins: zstyle is used to define and lookup styles. zformat provides two different forms of formatting. zregexparse implements some internals of the _regex_arguments function zparseopts simplifies the parsing of options in positional parameters","title":"zsh/zutil"},{"location":"shell/zsh/#zshnettcp","text":"# list all open file descriptors ($$ refers to the current process) \u276f ls -la /proc/ $$ /fd \u276f ztcp File descriptors Wikipedia: \ud83d\udd17 Send to stdout of the current terminal echo \"hello\" >> /proc/ $$ /fd/2","title":"zsh/net/tcp"},{"location":"shell/zsh/#plugins","text":"zsh-z Jump quickly to directories that you have visited \"frecently.\" zsh-autosuggestions Fish-like autosuggestions for zsh","title":"Plugins"},{"location":"shell/zsh/#other-links","text":"Adding Vi to your Zsh Moving to Zsh Introduction \u00e0 la programmation parall\u00e8le avec Open MPI et Open MP: \ud83d\udd17","title":"Other links"},{"location":"shell/Ubuntu/configuration/","text":"Configuration \u00b6 Environment variables \u00b6 https://help.ubuntu.com/community/EnvironmentVariables LVM \u00b6 https://doc.ubuntu-fr.org/lvm Partitioning: https://www.cyberciti.biz/tips/fdisk-unable-to-create-partition-greater-2tb.html Touchpad \u00b6 libinput \u00b6 See https://wayland.freedesktop.org/libinput/doc/latest/index.html libinput-gesture fusuma","title":"Ubuntu"},{"location":"shell/Ubuntu/configuration/#configuration","text":"","title":"Configuration"},{"location":"shell/Ubuntu/configuration/#environment-variables","text":"https://help.ubuntu.com/community/EnvironmentVariables","title":"Environment variables"},{"location":"shell/Ubuntu/configuration/#lvm","text":"https://doc.ubuntu-fr.org/lvm Partitioning: https://www.cyberciti.biz/tips/fdisk-unable-to-create-partition-greater-2tb.html","title":"LVM"},{"location":"shell/Ubuntu/configuration/#touchpad","text":"","title":"Touchpad"},{"location":"shell/Ubuntu/configuration/#libinput","text":"See https://wayland.freedesktop.org/libinput/doc/latest/index.html libinput-gesture fusuma","title":"libinput"},{"location":"sw_dvpt/git/","text":"GIT \u00b6 Configuration \u00b6 The configuration is made out of four files : $(prefix)/etc/gitconfig $XDG_CONFIG_HOME/git/config ~/.gitconfig $GIT_DIR/config Add credential cache (timed out daemon) when not using ssh authentication: git config --global credential.helper cache # Set the timeout to 300s instead 900s (defaut) git config --global credential.helper 'cache --timeout=300' # To explicitly exits the daemon git credential-cache exit Revision selection \u00b6 Individual commit selection \u00b6 SHA1 selection Git allows selection of a single commit by its full 40 char. SHA1-hash. git log <OPTIONS> to display and locate commits. Ouptut format can be heavily customized. git reflog show local editions git show <COMMIT> to inspect a specific commit, for reflog specific entries, @{<n>} can be used to display history, e.g. git show HEAD@{5} will show the fifth entry of your reflog git rev-parse <OPTIONS> , belonging to plumbing tools can be used to investigate revisons at a lower lever Ancestry selection An ancestry can be selected by adding a ^ (caret) at the end of a reference, e.g. HEAD^ to select the element's parent. Several carets can be used to select the parent in direct line or ~ (tilde). A parent sibling branch is selected by using a number next to the caret. Range selection \u00b6 Double dot Enable to see commits between two history points that can be on different branches, e.g.: # Show what is beeing pulled (what's between HEAD and origin/master) git log --pretty = oneline -n 10 HEAD..origin/master # Show a branch history (master to parent's commit o new_branch) git log master..new_branch^ Exclude reachable commit \u00b6 This can be done with ^ before the commit or branch or by using thee --not syntax. e.g. to see all commits reachable from refA and refB but not refC : # Usage are equivalent git log revA revB ^revC git log revA revB --not revC # Usage are equivalent git log revA..revB git log ^revA revB git log rebB --not revA Mutualy exclution: triple dot \u00b6 Specify commits that are reachabel either by both references Examples \u00b6 Loeliger notation G H I J \\ / \\ / D E F \\ | / \\ \\ | / | \\|/ | B C \\ / \\ / A Ancestry selection G H I J | A = = A^0 \\ / \\ / | B = A^ = A^1 = A~1 D E F | C = A^2 = A^2 \\ | / \\ | D = A^^ = A^1^1 = A~2 \\ | / | | E = B^2 = A^^2 \\|/ | | F = B^3 = A^^3 B C | G = A^^^ = A^1^1^1 = A~3 \\ / | H = D^2 = B^^2 = A^^^2 = A~2^2 \\ / | I = F^ = B^3^ = A^^3^ A | J = F^2 = B^3^2 = A^^3^2 Extended selection G H I J | Args | Expanded arguments | Selected commits \\ / \\ / | ----------|----------------------|------------------ D E F | D | | G H D \\ | / \\ | D F | | G H I J D F \\ | / | | ^G D | | H D \\|/ | | ^D B | | E I J F B B C | ^D B C | | E I J F B C \\ / | C | | I J F C \\ / | B..C | = ^B C | C A | B...C | = B ^F C | G H D E B C | B^- | = B^..B | | | = ^B^1 B | E I J F B | C^@ | = C^1 | | | = F | I J F | B^@ | = B^1 B^2 B^3 | | | = D E F | D G H E F I J | C^! | = C ^C^@ | | | = C ^C^1 | | | = C ^F | C | B^! | = B ^B^@ | | | = B ^B^1 ^B^2 ^B^3 | | | = B ^D ^E ^F | B | F^! D | = F ^I ^J D | G H D F Submodules \u00b6 Commands \u00b6 status prints the SHA1 status of checked submodules. Prefixed with: - if the submodule is not initialized + in case of conflicts between current subdmodule and the index of the containing directory U in case of merge conflicts Remove a submodule \u00b6 A submodule can be deleted by running git rm <submodule path> && git commit . $GIT_DIR/modules/<name> delete the submodule completly. Util then, deletion can be undone using git revert . Alternative method: Remove the submodule entry from .git/config git submodule deinit -f path/to/submodule Remove the submodule directory from the superproject's .git/modules directory rm -rf .git/modules/path/to/submodule Commit the changes git commit-m \"Removed submodule \" Remove the entry in .gitmodules and remove the submodule directory located at path/to/submodule git rm -f path/to/submodule Updating submodule url and branch \u00b6 The submodule configuration can be displayed with git config : git config -l A specific config file can be given to git config with the --file flag : git config -l --file=.gitmodules Url, branch and other parameters can be configured via git config git config --file=.gitmodules submodule.<submodule_name>.url <git@github.com:username/repository.git> git config --file=.gitmodules submodule.<submodule_name>.branch <branch_name> Synchronization adn update of the submodules are done with: git submodule sync git submodule update --init --recursive --remote --merge # ! If --merge option is missing, HEAD will be detached Tags \u00b6 Get the most recent tag: git describe --tags --abbrev=0 Git diff \u00b6 Git diff can be displayed side by side with delta as a pager [core] pager = delta Open all files with git merge conflicts. git diff --name-only | uniq | xargs vim Vim has a powerfull diff mode . Jumping to diff, backwards/forewargs: [c , ]c . History revision \u00b6 Rewrite history: git rebase Edit already pushed specific commit \u00b6 This is to be done in very specific situations Specify a rebase by identifying an earlier commit git rebase -i <Earlier Commit> in the interactive pane, select edit for the commit to be rewritten amend the part of the commit to be edited, e.g.: git commit --amend --author=\"Author Name <email@address.com>\" git commit --amend --date=\"$(date -R)\" git commit --amend -m \"New Commit Message\" eventualy, edit the commit message continue with the rebase: git rebase --continue force a pull git pull --force Cherry pick from another repository \u00b6 First the other repository source must be added to the remote list git remote add other https://other.url/repository.git git fetch other Then use git cherry-pick Others \u00b6 conform is a tool for enforcing policies on your build pipelines. Conventional commits Conventional Commits 1.0.0 \u00b6 Summary \u00b6 The Conventional Commits specification is a lightweight convention on top of commit messages. It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated tools on top of. This convention dovetails with SemVer , by describing the features, fixes, and breaking changes made in commit messages. The commit message should be structured as follows: <type>[optional scope]: <description> [optional body] [optional footer(s)] \u00b6 The commit contains the following structural elements, to communicate intent to the consumers of your library: fix: a commit of the type fix patches a bug in your codebase (this correlates with PATCH in semantic versioning). feat: a commit of the type feat introduces a new feature to the codebase (this correlates with MINOR in semantic versioning). BREAKING CHANGE: a commit that has a footer BREAKING CHANGE: , or appends a ! after the type/scope, introduces a breaking API change (correlating with MAJOR in semantic versioning). A BREAKING CHANGE can be part of commits of any type . types other than fix: and feat: are allowed, for example @commitlint/config-conventional (based on the the Angular convention ) recommends build: , chore: , ci: , docs: , style: , refactor: , perf: , test: , and others. footers other than BREAKING CHANGE: <description> may be provided and follow a convention similar to git trailer format . Additional types are not mandated by the Conventional Commits specification, and have no implicit effect in semantic versioning (unless they include a BREAKING CHANGE). A scope may be provided to a commit's type, to provide additional contextual information and is contained within parenthesis, e.g., feat(parser): add ability to parse arrays . Examples \u00b6 Commit message with description and breaking change footer \u00b6 feat: allow provided config object to extend other configs BREAKING CHANGE: `extends` key in config file is now used for extending other config files Commit message with ! to draw attention to breaking change \u00b6 refactor!: drop support for Node 6 Commit message with both ! and BREAKING CHANGE footer \u00b6 refactor!: drop support for Node 6 BREAKING CHANGE: refactor to use JavaScript features not available in Node 6. Commit message with no body \u00b6 docs: correct spelling of CHANGELOG Commit message with scope \u00b6 feat(lang): add polish language Commit message with multi-paragraph body and multiple footers \u00b6 fix: correct minor typos in code see the issue for details on typos fixed. Reviewed-by: Z Refs #133 Specification \u00b6 The key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD NOT\u201d, \u201cRECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be interpreted as described in RFC 2119 . Commits MUST be prefixed with a type, which consists of a noun, feat , fix , etc., followed by the OPTIONAL scope, OPTIONAL ! , and REQUIRED terminal colon and space. The type feat MUST be used when a commit adds a new feature to your application or library. The type fix MUST be used when a commit represents a bug fix for your application. A scope MAY be provided after a type. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., fix(parser): A description MUST immediately follow the colon and space after the type/scope prefix. The description is a short summary of the code changes, e.g., fix: array parsing issue when multiple spaces were contained in string . A longer commit body MAY be provided after the short description, providing additional contextual information about the code changes. The body MUST begin one blank line after the description. A commit body is free-form and MAY consist of any number of newline separated paragraphs. One or more footers MAY be provided one blank line after the body. Each footer MUST consist of a word token, followed by either a :<space> or <space># separator, followed by a string value (this is inspired by the git trailer convention ). A footer's token MUST use - in place of whitespace characters, e.g., Acked-by (this helps differentiate the footer section from a multi-paragraph body). An exception is made for BREAKING CHANGE , which MAY also be used as a token. A footer's value MAY contain spaces and newlines, and parsing MUST terminate when the next valid footer token/separator pair is observed. Breaking changes MUST be indicated in the type/scope prefix of a commit, or as an entry in the footer. If included as a footer, a breaking change MUST consist of the uppercase text BREAKING CHANGE, followed by a colon, space, and description, e.g., BREAKING CHANGE: environment variables now take precedence over config files . If included in the type/scope prefix, breaking changes MUST be indicated by a ! immediately before the : . If ! is used, BREAKING CHANGE: MAY be omitted from the footer section, and the commit description SHALL be used to describe the breaking change. Types other than feat and fix MAY be used in your commit messages, e.g., docs: updated ref docs. The units of information that make up Conventional Commits MUST NOT be treated as case sensitive by implementors, with the exception of BREAKING CHANGE which MUST be uppercase. BREAKING-CHANGE MUST be synonymous with BREAKING CHANGE, when used as a token in a footer. ghq provides a way to organize remote repository clones, like go get does. Hooks \u00b6 Hooks are executable scripts, generaly located in .git/hooks . They can be devided into two groups: client-side server-side Client side \u00b6 Hook Run description post-checkout after a successful git checkout pre-commit before commiting message, general checks like linting prepare-commit-msg before the commit message editor is fired up but after the default message is created, good for commits where the default message is auto-generated commit-msg validate project state or commit message pre-rebase before you rebase anything pre-push during git push , after the remote refs have been updated but before any objects have been transferred post-rewrite triggered by commands that replace commits, such as git commit --amend and git rebase post-merge after a successful merge command post-commit once eveything coompleted. There are other hooks, invoked by specific commands: pre-auto-gc by invoking garbage collection git gc --auto applypatch-msg , pre-applypatch and post-applypatch all invoked by git am for an email-based workflow. Post commit #!/bin/bash # # Update a superproject when a commit is made to a submodule. # Intended for .git/**modules/{THE_SUBMODULE}/hooks/post-commit # where the double-star indicates variadic path elements. # # Depends on Git >= 2.13. # Clean the Git environment before crossing repository boundaries. # From https://stackoverflow.com/questions/36196548 while read variable ; do unset $variable done < < ( env | grep \"^GIT_\" | sed 's/=.*//g' ) COMMIT_MSG = $( git log --format = %B -n 1 ) GIT = \"git\" SUPERPROJECT_WORKING_TREE = ` git rev-parse --show-superproject-working-tree ` echo \"\ud83d\udce3 Committing to $SUPERPROJECT_WORKING_TREE .\" cd $SUPERPROJECT_WORKING_TREE $GIT add . $GIT commit -m \" $COMMIT_MSG \" Server side \u00b6 Hook Run description pre-receive first script to run when handling a push from a client. Runs only once. post-receive run once for each branch the pusher is trying to update update after the entire process is completed and can be used to update other services or notify users Installation must be performed on the server, see e.g. for gitlab . If no admin rights are available, some alternatives: webhooks github / gitlab CI/CD pipeline github gitlab push rules gitlab Git flow \u00b6 From Scott Chacon blog : To work on something new, create a descriptively named branch off of master Commit to that branch locally and regularly push your work to the same named branch on the server When you need feedback or help, or you think the branch is ready for merging, open a pull request After someone else has reviewed and signed off on the feature, you can merge it into master Pull request \u00b6 https://github.blog/2015-01-21-how-to-write-the-perfect-pull-request/ https://stackoverflow.com/questions/14680711 https://stackoverflow.com/questions/29049650 Switch branches or restore working tree files git checkout master git checkout -b mybranch git remote manage the set of repositories (\"remotes\") whose branches you track. git remote -v # If upstream is not configured, add the upstream route git remote add upstream /url/original/repo git fetch upstream # reset master to upstream/master git checkout master git reset --hard upstream/master git push --force y--y--y (mybranch) / z--z--z (master, upstream/master, origin/master) # replay the patches (even they are rejected for now) on top of master git checkout mybranch git rebase master git push -u origin mybranch y'--y'--y' (mybranch, origin/mybranch) / z--z--z (master, upstream/master, origin/master) Platform specific \u00b6 Github \u00b6 cli is github official cli tool. Change the repository language detection .gitattributes s used for the files you want to override using the linguist-documentation , linguist-language , linguist-vendored , linguist-generated and linguist-detectable attributes. Installation is performed with gem: gem install github-linguist Github action act run GitHub Actions locally.","title":"git"},{"location":"sw_dvpt/git/#git","text":"","title":"GIT"},{"location":"sw_dvpt/git/#configuration","text":"The configuration is made out of four files : $(prefix)/etc/gitconfig $XDG_CONFIG_HOME/git/config ~/.gitconfig $GIT_DIR/config Add credential cache (timed out daemon) when not using ssh authentication: git config --global credential.helper cache # Set the timeout to 300s instead 900s (defaut) git config --global credential.helper 'cache --timeout=300' # To explicitly exits the daemon git credential-cache exit","title":"Configuration"},{"location":"sw_dvpt/git/#revision-selection","text":"","title":"Revision selection"},{"location":"sw_dvpt/git/#individual-commit-selection","text":"","title":"Individual commit selection"},{"location":"sw_dvpt/git/#range-selection","text":"","title":"Range selection"},{"location":"sw_dvpt/git/#exclude-reachable-commit","text":"This can be done with ^ before the commit or branch or by using thee --not syntax. e.g. to see all commits reachable from refA and refB but not refC : # Usage are equivalent git log revA revB ^revC git log revA revB --not revC # Usage are equivalent git log revA..revB git log ^revA revB git log rebB --not revA","title":"Exclude reachable commit"},{"location":"sw_dvpt/git/#mutualy-exclution-triple-dot","text":"Specify commits that are reachabel either by both references","title":"Mutualy exclution: triple dot"},{"location":"sw_dvpt/git/#examples","text":"Loeliger notation G H I J \\ / \\ / D E F \\ | / \\ \\ | / | \\|/ | B C \\ / \\ / A Ancestry selection G H I J | A = = A^0 \\ / \\ / | B = A^ = A^1 = A~1 D E F | C = A^2 = A^2 \\ | / \\ | D = A^^ = A^1^1 = A~2 \\ | / | | E = B^2 = A^^2 \\|/ | | F = B^3 = A^^3 B C | G = A^^^ = A^1^1^1 = A~3 \\ / | H = D^2 = B^^2 = A^^^2 = A~2^2 \\ / | I = F^ = B^3^ = A^^3^ A | J = F^2 = B^3^2 = A^^3^2 Extended selection G H I J | Args | Expanded arguments | Selected commits \\ / \\ / | ----------|----------------------|------------------ D E F | D | | G H D \\ | / \\ | D F | | G H I J D F \\ | / | | ^G D | | H D \\|/ | | ^D B | | E I J F B B C | ^D B C | | E I J F B C \\ / | C | | I J F C \\ / | B..C | = ^B C | C A | B...C | = B ^F C | G H D E B C | B^- | = B^..B | | | = ^B^1 B | E I J F B | C^@ | = C^1 | | | = F | I J F | B^@ | = B^1 B^2 B^3 | | | = D E F | D G H E F I J | C^! | = C ^C^@ | | | = C ^C^1 | | | = C ^F | C | B^! | = B ^B^@ | | | = B ^B^1 ^B^2 ^B^3 | | | = B ^D ^E ^F | B | F^! D | = F ^I ^J D | G H D F","title":"Examples"},{"location":"sw_dvpt/git/#submodules","text":"","title":"Submodules"},{"location":"sw_dvpt/git/#commands","text":"status prints the SHA1 status of checked submodules. Prefixed with: - if the submodule is not initialized + in case of conflicts between current subdmodule and the index of the containing directory U in case of merge conflicts","title":"Commands"},{"location":"sw_dvpt/git/#remove-a-submodule","text":"A submodule can be deleted by running git rm <submodule path> && git commit . $GIT_DIR/modules/<name> delete the submodule completly. Util then, deletion can be undone using git revert . Alternative method: Remove the submodule entry from .git/config git submodule deinit -f path/to/submodule Remove the submodule directory from the superproject's .git/modules directory rm -rf .git/modules/path/to/submodule Commit the changes git commit-m \"Removed submodule \" Remove the entry in .gitmodules and remove the submodule directory located at path/to/submodule git rm -f path/to/submodule","title":"Remove a submodule"},{"location":"sw_dvpt/git/#updating-submodule-url-and-branch","text":"The submodule configuration can be displayed with git config : git config -l A specific config file can be given to git config with the --file flag : git config -l --file=.gitmodules Url, branch and other parameters can be configured via git config git config --file=.gitmodules submodule.<submodule_name>.url <git@github.com:username/repository.git> git config --file=.gitmodules submodule.<submodule_name>.branch <branch_name> Synchronization adn update of the submodules are done with: git submodule sync git submodule update --init --recursive --remote --merge # ! If --merge option is missing, HEAD will be detached","title":"Updating submodule url and branch"},{"location":"sw_dvpt/git/#tags","text":"Get the most recent tag: git describe --tags --abbrev=0","title":"Tags"},{"location":"sw_dvpt/git/#git-diff","text":"Git diff can be displayed side by side with delta as a pager [core] pager = delta Open all files with git merge conflicts. git diff --name-only | uniq | xargs vim Vim has a powerfull diff mode . Jumping to diff, backwards/forewargs: [c , ]c .","title":"Git diff"},{"location":"sw_dvpt/git/#history-revision","text":"Rewrite history: git rebase","title":"History revision"},{"location":"sw_dvpt/git/#edit-already-pushed-specific-commit","text":"This is to be done in very specific situations Specify a rebase by identifying an earlier commit git rebase -i <Earlier Commit> in the interactive pane, select edit for the commit to be rewritten amend the part of the commit to be edited, e.g.: git commit --amend --author=\"Author Name <email@address.com>\" git commit --amend --date=\"$(date -R)\" git commit --amend -m \"New Commit Message\" eventualy, edit the commit message continue with the rebase: git rebase --continue force a pull git pull --force","title":"Edit already pushed specific commit"},{"location":"sw_dvpt/git/#cherry-pick-from-another-repository","text":"First the other repository source must be added to the remote list git remote add other https://other.url/repository.git git fetch other Then use git cherry-pick","title":"Cherry pick from another repository"},{"location":"sw_dvpt/git/#others","text":"conform is a tool for enforcing policies on your build pipelines. Conventional commits","title":"Others"},{"location":"sw_dvpt/git/#conventional-commits-100","text":"","title":"Conventional Commits 1.0.0"},{"location":"sw_dvpt/git/#summary","text":"The Conventional Commits specification is a lightweight convention on top of commit messages. It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated tools on top of. This convention dovetails with SemVer , by describing the features, fixes, and breaking changes made in commit messages. The commit message should be structured as follows:","title":"Summary"},{"location":"sw_dvpt/git/#typeoptional-scope-description-optional-body-optional-footers","text":"The commit contains the following structural elements, to communicate intent to the consumers of your library: fix: a commit of the type fix patches a bug in your codebase (this correlates with PATCH in semantic versioning). feat: a commit of the type feat introduces a new feature to the codebase (this correlates with MINOR in semantic versioning). BREAKING CHANGE: a commit that has a footer BREAKING CHANGE: , or appends a ! after the type/scope, introduces a breaking API change (correlating with MAJOR in semantic versioning). A BREAKING CHANGE can be part of commits of any type . types other than fix: and feat: are allowed, for example @commitlint/config-conventional (based on the the Angular convention ) recommends build: , chore: , ci: , docs: , style: , refactor: , perf: , test: , and others. footers other than BREAKING CHANGE: <description> may be provided and follow a convention similar to git trailer format . Additional types are not mandated by the Conventional Commits specification, and have no implicit effect in semantic versioning (unless they include a BREAKING CHANGE). A scope may be provided to a commit's type, to provide additional contextual information and is contained within parenthesis, e.g., feat(parser): add ability to parse arrays .","title":"&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n"},{"location":"sw_dvpt/git/#examples_1","text":"","title":"Examples"},{"location":"sw_dvpt/git/#commit-message-with-description-and-breaking-change-footer","text":"feat: allow provided config object to extend other configs BREAKING CHANGE: `extends` key in config file is now used for extending other config files","title":"Commit message with description and breaking change footer"},{"location":"sw_dvpt/git/#commit-message-with-to-draw-attention-to-breaking-change","text":"refactor!: drop support for Node 6","title":"Commit message with ! to draw attention to breaking change"},{"location":"sw_dvpt/git/#commit-message-with-both-and-breaking-change-footer","text":"refactor!: drop support for Node 6 BREAKING CHANGE: refactor to use JavaScript features not available in Node 6.","title":"Commit message with both ! and BREAKING CHANGE footer"},{"location":"sw_dvpt/git/#commit-message-with-no-body","text":"docs: correct spelling of CHANGELOG","title":"Commit message with no body"},{"location":"sw_dvpt/git/#commit-message-with-scope","text":"feat(lang): add polish language","title":"Commit message with scope"},{"location":"sw_dvpt/git/#commit-message-with-multi-paragraph-body-and-multiple-footers","text":"fix: correct minor typos in code see the issue for details on typos fixed. Reviewed-by: Z Refs #133","title":"Commit message with multi-paragraph body and multiple footers"},{"location":"sw_dvpt/git/#specification","text":"The key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD NOT\u201d, \u201cRECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be interpreted as described in RFC 2119 . Commits MUST be prefixed with a type, which consists of a noun, feat , fix , etc., followed by the OPTIONAL scope, OPTIONAL ! , and REQUIRED terminal colon and space. The type feat MUST be used when a commit adds a new feature to your application or library. The type fix MUST be used when a commit represents a bug fix for your application. A scope MAY be provided after a type. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., fix(parser): A description MUST immediately follow the colon and space after the type/scope prefix. The description is a short summary of the code changes, e.g., fix: array parsing issue when multiple spaces were contained in string . A longer commit body MAY be provided after the short description, providing additional contextual information about the code changes. The body MUST begin one blank line after the description. A commit body is free-form and MAY consist of any number of newline separated paragraphs. One or more footers MAY be provided one blank line after the body. Each footer MUST consist of a word token, followed by either a :<space> or <space># separator, followed by a string value (this is inspired by the git trailer convention ). A footer's token MUST use - in place of whitespace characters, e.g., Acked-by (this helps differentiate the footer section from a multi-paragraph body). An exception is made for BREAKING CHANGE , which MAY also be used as a token. A footer's value MAY contain spaces and newlines, and parsing MUST terminate when the next valid footer token/separator pair is observed. Breaking changes MUST be indicated in the type/scope prefix of a commit, or as an entry in the footer. If included as a footer, a breaking change MUST consist of the uppercase text BREAKING CHANGE, followed by a colon, space, and description, e.g., BREAKING CHANGE: environment variables now take precedence over config files . If included in the type/scope prefix, breaking changes MUST be indicated by a ! immediately before the : . If ! is used, BREAKING CHANGE: MAY be omitted from the footer section, and the commit description SHALL be used to describe the breaking change. Types other than feat and fix MAY be used in your commit messages, e.g., docs: updated ref docs. The units of information that make up Conventional Commits MUST NOT be treated as case sensitive by implementors, with the exception of BREAKING CHANGE which MUST be uppercase. BREAKING-CHANGE MUST be synonymous with BREAKING CHANGE, when used as a token in a footer. ghq provides a way to organize remote repository clones, like go get does.","title":"Specification"},{"location":"sw_dvpt/git/#hooks","text":"Hooks are executable scripts, generaly located in .git/hooks . They can be devided into two groups: client-side server-side","title":"Hooks"},{"location":"sw_dvpt/git/#client-side","text":"Hook Run description post-checkout after a successful git checkout pre-commit before commiting message, general checks like linting prepare-commit-msg before the commit message editor is fired up but after the default message is created, good for commits where the default message is auto-generated commit-msg validate project state or commit message pre-rebase before you rebase anything pre-push during git push , after the remote refs have been updated but before any objects have been transferred post-rewrite triggered by commands that replace commits, such as git commit --amend and git rebase post-merge after a successful merge command post-commit once eveything coompleted. There are other hooks, invoked by specific commands: pre-auto-gc by invoking garbage collection git gc --auto applypatch-msg , pre-applypatch and post-applypatch all invoked by git am for an email-based workflow. Post commit #!/bin/bash # # Update a superproject when a commit is made to a submodule. # Intended for .git/**modules/{THE_SUBMODULE}/hooks/post-commit # where the double-star indicates variadic path elements. # # Depends on Git >= 2.13. # Clean the Git environment before crossing repository boundaries. # From https://stackoverflow.com/questions/36196548 while read variable ; do unset $variable done < < ( env | grep \"^GIT_\" | sed 's/=.*//g' ) COMMIT_MSG = $( git log --format = %B -n 1 ) GIT = \"git\" SUPERPROJECT_WORKING_TREE = ` git rev-parse --show-superproject-working-tree ` echo \"\ud83d\udce3 Committing to $SUPERPROJECT_WORKING_TREE .\" cd $SUPERPROJECT_WORKING_TREE $GIT add . $GIT commit -m \" $COMMIT_MSG \"","title":"Client side"},{"location":"sw_dvpt/git/#server-side","text":"Hook Run description pre-receive first script to run when handling a push from a client. Runs only once. post-receive run once for each branch the pusher is trying to update update after the entire process is completed and can be used to update other services or notify users Installation must be performed on the server, see e.g. for gitlab . If no admin rights are available, some alternatives: webhooks github / gitlab CI/CD pipeline github gitlab push rules gitlab","title":"Server side"},{"location":"sw_dvpt/git/#git-flow","text":"From Scott Chacon blog : To work on something new, create a descriptively named branch off of master Commit to that branch locally and regularly push your work to the same named branch on the server When you need feedback or help, or you think the branch is ready for merging, open a pull request After someone else has reviewed and signed off on the feature, you can merge it into master","title":"Git flow"},{"location":"sw_dvpt/git/#pull-request","text":"https://github.blog/2015-01-21-how-to-write-the-perfect-pull-request/ https://stackoverflow.com/questions/14680711 https://stackoverflow.com/questions/29049650 Switch branches or restore working tree files git checkout master git checkout -b mybranch git remote manage the set of repositories (\"remotes\") whose branches you track. git remote -v # If upstream is not configured, add the upstream route git remote add upstream /url/original/repo git fetch upstream # reset master to upstream/master git checkout master git reset --hard upstream/master git push --force y--y--y (mybranch) / z--z--z (master, upstream/master, origin/master) # replay the patches (even they are rejected for now) on top of master git checkout mybranch git rebase master git push -u origin mybranch y'--y'--y' (mybranch, origin/mybranch) / z--z--z (master, upstream/master, origin/master)","title":"Pull request"},{"location":"sw_dvpt/git/#platform-specific","text":"","title":"Platform specific"},{"location":"sw_dvpt/git/#github","text":"cli is github official cli tool.","title":"Github"},{"location":"sw_dvpt/make/","text":"Make \u00b6 Wildcard characters \u00b6 * , ? and [...] Variables \u00b6 Variables are case sensitive, may contain function and variable references, which are expanded when the line is read to find the actual variable name to use. Variables definition \u00b6 Variables can be declated through various operators: with = , they are called recursively expanded , i.e. lazily evaluated with the specificity of being always re-evaluated. with := or ::= , they are simply expanded . The righthand side is expanded immediately upon reading the line. ?= is the conditional variable assignment operator . Assignement is performed only is the variables does not have a value. += is used to append to a variable. This one is created if it does not exist. Automatic variables \u00b6 Most important variables Variable Description $@ File name of the target of the rule. $% Target member name, when the target is an archive member. For example, if the target is foo.a(bar.o) then \u2018 %\u2019 is bar.o and \u2018 %\u2019 is bar.o and \u2018 @\u2019 is foo.a. Empty when the target is not an archive member. $< Name of the first prerequisite. $? Names of all the prerequisites that are newer than the target, with spaces between them. $^ Names of all the prerequisites, with spaces between them. $+ Like \u2018$^\u2019, but prerequisites listed more than once are duplicated in the order they were listed in the makefile. $| Names of all the order-only prerequisites, with spaces between them. $* Stem with which an implicit rule matches. Each of those variables has complementary directory or file portion, e.g. for the target: Variable Description \u2018$(@D)\u2019 The directory part of the file name of the target, with the trailing slash removed. \u2018$(@F)\u2019 The file-within-directory part of the file name of the target. \"Macros\" \u00b6 Variables can contain one liner expressions, for more complex sequences, a variable can use the sequence define ... enddef . define two-lines echo foo echo $( bar ) endef Expansion \u00b6 Expansion is only made immediately when the variable is declare with = . Links \u00b6 https://makefiletutorial.com Introduction \u00e0 Makefile https://gl.developpez.com/tutoriel/outil/makefile/ Splitting Recipe Lines https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html","title":"make"},{"location":"sw_dvpt/make/#make","text":"","title":"Make"},{"location":"sw_dvpt/make/#wildcard-characters","text":"* , ? and [...]","title":"Wildcard characters"},{"location":"sw_dvpt/make/#variables","text":"Variables are case sensitive, may contain function and variable references, which are expanded when the line is read to find the actual variable name to use.","title":"Variables"},{"location":"sw_dvpt/make/#variables-definition","text":"Variables can be declated through various operators: with = , they are called recursively expanded , i.e. lazily evaluated with the specificity of being always re-evaluated. with := or ::= , they are simply expanded . The righthand side is expanded immediately upon reading the line. ?= is the conditional variable assignment operator . Assignement is performed only is the variables does not have a value. += is used to append to a variable. This one is created if it does not exist.","title":"Variables definition"},{"location":"sw_dvpt/make/#automatic-variables","text":"Most important variables Variable Description $@ File name of the target of the rule. $% Target member name, when the target is an archive member. For example, if the target is foo.a(bar.o) then \u2018 %\u2019 is bar.o and \u2018 %\u2019 is bar.o and \u2018 @\u2019 is foo.a. Empty when the target is not an archive member. $< Name of the first prerequisite. $? Names of all the prerequisites that are newer than the target, with spaces between them. $^ Names of all the prerequisites, with spaces between them. $+ Like \u2018$^\u2019, but prerequisites listed more than once are duplicated in the order they were listed in the makefile. $| Names of all the order-only prerequisites, with spaces between them. $* Stem with which an implicit rule matches. Each of those variables has complementary directory or file portion, e.g. for the target: Variable Description \u2018$(@D)\u2019 The directory part of the file name of the target, with the trailing slash removed. \u2018$(@F)\u2019 The file-within-directory part of the file name of the target.","title":"Automatic variables"},{"location":"sw_dvpt/make/#macros","text":"Variables can contain one liner expressions, for more complex sequences, a variable can use the sequence define ... enddef . define two-lines echo foo echo $( bar ) endef","title":"\"Macros\""},{"location":"sw_dvpt/make/#expansion","text":"Expansion is only made immediately when the variable is declare with = .","title":"Expansion"},{"location":"sw_dvpt/make/#links","text":"https://makefiletutorial.com Introduction \u00e0 Makefile https://gl.developpez.com/tutoriel/outil/makefile/ Splitting Recipe Lines https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html","title":"Links"},{"location":"sw_dvpt/patterns/","text":"Design patterns \u00b6 Dependency injection \u00b6 Examples: Pytest fixtures AngularJS","title":"Design patterns"},{"location":"sw_dvpt/patterns/#design-patterns","text":"","title":"Design patterns"},{"location":"sw_dvpt/patterns/#dependency-injection","text":"Examples: Pytest fixtures AngularJS","title":"Dependency injection"},{"location":"sw_dvpt/version_manager/","text":"Version managers \u00b6 These tools help managing developping environements for","title":"Version managers"},{"location":"sw_dvpt/version_manager/#version-managers","text":"These tools help managing developping environements for","title":"Version managers"},{"location":"sw_dvpt/ci_cd/cicd/","text":"CI/CD \u00b6 Continuous Integration ensure an application build and test triggered by defined changes. Continuous Integration/Delivery with pre-commmit \u00b6 is a command line utility - pre-commit aliased pc - that can be used for automation of the creation of git pre-commit hook . What is a git pre-commit hook? It's used to inspect the snapshot that\u2019s about to be committed, to see if you\u2019ve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. Exiting non-zero from this hook aborts the commit. pre-commmit stores its config in a yaml file .pre-commit-config.yaml whose root value is repos . A template can be generated with: pre-commit sample-config > .pre-commit-config.yaml and the script is installed with: pre-commit install Some hooks are available for various purpose: General \u00b6 Some \"built-in\" hooks are provided with pre-commit. Example - repo : https://github.com/pre-commit/pre-commit-hooks rev : v2.4.0 hooks : - id : end-of-file-fixer - id : trailing-whitespace Code style \u00b6 Isort Example - repo : https://github.com/psf/black rev : v3.3.0 hooks : - id : isort Black Example - repo : https://github.com/psf/black rev : v3.3.0 hooks : - id : black Lint \u00b6 yamllint Example - repo : https://github.com/adrienverge/yamllint rev : v1.25.0 hooks : - id : yamllint flake8 Example - repo : https://gitlab.com/pycqa/flake8 rev : 3.8.1 hooks : - id : flake8 additional_dependencies : [ flake8-bugbear ] Code checker \u00b6 MyPy \u00b6 Example - repo : https://github.com/pre-commit/mirrors-mypy rev : v0.770 hooks : - id : mypy exclude : ^docs/conf.py","title":"Intro"},{"location":"sw_dvpt/ci_cd/cicd/#cicd","text":"Continuous Integration ensure an application build and test triggered by defined changes. Continuous Integration/Delivery","title":"CI/CD"},{"location":"sw_dvpt/ci_cd/cicd/#with-pre-commmit","text":"is a command line utility - pre-commit aliased pc - that can be used for automation of the creation of git pre-commit hook . What is a git pre-commit hook? It's used to inspect the snapshot that\u2019s about to be committed, to see if you\u2019ve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. Exiting non-zero from this hook aborts the commit. pre-commmit stores its config in a yaml file .pre-commit-config.yaml whose root value is repos . A template can be generated with: pre-commit sample-config > .pre-commit-config.yaml and the script is installed with: pre-commit install Some hooks are available for various purpose:","title":"with pre-commmit"},{"location":"sw_dvpt/ci_cd/cicd/#general","text":"Some \"built-in\" hooks are provided with pre-commit. Example - repo : https://github.com/pre-commit/pre-commit-hooks rev : v2.4.0 hooks : - id : end-of-file-fixer - id : trailing-whitespace","title":"General"},{"location":"sw_dvpt/ci_cd/cicd/#code-style","text":"","title":"Code style"},{"location":"sw_dvpt/ci_cd/cicd/#lint","text":"","title":"Lint"},{"location":"sw_dvpt/ci_cd/cicd/#code-checker","text":"","title":"Code checker"},{"location":"sw_dvpt/ci_cd/cicd/#mypy","text":"Example - repo : https://github.com/pre-commit/mirrors-mypy rev : v0.770 hooks : - id : mypy exclude : ^docs/conf.py","title":"MyPy"},{"location":"sw_dvpt/ci_cd/codecov/","text":"Code coverage \u00b6 In computer science, test coverage is a measure used to describe the degree to which the source code of a program is executed when a particular test suite runs. Coverage criteria \u00b6 There are a number of coverage criteria, the main ones being: Function coverage has each function (or subroutine) in the program been called? Statement coverage has each statement in the program been executed? Edge coverage has every edge in the Control flow graph been executed? Branch coverage has each branch (also called DD-path) of each control structure (such as in if and case statements) been executed? For example, given an if statement, have both the true and false branches been executed? This is a subset of edge coverage. Condition coverage (or predicate coverage) has each Boolean sub-expression evaluated both to true and false? https://codecov.io/","title":"Code coverage"},{"location":"sw_dvpt/ci_cd/codecov/#code-coverage","text":"In computer science, test coverage is a measure used to describe the degree to which the source code of a program is executed when a particular test suite runs.","title":"Code coverage"},{"location":"sw_dvpt/ci_cd/codecov/#coverage-criteria","text":"There are a number of coverage criteria, the main ones being: Function coverage has each function (or subroutine) in the program been called? Statement coverage has each statement in the program been executed? Edge coverage has every edge in the Control flow graph been executed? Branch coverage has each branch (also called DD-path) of each control structure (such as in if and case statements) been executed? For example, given an if statement, have both the true and false branches been executed? This is a subset of edge coverage. Condition coverage (or predicate coverage) has each Boolean sub-expression evaluated both to true and false? https://codecov.io/","title":"Coverage criteria"},{"location":"sw_dvpt/protocols/kerberos/","text":"Kerberos \u00b6 Kerberos (mirror) is a network authentication protocol. It provides a strong authentication for client/server applications by using secret-key cryptography. For ticket management at the user level some utilities are available: kinit obtains and caches an initial ticket-granting ticket for principal. If principal is absent, kinit chooses an appropriate principal name based on existing credential cache contents or the local username of the user invoking kinit. > kinit <PRINCIPAL> > kinit -kt <KEYTAB> <PRINCIPAL> klist lists the Kerberos principal and Kerberos tickets held in a credentials cache, or the keys held in a keytab file. > klist > klist -k <KEYTAB> kdestroy destroys the user\u2019s active Kerberos authorization tickets by overwriting and deleting the credentials cache that contains them. If the credentials cache is not specified, the default credentials cache is destroyed. ktutil invokes a command interface from which an administrator can read, write, or edit entries in a keytab. Some environment variables control KRB5 behavior, e.g.: KRB5_CONFIG , specifying the location of the Kerberos configuration file. The default is SYSCONFDIR/krb5.conf . KRB5CCNAME holds the name for the credentials cache file, default to /tmp/krb5cc_$(ud -u) . Can be used to switch context between users.","title":"kerberos"},{"location":"sw_dvpt/protocols/kerberos/#kerberos","text":"Kerberos (mirror) is a network authentication protocol. It provides a strong authentication for client/server applications by using secret-key cryptography. For ticket management at the user level some utilities are available: kinit obtains and caches an initial ticket-granting ticket for principal. If principal is absent, kinit chooses an appropriate principal name based on existing credential cache contents or the local username of the user invoking kinit. > kinit <PRINCIPAL> > kinit -kt <KEYTAB> <PRINCIPAL> klist lists the Kerberos principal and Kerberos tickets held in a credentials cache, or the keys held in a keytab file. > klist > klist -k <KEYTAB> kdestroy destroys the user\u2019s active Kerberos authorization tickets by overwriting and deleting the credentials cache that contains them. If the credentials cache is not specified, the default credentials cache is destroyed. ktutil invokes a command interface from which an administrator can read, write, or edit entries in a keytab. Some environment variables control KRB5 behavior, e.g.: KRB5_CONFIG , specifying the location of the Kerberos configuration file. The default is SYSCONFDIR/krb5.conf . KRB5CCNAME holds the name for the credentials cache file, default to /tmp/krb5cc_$(ud -u) . Can be used to switch context between users.","title":"Kerberos"},{"location":"sw_dvpt/protocols/ssh/","text":"SSH \u00b6 Seure shell is a protocol to safely administrying remote servers. Underlying entcryption techniques used: symmetrical encryption: type of entcryption where one key can be used to entcrypt messages to the opposite party, also to decrypt the messages received from the other participant. Also called shared secret or secret key encryption, typically one single key for all operations, or a pair of keys.","title":"SSH"},{"location":"sw_dvpt/protocols/ssh/#ssh","text":"Seure shell is a protocol to safely administrying remote servers. Underlying entcryption techniques used: symmetrical encryption: type of entcryption where one key can be used to entcrypt messages to the opposite party, also to decrypt the messages received from the other participant. Also called shared secret or secret key encryption, typically one single key for all operations, or a pair of keys.","title":"SSH"},{"location":"sw_dvpt/protocols/ssl/","text":"TLS / SSL \u00b6 Transport Layer Security (TLS), and its now-deprecated predecessor, Secure Sockets Layer (SSL), are cryptographic protocols designed to provide communications security over a computer network","title":"TLS / SSL"},{"location":"sw_dvpt/protocols/ssl/#tls-ssl","text":"Transport Layer Security (TLS), and its now-deprecated predecessor, Secure Sockets Layer (SSL), are cryptographic protocols designed to provide communications security over a computer network","title":"TLS / SSL"},{"location":"sw_dvpt/testing/","text":"Testing \u00b6 Altlassian CI/CD: types of SW testing Unit testing \u00b6 Repeatable, independant - isolated from the rest of the system - checking for proper operation of the smallest testable part of an application a module, function or procedure in procedural programming a class in object-oriented programming With parametrized tests, multiple tests can be executed with different inputs. Links \u00b6 tox <badge-doc Software testing for continuous delivery at Atlassian Testing standards and style guidelines on the gitlab project","title":"Intro"},{"location":"sw_dvpt/testing/#testing","text":"Altlassian CI/CD: types of SW testing","title":"Testing"},{"location":"sw_dvpt/testing/#unit-testing","text":"Repeatable, independant - isolated from the rest of the system - checking for proper operation of the smallest testable part of an application a module, function or procedure in procedural programming a class in object-oriented programming With parametrized tests, multiple tests can be executed with different inputs.","title":"Unit testing"},{"location":"sw_dvpt/testing/#links","text":"tox <badge-doc Software testing for continuous delivery at Atlassian Testing standards and style guidelines on the gitlab project","title":"Links"}]}